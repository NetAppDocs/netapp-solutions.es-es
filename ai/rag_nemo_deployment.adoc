---
sidebar: sidebar 
permalink: ai/rag_nemo_deployment.html 
keywords: RAG, Retrieval Augmented Generation, NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NeMo, NIM, NIMS, Hybrid, Hybrid Cloud, Hybrid Multicloud, NetApp ONTAP, FlexCache, SnapMirror, BlueXP 
summary: Enterprise RAG con NetApp - Instalación de microservicios Nemo 
---
= Puesta en marcha de microservicios de Nemo
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
En esta sección se describen las tareas que deben realizarse para implementar microservicios NVIDIA Nemo junto con el almacenamiento de NetApp. Los microservicios Nemo de NVIDIA se pondrán en funcionamiento mediante el link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/index.html["Operador de NVIDIA Enterprise RAG LLM"].



== Requisitos previos

Antes de realizar los pasos que se describen en esta sección, asumimos que ya ha realizado las siguientes tareas:

* Ya tiene un clúster de Kubernetes en funcionamiento y está ejecutando una versión de Kubernetes compatible con el operador NVIDIA Enterprise RAG LLM. Para ver una lista de las versiones de Kubernetes compatibles, consulte la link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/platform-support.html["Documentación del operador de RAG LLM."] Este clúster de Kubernetes puede estar en las instalaciones o en el cloud.
* Su clúster de Kubernetes incluye al menos tres GPU que son compatibles con el operador NVIDIA Enterprise RAG LLM. Para ver una lista de GPU compatibles, consulte la link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/platform-support.html["Documentación del operador de RAG LLM."]
* Ya ha instalado y configurado Astra Trident de NetApp en su clúster de Kubernetes. Si quiere más información sobre Astra Trident, consulte la link:https://docs.netapp.com/us-en/trident/index.html["Documentación de Astra Trident"]. Esta solución es compatible con cualquier dispositivo de almacenamiento físico NetApp, instancia definida por software o servicio cloud que sea compatible con Trident.




== Utilice el operador NVIDIA Enterprise RAG LLM para implementar microservicios NVIDIA Nemo

. Si el operador de GPU de NVIDIA aún no está instalado en su clúster de Kubernetes, instale el operador de GPU de NVIDIA siguiendo las instrucciones descritas en link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/install.html#install-the-nvidia-gpu-operator["Documentación del operador de RAG LLM."]
. Instale el operador NVIDIA Enterprise RAG LLM siguiendo las instrucciones descritas en link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/install.html#install-the-rag-llm-operator["Documentación del operador de RAG LLM."]
. Cree una canalización RAG mediante el operador NVIDIA Enterprise RAG LLM siguiendo las instrucciones descritas en link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/pipelines.html["Documentación del operador de RAG LLM."]
+
** Al especificar un StorageClass, asegúrese de especificar una StorageClass que utilice Astra Trident.
** De forma predeterminada, la canalización de RAG desplegará una nueva base de datos pgvector para servir como almacén de vectores/base de conocimientos para la implementación de RAG. Si desea utilizar una instancia existente de pgvector o Milvus en su lugar, siga las instrucciones descritas en link:https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/vector-database.html["Documentación del operador de RAG LLM."] Para obtener más información sobre cómo ejecutar una base de datos vectorial con NetApp, consulte la link:https://docs.netapp.com/us-en/netapp-solutions/ai/vector-database-solution-with-netapp.html["Documentación de la solución de base de datos vectorial de NetApp."]



