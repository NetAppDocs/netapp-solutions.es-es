---
sidebar: sidebar 
permalink: ai/aks-anf_load_day_15_in_dask_and_train_a_dask_cuml_random_forest_model.html 
keywords: dask, cuml, dataframe, criteo, click, logs, pandas, scikit, cudf 
summary: En esta sección se describe la carga de Criteo Click Logs Day 15 en Pandas y el entrenamiento de un modelo de bosque aleatorio scikit-Learn. En este ejemplo, realizamos la carga de DataFrame con DASK cuDF y entrenamos un modelo de bosque aleatorio en DASK cuML. 
---
= Cargar día 15 en DASK y entrenar un modelo de bosque aleatorio DASK cuML
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aks-anf_load_criteo_click_logs_day_15_in_pandas_and_train_a_scikit-learn_random_forest_model.html["Anterior: Cargar Criteo Click Logs Day 15 en Pandas y entrenar un cikit-aprender modelo de bosque aleatorio."]

[role="lead"]
De una manera similar a la sección anterior, cargue Criteo Click Logs Day 15 en Pandas y entrena un cikit-aprende el modelo de bosque aleatorio. En este ejemplo, realizamos la carga de DataFrame con DASK cuDF y entrenamos un modelo de bosque aleatorio en DASK cuML. Hemos comparado las diferencias en el tiempo de formación y el escalado en la sección link:aks-anf_training_time_comparison.html["“Comparación del tiempo de formación”."]



== criteo_dask_RF.ipynb

Este portátil importa `numpy`, `cuml`, y lo necesario `dask` bibliotecas, como se muestra en el siguiente ejemplo:

....
import cuml
from dask.distributed import Client, progress, wait
import dask_cudf
import numpy as np
import cudf
from cuml.dask.ensemble import RandomForestClassifier as cumlDaskRF
from cuml.dask.common import utils as dask_utils
....
Inicie cliente DASK().

....
client = Client()
....
Si su clúster está configurado correctamente, puede ver el estado de los nodos de trabajo.

....
client
workers = client.has_what().keys()
n_workers = len(workers)
n_streams = 8 # Performance optimization
....
En nuestro clúster AKS, se muestra el siguiente estado:

image:aks-anf_image12.png["Error: Falta la imagen gráfica"]

Tenga en cuenta que DASK emplea el paradigma de ejecución lenta: En lugar de ejecutar el código de procesamiento al instante, DASK crea en su lugar un gráfico cíclico dirigido (DAG) de ejecución. DAG contiene un conjunto de tareas y sus interacciones que cada trabajador necesita ejecutar. Este diseño significa que las tareas no se ejecutan hasta que el usuario le indique a DASK que las ejecute de una forma u otra. Con DASK tiene tres opciones principales:

* *Call comput() en un DataFrame.* esta llamada procesa todas las particiones y, a continuación, devuelve los resultados al planificador para la agregación final y conversión a cuDF DataFrame. Esta opción debe usarse con moderación y sólo en resultados muy reducidos a menos que el nodo del programador se quede sin memoria.
* *Call persistent() en un DataFrame.* esta llamada ejecuta el gráfico, pero, en lugar de devolver los resultados al nodo del planificador, los mantiene en la memoria a través del clúster para que el usuario pueda reutilizar estos resultados intermedios en la canalización sin necesidad de volver a ejecutar el mismo procesamiento.
* *Call head() en un DataFrame.* al igual que con cuDF, esta llamada devuelve 10 registros al nodo del planificador. Esta opción se puede utilizar para comprobar rápidamente si el DataFrame contiene el formato de salida deseado o si los propios registros tienen sentido, en función del procesamiento y cálculo.


Por lo tanto, a menos que el usuario llama a cualquiera de estas acciones, los trabajadores se sientan inactivos esperando que el programador inicie el procesamiento. Este paradigma de ejecución perezosa es común en marcos informáticos modernos en paralelo y distribuidos como Apache Spark.

En el siguiente párrafo se entrena un modelo de bosque aleatorio mediante el uso de DASK cuML para computación acelerada por GPU distribuida y se calcula la precisión de predicción del modelo.

....
Adsf
# Random Forest building parameters
n_streams = 8 # optimization
max_depth = 10
n_bins = 16
n_trees = 10
cuml_model = cumlDaskRF(max_depth=max_depth, n_estimators=n_trees, n_bins=n_bins, n_streams=n_streams, verbose=True, client=client)
cuml_model.fit(gdf_sliced_small, Y)
# Model prediction
pred_df = cuml_model.predict(gdf_test)
# calculate accuracy
cu_score = cuml.metrics.accuracy_score( test_y, pred_df )
....
link:aks-anf_monitor_dask_using_native_task_streams_dashboard.html["Siguiente: Supervisión de tarea mediante el panel de control de flujos de tareas nativo."]
