---
sidebar: sidebar 
permalink: ai/ai-dgx-superpod.html 
keywords: netapp, aipod, nvidia, dgx superpod, ai solution, design 
summary: Esta arquitectura verificada de NetApp describe el diseño de los componentes básicos de NVIDIA DGX SuperPOD con NetApp® BeeGFS. Esta solución es una plataforma de centro de datos de pila completa que se valida en un clúster de aceptación dedicado de NVIDIA. 
---
= NVIDIA DGX SuperPOD con NetApp: Guía de diseño
:allow-uri-read: 




== NVIDIA DGX SuperPOD con NetApp: Guía de diseño

image::NVIDIAlogo.png[200]

Amina Bennani, David Arnette y Sathish Thyagarajan, NetApp



== Resumen ejecutivo

Si bien la inteligencia artificial mejora la vida de los consumidores y ayuda a organizaciones de todos los sectores a innovar y hacer crecer sus negocios, lo cierto es que no deja de ser un DISRUPTOR TECNOLÓGICO. Con el fin de apoyar a las empresas, los DEPARTAMENTOS TECNOLÓGICOS trabajan a marchas forzadas para poner en marcha soluciones de computación de alto rendimiento (HPC) que satisfagan las exigentes demandas de las cargas de trabajo de la inteligencia artificial. A medida que la competencia por la inteligencia artificial se intensifica, la necesidad de contar con una solución que sea fácil de poner en marcha, escalar y gestionar es cada vez más apremiante.

Con NVIDIA DGX SuperPOD, la infraestructura de supercomputación es fácilmente accesible para cualquier organización y ofrece la potencia de cálculo extrema necesaria para solucionar incluso los problemas de IA más complejos. Para ayudar a los clientes a implementar hoy mismo a escala, esta solución lista para usar NVIDIA y NetApp elimina la complejidad y las conjeturas del diseño de la infraestructura y ofrece una solución completa y validada que incluye la mejor informática, redes, almacenamiento y software.



== Resumen del programa

NVIDIA DGX SuperPOD con sistemas NVIDIA DGX H100 y NVIDIA Base Command combina un diseño optimizado de computación de inteligencia artificial, estructura de red, almacenamiento, software y soporte. La arquitectura BeeGFS en NetApp se ha validado previamente en un clúster de aceptación dedicado de NVIDIA. La arquitectura más reciente amplía esa validación manteniendo el diseño demostrado a la vez que incorpora compatibilidad con el hardware más reciente de NVIDIA.



== Descripción general de la solución

NVIDIA DGX SuperPOD es una plataforma de infraestructura de centro de datos de IA que se ofrece como solución lista para usar para QUE LOS DEPARTAMENTOS DE tecnología den soporte a las cargas de trabajo de IA más complejas que enfrentan las empresas actuales. Simplifica la puesta en marcha y la gestión a la vez que proporciona una escalabilidad prácticamente ilimitada del rendimiento y la capacidad. En otras palabras, DGX SuperPOD le permite centrarse en la información en lugar de en la infraestructura.
Con las cabinas all-flash EF600 de NetApp como base de un NVIDIA DGX SuperPOD, los clientes obtienen una solución ágil de inteligencia artificial que se escala sin problemas. La flexibilidad y la escalabilidad de esta solución le permiten dar cabida y adaptarse a la evolución de las cargas de trabajo, y la convierten en una base sólida para satisfacer las necesidades de almacenamiento actuales y futuras. Los elementos básicos de almacenamiento modular permiten un enfoque granular del crecimiento y se escala de forma fluida de terabytes a petabytes. Al aumentar el número de elementos básicos de almacenamiento, los clientes pueden escalar verticalmente el rendimiento y la capacidad del sistema de archivos, lo que permite a la solución gestionar las cargas de trabajo más extremas de forma sencilla.



=== Tecnología de soluciones

* NVIDIA DGX SuperPOD con los sistemas DGX H100 de NVIDIA aprovecha los sistemas DGX H100 con almacenamiento compartido validado externamente:
+
** Cada unidad escalable (SU) de DGX SuperPOD consta de 32 sistemas DGX H100 y es capaz de 640 petaflops de rendimiento de IA con precisión de FP8 PB. Normalmente contiene al menos dos elementos básicos BeeGFS de NetApp, en función de los requisitos de rendimiento y capacidad para una instalación concreta.




_Una vista de alto nivel de la solución_ image::EF_SuperPOD_HighLevel.png[]

* Los elementos básicos de BeeGFS de NetApp constan de dos cabinas EF600 de NetApp y dos servidores x86:
+
** Con las cabinas all-flash EF600 de NetApp como base de NVIDIA DGX SuperPOD, los clientes obtienen una base de almacenamiento fiable respaldada por un tiempo de actividad de seis 9s ms.
** La capa del sistema de archivos entre el sistema NetApp EF600 y el NVIDIA DGX H100 es el sistema de archivos paralelo BeeGFS. BeeGFS fue creado en el Centro Fraunhofer de Computación de Alto Rendimiento en Alemania para dar solución a los puntos débiles de los sistemas de archivos paralelos heredados. El resultado es un sistema de archivos con una arquitectura moderna de espacio del usuario que ahora desarrolla y distribuye ThinkParQ, y al que recurren muchos entornos de supercomputación.
** El soporte de NetApp para BeeGFS alinea la excelente organización de soporte de NetApp con los requisitos de rendimiento y tiempo de actividad del cliente. Los clientes obtienen acceso a recursos de soporte superiores, acceso previo a lanzamientos de BeeGFS y acceso a funciones empresariales selectas de BeeGFS, como el cumplimiento de cuotas y alta disponibilidad.


* La combinación de los elementos básicos NVIDIA SuperPOD SUS y BeeGFS de NetApp proporciona una solución de IA ágil en la que la computación o el almacenamiento se pueden escalar de forma fácil y fluida.


_NetApp BeeGFS Building block_ image::ef_SuperPOD_buildingblock.png[]



=== Resumen de casos de uso

Esta solución se aplica a los siguientes casos de uso:

* Inteligencia artificial (AI) incluido el aprendizaje automático (ML), aprendizaje profundo (DL), procesamiento del lenguaje natural (NLP), conocimiento del lenguaje natural (NLU) y g
IA generativa (GenAI).
* Formación de IA a escala media y grande
* Modelos de visión computarizada, habla, audio y lenguaje
* HPC que incluye aplicaciones aceleradas mediante la interfaz de paso de mensajes (MPI) y otras técnicas informáticas distribuidas
* Cargas de trabajo de aplicaciones que se caracterizan por las siguientes características:
+
** Leer o escribir en archivos de más de 1 GB
** Leyendo o escribiendo en el mismo archivo por varios clientes (10s, 100s y 1000s).


* Conjuntos de datos de varios terabytes o varios petabytes
* Entornos que requieren un único espacio de nombres de almacenamiento optimizable para una combinación de archivos grandes y pequeños




== Requisitos tecnológicos

En esta sección se tratan los requisitos tecnológicos de la solución NVIDIA DGX SuperPOD con NetApp.



=== Requisitos de hardware

La tabla 1 que aparece a continuación enumera los componentes de hardware necesarios para implementar la solución para una única SU. El ajuste de tamaño de la solución comienza con 32 sistemas NVIDIA DGX H100 y dos o tres elementos básicos BeeGFS de NetApp.
Un único elemento básico BeeGFS de NetApp consta de dos cabinas EF600 de NetApp y dos servidores x86. Los clientes pueden agregar elementos básicos adicionales a medida que aumenta el tamaño de la puesta en marcha. Para obtener más información, consulte https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-h100/latest/dgx-superpod-components.html["Arquitectura de referencia NVIDIA DGX H100 SuperPOD"^] y.. https://fieldportal.netapp.com/content/1792438["NVA-1164-DESIGN: BeeGFS en diseño NVA de NetApp"^].

|===
| Hardware subyacente | Cantidad 


| DGX H100 DE NVIDIA | 32 


| Switches NVIDIA Quantum QM9700 | 8 hoja, 4 espina 


| Elementos básicos BeeGFS de NetApp | 3 
|===


=== Requisitos de software

En la tabla 2 que aparece a continuación se enumeran los componentes de software necesarios para implementar la solución. Los componentes que se usan en cualquier implementación particular de la solución pueden variar en función de las necesidades del cliente.

|===
| De NetApp 


| Pila de software NVIDIA DGX 


| Administrador de comandos base de NVIDIA 


| Sistema de archivos paralelo BeeGFS de ThinkParQ 
|===


== Verificación de la solución

NVIDIA DGX SuperPOD con NetApp ha sido validado en un clúster de aceptación dedicado de NVIDIA empleando los elementos básicos BeeGFS de NetApp. Los criterios de aceptación se basaron en una serie de pruebas de aplicación, rendimiento y estrés realizadas por NVIDIA. Para obtener más información, consulte https://nvidia-gpugenius.highspot.com/viewer/62915e2ef093f1a97b2d1fe6?iid=62913b14052a903cff46d054&source=email.62915e2ef093f1a97b2d1fe7.4["NVIDIA DGX SuperPOD: Arquitectura de referencia de NetApp EF600 y BeeGFS"^].



== Conclusión

NetApp y NVIDIA llevan mucho tiempo colaborando para ofrecer una cartera de soluciones de inteligencia artificial al mercado. NVIDIA DGX SuperPOD con la cabina all-flash EF600 de NetApp es una solución demostrada y validada que los clientes pueden poner en marcha con total confianza. Su arquitectura, totalmente integrada y lista para usar, acaba con los riesgos de la puesta en marcha y permite que cualquiera pueda ganar terreno en el liderazgo de la IA.



== Dónde encontrar información adicional

Si quiere más información sobre el contenido de este documento, consulte los siguientes documentos o sitios web:
NVA-1164-DESIGN: BeeGFS en diseño NVA de NetApp
https://www.netapp.com/media/71123-nva-1164-design.pdf[]
NVA-1164-DEPLOY: Puesta en marcha de NVA de BeeGFS en NetApp
https://www.netapp.com/media/71124-nva-1164-deploy.pdf[]
Arquitectura de referencia de NVIDIA DGX SuperPOD
https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-h100/latest/index.html#[]
Guía de referencia de diseño del centro de datos NVIDIA DGX SuperPOD
https://docs.nvidia.com/nvidia-dgx-superpod-data-center-design-dgx-h100.pdf[]
NVIDIA DGX SuperPOD: NetApp EF600 y BeeGFS
https://nvidiagpugenius.highspot.com/viewer/62915e2ef093f1a97b2d1fe6?iid=62913b14052a903cff46d054&source=email.62915e2ef093f1a97b2d1fe7.4[]
