---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-hadoop-data-protection-and-netapp.html 
keywords: distcp, copy, backup workflow, hdfs, mapreduce 
summary: Hadoop DistCp es una herramienta nativa que se usa para copiar dentro de los clústeres y crear clústeres de gran tamaño. El proceso básico de Hadoop DistCp es un flujo de trabajo de backup típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde un origen de HDFS en un destino correspondiente. 
---
= Protección de datos para Hadoop y NetApp
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
Hadoop DistCp es una herramienta nativa que se usa para copiar dentro de los clústeres y crear clústeres de gran tamaño. El proceso básico de Hadoop DistCp que se muestra en la siguiente figura es un flujo de trabajo de backup típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde un origen de HDFS a un destino correspondiente.

El acceso directo NFS de NetApp permite a los clientes establecer NFS como destino para la herramienta Hadoop DistCp para copiar los datos desde el origen HDFS en un recurso compartido de NFS a través de MapReduce. El acceso directo para NFS de NetApp actúa como controlador NFS de la herramienta DistCp.

image::hdcs-sh-image4.png[hdcs sh image4]
