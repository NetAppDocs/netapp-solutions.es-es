---
sidebar: sidebar 
permalink: data-analytics/bda-ai-data-mover-solution-for-ai.html 
keywords: data mover, ai, hadoop, nipam, nfs, azure, 
summary: La solución de movimiento de datos para IA se basa en las necesidades del cliente de procesar datos de Hadoop desde operaciones de IA. NetApp mueve datos de HDFS a NFS mediante EL COMANDO NIPAM. En un caso de uso, el cliente necesitaba mover datos a NFS en las instalaciones y otro cliente necesitaba mover datos de Windows Azure Storage Blob a Cloud Volumes Service para procesar los datos de las instancias de cloud de la GPU en el cloud. 
---
= Solución de movimiento de datos para IA
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
La solución de movimiento de datos para IA se basa en las necesidades del cliente de procesar datos de Hadoop desde operaciones de IA. NetApp mueve datos de HDFS a NFS mediante EL COMANDO NIPAM. En un caso de uso, el cliente necesitaba mover datos a NFS en las instalaciones y otro cliente necesitaba mover datos de Windows Azure Storage Blob a Cloud Volumes Service para procesar los datos de las instancias de cloud de la GPU en el cloud.

El siguiente diagrama muestra los detalles de la solución del transportador de datos.

image:bda-ai-image4.png[""]

Para crear la solución de movimiento de datos se requieren los siguientes pasos:

. SAN de ONTAP proporciona HDFS y NAS proporciona el volumen NFS a través DE NIPAM al clúster de lago de datos de producción.
. Los datos del cliente se encuentran en HDFS y NFS. Los datos de NFS pueden ser datos de producción de otras aplicaciones que se usan para el análisis de Big Data y operaciones de IA.
. La tecnología FlexClone de NetApp crea un clon del volumen NFS de producción y lo aprovisiona al clúster de IA en las instalaciones.
. Los datos de un LUN DE SAN HDFS se copian en un volumen NFS con NIPAM y el `hadoop distcp` comando. NIPAM utiliza el ancho de banda de varias interfaces de red para transferir datos. Este proceso reduce el tiempo de copia de datos para poder transferir más datos.
. Ambos volúmenes NFS se aprovisionan en el clúster de IA para operaciones de IA.
. Para procesar datos NFS en las instalaciones con GPU en el cloud, los volúmenes NFS se duplican en el almacenamiento privado de NetApp (NPS) con la tecnología SnapMirror de NetApp y se montan en proveedores de servicios cloud para GPU.
. El cliente desea procesar datos en servicios EC2/EMR, HDInsight o DataProc en GPU de proveedores de servicios cloud. El transportador de datos de Hadoop mueve los datos de servicios de Hadoop a Cloud Volumes Services con NIPAM y el `hadoop distcp` comando.
. Los datos de Cloud Volumes Service se aprovisionan para IA a través del protocolo NFS. Los datos que se procesan mediante IA se pueden enviar en una ubicación local para análisis de Big Data, además del clúster de NVIDIA a través DE NIPAM, SnapMirror y NPS.


En esta situación, el cliente tiene grandes datos con recuento de archivos en el sistema NAS en una ubicación remota necesaria para procesar IA en la controladora de almacenamiento de NetApp en las instalaciones. En este caso, es mejor utilizar la herramienta de migración XCP para migrar los datos a una velocidad más rápida.

El cliente de caso de uso híbrido puede usar la copia y sincronización de BlueXP para migrar datos en las instalaciones de NFS, CIFS y S3 a la nube y viceversa para el procesamiento de IA usando GPU como las de un clúster NVIDIA. Tanto la copia y sincronización de BlueXP como la herramienta de migración XCP se utilizan para la migración de datos de NFS a NFS de NetApp ONTAP.
