<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="6dab61143f0fe37930fbd783e5c57c81" category="paragraph"><block ref="6dab61143f0fe37930fbd783e5c57c81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="816445ad7ba016a8c0be293c985f068b" category="list-text">Para bases de datos de gran tamaño, la distribución de volúmenes recomendada es varios volúmenes: Uno para datos de Oracle y un archivo de control duplicado, y otro para el registro activo de Oracle, el registro archivado y el archivo de control. NetApp recomienda encarecidamente asignar un volumen para el binario de Oracle en lugar de la unidad local para poder reubicar la base de datos en un nuevo host y restaurarlos rápidamente.</block>
  <block id="955db4ecf8716abf17a3ea3f8e113671" category="inline-image-macro">Esta imagen muestra dos bases de datos con dos volúmenes cada una. El primer volumen contiene archivos de datos, mientras que el segundo volumen de cada base de datos contiene registros de recuperación, registros de archivos y archivos de control. Todo dentro de un único pool de capacidad.</block>
  <block id="7432b939dcc290776a34b2e9610a2775" category="paragraph"><block ref="7432b939dcc290776a34b2e9610a2775" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">Configuración de NFS</block>
  <block id="efeaafaa286e164985a0c325f0727cf1" category="paragraph">Linux, el sistema operativo más común, incluye funcionalidades NFS nativas. Oracle ofrece un cliente NFS directo (dNFS) integrado de forma nativa en Oracle. Oracle dNFS omite la caché del sistema operativo y permite el procesamiento en paralelo para mejorar el rendimiento de las bases de datos. Oracle tiene compatibilidad con NFSv3 durante más de 20 años y NFSv4 es compatible con Oracle 12.1.0.2 y versiones posteriores.</block>
  <block id="be5ef2ba2540e077db09ca784b1ac18f" category="paragraph">Al usar dNFS (disponible desde Oracle 11g), una base de datos de Oracle que se ejecuta en una máquina virtual de Azure puede generar una cantidad significativamente superior de I/o que el cliente NFS nativo. La puesta en marcha automatizada de Oracle mediante el kit de herramientas de automatización de NetApp configura automáticamente dNFS en NFSv3.</block>
  <block id="632bf0b812e05925eff22d7d0a7677c2" category="paragraph">El siguiente diagrama muestra el punto de referencia SLOB en Azure NetApp Files with Oracle dNFS.</block>
  <block id="08826656fd88155bdfaebbb292320e33" category="inline-image-macro">Este gráfico muestra de forma espectacular que dNFS mejora la latencia de archivos secuenciales de la base de datos (ms) por encima de KNFS.</block>
  <block id="258bafba486e8ac35578ed4c5fff8ab1" category="paragraph"><block ref="258bafba486e8ac35578ed4c5fff8ab1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">Otros factores a considerar:</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">Las tablas de ranuras TCP son el equivalente en NFS de la profundidad de cola del adaptador de host-bus (HBA). En estas tablas se controla el número de operaciones de NFS que pueden extraordinarias a la vez. El valor predeterminado suele ser 16, que es demasiado bajo para un rendimiento óptimo. El problema opuesto ocurre en los kernels más nuevos de Linux, que pueden aumentar automáticamente el límite de la tabla de ranuras TCP a un nivel que sature el servidor NFS con solicitudes.</block>
  <block id="24019b0d54b5da3a46b400c6a6dfee77" category="paragraph">Para obtener un rendimiento óptimo y evitar problemas de rendimiento, ajuste los parámetros del kernel que controlan las tablas de ranuras TCP a 128.</block>
  <block id="754e164c2de7ed1f02667d5f74297a0e" category="list-text">En la siguiente tabla, se ofrecen opciones de montaje de NFS recomendadas para una única instancia de NFSv3 de Linux.</block>
  <block id="fa7abb28d1b83f9ee23d95aff1d3123b" category="inline-image-macro">En esta tabla, se muestran las opciones de montaje NFS detalladas para los siguientes tipos de archivos, archivos de control, archivos de datos, registros de recuperación, ORACLE_HOME, Y ORACLE_BASE.</block>
  <block id="082aad17dee7d03a3d502a422c1a8c53" category="paragraph"><block ref="082aad17dee7d03a3d502a422c1a8c53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">Antes de utilizar dNFS, compruebe que están instalados los parches descritos en Oracle Doc 1495104.1. A partir de Oracle 12c, DNFS incluye compatibilidad para NFSv3, NFSv4 y NFSv4.1. Las políticas de soporte de NetApp cubren v3 y v4 para todos los clientes; sin embargo, en el momento de la escritura, NFSv4.1 no es compatible para su uso con Oracle dNFS.</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">Siguiente: Procedimientos de implantación.</block>
  <block id="b71b592b003a6232eebe484a1736be7a" category="paragraph"><block ref="b71b592b003a6232eebe484a1736be7a" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">Ciertos requisitos previos deben configurarse tanto en las instalaciones como en el cloud antes de ejecutar las cargas de trabajo de las bases de datos del cloud híbrido. En la siguiente sección se proporciona un resumen de alto nivel de este proceso, y los siguientes enlaces proporcionan información adicional sobre la configuración necesaria del sistema.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">Configuración de requisitos previos</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">Anterior: Requisitos de las soluciones.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">En el entorno local</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="list-text">Instalación y configuración de SnapCenter</block>
  <block id="df3fb602185c77a88bab186791d02636" category="list-text">Configuración del almacenamiento del servidor de bases de datos local</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="list-text">Requisitos de licencia</block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="list-text">Redes y seguridad</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">Cloud público</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">Un inicio de sesión en Cloud Central de NetApp</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Acceso a la red desde un explorador Web hasta varios puntos finales</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">Una ubicación de red para un conector</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">Permisos del proveedor de cloud</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">Creación de redes para servicios individuales</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">Consideraciones importantes:</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">¿Dónde se debe poner en marcha Cloud Manager Connector?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Ajuste de tamaño y arquitectura de Cloud Volume ONTAP</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">¿Nodo único o alta disponibilidad?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">Los siguientes enlaces proporcionan más información:</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">En el entorno local</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">Cloud público</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">Siguiente: Requisitos previos en las instalaciones.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">En esta sección se ofrecen detalles sobre cómo se gestionan los sistemas de almacenamiento personalizados de AWS para las bases de datos de Oracle mediante la interfaz de usuario de SnapCenter como complemento para la interfaz de usuario de la consola de AWS RDS.</block>
  <block id="d0dfaca5f0573d672a0f4dc66997c002" category="doc">Gestión de bases de datos Oracle EC2 y FSX</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">Anterior: Procedimientos de implantación.</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">Además de la consola de gestión de AWS EC2 y FSX, el nodo de control de Ansible y la herramienta de interfaz de usuario de SnapCenter se ponen en marcha para la gestión de bases de datos en este entorno de Oracle.</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Se puede usar un nodo de control de Ansible para gestionar la configuración de un entorno de Oracle, con actualizaciones paralelas que mantienen las instancias principales y en espera sincronizadas con las actualizaciones del kernel o de las revisiones. La conmutación al nodo de respaldo, la resincronización y la conmutación tras recuperación se pueden automatizar con el kit de herramientas de automatización de NetApp para archivar la disponibilidad y la recuperación rápidas de aplicaciones con Ansible. Algunas tareas de administración de bases de datos repetibles se pueden ejecutar utilizando un libro de aplicaciones para reducir los errores humanos.</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">Información general sobre el plugin de SnapCenter para bases de datos de Oracle</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">La herramienta de interfaz de usuario de SnapCenter puede realizar backup de snapshot de base de datos, recuperación de un momento específico, clonado de base de datos, etc. con el complemento de SnapCenter para bases de datos de Oracle. Para obtener más información sobre las características del complemento Oracle, consulte <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>.</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">En las siguientes secciones se ofrecen detalles sobre cómo se cumplen las funciones clave de la gestión de bases de datos de Oracle con la interfaz de usuario de SnapCenter:</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">Backups de snapshots de base de datos</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">Restauración a un momento específico de la base de datos</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">Creación de clones de base de datos</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">La clonado de bases de datos crea una réplica de una base de datos primaria en un host EC2 independiente para la recuperación de datos en caso de errores o daños en los datos lógicos, y los clones también pueden utilizarse para pruebas de aplicaciones, depuración, validación de parches, etc.</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">Realizar una instantánea</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">Se realiza una copia de seguridad periódica de una base de datos EC2/FSX a intervalos configurados por el usuario. Un usuario también puede realizar un backup de snapshot único en cualquier momento. Esto se aplica tanto a backups Snapshot de base de datos completa como a backups Snapshot de solo registros de archivo.</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">Haciendo una instantánea completa de la base de datos</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">Una instantánea completa de base de datos incluye todos los archivos de Oracle, incluidos los archivos de datos, los archivos de control y los archivos de registro de archivo.</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">Inicie sesión en la interfaz de usuario de SnapCenter y haga clic en Resources en el menú que aparece a la izquierda. En el menú desplegable View, cambie a la vista Resource Group.</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">Haga clic en el nombre completo del recurso de backup y luego en el icono Backup Now para iniciar un backup Add-hoc.</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">Haga clic en Backup y, a continuación, confirme el backup para iniciar un backup completo de la base de datos.</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">En la vista Resource de la base de datos, abra la página Database Managed Backup Copies para comprobar que el backup inicial se ha realizado correctamente. Un backup de base de datos completo crea dos copias de Snapshot: Una para el volumen de datos y otra para el volumen de registro.</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">Tomar una instantánea del registro de archivo</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">Solo se toma una snapshot de registro de archivos para el volumen de registro de archivos de Oracle.</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">Inicie sesión en la interfaz de usuario de SnapCenter y haga clic en la pestaña Resources en la barra de menús de la izquierda. En el menú desplegable View, cambie a la vista Resource Group.</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">Haga clic en el nombre del recurso de backup de registro y, a continuación, en el icono Backup Now para iniciar un backup Add-hoc para los registros de archivos.</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">Haga clic en Backup y, a continuación, confirme el backup para iniciar el backup de los registros de archivos.</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">En la vista Resource de la base de datos, abra la página Database Managed Backup Copies para verificar que el backup de registro de archivo único se haya completado correctamente. Un backup de registros de archivos crea una copia de Snapshot para el volumen de registro.</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">Restauración a un momento específico</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">La restauración basada en SnapCenter a un momento específico se ejecuta en el mismo host de instancia de EC2. Complete los siguientes pasos para realizar la restauración:</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">En la pestaña SnapCenter Resources &gt; Database, haga clic en el nombre de la base de datos para abrir el backup de la base de datos.</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">Seleccione la copia de backup de la base de datos y el momento específico que desea restaurar. Marque también el número SCN correspondiente para el punto en tiempo. La restauración a un momento específico se puede ejecutar mediante el tiempo o el SCN.</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">Destaque la copia de Snapshot del volumen de registro y haga clic en el botón Mount para montar el volumen.</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">Seleccione la instancia primaria de EC2 para montar el volumen de registro.</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">Compruebe que el trabajo de montaje se haya completado correctamente. Compruebe también el host de la instancia de EC2 para ver el volumen de registro montado y la ruta de punto de montaje.</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">Copie los registros de archivos del volumen de registro montado en el directorio actual de registro de archivos.</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">Vuelva a la página SnapCenter Resource tab &gt; backup de base de datos, destaque la copia de Snapshot de datos y haga clic en el botón Restore para iniciar el flujo de trabajo de restauración de base de datos.</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">Marque "All Datafiles" y "Change database state if needed for restore and recovery", y haga clic en Next.</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">Elija el alcance de recuperación que desee mediante SCN o Time. En lugar de copiar los registros de archivo montados en el directorio de registro actual como se muestra en el paso 6, la ruta de acceso de registro de archivo montada puede aparecer en "Specify external archive log locations" para su recuperación.</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">Especifique un script previo opcional para ejecutarlo si es necesario.</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">Especifique un script posterior opcional para ejecutarlo si es necesario. Compruebe la base de datos abierta después de la recuperación.</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">Indique un servidor SMTP y una dirección de correo electrónico si se necesita una notificación de trabajo.</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">Restaure el resumen de trabajos. Haga clic en Finalizar para iniciar el trabajo de restauración.</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">Validar la restauración desde SnapCenter.</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">Validar la restauración desde el host de la instancia de EC2.</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">Para desmontar el volumen de registro de restauración, invierta los pasos del paso 4.</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">Creación de un clon de base de datos</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">En la siguiente sección se muestra cómo utilizar el flujo de trabajo del clon de SnapCenter para crear un clon de la base de datos desde una base de datos principal a una instancia de EC2 en espera.</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">Haga un backup completo de Snapshot de la base de datos primaria de SnapCenter mediante el grupo de recursos de backup completo.</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">En la ficha recurso de SnapCenter &gt; Vista base de datos, abra la página Gestión de copias de seguridad de la base de datos principal a partir de la cual se creará la réplica.</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">Monte la snapshot del volumen de registro tomada en el paso 4 en el host de la instancia de EC2 en espera.</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">Destaque la copia snapshot que se va a clonar para la réplica y haga clic en el botón Clonar para iniciar el procedimiento de clonación.</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">Cambie el nombre de la copia de réplica para que sea diferente del nombre de la base de datos principal. Haga clic en Siguiente.</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">Cambie el host del clon al host EC2 en espera, acepte el nombre predeterminado y haga clic en Siguiente.</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Cambie la configuración inicial de Oracle para que coincida con la configurada para el host de destino del servidor Oracle y haga clic en Siguiente.</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">Especifique un punto de recuperación mediante Time o el SCN y la ruta de registro de archivos montada.</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">Envíe la configuración de correo electrónico SMTP si es necesario.</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">Clone el resumen de trabajos y haga clic en Finish para iniciar el trabajo de clonado.</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">Revise el registro de trabajos de clonado para validar el clon de la réplica.</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">La base de datos clonada se registra de inmediato en SnapCenter.</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Desactive el modo de registro de archivo de Oracle. Inicie sesión en la instancia de EC2 como usuario de oracle y ejecute el siguiente comando:</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">En lugar de ello, las copias de backup primarias de Oracle también se puede crear un clon a partir de copias de backup secundarias replicadas en el clúster FSX de destino con los mismos procedimientos.</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">Conmutación al respaldo DE ALTA DISPONIBILIDAD para modo de espera y resincronización</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">El clúster de alta disponibilidad de Oracle en espera proporciona una alta disponibilidad en caso de fallo en el sitio principal, ya sea en la capa informática o en la capa de almacenamiento. Un beneficio significativo de la solución es que un usuario puede probar y validar la infraestructura en cualquier momento o con cualquier frecuencia. La conmutación por error puede simularse por el usuario o desencadenarse por un fallo real. Los procesos de conmutación por error son idénticos y se pueden automatizar para una rápida recuperación de aplicaciones.</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">Consulte la siguiente lista de procedimientos de conmutación por error:</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">En caso de una conmutación por error simulada, ejecute un backup de snapshot de registro para vaciar las transacciones más recientes en el sitio en espera, como se muestra en la sección <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>. Para una recuperación tras fallos activada por un error real, los últimos datos recuperables se replican en el sitio en espera con el último backup de volumen de registro programado correcto.</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">Rompa la SnapMirror entre el clúster FSX principal y el en espera.</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">Montar los volúmenes de la base de datos en espera replicados en el host de la instancia de EC2 en espera.</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">Vuelva a enlazar el binario de Oracle si se utiliza el binario de Oracle replicado para la recuperación de Oracle.</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">Recupere la base de datos Oracle en espera en el último registro de archivo disponible.</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">Abra la base de datos Oracle en espera para acceder a aplicaciones y usuarios.</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">En el caso de un fallo real del sitio primario, la base de datos de Oracle en espera ahora asume la función del nuevo sitio principal y los volúmenes de base de datos se pueden usar para reconstruir la ubicación primaria en la que se ha producido el fallo como un nuevo sitio en espera con el método SnapMirror inverso.</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">En caso de un fallo simulado en el centro principal para realizar pruebas o validación, cierre la base de datos Oracle en espera después de finalizar los ejercicios de prueba. A continuación, desmonte los volúmenes de la base de datos en espera del host de la instancia de EC2 en espera y vuelva a sincronizar la replicación del sitio principal con el sitio en espera.</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">Puede llevar a cabo estos procedimientos con el kit de herramientas de automatización de NetApp, que puede descargarse en el sitio público de GitHub de NetApp.</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">Lea detenidamente la instrucción README antes de intentar la configuración y la prueba de conmutación por error.</block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">Siguiente: Migración de bases de datos.</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">La herramienta NetApp SnapCenter utiliza el control de acceso basado en roles (RBAC) para gestionar el acceso a recursos de usuario y las concesiones de permisos, y la instalación de SnapCenter crea roles predefinidos. También puede crear funciones personalizadas según sus necesidades o aplicaciones.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">Introducción a las instalaciones</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">Anterior: Introducción.</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. Configurar el usuario administrador de la base de datos en SnapCenter</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">La herramienta NetApp SnapCenter utiliza el control de acceso basado en roles (RBAC) para gestionar el acceso a recursos de usuario y permisos, y la instalación de SnapCenter crea roles predefinidos. También puede crear funciones personalizadas según sus necesidades o aplicaciones. Tiene sentido tener un ID de usuario administrador dedicado para cada plataforma de base de datos compatible con SnapCenter para backup, restauración y/o recuperación ante desastres de bases de datos. También es posible usar un ID único para gestionar todas las bases de datos. En nuestros casos de prueba y demostración, creamos un usuario de administrador dedicado para Oracle y SQL Server, respectivamente.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">Ciertos recursos de SnapCenter solo pueden aprovisionarse con el rol de administrador de SnapCenter. Los recursos se pueden asignar a otros ID de usuario para tener acceso.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">En un entorno SnapCenter local preinstalado y configurado, es posible que las siguientes tareas ya se hayan completado. De lo contrario, los siguientes pasos crean un usuario administrador de base de datos:</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Agregue el usuario admin a Windows Active Directory.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">Inicie sesión en SnapCenter con un ID que cuenta con el rol de administrador de SnapCenter.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">Vaya a la ficha Access en Configuración y usuarios y haga clic en Agregar para agregar un nuevo usuario. El nuevo ID de usuario está vinculado al usuario administrador creado en Windows Active Directory en el paso 1. . Asigne el rol adecuado al usuario según sea necesario. Asigne recursos al usuario administrador según corresponda.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. Requisitos previos de instalación del complemento SnapCenter</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter realiza funciones de backup, restauración, clonado y otras mediante un agente de complementos que se ejecuta en los hosts de la base de datos. Se conecta al host de la base de datos y a la base de datos mediante credenciales configuradas en la pestaña Setting and Credentials para la instalación del plugin y otras funciones de administración. Existen requisitos de privilegios específicos según el tipo de host de destino, como Linux o Windows, así como el tipo de base de datos.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">Las credenciales de los hosts DE la BASE de DATOS deben configurarse antes de instalar el plugin de SnapCenter. Generalmente, desea utilizar cuentas de usuario de administrador en el host de la base de datos como credenciales de conexión de host para la instalación del plugin. También puede otorgar el mismo ID de usuario para el acceso a la base de datos mediante la autenticación basada en el sistema operativo. Por otro lado, también puede utilizar la autenticación de la base de datos con distintos ID de usuario de la base de datos para el acceso a la administración de la base de datos. Si decide utilizar la autenticación basada en el sistema operativo, debe concederse acceso a la base de datos al ID de usuario administrador del sistema operativo. Para la instalación de SQL Server basada en dominios de Windows, se puede utilizar una cuenta de administrador de dominio para administrar todos los servidores SQL Server dentro del dominio.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">Host Windows para SQL Server:</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">Si utiliza credenciales de Windows para la autenticación, debe configurar la credencial para poder instalar plugins.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">Si utiliza una instancia de SQL Server para la autenticación, debe añadir las credenciales después de instalar plugins.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">Si habilitó la autenticación por SQL durante la configuración de las credenciales, la instancia o la base de datos detectadas se mostrarán con un icono de candado rojo. Si se muestra el icono de candado, es necesario especificar las credenciales de la instancia o la base de datos para añadir correctamente la instancia o la base de datos al grupo de recursos.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">Debe asignar la credencial a un usuario de RBAC sin acceso de administrador del sistema cuando se cumplan las siguientes condiciones:</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">La credencial se asigna a una instancia de SQL.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">La instancia o el host de SQL se asignan a un usuario de RBAC.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">El usuario administrador de la base de datos de RBAC debe tener privilegios de backup y grupo de recursos.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Host UNIX para Oracle:</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">Debe haber habilitado la conexión SSH basada en contraseña para el usuario raíz o no raíz editando sshd.conf y reiniciando el servicio sshd. La autenticación SSH basada en contraseña en la instancia de AWS está desactivada de forma predeterminada.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">Configure los privilegios sudo para el usuario que no sea raíz para instalar e iniciar el proceso del plugin. Después de instalar el plugin, los procesos se ejecutan como un usuario root efectivo.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">Cree credenciales con el modo de autenticación de Linux para el usuario de instalación.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Debe instalar Java 1.8.x (64 bits) en el host Linux.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">La instalación del complemento Oracle Database también instala el complemento SnapCenter para Unix.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. Instalación del complemento de host de SnapCenter</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">Antes de intentar instalar los plugins de SnapCenter en instancias de servidor de la base de datos en la nube, asegúrese de que todos los pasos de configuración se han completado como se indica en la sección pertinente de la nube para la implementación de la instancia de computación.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">Los siguientes pasos ilustran cómo se añade un host de base de datos a SnapCenter mientras se instala un plugin de SnapCenter en el host. El procedimiento aplica a añadir hosts en las instalaciones y hosts de cloud. La siguiente demostración añade un host de Windows o Linux que reside en AWS.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">Configuración de los ajustes globales de VMware de SnapCenter</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">Vaya a Configuración &gt; Configuración global. Seleccione "VMs have iSCSI direct attached disks or NFS for all the hosts" en Hypervisor Settings y haga clic en Update.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Añada el host de Windows y la instalación del plugin en el host</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">Inicie sesión en SnapCenter con un ID de usuario con privilegios de administrador de SnapCenter.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">Haga clic en la ficha hosts del menú de la izquierda y, a continuación, haga clic en Agregar para abrir el flujo de trabajo Agregar host.</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">Elija Windows para Tipo de host; el nombre de host puede ser un nombre de host o una dirección IP. El nombre de host debe solucionarse con la dirección IP de host correcta desde el host SnapCenter. Seleccione las credenciales de host creadas en el paso 2. Elija Microsoft Windows y Microsoft SQL Server como los paquetes de complementos que se van a instalar.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Una vez instalado el plugin en un host de Windows, su estado general se muestra como "Configure log directory".</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">Haga clic en Nombre de host para abrir la configuración del directorio de registro de SQL Server.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">Haga clic en "Configure log directory" para abrir "Configure Plug-in for SQL Server".</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">Haga clic en examinar para detectar el almacenamiento de NetApp de manera que se pueda configurar un directorio de registro; SnapCenter utiliza este directorio de registro para revertir los archivos de registro de transacciones de SQL Server. A continuación, haga clic en Guardar.</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">Para que el almacenamiento de NetApp aprovisionado a un host de base de datos se detecte, es necesario añadir el almacenamiento (local o CVO) a SnapCenter, como se muestra en el paso 6 para CVO como ejemplo.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">Una vez configurado el directorio de registro, el estado general del plugin del host de Windows cambia a Running.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">Para asignar el host al ID de usuario de administración de base de datos, desplácese a la ficha Access en Configuración y usuarios, haga clic en el ID de usuario de administración de la base de datos (en nuestro caso, la sqldba a la que se debe asignar el host) y haga clic en Save para completar la asignación de recursos del host.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Agregar el host Unix y la instalación del plugin en el host</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">Haga clic en la ficha hosts del menú de la izquierda y haga clic en Agregar para abrir el flujo de trabajo Agregar host.</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">Elija Linux como el tipo de host. El nombre del host puede ser el nombre de host o una dirección IP. Sin embargo, se debe resolver el nombre de host para corregir la dirección IP del host desde el host SnapCenter. Seleccione las credenciales de host creadas en el paso 2. Las credenciales del host requieren privilegios sudo. Compruebe Oracle Database como el plugin que se va a instalar, que instala complementos de host de Oracle y Linux.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">Haga clic en más opciones y seleccione "Omitir comprobaciones previas a la instalación". Se le pedirá que confirme la omisión de la comprobación de preinstalación. Haga clic en Yes y, a continuación, Save.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Haga clic en Enviar para iniciar la instalación del complemento. Se le pedirá que confirme la huella dactilar, tal como se muestra a continuación.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter realiza la validación y el registro del host y, a continuación, se instala el plugin en el host Linux. El estado cambia de Installing Plugin a Running.</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">Asigne el host recién añadido al ID de usuario de administración de base de datos adecuado (en nuestro caso, oradba).</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. Detección de recursos de base de datos</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">Cuando el plugin se instala correctamente, los recursos de la base de datos en el host se pueden detectar de inmediato. Haga clic en la ficha Recursos del menú de la izquierda. En función del tipo de plataforma de base de datos, hay disponibles varias vistas, como la base de datos, el grupo de recursos, etc. Puede ser necesario hacer clic en la pestaña Refresh Resources si no se detectan y se muestran los recursos en el host.</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">Cuando se detecta inicialmente la base de datos, el estado general se muestra como "no protegido". La captura de pantalla anterior muestra que una base de datos Oracle aún no está protegida por una política de backup.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">Cuando se configura una política o configuración de backup y se ejecuta un backup, el estado general de la base de datos muestra el estado de backup como "Backup succeeded" y la Marca temporal del último backup. La siguiente captura de pantalla muestra el estado de la copia de seguridad de una base de datos de usuario de SQL Server.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">Si las credenciales de acceso a la base de datos no están configuradas correctamente, un botón de bloqueo rojo indica que no se puede acceder a la base de datos. Por ejemplo, si las credenciales de Windows no tienen acceso de administrador del sistema a una instancia de base de datos, las credenciales de la base de datos deben volver a configurarse para desbloquear el bloqueo rojo.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Una vez configuradas las credenciales adecuadas en el nivel de Windows o en la base de datos, desaparece el bloqueo rojo y se recopila y revisa la información de SQL Server Type.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. Configurar la conexión entre clústeres de almacenamiento y la replicación de volúmenes de base de datos</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">Para proteger los datos de sus bases de datos locales mediante un cloud público como destino, los volúmenes de base de datos de clúster ONTAP en las instalaciones se replican en el cloud CVO mediante la tecnología SnapMirror de NetApp. A continuación, los volúmenes de destino replicados se pueden clonar para ACTIVIDADES DE DESARROLLO y operaciones, o bien para la recuperación ante desastres. Los siguientes pasos de alto nivel le permiten configurar la replicación entre iguales de clústeres y volúmenes de base de datos.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">Configure las LIF de interconexión de clústeres para la agrupación de clústeres en el clúster local y en la instancia de clúster de CVO. Este paso se puede llevar a cabo con ONTAP System Manager. Una puesta en marcha predeterminada de CVO tiene LIF entre clústeres configurados automáticamente.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">Clúster en las instalaciones:</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">Clúster de CVO de destino:</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">Introducción: Cloud público de AWS</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">Con las LIF de interconexión de clústeres configuradas, la interconexión de clústeres entre iguales y la replicación de volúmenes se pueden configurar mediante el método de arrastrar y soltar en Cloud Manager de NetApp. Consulte <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">Como alternativa, se puede llevar a cabo la paridad de clústeres y la replicación de volúmenes de base de datos mediante System Manager de ONTAP de la siguiente manera:</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">Inicie sesión en el Administrador del sistema de ONTAP. Acceda a Cluster &gt; Settings y haga clic en Peer Cluster para configurar Cluster peering con la instancia de CVO en el cloud.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Vaya a la pestaña Volumes. Seleccione el volumen de la base de datos que se va a replicar y haga clic en Protect.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">Establezca la directiva de protección en Asynchronous. Seleccione el clúster de destino y la SVM de almacenamiento.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">Compruebe que el volumen esté sincronizado entre el origen y el destino y que la relación de replicación sea correcta.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. Añada SVM de almacenamiento de base de datos de CVO a SnapCenter</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">Haga clic en la pestaña Storage System del menú y, a continuación, haga clic en New para añadir una SVM de almacenamiento CVO que aloja volúmenes de base de datos de destino replicados a SnapCenter. Introduzca la IP de gestión del clúster en el campo Storage System e introduzca el nombre de usuario y la contraseña correspondientes.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">Haga clic en más opciones para abrir opciones de configuración de almacenamiento adicional. En el campo Plataforma, seleccione Cloud Volumes ONTAP, seleccione secundario y haga clic en Guardar.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">Asigne los sistemas de almacenamiento a los ID de usuario de administración de bases de datos SnapCenter tal y como se muestra en <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. Configuración de la política de copia de seguridad de la base de datos en SnapCenter</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">En los siguientes procedimientos se muestra cómo crear una base de datos completa o una política de backup de archivos de registro. Luego, la política puede implementarse para proteger los recursos de las bases de datos. El objetivo de punto de recuperación (RPO) o el objetivo de tiempo de recuperación (RTO) determina la frecuencia de los backups de la base de datos o de registros.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Cree una política de backup de base de datos completa para Oracle</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">Inicie sesión en SnapCenter como identificador de usuario de administración de bases de datos, haga clic en Configuración y, a continuación, en políticas.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">Haga clic en New para iniciar un nuevo flujo de trabajo de creación de políticas de backup o seleccione una política existente para modificarla.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">Seleccione el tipo de backup y la frecuencia de programación.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">Establezca el valor de retención de copias de seguridad. Esto define cuántas copias de backup de base de datos completas se deben conservar.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">Seleccione las opciones de replicación secundaria para insertar los backups de las snapshots primarias locales que se van a replicar en una ubicación secundaria en el cloud.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">Especifique cualquier script opcional antes y después de la ejecución de un backup.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">Ejecute la verificación del backup si lo desea.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">Resumen.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Cree una política de backup del registro de la base de datos para Oracle</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de administración de bases de datos, haga clic en Configuración y, a continuación, en políticas.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">Haga clic en New para iniciar un nuevo flujo de trabajo de creación de políticas de backup o seleccione una política existente para modificarla.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">Configure el período de retención del registro.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">Habilite la replicación en una ubicación secundaria en el cloud público.</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">Especifique cualquier script opcional para ejecutar antes y después del backup de registros.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">Especifique cualquier script de verificación de backup.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">Cree una política de backup de base de datos completa para SQL</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">Defina las opciones de backup y la frecuencia de programación. Para SQL Server configurado con un grupo de disponibilidad, es posible establecer una réplica de backup preferida.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">Establezca el período de retención de las copias de seguridad.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">Habilite la replicación de copias de backup en una ubicación secundaria en el cloud.</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">Especifique cualquier script opcional que se ejecute antes o después de un trabajo de backup.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">Especifique las opciones para ejecutar la verificación de backup.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">Crear una política de backup del registro de la base de datos para SQL.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de administración de bases de datos, haga clic en Configuración &gt; políticas y, a continuación, en Nuevo para iniciar un nuevo flujo de trabajo de creación de directivas.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">Defina las opciones de backup de registros y la frecuencia de programación. Para SQL Server configurado con un grupo de disponibilidad, se puede establecer una réplica de backup preferida.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">La política de backup de datos de SQL Server define la retención de backup de registros; acepte los valores predeterminados aquí.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">Habilite la replicación de backups de registros en almacenamiento secundario en el cloud.</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. Implementar la política de copia de seguridad para proteger la base de datos</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter utiliza un grupo de recursos para realizar el backup de una base de datos en una agrupación lógica de recursos de base de datos, como varias bases de datos alojadas en un servidor, una base de datos que comparte los mismos volúmenes de almacenamiento, varias bases de datos que admiten una aplicación empresarial, etc. Proteger una sola base de datos crea un grupo de recursos propio. Los siguientes procedimientos muestran cómo implementar una política de backup creada en la sección 7 para proteger las bases de datos de Oracle y SQL Server.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Cree un grupo de recursos para un backup completo de Oracle</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de gestión de bases de datos y vaya a la pestaña Resources. En la lista desplegable View, seleccione Database o Resource Group para iniciar el flujo de trabajo de creación de grupos de recursos.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">Proporcione un nombre y etiquetas para el grupo de recursos. Puede definir un formato de nomenclatura para la copia Snapshot y omitir el destino de registro de archivos redundante, si se ha configurado.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">Añada los recursos de la base de datos al grupo de recursos.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">Seleccione una política de backup completa creada en la sección 7 de la lista desplegable.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">Haga clic en el signo (+) para configurar la programación de copia de seguridad deseada.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Haga clic en Load Locators para cargar el volumen de origen y destino.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">Configure el servidor SMTP para la notificación por correo electrónico si lo desea.</block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Cree un grupo de recursos para el backup de registros de Oracle</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">Seleccione una política de backup de registros creada en la sección 7 de la lista desplegable.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">Haga clic en el signo (+) para configurar la programación de copia de seguridad deseada.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">Si la verificación del backup está configurada, se muestra aquí.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">Configure un servidor SMTP para la notificación por correo electrónico si lo desea.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">Cree un grupo de recursos para backup completo de SQL Server</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de gestión de bases de datos y vaya a la pestaña Resources. En la lista desplegable View, seleccione una base de datos o un grupo de recursos para iniciar el flujo de trabajo de creación de grupo de recursos. Proporcione un nombre y etiquetas para el grupo de recursos. Puede definir un formato de nomenclatura para la copia Snapshot.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">Seleccione los recursos de la base de datos que desea incluir en el backup.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">Seleccione una política de backup de SQL completa creada en la sección 7.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">Añada una hora exacta para backups y la frecuencia.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">Seleccione el servidor de verificación para el backup en secundario si desea realizar la verificación de backup. Haga clic en Load Locator para rellenar la ubicación de almacenamiento secundario.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">Crear un grupo de recursos para backup de registros de SQL Server</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de gestión de bases de datos y vaya a la pestaña Resources. En la lista desplegable View, seleccione una base de datos o un grupo de recursos para iniciar el flujo de trabajo de creación de grupo de recursos. Proporcione el nombre y las etiquetas del grupo de recursos. Puede definir un formato de nomenclatura para la copia Snapshot.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">Seleccione una política de backup de registro SQL creada en la sección 7.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">Añada la hora exacta para la copia de seguridad así como la frecuencia.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">Seleccione el servidor de verificación para el backup en secundario si desea realizar la verificación de backup. Haga clic en Load Locator para rellenar la ubicación de almacenamiento secundario.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. Validar el backup</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">Después de crear grupos de recursos de backup de bases de datos para proteger los recursos de las bases de datos, las tareas de backup se ejecutan según la programación predefinida. Compruebe el estado de ejecución del trabajo en la pestaña Monitor.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">Vaya a la pestaña Resources, haga clic en el nombre de la base de datos para ver los detalles del backup de la base de datos, y cambie entre copias locales y copias de mirroring para verificar que los backups de Snapshot se replican en una ubicación secundaria en el cloud público.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">En este momento, las copias de backup de base de datos en el cloud están listas para clonar para ejecutar los procesos de desarrollo y pruebas o para la recuperación ante desastres en caso de un fallo principal.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">Siguiente: Introducción al cloud público de AWS.</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">Si quiere más información sobre la información descrita en este documento, consulte los siguientes enlaces a sitios web:</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Arquitecturas de soluciones que utilizan Azure NetApp Files</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Ventajas de utilizar Azure NetApp Files para la instalación de SQL Server</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">Guía de implementación de SQL Server en Azure mediante Azure NetApp Files</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Con Azure NetApp Files, alta disponibilidad y resiliencia ante fallos</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">La agilidad del cloud público, la rentabilidad de la inversión, la reducción de costes son propuestas de valor significativas para que las empresas adopten el cloud público para el esfuerzo de desarrollo y pruebas de aplicaciones de bases de datos. No hay mejor herramienta que SnapCenter para hacer de esto una realidad con prisa. SnapCenter no solo puede proteger su base de datos de producción en las instalaciones, sino que también puede clonar rápidamente una copia para desarrollo de aplicaciones o pruebas de código en el cloud público a la vez que consume muy poco almacenamiento adicional. A continuación se detallan los procesos paso a paso utilizando la herramienta.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">Flujo de trabajo para la descarga de pruebas y desarrollo en el cloud</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">Anterior: Introducción al cloud público de AWS.</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">La agilidad del cloud público, la rentabilidad de la inversión y la reducción de los costes son propuestas de valor significativas para empresas que adoptan el cloud público para el esfuerzo de desarrollo y pruebas de aplicaciones de bases de datos. No hay mejor herramienta que SnapCenter para hacer esto una realidad. SnapCenter no solo puede proteger su base de datos de producción localmente, sino que también puede clonar rápidamente una copia para desarrollar o probar código en el cloud público mientras consume muy poco almacenamiento adicional. A continuación se detallan los procesos paso a paso para utilizar esta herramienta.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">Clonar una base de datos de Oracle para desarrollo y pruebas a partir de un backup de Snapshot replicado</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de administración de bases de datos para Oracle. Desplácese hasta la pestaña Resources, donde se muestran las bases de datos de Oracle que está protegida por SnapCenter.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">Haga clic en el nombre de la base de datos en las instalaciones indicado para la topología de backup y la vista detallada. Si se habilita una ubicación de replicación secundaria, se muestran backups de reflejos vinculados.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">Para alternar la vista de backups reflejados, haga clic en backups reflejados. Luego, se muestran los backups de reflejos secundarios.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">Elija una copia de backup de base de datos secundaria reflejada que se clonará y determine un punto de recuperación por tiempo y número de cambio de sistema o por SCN. Por lo general, el punto de recuperación debe contener el tiempo de backup completo de la base de datos o el SCN que se va a clonar. Una vez decidido un punto de recuperación, es necesario montar el backup de archivo de registro necesario para la recuperación. El backup del archivo de registro debe montarse en el servidor de la base de datos de destino donde se va a alojar la base de datos del clon.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">Si se habilita la eliminación de registros y el punto de recuperación se amplía más allá de la última eliminación de registros, es posible que sea necesario montar varios backups de registros de archivo.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">Destaque la copia de backup completa de la base de datos que se va a clonar y haga clic en el botón clonar para iniciar el flujo de trabajo de clonado de base de datos.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">Elija un SID de base de datos del clon adecuado para una base de datos completa del contenedor o un clon de la CDB.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">Seleccione el host del clon objetivo en el cloud y el flujo de trabajo del clon creará el archivo de datos, el archivo de control y los directorios de registro de recuperación.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">El nombre de la credencial None se utiliza para la autenticación basada en el sistema operativo, lo que hace que el puerto de la base de datos sea irrelevante. Rellene el directorio inicial de Oracle, el usuario del sistema operativo Oracle y el grupo del sistema operativo Oracle que se hayan configurado en el servidor de la base de datos del clon de destino.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">Especifique los scripts que se ejecutarán antes de la operación de clonado. Lo que es más importante, el parámetro de instancia de base de datos se puede ajustar o definir aquí.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">Especifique el punto de recuperación por fecha y hora o SCN. Until Cancel recupera la base de datos hasta los registros de archivo disponibles. Especifique la ubicación del registro de archivos externo desde el host de destino donde se monta el volumen de registro de archivos. Si el propietario de Oracle del servidor de destino es diferente del servidor de producción local, compruebe que el propietario de Oracle del servidor de destino puede leer el directorio de registro de archivado.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">Resumen de clones.</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">Debe validar después de la clonación para asegurarse de que la base de datos clonada funcione. Algunas tareas adicionales, como iniciar el listener o desactivar el modo de archivo de registro de DB, se pueden realizar en la base de datos de prueba/desarrollo.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">Clonar una base de datos de SQL para desarrollo y pruebas a partir de un backup de Snapshot replicado</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de administración de bases de datos para SQL Server. Desplácese hasta la pestaña Resources, donde se muestran las bases de datos de usuario SQL Server protegidas por SnapCenter y una instancia de SQL en espera de destino en la nube pública.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">Haga clic en el nombre previsto de la base de datos de usuario de SQL Server en las instalaciones para obtener la topología y la vista detallada de las copias de seguridad. Si se habilita una ubicación de replicación secundaria, se muestran backups de reflejos vinculados.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">Para alternar a la vista Mirrored backups, haga clic en Mirrored backups. Luego, se mostrarán los backups de reflejo secundarios. Dado que SnapCenter realiza un backup del registro de transacciones de SQL Server en una unidad dedicada para la recuperación, solo se muestran aquí backups completos de la base de datos.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">Seleccione una copia de backup y, a continuación, haga clic en el botón Clone para iniciar el flujo de trabajo Clone desde Backup.</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">Seleccione un servidor en cloud como el servidor de clonado de destino, el nombre de la instancia de clon y el nombre de la base de datos de clonado. Seleccione un punto de montaje de asignación automática o una ruta de punto de montaje definida por el usuario.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">Determine un punto de recuperación por hora de backup del registro o por una fecha y hora específicas.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">Especifique scripts opcionales que ejecutar antes y después de la operación de clonado.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">Configure un servidor SMTP si se desea recibir una notificación por correo electrónico.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">Resumen de clones.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">Supervise el estado del trabajo y valide que la base de datos de usuario prevista se ha adjuntado a una instancia de SQL de destino en el servidor de clones en cloud.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">Configuración posterior al clon</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">Normalmente, una base de datos de producción de Oracle en las instalaciones se ejecuta en modo de archivado de registros. Este modo no es necesario para una base de datos de desarrollo o prueba. Para desactivar el modo de archivo de registro, inicie sesión en la base de datos Oracle como sysdba, ejecute un comando de cambio de modo de registro e inicie la base de datos para obtener acceso.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Configurar un listener de Oracle o registrar la base de datos que se acaba de clonar con un listener existente para que el usuario pueda acceder a ella.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">En SQL Server, cambie el modo de registro de Full a Easy para que el archivo de registro de prueba/desarrollo de SQL Server se pueda reducir fácilmente al llenar el volumen de registro.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">Actualice el clon de la base de datos</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">Borre las bases de datos clonadas y borre el entorno del servidor de bases de datos de cloud. A continuación, siga los procedimientos anteriores para clonar una nueva base de datos con datos nuevos. Solo se tarda unos minutos en clonar una nueva base de datos.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">Actualizar un clon</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">Apague la base de datos de clonado, ejecute un comando de actualización de clonado mediante la CLI. Consulte la siguiente documentación de SnapCenter para obtener detalles: <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">Si necesita ayuda con esta solución y los casos de uso, únase al <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> y busque el canal de automatización de soluciones para publicar sus preguntas o preguntas.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">Siguiente: Flujo de trabajo de recuperación ante desastres.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">En esta sección se describen los diferentes problemas que debe tener en cuenta cuando Azure NetApp Files con SQL Server en el cloud.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">Factores a considerar</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">Rendimiento de VM</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">optimizada para la memoria</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">Seleccionar el tamaño correcto de máquina virtual es importante para optimizar el rendimiento de una base de datos relacional en un cloud público. Microsoft recomienda continuar utilizando las mismas opciones de ajuste del rendimiento de base de datos que se aplican a SQL Server en entornos de servidor locales. Uso<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> Tamaños de equipos virtuales para obtener el mejor rendimiento de las cargas de trabajo de SQL Server. Recopile los datos de rendimiento de la implementación existente para identificar el uso de la RAM y la CPU a la vez que elige las instancias adecuadas. La mayoría de puestas en marcha elige entre las series D, E o M.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">*Notas:*</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">Para obtener el mejor rendimiento de las cargas de trabajo de SQL Server, utilice tamaños de VM optimizados para memoria.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp y Microsoft recomiendan identificar los requisitos de rendimiento del almacenamiento antes de elegir el tipo de instancia con la ratio de memoria a Vcore adecuada. Así mismo, también es posible seleccionar un tipo de instancia inferior con el ancho de banda de red adecuado para superar los límites de rendimiento del almacenamiento de la máquina virtual.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">Redundancia de máquinas virtuales</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">conjunto de disponibilidad</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">zonas de disponibilidad</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">Para aumentar la redundancia y la alta disponibilidad, las máquinas virtuales de SQL Server deben estar en la misma<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> o diferente<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Al crear máquinas virtuales de Azure, debe elegir entre configurar conjuntos de disponibilidad frente a las zonas de disponibilidad; una máquina virtual de Azure no puede participar en ambos.</block>
  <block id="05807e454c19f244770adae059b3c330" category="section-title">Alta disponibilidad</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">Para una alta disponibilidad, es la mejor opción configurar SQL Server AOAG o Always On Failover Cluster Instance (FCI, instancia de clúster de conmutación por error siempre activa). Para AOAG, implica varias instancias de SQL Server en máquinas virtuales de Azure en una red virtual. Si se requiere una alta disponibilidad en el nivel de base de datos, considere la configuración de grupos de disponibilidad SQL Server.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configuración del almacenamiento</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server se puede poner en marcha con un recurso compartido de archivos SMB como opción de almacenamiento. A partir de SQL Server 2012, bases de datos del sistema (master, model, msdb o tempdb), Y las bases de datos de usuario se pueden instalar con el servidor de archivos bloque de mensajes del servidor (SMB) como una opción de almacenamiento. Esto se aplica tanto a SQL Server independiente como a SQL Server FCI.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">El almacenamiento de recursos compartidos de archivos para bases de datos de SQL Server debe admitir la propiedad continuamente disponible. Esto proporciona acceso ininterrumpido a los datos de recursos compartidos de archivos.</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files proporciona un almacenamiento de ficheros de alto rendimiento que satisface las exigentes cargas de trabajo; además, reduce el coste total de propiedad de SQL Server en comparación con las soluciones de almacenamiento basado en bloques. Con el almacenamiento en bloques, los equipos virtuales han impuesto límites de I/o y ancho de banda para las operaciones de disco; los límites de ancho de banda de red se aplican por sí solos a Azure NetApp Files. Es decir, no se aplican límites de I/o a nivel de máquina virtual a Azure NetApp Files. Sin estos límites de I/o, la ejecución de SQL Server en máquinas virtuales más pequeñas conectadas a Azure NetApp Files puede provocar el mismo rendimiento que la ejecución de SQL Server en máquinas virtuales mucho más grandes. Azure NetApp Files reduce los costes de implementación de SQL Server reduciendo los costes de licencias de software y computación. Para obtener información detallada sobre los análisis de costes y las ventajas de rendimiento del uso de Azure NetApp Files para la implantación de SQL Server, consulte<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">Entre las ventajas de utilizar Azure NetApp Files para SQL Server se incluyen las siguientes:</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">El uso de Azure NetApp Files le permite utilizar instancias más pequeñas, lo que reduce los costes de computación.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">Azure NetApp Files también reduce los costes de licencias de software, con lo que se reduce el TCO general.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">La funcionalidad de este tipo de volúmenes se está remodelando y el nivel de servicio dinámico optimiza los costes ajustando el tamaño de las cargas de trabajo de estado constante y evitando el sobreaprovisionamiento.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">Para aumentar la redundancia y la alta disponibilidad, las máquinas virtuales de SQL Server deben estar en la misma<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> o en diferente<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Considere los requisitos de ruta de archivo si es necesario utilizar archivos de datos definidos por el usuario; en ese caso, seleccione SQL FCI over SQL AOAG.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.test\SQLDB y \\ANFSMB-b4ca.anf.test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">Se admite la siguiente ruta UNC:<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">No se admite la ruta de bucle de retroceso UNC.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">Para realizar tareas de ajuste de tamaño, use datos históricos de su entorno local. En el caso de cargas de trabajo OLTP, haga coincidir la tasa de IOPS de destino con los requisitos de rendimiento utilizando cargas de trabajo a la media y los picos de actividad junto con las lecturas/s del disco y contadores de rendimiento de escrituras/s del disco. En el caso de cargas de trabajo que requieran informes y almacenes de datos, haga coincidir el rendimiento objetivo con las cargas de trabajo a la media y los picos de actividad, así como los bytes de lectura/s del disco y los bytes de escritura en disco/s. Los valores medios se pueden usar junto con las funcionalidades de nueva formulación de volúmenes.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">Crear recursos compartidos constantemente disponibles</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">Creación de un recurso compartido disponible de forma continua</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Cree recursos compartidos constantemente disponibles con el portal de Azure o la interfaz de línea de comandos de Azure. En el portal, seleccione la opción de la propiedad Enable Continuous Availability (Activar disponibilidad continua). Para la CLI de Azure, especifique el recurso compartido como un recurso compartido disponible continuamente mediante el<block ref="0be8c8a92e4fe4621be30aa11942bc4d" prefix=" " category="inline-code"></block> opción establecida en<block ref="91da4c74e2fced40755d4d3997af3488" prefix=" " category="inline-code"></block>. Para obtener más información sobre la creación de un volumen nuevo con la función de disponibilidad continua, consulte<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">Habilite la disponibilidad continua para el volumen SMB como se muestra en la siguiente imagen.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">Si se utiliza una cuenta de dominio que no es de administrador, asegúrese de que la cuenta tiene asignado el privilegio de seguridad requerido.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">Establezca los permisos adecuados en el nivel de recurso compartido y los permisos de nivel de archivo adecuados.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">Convierta los volúmenes de SMB existentes para utilizar disponibilidad continua</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">No puede habilitarse una propiedad disponible de forma continua en volúmenes de SMB existentes. Para convertir un volumen existente para utilizar un recurso compartido disponible de forma continua, use la tecnología Snapshot de NetApp. Para obtener más información, consulte<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Rendimiento</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files admite tres niveles de servicio: Estándar (16 Mbps por terabyte), Premium (64 Mb/s por terabyte) y Ultra (128 MB/s por terabyte). El aprovisionamiento de un tamaño de volumen adecuado es importante para un rendimiento óptimo de la carga de trabajo de la base de datos. Con Azure NetApp Files, el rendimiento de los volúmenes y el límite de rendimiento se basan en una combinación de los siguientes factores:</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">El nivel de servicio del pool de capacidad al que pertenece el volumen</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">La cuota asignada al volumen</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">El tipo de calidad de servicio (QoS) (automática o manual) del pool de capacidad</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Niveles de servicio para Azure NetApp Files</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">Para obtener más información, consulte<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validación del rendimiento</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">Herramienta SB (Storage Benchmark) de SQL Server</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">Al igual que con cualquier puesta en marcha, probar la máquina virtual y el almacenamiento es vital. Para la validación del almacenamiento, herramientas como HammerDB, Apploader, el<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>, O cualquier script personalizado o FIO con la mezcla de lectura/escritura apropiada debe ser utilizado. Tenga en cuenta, sin embargo, que la mayoría de las cargas de trabajo de SQL Server, incluso las cargas de trabajo OLTP con mucho tráfico, están más cerca de un 80 %–90 % de lectura y de un 10 %–20 % de escritura.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">Para demostrar el rendimiento, se realizó una prueba rápida en un volumen con niveles de servicio premium. En esta prueba, el tamaño del volumen aumentó de 100 GB a 2 TB sobre la marcha sin interrupciones en el acceso a las aplicaciones ni en la migración de datos cero.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">He aquí otro ejemplo de pruebas de rendimiento en tiempo real realizadas con HammerDB para la puesta en marcha que abarca este documento. Para esta prueba, utilizamos una pequeña instancia con ocho vCPU, una SSD Premium de 500 GB y un volumen Azure NetApp Files SMB de 500 GB. HammerDB se configuró con 80 almacenes y ocho usuarios.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">El siguiente gráfico muestra que Azure NetApp Files pudo proporcionar 2,6 veces más transacciones por minuto con una latencia 4 veces menor cuando se utiliza un volumen de tamaño comparable (500 GB).</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">Se realizó una prueba adicional con el cambio de tamaño a una instancia más grande con 32 x vCPU y un volumen Azure NetApp Files de 16 TB. Hubo un aumento significativo en las transacciones por minuto con una latencia constante de 1 ms. HammerDB se configuró con 80 almacenes y 64 usuarios para esta prueba.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">Optimización de costes</block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files permite redimensionar los volúmenes sin interrupciones y transparente, y la capacidad de cambiar los niveles de servicio sin provocar ningún tiempo de inactividad y sin provocar ningún efecto en las aplicaciones. Esta es una función única que permite una gestión de costes dinámica que evita la necesidad de realizar ajustes de tamaño de bases de datos con métricas máximas. En su lugar, puede usar cargas de trabajo de estado constante, lo que evita costes iniciales. La modificación del volumen y el cambio dinámico a nivel de servicio le permiten ajustar el ancho de banda y el nivel de servicio de los volúmenes de Azure NetApp Files bajo demanda de forma casi instantánea sin interrumpir la actividad de I/o y conservar el acceso a los datos.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">Las ofertas de PaaS de Azure, como LogicApp o funciones, se pueden utilizar para cambiar fácilmente el tamaño del volumen en función de un determinado enlace web o activador de alertas, con el fin de satisfacer las demandas de las cargas de trabajo y gestionar dinámicamente el coste.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">Por ejemplo, piense en una base de datos que necesita 250 Mbps para un funcionamiento estable; sin embargo, también requiere un rendimiento máximo de 400 Mbps. En este caso, la puesta en marcha se debe realizar con un volumen de 4 TB dentro del nivel de servicio Premium para satisfacer los requisitos de rendimiento en estado constante. Para manejar las cargas de trabajo pico, aumente el tamaño del volumen usando las funciones de Azure hasta 7 TB para ese período específico y, a continuación, reduzca el tamaño del volumen para que la puesta en marcha sea rentable. Esta configuración evita el sobreaprovisionamiento del almacenamiento.</block>
  <block id="ebcadd0d5b1096e72d18133b1e0e3098" category="doc">TR-4467: SAP con Microsoft SQL Server en Windows: Prácticas recomendadas con Clustered Data ONTAP y SnapCenter de NetApp</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen: NetApp</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467 proporciona a los clientes y partners prácticas recomendadas para la puesta en marcha de Clustered Data ONTAP de NetApp para dar soporte a las soluciones de SAP Business Suite que se ejecutan en un entorno Microsoft SQL Server en Windows.</block>
  <block id="d90b6dfa1c90883fc207f3309f98b1bf" category="paragraph"><block ref="d90b6dfa1c90883fc207f3309f98b1bf" category="inline-link-macro-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">Esta página describe el método automatizado para poner en marcha Oracle19c en el almacenamiento ONTAP de NetApp.</block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">Las organizaciones están automatizando sus entornos para conseguir eficiencias, acelerar las puestas en marcha y reducir el esfuerzo manual. Se están utilizando herramientas de gestión de configuraciones como Ansible para optimizar las operaciones de las bases de datos empresariales. En esta solución, demostramos cómo puede usar Ansible para automatizar el aprovisionamiento y la configuración de Oracle 19c con ONTAP de NetApp. Al permitir que los administradores de almacenamiento, los administradores de sistemas y los administradores de bases de datos instalen de forma constante y rápida almacenamiento nuevo, configuren los servidores de la base de datos e instalen el software Oracle 19c, obtiene las siguientes ventajas:</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">Elimine las complejidades de diseño y los errores humanos e implemente una puesta en marcha consistente y mejores prácticas repetibles</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">Reducir el tiempo de aprovisionamiento del almacenamiento, configuración de hosts de bases de datos e instalación de Oracle</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">Aumente la productividad de los administradores de bases de datos, de sistemas y de almacenamiento</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">Facilite un escalado del almacenamiento y las bases de datos</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp proporciona a los clientes módulos y funciones Ansible validados para acelerar la puesta en marcha, la configuración y la gestión del ciclo de vida de su entorno de base de datos de Oracle. Esta solución proporciona instrucciones y el código del libro de estrategia de Ansible, para ayudarle a:</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Crear y configurar el almacenamiento NFS de ONTAP para la base de datos de Oracle</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Instale Oracle 19c en RedHat Enterprise Linux 7/8 o Oracle Linux 7/8</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">Configurar Oracle 19c en el almacenamiento NFS de ONTAP</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">Para obtener más información o para empezar, consulte los vídeos de resumen que aparecen a continuación.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">Implementaciones de AWX/Tower</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">Parte 1: Introducción, requisitos, detalles de automatización y configuración inicial de AWX/Tower</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">Parte 2: Variables y ejecución de la guía</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">Puesta en marcha de CLI</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">Parte 1: Introducción, requisitos, detalles de la automatización y configuración del host de Ansible Control</block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">En esta sección se describe una arquitectura de cloud híbrido típica para operaciones de desarrollo y pruebas y recuperación ante desastres.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">En el siguiente diagrama de arquitectura se ilustra una implementación típica de operaciones de bases de datos empresariales en un cloud híbrido para operaciones de recuperación ante desastres y desarrollo y pruebas.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">En operaciones empresariales normales, los volúmenes de bases de datos sincronizados en el cloud se pueden clonar y montar en instancias de base de datos de desarrollo y pruebas para desarrollar o probar aplicaciones. En caso de que se produzca un fallo, los volúmenes de la base de datos sincronizados en el cloud pueden activarse para realizar la recuperación ante desastres.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">Siguiente: Requisitos de soluciones.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="b985336298cf9391b91c898572090625" category="summary">En esta sección se muestra una arquitectura de instalación y protección de datos de Oracle Database con almacenamiento de Azure NetApp Files y máquinas virtuales de Azure.</block>
  <block id="fc6024ee9167308c3126789695e7353f" category="paragraph"><block ref="fc6024ee9167308c3126789695e7353f" category="inline-link-macro-rx"></block></block>
  <block id="91e17bfb5f535513b5320d68f6afe1fc" category="paragraph">En el siguiente diagrama arquitectura se muestra la puesta en marcha de bases de datos de Oracle de alta disponibilidad en instancias de Azure VM y en almacenamiento de Azure NetApp Files.</block>
  <block id="520c5c426000f1dbbd8ac385d5547603" category="paragraph">En el entorno, la instancia de computación de Oracle se pone en marcha a través de una consola de máquina virtual de servicios de Azure. Hay varios tipos de instancias de Azure disponibles en la consola. NetApp recomienda la puesta en marcha de una instancia de Azure VM orientada a bases de datos que cumpla con su carga de trabajo esperada.</block>
  <block id="9e20ded809aa2fa1bd072f48ceacfdd8" category="paragraph">El almacenamiento de bases de datos de Oracle, por su parte, se pone en marcha con el servicio Azure NetApp Files disponible en la consola de Azure. Los volúmenes binarios, datos o registro de Oracle se presentan y, a continuación, se montan en un host Linux de instancia de Azure VM.</block>
  <block id="6b5cae77dbc9c4b759bf654b117eb10b" category="inline-image-macro">Esta imagen muestra la relación entre el Sitio primario, el Sitio en espera y la interconexión vNet de cada uno de estos sitios. Esto forma cuatro redes virtuales separadas.</block>
  <block id="2246b51fdf61c77213e0ce37d743cd03" category="paragraph"><block ref="2246b51fdf61c77213e0ce37d743cd03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03aa17a1290e1122adecd07d53463cde" category="paragraph">En muchos aspectos, la implementación de Azure NetApp Files en el cloud de Azure es muy similar a una arquitectura de almacenamiento de datos de ONTAP en las instalaciones con muchas redundancias incorporadas, como RAID y controladoras dobles. Para la recuperación ante desastres, se puede configurar un sitio en espera en distintas regiones y la base de datos se puede sincronizar con el sitio principal mediante la replicación a nivel de aplicación (por ejemplo, Oracle Data Guard).</block>
  <block id="6f1714a5ced243b141295d01d4038364" category="paragraph">En nuestra validación de pruebas para la puesta en marcha y protección de datos de bases de datos de Oracle, la base de datos de Oracle se pone en marcha en una única máquina virtual de Azure, tal y como se muestra en el siguiente diagrama:</block>
  <block id="fef3344ae2f384e724a169b6e9d90be7" category="inline-image-macro">Esta imagen muestra la organización de un único equipo virtual de Azure con vNet peering para hacer dos redes virtuales independientes.</block>
  <block id="f3699a22a9267b8e767816c81f821522" category="paragraph"><block ref="f3699a22a9267b8e767816c81f821522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69cf5342936c24c9fac1c6529c4f825f" category="paragraph">El entorno de Azure Oracle se puede gestionar con un nodo de controladora de Ansible para la automatización, utilizando los kits de herramientas proporcionados por NetApp para la puesta en marcha de bases de datos, backup, recuperación y migración de bases de datos. Cualquier actualización del kernel del sistema operativo de la instancia de Oracle Azure VM o la revisión de Oracle se puede realizar en paralelo para mantener la sincronización principal y en espera. De hecho, los kits de herramientas iniciales se pueden ampliar fácilmente para realizar tareas diarias de Oracle si es necesario. Si necesita ayuda para configurar una controladora CLI de Ansible, consulte <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block> para empezar.</block>
  <block id="149b87e0b981bcf1e3d652831c207e04" category="inline-link-macro">Siguiente: Factores a considerar.</block>
  <block id="0a9d288b4b8679857f2d7e7f0d5a63f6" category="paragraph"><block ref="0a9d288b4b8679857f2d7e7f0d5a63f6" category="inline-link-macro-rx"></block></block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">En esta sección, se proporcionan detalles sobre los factores que se deben tener en cuenta al migrar la base de datos de Oracle de las instalaciones a la instancia de AWS EC2 y al almacenamiento FSX.</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">Migración de bases de datos de las instalaciones al cloud público</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">Anterior: Gestión de bases de datos.</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">La migración de bases de datos es una tarea difícil de cualquier modo. Migrar una base de datos de Oracle de las instalaciones al cloud no es una excepción.</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">Las siguientes secciones proporcionan factores clave que se deben tener en cuenta a la hora de migrar bases de datos de Oracle al cloud público de AWS con la computación EC2 de AWS y la plataforma de almacenamiento FSX.</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">El almacenamiento de ONTAP está disponible en las instalaciones</block>
  <block id="3c2e1436532e8615aa8fdb7bb7432f80" category="paragraph">Si la base de datos de Oracle local se encuentra en una cabina de almacenamiento ONTAP, resulta más fácil configurar la replicación para la migración de bases de datos mediante la tecnología SnapMirror de NetApp integrada en el almacenamiento ONTAP FSX de AWS. El proceso de migración puede orquestarse mediante la consola BlueXP de NetApp.</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">Cree una instancia de EC2 de computación de destino que coincida con la instancia local.</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">Aprovisionamiento de volúmenes de base de datos de igual tamaño desde la consola FSX.</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">Montar los volúmenes de la base de datos FSX en la instancia de EC2.</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">Configure la replicación de SnapMirror entre los volúmenes de base de datos locales en los volúmenes de base de datos FSX de destino. Es posible que la sincronización inicial tarde un poco en mover los datos de origen primarios, pero cualquier actualización incremental posterior es mucho más rápida.</block>
  <block id="ed7c233990ddaa2e7103a9f5b77ee3de" category="list-text">En el momento de la conmutación, cierre la aplicación principal para detener todas las transacciones. Desde la interfaz de línea de comandos de Oracle sqlplus, ejecutar un switch de registro en línea de Oracle y permitir que la sincronización SnapMirror mueva el último registro archivado al volumen de destino.</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">Rompa los volúmenes reflejados, ejecute la recuperación de Oracle en el destino y cree la base de datos para su servicio.</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">Dirija sus aplicaciones a la base de datos de Oracle en el cloud.</block>
  <block id="094ef1326e70f1212e06a1b5d65d2922" category="paragraph">En el siguiente vídeo se muestra cómo migrar una base de datos de Oracle de las instalaciones a AWS FSX/EC2 mediante la consola BlueXP de NetApp y la replicación de SnapMirror.</block>
  <block id="0ed0689d68d30d32584025a19c85c9e1" category="inline-link-macro">Migración de bases de datos Oracle de las instalaciones a FSX/EC2 a través de SnapMirror y BlueXP</block>
  <block id="bb74f90e0bd42cad827c08c3b5a1d1f8" category="paragraph"><block ref="bb74f90e0bd42cad827c08c3b5a1d1f8" category="inline-link-macro-rx"></block></block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">El almacenamiento ONTAP no está disponible en las instalaciones</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">Si la base de datos de Oracle local se aloja en un almacenamiento de terceros distinto a ONTAP, la migración de bases de datos se basa en la restauración de una copia de backup de base de datos de Oracle. Debe reproducir el archivo de registro para que esté actualizado antes de realizar la conmutación.</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3 se puede usar como área de almacenamiento provisional para el movimiento y la migración de bases de datos. Consulte los siguientes pasos de nivel alto para este método:</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">Aprovisione una instancia nueva de EC2 que coincida con la instancia de las instalaciones.</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">Aprovisionar volúmenes de base de datos iguales del almacenamiento FSX y montar los volúmenes en la instancia de EC2.</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">Cree una copia de backup de Oracle en el nivel de disco.</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">Mueva la copia de backup al almacenamiento AWS S3.</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">Vuelva a crear el archivo de control de Oracle, restaure y recupere la base de datos. Para ello, extrae datos y el registro de archivos del almacenamiento S3.</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">Sincronice la base de datos de Oracle de destino con la base de datos de origen en las instalaciones.</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">Al efectuar la conmutación, cierre la aplicación y la base de datos Oracle de origen. Copie los últimos registros de archivo y aplíquelos a la base de datos Oracle de destino para ponerlos al día.</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">Inicie la base de datos de destino para el acceso del usuario.</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">Redirigir la aplicación a la base de datos de destino para completar la conmutación.</block>
  <block id="e54801d4a4497c3566a98c0ef4ec6f18" category="section-title">Migración de bases de datos de Oracle locales a AWS FSX/EC2 mediante la reubicación de PDB con la máxima disponibilidad</block>
  <block id="16d584a60d17de3de7cd0dcc0828fee9" category="paragraph">Este método de migración es más adecuado para las bases de datos de Oracle que ya se ponen en marcha en el modelo multi-tenant de PDB/CDB y el almacenamiento de ONTAP no está disponible en las instalaciones. El método de reubicación de PDB utiliza la tecnología de clonado activo de PDB de Oracle para mover PDB entre una CDB de origen y una CDB de destino al mismo tiempo que minimiza la interrupción del servicio.</block>
  <block id="c5bd16be343bf2e5a3c081284c6c799b" category="paragraph">En primer lugar, cree una CDB en el AWS FSX/EC2 con almacenamiento suficiente para migrar las PDB de host desde las instalaciones. Es posible reubicar varios PDB en las instalaciones de uno en uno.</block>
  <block id="d7acbe14b605ece64e94636c2ac85151" category="inline-link-macro">Convertir una sola instancia que no es una CDB en una PDB en una CDB multitenant</block>
  <block id="a6c9ea7b4477a21ac635b1db86abae5e" category="list-text">Si la base de datos en las instalaciones se implementa en una sola instancia en lugar de en el modelo de PDB/CDB multitenant, siga las instrucciones de <block ref="1a6a40cd2cc4844be72d5fbe9fd5f1e6" category="inline-link-macro-rx"></block> Para convertir la instancia única en PDB/CDB multitenant. A continuación, siga el siguiente paso para migrar la PDB convertida a CDB en AWS FSX/EC2.</block>
  <block id="92c29ab4b5bfbc6de30e29363bc9aea7" category="inline-link-macro">Migre bases de datos de Oracle locales al cloud con la reubicación de PDB</block>
  <block id="522ca40aa0d528d119dec226eb9719b8" category="list-text">Si la base de datos en las instalaciones ya está implementada en el modelo multi-tenant PDB/CDB, siga las instrucciones de <block ref="02137814e079cdfea8552a492195c829" category="inline-link-macro-rx"></block> para realizar la migración.</block>
  <block id="499d7c245aad786a568d21227b5b65d8" category="paragraph">En el siguiente vídeo se muestra cómo se puede migrar una base de datos de Oracle (PDB) a FSX/EC2 mediante la reubicación de PDB con la disponibilidad máxima.</block>
  <block id="c0d2cea4b49d55201605052121b68ca7" category="inline-link-macro">Migre la PDB de Oracle local a la CDB AWS con la máxima disponibilidad</block>
  <block id="e3d2de69302b3f20931015cece4526e4" category="paragraph"><block ref="5deefe7b3e78f7f08541c2e7b5b56e54" category="inline-link-macro-rx"></block></block>
  <block id="5eae2f4290a9e1f77061f80c6c015bc6" category="admonition">Aunque las instrucciones del paso 1 y 2 se ilustran en el contexto del cloud público de Azure, los procedimientos se pueden aplicar al cloud AWS sin cambios.</block>
  <block id="41099d15ad008ac11d04538ef8e57575" category="paragraph">El equipo de automatización de soluciones de NetApp proporciona un kit de herramientas de migración que puede facilitar la migración de bases de datos de Oracle de las instalaciones al cloud de AWS. Utilice este comando para descargar el kit de herramientas de migración de bases de datos de Oracle para la reubicación de PDB.</block>
  <block id="1572d96530c843cddbe2d0a8b47abf8a" category="summary">Esta guía de mejores prácticas ofrece detalles de una solución para poner en marcha y proteger bases de datos de Oracle en almacenamiento de archivos Azure NetApp y Azure VM.</block>
  <block id="2e0520fcae6cb49914d2308fbaf4e1a8" category="doc">TR-4954: Puesta en marcha y protección de bases de datos de Oracle en Azure NetApp Files</block>
  <block id="b2bd5134cf9b573edd93cbfe6ee4559d" category="paragraph">Muchas bases de datos empresariales críticas para la misión de Oracle aún se encuentran en las instalaciones, y muchas empresas tratan de migrar estas bases de datos de Oracle a un cloud público. A menudo, estas bases de datos de Oracle están centradas en aplicaciones y, por ello, requieren configuraciones específicas del usuario, una funcionalidad que falta en muchas ofertas de cloud público de base de datos como servicio. Por lo tanto, el panorama actual de las bases de datos exige una solución de base de datos de Oracle basada en el cloud público creada a partir de un servicio de almacenamiento y computación escalable de alto rendimiento que pueda satisfacer requisitos particulares. Las instancias de computación de máquina virtual de Azure y el servicio de almacenamiento de Azure NetApp Files pueden ser las piezas que faltan de este rompecabezas para crear y migrar sus cargas de trabajo de bases de datos de Oracle esenciales a una nube pública.</block>
  <block id="a58dc8965e4de69beb97a33a5a1935ea" category="paragraph">Las máquinas virtuales de Azure son uno de los diversos tipos de recursos de computación bajo demanda y escalables que ofrece Azure. Por lo general, se elige una máquina virtual cuando se necesita más control sobre el entorno de computación de lo que ofrecen las otras opciones. Las máquinas virtuales Azure ofrecen una forma rápida y sencilla de crear un equipo con configuraciones específicas necesarias para ejecutar su base de datos de Oracle, ya sea para cargas de trabajo con un uso intensivo de la computación o de la memoria. Las máquinas virtuales de una red virtual de Azure se pueden conectar fácilmente a la red de la organización, por ejemplo, a través de un túnel VPN seguro.</block>
  <block id="466d154dd31c873c4a2fd7113dc6b818" category="paragraph">Azure NetApp Files es un servicio de Microsoft totalmente gestionado que llevará la carga de trabajo de su base de datos al cloud de forma más rápida y segura que nunca. Se ha diseñado para satisfacer los requisitos centrales de la ejecución de cargas de trabajo de alto rendimiento, como las bases de datos de Oracle en el cloud, y proporciona niveles de rendimiento que reflejan la gama real de demandas de IOPS, baja latencia, alta disponibilidad, alta durabilidad, capacidad de gestión a escala, así como backup, recuperación y clonado rápidos y eficientes. Estas funcionalidades son posibles porque Azure NetApp Files se basa en los sistemas ONTAP all-flash físicos de NetApp que se ejecutan en el entorno de centro de datos Azure. Azure NetApp Files está completamente integrado en los centros de datos y el portal de Azure y los clientes pueden utilizar las mismas API y la misma interfaz gráfica para crear y gestionar archivos compartidos que cualquier otro objeto de Azure. Con Azure NetApp File, puede desbloquear todas las funcionalidades de Azure sin riesgos adicionales, costes ni tiempo, y confiar en el único servicio de archivos empresariales nativo de Azure.</block>
  <block id="30106aaa3e986f62cbb327f935569bca" category="inline-link-macro">Bases de datos de Oracle en Microsoft Azure</block>
  <block id="bdb41d103336edebf957f48add0f3554" category="inline-link-macro">Automatización de NetApp</block>
  <block id="c2add34b573ef3798dd7c5b8972c008a" category="paragraph">En esta documentación se describe detalladamente cómo implementar, configurar y proteger una base de datos de Oracle con un servicio de máquina virtual de Azure y almacenamiento de Azure NetApp Files que ofrece rendimiento y durabilidad similares a un sistema en las instalaciones. Para obtener instrucciones sobre prácticas recomendadas, consulte TR-4780 <block ref="43d70d3cb7600babfb5820086b5480b6" category="inline-link-macro-rx"></block>. Y lo que es más importante, NetApp también proporciona kits de herramientas de automatización que automatizan la mayoría de las tareas necesarias para la puesta en marcha, la configuración, la protección de datos, la migración y la gestión de la carga de trabajo de la base de datos de Oracle en el cloud público de Azure. Los kits de herramientas de automatización están disponibles para su descarga en el sitio público de GitHub de NetApp: <block ref="1b9adaed0e4ba13a6d8f6edc7ab8f2d8" category="inline-link-macro-rx"></block>.</block>
  <block id="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="paragraph"><block ref="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="inline-link-macro-rx"></block></block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">Esta página describe el método automatizado para implementar la protección de datos de Oracle en el almacenamiento ONTAP de NetApp.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">Primeros pasos</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">Esta solución se ha diseñado para ejecutarse en un entorno AWX/Tower.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/Tower</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">En el caso de los entornos AWX/Tower, se le guiará a través de la creación de un inventario de la gestión del clúster de ONTAP y del servidor de Oracle (IP y nombres de host), lo que crea credenciales, configura un proyecto que extrae el código de Ansible de la cuenta de Automation Github y la plantilla de trabajo que inicia la automatización.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">La solución se ha diseñado para ejecutarse en un escenario de cloud privado (desde las instalaciones hasta en las instalaciones) y cloud híbrido (desde las instalaciones hasta Cloud Volumes ONTAP de cloud público [CVO])</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">Rellene las variables específicas de su entorno y cópielas y péguelas en los campos más Vars de la plantilla de trabajo.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">Cuando se hayan añadido los var adicionales a su plantilla de trabajo, podrá iniciar la automatización.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">La automatización se ha establecido para ejecutarse tres fases (configuración, Replication Schedule para binarios de Oracle, base de datos, registros y Replication Schedule solo para registros) y una fase inicial para recuperar la base de datos en un centro de recuperación ante desastres.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">Reunir los requisitos previos para las implementaciones de CVO y conector</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">Para obtener instrucciones detalladas sobre cómo obtener las claves y los tokens necesarios para la visita Protección de datos de CVO <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;strong class="big"&gt; de &lt;/strong&gt; &lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Entorno Oracle</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">*Entorno Ansible*</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 y superior</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Bibliotecas Python - netapp-lib - xmltodict - jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">*ONTAP*</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP versión 9.8 +</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">Dos agregados de datos</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">se han creado nfs vlan e ifgrp</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">*Servidor(s) Oracle*</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">Interfaces de red para NFS, público y gestión opcional</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">Entorno de Oracle existente en origen y sistema operativo Linux equivalente en destino (sitio de recuperación ante desastres o cloud público)</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;strong class="big"&gt; &lt;/strong&gt; de O</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Establezca el espacio de intercambio adecuado en la instancia de Oracle EC2; de forma predeterminada, algunas instancias de EC2 se implementan con 0 swap</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">*Cloud Manager/AWS*</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">Acceso a AWS/clave secreta</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">Cuenta de Cloud Manager de NetApp</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">Token de actualización de Cloud Manager de NetApp</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">Detalles de automatización</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">Esta puesta en marcha automatizada se ha diseñado con un único libro de aplicaciones de Ansible que consiste en tres roles independientes. Los roles están destinados a configuraciones de ONTAP, Linux y Oracle. La siguiente tabla describe qué tareas se automatizan.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Libro de estrategia</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">*ontap_setup*</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">Comprobación previa del entorno de ONTAP</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">Creación de LIF de interconexión de clústeres en el clúster de origen (OPCIONAL)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">Creación de LIF de interconexión de clústeres en el clúster de destino (OPCIONAL)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">Creación de relaciones entre iguales de clústeres y SVM</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">Creación de SnapMirror de destino e inicialización de volúmenes de Oracle designados</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">*ora_replication_cg*</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">Habilite el modo de backup para cada base de datos en /etc/oratab</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Snapshot tomada de volúmenes binarios y de bases de datos de Oracle</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror actualizado</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">Desactive el modo de backup para cada base de datos en /etc/oratab</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">*ora_replication_log*</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">Cambie el registro actual de cada base de datos en /etc/oratab</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Snapshot tomada del volumen de registro de Oracle</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">*ora_recuperación*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">Rompa la SnapMirror</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">Habilite NFS y cree una ruta de unión para los volúmenes de Oracle en el destino</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">Configurar DR Oracle Host</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Montar y verificar volúmenes de Oracle</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Recuperar e iniciar la base de datos de Oracle</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">*cvo_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">Comprobación previa del entorno</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS Configure/AWS Access Key ID/Secret Key/Default Region</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">Creación del rol de AWS</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">Creación de la instancia del conector Cloud Manager de NetApp en AWS</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">Creación de la instancia de Cloud Volumes ONTAP (CVO) en AWS</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">Añada el clúster de ONTAP de origen en las instalaciones a Cloud Manager de NetApp</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">Habilite NFS y cree una ruta de unión para los volúmenes de Oracle en la CVO de destino</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">Parámetros predeterminados</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">Para simplificar la automatización, hemos predefinido muchos parámetros de Oracle necesarios con valores predeterminados. Por lo general, no es necesario cambiar los parámetros predeterminados para la mayoría de las implementaciones. Un usuario más avanzado puede realizar cambios en los parámetros predeterminados con precaución. Los parámetros predeterminados se encuentran en cada carpeta de funciones en el directorio por defecto.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">Licencia</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Debe leer la información de la licencia como se indica en el repositorio de Github. Al acceder, descargar, instalar o utilizar el contenido de este repositorio, acepta los términos de la licencia establecidos <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">Tenga en cuenta que existen ciertas restricciones en la producción y/o uso compartido de cualquier trabajo derivado con el contenido de este repositorio. Asegúrese de leer los términos del <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> antes de utilizar el contenido. Si no acepta todos los términos, no acceda, descargue ni utilice el contenido de este repositorio.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">Aquí encontrará información detallada sobre los procedimientos de AWX/Tower</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">Una vez que esté listo, haga clic en <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="3282bd4b5c29b5e9be65469e592bba18" category="doc">Modernización del entorno Microsoft SQL Server</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">Optimice las operaciones y libere todo el potencial de sus datos, ya sea en las instalaciones o en el cloud.</block>
  <block id="b5b095487ccabae138c7872353cadbe6" category="paragraph"><block ref="b5b095487ccabae138c7872353cadbe6" category="inline-link-macro-rx"></block></block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">Esta sección describe los procedimientos de implementación de la base de datos personalizada RDS de Oracle con almacenamiento FSX.</block>
  <block id="a73e5c65844b18c49122a8a79ef3fa65" category="doc">Procedimientos detallados de puesta en marcha de Oracle en Azure VM y Azure NetApp Files</block>
  <block id="f8de11946f5850d6f1597a7cf5fc2234" category="inline-link-macro">Anterior: Factores a considerar.</block>
  <block id="e9704920b930163220a6e7564d7d680e" category="paragraph"><block ref="e9704920b930163220a6e7564d7d680e" category="inline-link-macro-rx"></block></block>
  <block id="cf2fb9f52eae11aaa1b6818cc22ade30" category="section-title">Ponga en marcha una máquina virtual de Azure con ANF para Oracle a través de la consola del portal de Azure</block>
  <block id="5e89dc82cb54763baa7cece42e7c3189" category="paragraph">Si es nuevo en Azure, primero tiene que configurar un entorno de cuenta de Azure. Esto incluye registrarse a su organización para utilizar Azure Active Directory. La siguiente sección es un resumen de estos pasos. Para obtener más detalles, consulte la documentación específica de Azure vinculada.</block>
  <block id="c743c9c56cd6cc2acf874405ef178af3" category="section-title">Cree y consuma recursos de Azure</block>
  <block id="cc59653114a0ca329e90c87f8de8f2da" category="paragraph">Después de configurar su entorno de Azure y se crea una cuenta y se asocia con una suscripción, puede iniciar sesión en el portal de Azure con la cuenta para crear los recursos necesarios para ejecutar Oracle.</block>
  <block id="4848dfd418cc69fdc8a92da472ac41b8" category="section-title">1. Crear una red virtual o vnet</block>
  <block id="dd587303db328c6fc30f15fbf133eade" category="paragraph">La red virtual de Azure (vnet) es el elemento básico fundamental para su red privada en Azure. Vnet permite que muchos tipos de recursos de Azure, como los equipos virtuales de Azure, se comuniquen de forma segura entre sí, Internet y redes en las instalaciones. Antes de aprovisionar una máquina virtual de Azure, primero se debe configurar un vnet (donde se pone en marcha una máquina virtual).</block>
  <block id="2b9029fce84bbf7056c94e4b86015679" category="inline-link-macro">Cree una red virtual mediante el portal de Azure</block>
  <block id="698a842fc17e080abbf6b6796628879b" category="paragraph">Consulte <block ref="f497c9708f9505977884a23053323735" category="inline-link-macro-rx"></block> Para crear un vnet.</block>
  <block id="66d98f4e89afee6dc557332b0e9ebe43" category="section-title">2. Cree una cuenta de almacenamiento de NetApp y un pool de capacidad para ANF</block>
  <block id="fecd60b0aedf111caefb4cf98b8d7be5" category="paragraph">En esta situación de puesta en marcha, se aprovisiona un SO de Azure VM con almacenamiento Azure normal, pero los volúmenes ANF se aprovisionan para ejecutar la base de datos de Oracle a través de NFS. En primer lugar, debe crear una cuenta de almacenamiento de NetApp y un pool de capacidad para alojar los volúmenes de almacenamiento.</block>
  <block id="76dc01e3f39d83b88a3d3ad36c338654" category="inline-link-macro">Configure Azure NetApp Files y cree un volumen NFS</block>
  <block id="8a57d5f988c678cd141c2f704e110472" category="paragraph">Consulte <block ref="2337ae471c0cc5402cdba65ad3b4dc78" category="inline-link-macro-rx"></block> Para configurar un pool de capacidad de ANF.</block>
  <block id="ed39ba49be7769bdf483ae876d88cdff" category="section-title">3. Aprovisione Azure VM para Oracle</block>
  <block id="acb4908e71af4ce0945c90f9039d0fc2" category="paragraph">En función de su carga de trabajo, determine qué tipo de equipo virtual de Azure necesita y el tamaño de vCPU y RAM de equipo virtual que se va a poner en marcha para Oracle. A continuación, desde la consola de Azure, haga clic en el icono de máquina virtual para iniciar el flujo de trabajo de implementación de máquina virtual.</block>
  <block id="20d1e12ba2a72916f3917e44ff29b40a" category="list-text">En la página de Azure VM, haga clic en *Crear* y, a continuación, elija *máquina virtual de Azure*.</block>
  <block id="94f088d23454b3c408a17cfff3cb8989" category="inline-image-macro">Esta captura de pantalla muestra la lista de máquinas virtuales de Azure disponibles.</block>
  <block id="e28fc410c2020dcbd93af60f3d700d99" category="paragraph"><block ref="e28fc410c2020dcbd93af60f3d700d99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78ba4b8df4acae5536f056217b16c353" category="list-text">Elija el ID de suscripción de la implementación y elija el grupo de recursos, la región, el nombre de host, la imagen de máquina virtual, el tamaño y método de autenticación. Vaya a la página Disk.</block>
  <block id="cbbcba216ab68f94c8fab62d9c907a00" category="inline-image-macro">Esta captura de pantalla muestra la entrada de la página Crear una máquina virtual.</block>
  <block id="825d4c0973e48f04ab75cc30df85bbdc" category="inline-image-macro">Esta captura de pantalla muestra entradas adicionales para la página Crear una máquina virtual.</block>
  <block id="84982a7e7b9cc89bde9621d68800978e" category="paragraph"><block ref="a493253d19b28a6711494154a3160350" category="inline-image-macro-rx" type="image"></block>
<block ref="81b338659efc8df55ae98546f396c5b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c435f9a03a03e7cff44b06c9efafa31" category="list-text">Elija *SSD premium* para la redundancia local del SO y deje el disco de datos vacío porque los discos de datos están montados desde el almacenamiento ANF. Vaya a la página Networking.</block>
  <block id="04faa74bfe9ea34a9831d24d039dc159" category="inline-image-macro">Esta captura de pantalla muestra la entrada de la página Crear discos de máquina virtual.</block>
  <block id="2e21daafaa3607d62dda1a3411975b12" category="paragraph"><block ref="2e21daafaa3607d62dda1a3411975b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c5742f2bffff7dd4a50e578bfb093b" category="list-text">Seleccione el vnet y la subred. Asigne una IP pública para el acceso externo a una máquina virtual. A continuación, vaya a la página Management.</block>
  <block id="0c0077e9a9d4700a64e70d30e9d110df" category="inline-image-macro">Esta captura de pantalla muestra información adicional para la página Crear una máquina virtual.</block>
  <block id="4aea6dbf72aa0b36bd98ced95acebcbd" category="paragraph"><block ref="4aea6dbf72aa0b36bd98ced95acebcbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5e4bb7568c6e8fb6a1f49aea08e975" category="list-text">Mantenga todos los valores predeterminados de Management y desplácese a la página Advanced.</block>
  <block id="45291c6293e8de1084c3b8de71bfe120" category="inline-image-macro">Esta captura de pantalla muestra la entrada de la página Crear una máquina virtual Management.</block>
  <block id="b031dac11379aafec2eb9832f71648ba" category="paragraph"><block ref="b031dac11379aafec2eb9832f71648ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22b5d3beb0289dfe21618d5664538321" category="list-text">Conserve todos los valores predeterminados en la página Advanced a menos que necesite personalizar una máquina virtual tras la implementación con scripts personalizados. A continuación, vaya a la página Etiquetas.</block>
  <block id="1a911a2f1237ad150a29236bcfe044a0" category="inline-image-macro">Esta captura de pantalla muestra la entrada de la página Create a Virtual Machine Advanced.</block>
  <block id="00d8612fb98dc237476c6ecd9e0f52c9" category="paragraph"><block ref="00d8612fb98dc237476c6ecd9e0f52c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46dfe2059392afeb84a872afb7cd09d5" category="list-text">Añada una etiqueta para la máquina virtual si lo desea. A continuación, vaya a la página revisar + crear.</block>
  <block id="85e3843de649be49b63e3b04c6887bcd" category="inline-image-macro">Esta captura de pantalla muestra la entrada de la página Crear una máquina virtual Etiquetas.</block>
  <block id="ddeecdecd575fb71cf4e83d7f09717bc" category="paragraph"><block ref="ddeecdecd575fb71cf4e83d7f09717bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a6346e9ebfe8164361d5e2facffb62" category="list-text">El flujo de trabajo de implementación ejecuta una validación en la configuración y, si se supera la validación, haga clic en *Crear* para crear la VM.</block>
  <block id="dec1fd75845506029d8751bb7979c797" category="inline-image-macro">"Esta captura de pantalla muestra la entrada de la página Crear una máquina virtual de revisión y creación".</block>
  <block id="786b4cd98c208b72f71277850831c1aa" category="paragraph"><block ref="786b4cd98c208b72f71277850831c1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c18c3fe2e695bda0cb8b3e7ecccbdc4e" category="section-title">4. Aprovisionar volúmenes de base de datos ANF para Oracle</block>
  <block id="f162c2b2b89920293c1f24ac435c520e" category="paragraph">Debe crear tres volúmenes NFS para un pool de capacidad ANF para los volúmenes binarios de Oracle, datos y registro respectivamente.</block>
  <block id="09d8c19d5844128b31e1fa195808b215" category="list-text">Desde la consola de Azure, en la lista de servicios de Azure, haga clic en Azure NetApp Files para abrir un flujo de trabajo de creación de volúmenes. Si tiene más de una cuenta de almacenamiento de ANF, haga clic en la cuenta desde la cual desea aprovisionar volúmenes.</block>
  <block id="733cf6b848c8e38a49b4b604225141a5" category="inline-image-macro">Esta captura de pantalla muestra la página de Azure Services, con ANF resaltado.</block>
  <block id="cc553796f259bc80d8c801687c0c1cd0" category="paragraph"><block ref="cc553796f259bc80d8c801687c0c1cd0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8972cd5a80e6e385a27023ce45537a9" category="list-text">En su cuenta de almacenamiento de NetApp, haga clic en *volúmenes* y, a continuación, en *Añadir volumen* para crear nuevos volúmenes de Oracle.</block>
  <block id="c8ce9170654447aba6747494e61bf3a2" category="inline-image-macro">Esta captura de pantalla muestra la pantalla de destino de una cuenta de almacenamiento de NetApp.</block>
  <block id="b0d2d575f2aee1703b6e2896d43b72f9" category="inline-image-macro">Esta captura de pantalla muestra los volúmenes disponibles para la cuenta de almacenamiento de NetApp.</block>
  <block id="3371cc932d04403ab2cd0788634d63e5" category="paragraph"><block ref="7266705f76a6cb3a106c34a6e8dc5540" category="inline-image-macro-rx" type="image"></block>
<block ref="f59831fbf7eaa0d216e8685698d0c55b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbeaec71dc2b8275a14b23283d51cc04" category="list-text">Como práctica recomendada, identifique los volúmenes de Oracle con el nombre de host de VM como prefijo y, a continuación, seguido del punto de montaje en el host, como u01 para el binario de Oracle, u02 para los datos de Oracle y u03 para el registro de Oracle. Elija el mismo vnet para el volumen que para el equipo virtual. Haga clic en *Siguiente: Protocolo&gt;*.</block>
  <block id="ce4ff1bdb6d954e6967a7c241ff89518" category="inline-image-macro">Pantalla de creación de volumen.</block>
  <block id="bacf4983022360caacd6f75352136f59" category="paragraph"><block ref="bacf4983022360caacd6f75352136f59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b50bdcda066df8ed373847c60bc2f546" category="list-text">Elija el protocolo NFS, añada la dirección IP del host de Oracle al cliente permitido y elimine la política predeterminada que permite todas las direcciones IP 0.0.0.0/0. A continuación, haga clic en *Siguiente: Etiquetas&gt;*.</block>
  <block id="f8bc211f91c2b350b268959a57418393" category="inline-image-macro">Entrada de protocolo en la pantalla Volume Creation.</block>
  <block id="8ac138d8c4a217ce018b45be622db1ed" category="paragraph"><block ref="8ac138d8c4a217ce018b45be622db1ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fffcdc9cd5233d4718046c8f6d19c80b" category="list-text">Añada una etiqueta de volumen si lo desea. A continuación, haga clic en *revisar + Crear&gt;*.</block>
  <block id="05864b350d713935d13966f3c8fcbcd7" category="inline-image-macro">Entrada de etiquetas en la pantalla creación de volúmenes.</block>
  <block id="9bead8568a27fcf83faf41e77f52b246" category="paragraph"><block ref="9bead8568a27fcf83faf41e77f52b246" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e574c0c875926f1fe654026995f3543" category="list-text">Si la validación se supera, haga clic en *Crear* para crear el volumen.</block>
  <block id="4a585922412f050ac4a7fbcc34a2655b" category="inline-image-macro">Revise y cree la etapa de la pantalla Volume Creation.</block>
  <block id="e9c713f1ad3a3f0b14801d722fb77f16" category="paragraph"><block ref="e9c713f1ad3a3f0b14801d722fb77f16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d2dbc217706d8bb1248bc209e0ab9da" category="section-title">Instale y configure Oracle en Azure VM con ANF</block>
  <block id="7beaf3d9487c79b7245a1d9ae42d46aa" category="paragraph">El equipo de soluciones de NetApp ha creado muchos kits de herramientas de automatización basados en Ansible para ayudarle a poner en marcha Oracle en Azure con fluidez. Siga estos pasos para implementar Oracle en una máquina virtual de Azure.</block>
  <block id="0c782f45b1de4e6d016eafeeb60d286f" category="section-title">Configure una controladora de Ansible</block>
  <block id="58a105c56c05508f7233082bc282a654" category="paragraph">Si no ha configurado una controladora Ansible, consulte <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block>, Que tiene instrucciones detalladas sobre cómo configurar un controlador de Ansible.</block>
  <block id="ce9ef6052d2c6ac4b97c01049ee4ec2b" category="section-title">Obtenga el kit de herramientas de automatización de la implantación de Oracle</block>
  <block id="52eae91ee8ea917bc73df6d9f1792469" category="paragraph">Clone una copia del kit de herramientas de puesta en marcha de Oracle en el directorio inicial con el ID de usuario que utiliza para iniciar sesión en la controladora de Ansible.</block>
  <block id="19cd6e3dfb797a7325548b346dc358f1" category="section-title">Ejecute el kit de herramientas con su configuración</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="inline-link-macro">Puesta en marcha de la interfaz de línea de comandos Oracle 19c Database</block>
  <block id="aa98393908153ea46a2cef869e7dd100" category="paragraph">Consulte <block ref="e7ab084e08308da08da1b2dd8151530b" category="inline-link-macro-rx"></block> Para ejecutar el libro de estrategia con la CLI. Puede ignorar la porción ONTAP de la configuración de variables en el archivo VARS global cuando crea volúmenes de base de datos desde la consola de Azure en lugar de la CLI.</block>
  <block id="24e16cc700e2ced028e529370af380e1" category="admonition">Por defecto, el kit de herramientas implementa Oracle 19c con RU 19.8. Puede adaptarse fácilmente a cualquier otro nivel de parche con cambios de configuración predeterminados menores. También se implementan en el volumen de datos los archivos de registro activo de la base de datos de inicialización predeterminados. Si necesita archivos de registro activos en el volumen de registro, se deben reubicar tras la implementación inicial. Póngase en contacto con el equipo de soluciones de NetApp para obtener ayuda si es necesario.</block>
  <block id="dd52a71d2066e527d28efdbd46784e07" category="section-title">Configure la herramienta de backup AzAcSnap para realizar copias Snapshot coherentes con las aplicaciones para Oracle</block>
  <block id="211e60df4f320c617afaa9a96f62758f" category="paragraph">La herramienta Snapshot para aplicaciones de Azure (AzAcSnap) es una herramienta de línea de comandos que permite la protección de datos de bases de datos de terceros al gestionar todas las orquestación necesarias para ponerlas en un estado coherente con las aplicaciones antes de tomar una copia Snapshot de almacenamiento. A continuación, devuelve estas bases de datos a un estado operativo. NetApp recomienda la instalación de la herramienta en el host del servidor de bases de datos. Consulte los siguientes procedimientos de instalación y configuración.</block>
  <block id="40390144ce134a2e38bfef9f590f867b" category="section-title">Instale la herramienta AzAcSnap</block>
  <block id="c2d834909e264a2f3bf3d3facd27740b" category="inline-link-macro">El instalador de AzArcSnap</block>
  <block id="aed9be57adbc2906c27b7f325e1322aa" category="list-text">Obtenga la versión más reciente de <block ref="696590d44d21e9b71649cae0895a0bca" category="inline-link-macro-rx"></block>.</block>
  <block id="243004130aa732bde904924170fa2e5c" category="list-text">Copie el instalador automático descargado en el sistema de destino.</block>
  <block id="1aa45c54511185e4e2043ee91e8969bc" category="list-text">Ejecute el instalador automático como usuario root con la opción de instalación predeterminada. Si es necesario, haga que el archivo sea ejecutable mediante el<block ref="48c01707d676030dd223de543c6beb09" prefix=" " category="inline-code"></block> comando.</block>
  <block id="483944250a0e1f955ad6fec7c6578bde" category="section-title">Configurar la conectividad de Oracle</block>
  <block id="b6f7df8a3ada5b45cee3400740b83c9a" category="paragraph">Las herramientas Snapshot se comunican con la base de datos Oracle y necesitan un usuario de base de datos con los permisos adecuados para habilitar o deshabilitar el modo de backup.</block>
  <block id="6cd11918e51f60b6ce021e9d56c9e74a" category="section-title">1. Configurar el usuario de la base de datos AzAcSnap</block>
  <block id="84fe6666ea577b7ede5c61912d97705e" category="paragraph">Los siguientes ejemplos muestran la configuración del usuario de la base de datos Oracle y el uso de sqlplus para la comunicación con la base de datos Oracle. Los comandos de ejemplo configuran un usuario (AZACSNAP) en la base de datos de Oracle y cambian la dirección IP, los nombres de usuario y las contraseñas según corresponda.</block>
  <block id="342df2b2fb63c81cdd53e5e7bc5d00b9" category="list-text">Desde la instalación de la base de datos Oracle, inicie sqlplus para iniciar sesión en la base de datos.</block>
  <block id="ab0840eee4ba613870ae404c907c1948" category="list-text">Cree el usuario.</block>
  <block id="e90b9dc19df07f784e3fc408169077df" category="list-text">Conceda los permisos de usuario. En este ejemplo se establece el permiso para que el usuario AZACSNAP habilite la colocación de la base de datos en el modo de copia de seguridad.</block>
  <block id="f508d634fc1aa5df7fed84e6b58afce9" category="list-text">Cambie la fecha de caducidad de la contraseña del usuario predeterminada a ilimitada.</block>
  <block id="bc5fff092e99ce3d1966b94061cb5953" category="list-text">Validar la conectividad azacsnap para la base de datos.</block>
  <block id="8e0d0fb1cb3a50066ecd397700dfd22e" category="section-title">2. Configurar azacsnap de usuario de Linux para el acceso a la base de datos con la cartera de Oracle</block>
  <block id="7140a904f4b795616fdc3c3efbdcd066" category="paragraph">La instalación predeterminada de AzAcSnap crea un usuario de azacsnap OS. Su entorno Bash Shell debe estar configurado para el acceso a la base de datos Oracle con la contraseña almacenada en una cartera Oracle.</block>
  <block id="c54cf7bb99b0e669ce6dc05ec8272470" category="list-text">Como usuario raíz, ejecute el<block ref="760381f8107a856bc583301b7b272917" prefix=" " category="inline-code"></block> Comando para identificar las variables ORACLE_HOME y ORACLE_SID en el host.</block>
  <block id="2a4941dc3f20c8f34a09b066691e66a5" category="list-text">Añada LAS variables ORACLE_HOME, ORACLE_SID, TNS_ADMIN y PATH al perfil bash de usuario azacsnap. Cambie las variables según sea necesario.</block>
  <block id="e3c85fad3d30c470aac355430e98dc21" category="list-text">A medida que el usuario de Linux azacsnap, cree la cartera. Se le solicitará la contraseña de la cartera.</block>
  <block id="83617bd12022f2dd9ba94816c7e56670" category="list-text">Agregue las credenciales de cadena de conexión a Oracle Wallet. En el siguiente comando de ejemplo, AZACSNAP es el ConnectString que va a utilizar AzAcSnap, azacsnap es el usuario de la base de datos Oracle y AzPasswd1 es la contraseña de la base de datos de Oracle User. Se le volverá a solicitar la contraseña de la cartera.</block>
  <block id="02f08719de6240015b4e67725107792a" category="list-text">Cree el<block ref="9de875b13677cf9b036a438bf9aedf5c" prefix=" " category="inline-code"></block> archivo. En el siguiente comando de ejemplo, EL HOST debe estar configurado con la dirección IP de la base de datos Oracle y el SID del servidor debe estar configurado con el SID de la base de datos de Oracle.</block>
  <block id="0eec77cc5ed96c42afb08c83ea3f1e3b" category="list-text">Cree el<block ref="0501c2d94325e267bf15055591fb8157" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="cafefcc0e796f3e73bc39de23dfc6b68" category="list-text">Pruebe el acceso a Oracle con la cartera.</block>
  <block id="8bf6bfb76bcf25b5e1bb9c1d4ede3d34" category="paragraph">El resultado esperado del comando: [Azacsnap@acao-ora01 ~]$ sqlplus /@AZACSNAP como SYSBACKUP</block>
  <block id="9fac4799a7cb503012dac3d131cf3c15" category="paragraph">SQL*Plus: Lanzamiento 19.0.0.0.0 - producción el Jue Sep 8 18:02:07 2022 Versión 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. Todos los derechos reservados.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">Conectado a: Base de datos Oracle 19c Enterprise Edition Versión 19.0.0.0.0 - Versión de producción 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="54eb020b97d7e8a9f56d67e93754e270" category="section-title">Configurar la conectividad ANF</block>
  <block id="8c9356aaf30e863db064ba22b7d4b204" category="paragraph">En esta sección se explica cómo habilitar la comunicación con Azure NetApp Files (con una máquina virtual).</block>
  <block id="d78964ac0334c0f69ef24aada9864028" category="list-text">En una sesión de Azure Cloud Shell, asegúrese de que ha iniciado sesión en la suscripción que desea asociar al principal de servicio de forma predeterminada.</block>
  <block id="8611ff0fcccf2f05ff0dbde909379c14" category="list-text">Si la suscripción no es correcta, utilice el siguiente comando:</block>
  <block id="2d66e076b40e24c73ffa7a1704d985db" category="list-text">Cree un principal de servicio con la CLI de Azure como se muestra en el ejemplo siguiente:</block>
  <block id="707cc085819c641d15b9ea2b3b13cb53" category="paragraph">Resultado esperado:</block>
  <block id="e8e3af5b539b9415092afd10fc182ff7" category="paragraph">{ "ClientID": "00aa000a-aaaa-0000 0000-00a0-00aa000a0a", "clientSecret": "00aa000a-aaaa-0000-00a0-00aaa0", "SubscriptionId": "00aa000a-0000-00aa0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0 <block ref="abe1a2134e98a87862a225c33f62cde4" category="inline-link-rx"></block>, "ResourceManagerEndpointUrl": <block ref="5bbe1c35abcaa8749119f86fe8d12120" category="inline-link-rx"></block>, "ActiveDirectoryResourceId": <block ref="91645ab7f47cce4ce23956a6c4c7df7c" category="inline-link-rx"></block>, "SqlManagementEndpointUrl": <block ref="2ce5923f710fffcd9fdcfffa2d0db664" category="inline-link-rx"></block>, "GalleryEndpointUrl": <block ref="92fb62298a12469265ac683928098931" category="inline-link-rx"></block>, "ManagementEndpointUrl": <block ref="9a3197a885535f07c09e058a5f76aa0c" category="inline-link-rx"></block>}</block>
  <block id="c51a1e8c830ed4f63c489347dbcce1a7" category="list-text">Corte y pegue el contenido de salida en un archivo llamado<block ref="b50999884a39c5efe8da46cd87acfeb2" prefix=" " category="inline-code"></block> Se almacena en el directorio bin de usuario de Linux azacsnap y protege el archivo con los permisos de sistema adecuados.</block>
  <block id="211f39ae9cd979a9f01bb800eca0b832" category="admonition">Asegúrese de que el formato del archivo JSON es exactamente como se ha descrito anteriormente, especialmente con las direcciones URL encerradas entre comillas dobles (").</block>
  <block id="c1f6adfa882cba0dbd256d4909ac588c" category="section-title">Complete la configuración de la herramienta AzAcSnap</block>
  <block id="e0e7b63ff02eb3221940162934949dd0" category="paragraph">Siga estos pasos para configurar y probar las herramientas de snapshot. Después de realizar una prueba correcta, puede ejecutar la primera snapshot de almacenamiento coherente con la base de datos.</block>
  <block id="fe615094ac9bb468d26149280e3769d7" category="list-text">Cambiar a la cuenta de usuario de instantánea.</block>
  <block id="4ef9af49185e683998d060aa71c30e2b" category="list-text">Cambie la ubicación de los comandos.</block>
  <block id="412d274adbc3fc7cb51ab315d7a77f82" category="list-text">Configurar un archivo de detalles de copia de seguridad de almacenamiento. Esto crea un<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> archivo de configuración.</block>
  <block id="d4c18f094b4959d27f52ee2a9709a6b9" category="paragraph">El resultado esperado con tres volúmenes de Oracle:</block>
  <block id="849abd2456a4bd2ccddb94a12dfcc37d" category="paragraph">[Azacsnap@acao-ora01 bin]$ azacsnap -c configure --Configuration new Building new config file Añadir comentario al archivo de configuración (entrada en blanco para salir agregando comentarios): Oracle snapshot bkup Agregar comentario al archivo de configuración (entrada en blanco para salir agregando comentarios): Introduzca el tipo de base de datos a agregar, 'hana', 'oracle' o 'EXIT' (no)</block>
  <block id="fa7ad5b9d050b7a5baa27ffcd8863c42" category="paragraph">=== Add Oracle Database details === Oracle Database SID (por ejemplo, CDB1): ORATST Database Server's Address (nombre de host o dirección IP): 172.30.137.142 Oracle connect string (por ejemplo /@AZACSNAP): /@AZACSNAP</block>
  <block id="44b11046a63da89febd351b4213758cf" category="paragraph">=== detalles del almacenamiento de Azure NetApp Files ==¿utiliza Azure NetApp Files para la base de datos? (Y/n) [n]: Y ---- los volúmenes DE DATOS tienen la aplicación en estado coherente antes de que sean snapshot ----¿Agregar recurso Azure NetApp Files a la sección de DATOS volumen de la configuración de la base de datos? (Y/n) [n]: Y ID de recurso de volumen de almacenamiento completo de Azure NetApp Files (por ejemplo, /subscripciones/.../ResourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /subscripciones/0efa2dfb-917c-4497-b56a-b3f4eadb8111/ResourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u01 Service Key Authentication o File-ID (por ejemplo, código de archivo de archivo de archivo de autenticación principal de archivo de archivo de autenticación de código de archivo de archivo de archivo de archivo de archivo<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> oracle.json Add Azure NetApp Files resource a DATA Volume of Database Configuration? (Y/n) [n]: Y ID de recurso de volumen de almacenamiento completo de Azure NetApp Files (por ejemplo, /subscripciones/.../ResourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /subscripciones/0efa2dfb-917c-4497-b56a-b3f4eadb8111/ResourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u02 Service Key Authentication o File-ID (por ejemplo, código de archivo de archivo de archivo de autenticación principal de archivo de archivo de autenticación de código de archivo de archivo de archivo de archivo de archivo<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> oracle.json Add Azure NetApp Files resource a DATA Volume of Database Configuration? (Y/n) [n]: n ---- OTROS volúmenes son instantáneas inmediatamente sin preparar ninguna aplicación para la instantánea ---¿Añadir recurso Azure NetApp Files a OTRA sección volumen de la configuración de la base de datos? (Y/n) [n]: Y ID de recurso de volumen de almacenamiento completo de Azure NetApp Files (por ejemplo, /subscripciones/.../ResourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /subscripciones/0efa2dfb-917c-4497-b56a-b3f4eadb8111/ResourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u03 Service Key Authentication o File-ID (por ejemplo, código de archivo de archivo de archivo de autenticación principal de archivo de archivo de autenticación de código de archivo de archivo de archivo de archivo de archivo<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> ¿oracle.json Add Azure NetApp Files resource a OTROS volúmenes de la configuración de la base de datos? (s/n) [n]: n</block>
  <block id="e16c4d13d5c9c936ac3ca975a729784f" category="paragraph">=== detalles de Azure Managed Disk ==¿está utilizando los discos gestionados de Azure para la base de datos? (s/n) [n]: n</block>
  <block id="e5e08e0b27271cd7952c3cd754436294" category="paragraph">=== instancia grande de Azure (configuración básica) Detalles del almacenamiento ==¿utiliza la instancia grande de Azure (configuración básica) para la base de datos? (s/n) [n]: n</block>
  <block id="cec7485a9812da8e268c6d53917d0776" category="paragraph">Introduzca el tipo de base de datos que desea agregar, 'hana', 'oracle' o 'exit' (para no usar base de datos): Salir</block>
  <block id="c63145a4ad8c93cb8bdff88f44cf483b" category="paragraph">Editando la configuración finalizada, escribiendo el resultado en "azacsnap.json".</block>
  <block id="72b0a1cda785576a979ca4ee2e3c8c62" category="list-text">Como usuario de azacsnap Linux, ejecute el comando azacsnap test para una copia de seguridad de Oracle.</block>
  <block id="ce9bfcddebc567805a4fdb6bcdf15515" category="paragraph">[Azacsnap@acao-ora01 bin]$ azacsnap -c test --test oracle --configfile azacsnap.json COMENZAR : proceso de prueba iniciado para 'oracle' BEGIN : pruebas de Oracle DB PASADAS: Conectividad satisfactoria a Oracle DB versión 1908000000 FINAL : proceso de prueba completo para 'oracle' [azacsnap@acao-ora01 bin]$</block>
  <block id="7be23e8f29bfc799fd8fbcdc55fe0e77" category="list-text">Ejecute el primer backup de snapshot.</block>
  <block id="42481f217667e9b11be3ea64c971056a" category="inline-link-macro">Siguiente: Protección de bases de datos.</block>
  <block id="d39c73ea41fa36408b518637e929e754" category="paragraph"><block ref="d39c73ea41fa36408b518637e929e754" category="inline-link-macro-rx"></block></block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">Esta solución está diseñada en un entorno de cloud híbrido para admitir bases de datos de producción en las instalaciones que pueden usar en ráfagas en todos los clouds públicos populares para operaciones de desarrollo, pruebas y recuperación ante desastres.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">Requisitos de SnapCenter</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">Anterior: Arquitectura de la solución.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">Esta solución admite todas las bases de datos compatibles actualmente con SnapCenter, aunque solo se muestran aquí las bases de datos de Oracle y SQL Server. Esta solución se valida con cargas de trabajo de bases de datos virtualizadas, aunque también son compatibles las cargas de trabajo con configuración básica.</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">Asumimos que los servidores de bases de datos de producción se alojan en las instalaciones con volúmenes de bases de datos presentados a los hosts de bases de datos de un clúster de almacenamiento de ONTAP. El software SnapCenter se instala en las instalaciones para realizar tareas de backup de bases de datos y replicación de datos en el cloud. Se recomienda utilizar una controladora de Ansible, pero no es necesario para la automatización de la puesta en marcha de la base de datos o para la sincronización de la configuración del kernel de sistema operativo y la base de datos con una instancia de recuperación ante desastres en espera o instancias de desarrollo y pruebas en el cloud público.</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">*En el local*</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">Cualquier base de datos y versiones que SnapCenter admita</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 o superior</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 o superior</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">Clúster de ONTAP 9.x.</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">LIF de interconexión de clústeres configuradas</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">Conectividad desde las instalaciones a un VPC de cloud (VPN, interconexión, etc.)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">Puertos de red abiertos - ssh 22 - tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">*Cloud: AWS*</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Conector de Cloud Manager</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">Coincidencia de instancias de EC2 del sistema operativo de la base de datos con las instalaciones</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">*Cloud - Azure*</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">Comparación de máquinas virtuales de Azure con sistema operativo de base de datos a las instalaciones</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">*Cloud - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">Emparejamiento de instancias de Google Compute Engine del sistema operativo de base de datos a las instalaciones</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">Siguiente: Requisitos previos de la configuración.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">En esta sección se describe el proceso de puesta en marcha de Cloud Manager y Cloud Volumes ONTAP en AWS.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">Introducción al cloud público de AWS</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">Anterior: Introducción a las instalaciones.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">Cloud público de AWS</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">Para facilitar el seguimiento de las cosas, hemos creado este documento a partir de una puesta en marcha en AWS. Sin embargo, el proceso es muy similar para Azure y GCP.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. Control previo al vuelo</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">Antes de la puesta en marcha, asegúrese de que se ha implementado la infraestructura para permitir la puesta en marcha en la siguiente etapa. Esto incluye lo siguiente:</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">Cuenta de AWS</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">VPC en su región de preferencia</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">Subred con acceso a Internet pública</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">Permisos para añadir roles IAM a la cuenta de AWS</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">Una clave secreta y una clave de acceso para el usuario de AWS</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. Pasos para poner en marcha Cloud Manager y Cloud Volumes ONTAP en AWS</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">Documentación sobre cloud de NetApp</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Existen muchos métodos para poner en marcha Cloud Manager y Cloud Volumes ONTAP; este método es el más sencillo pero requiere el mayor número de permisos. Si este método no es adecuado para su entorno AWS, consulte<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Ponga en marcha el conector Cloud Manager</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">Cloud Central de NetApp</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">Vaya a.<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> e inicie sesión o regístrese.</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">Después de iniciar sesión, se le debe llevar al lienzo.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">Haga clic en "Add Working Environment" y elija Cloud Volumes ONTAP en AWS. Aquí, también puede elegir si desea poner en marcha un sistema de nodo único o un par de alta disponibilidad. He decidido implementar un par de alta disponibilidad.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">Si no se ha creado ningún conector, aparece una ventana emergente que le pide que cree un conector.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">Haga clic en lets Start y, a continuación, seleccione AWS.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">Página de políticas de NetApp</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">Introduzca la clave secreta y la clave de acceso. Asegúrese de que el usuario tiene los permisos correctos descritos en<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">Asigne al conector un nombre y utilice una función predefinida como se describe en<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> O pida a Cloud Manager que cree la función que usted desempeña.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">Proporcione la información de red necesaria para implementar el conector. Verifique que el acceso saliente a Internet esté habilitado por:</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">Dar al conector una dirección IP pública</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">Dar al conector un proxy a través del cual trabajar</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">Dar al conector una ruta a Internet pública a través de una puerta de enlace de Internet</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">Proporcione comunicación con el conector a través de SSH, HTTP y HTTPS ya sea proporcionando un grupo de seguridad o creando un nuevo grupo de seguridad. Sólo he habilitado el acceso al conector desde mi dirección IP.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">Revise la información de la página de resumen y haga clic en Agregar para implementar el conector.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">El conector ahora se pone en marcha utilizando una pila de formación de cloud. Puede supervisar su progreso desde Cloud Manager o a través de AWS.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">Una vez completada la implementación, aparece una página Success.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Ponga en marcha Cloud Volumes ONTAP</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">Seleccione AWS y el tipo de implementación según sus requisitos.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">Si no se ha asignado ninguna suscripción y desea comprarla con PAYGO, seleccione Editar credenciales.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">Seleccione Agregar suscripción.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">Elija el tipo de contrato al que desea suscribirse. Elegí el pago por uso.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">Se le redirigirá a AWS; elija continuar Suscribirse.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">Suscríbase y se le redirigirá a Cloud Central de NetApp. Si ya se ha suscrito y no se redirecciona, elija el enlace "haga clic aquí".</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Se le redirigirá a Cloud Central, donde debe dar un nombre a su suscripción y asignarla a su cuenta de Cloud Central.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">Cuando se realiza correctamente, aparece una página de Marca de verificación. Vuelva a la pestaña Cloud Manager.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">La suscripción aparece ahora en Cloud Central. Haga clic en aplicar para continuar.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">Introduzca los detalles del entorno de trabajo como:</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">Nombre del clúster</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">Contraseña del clúster</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">Etiquetas de AWS (opcional)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">Página de inicio de cloud de NetApp</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">Elija los servicios adicionales que le gustaría poner en marcha. Para obtener más información sobre estos servicios, visite la<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">Elija si desea implementar en varias zonas de disponibilidad (reguarida tres subredes, cada una en una zona AZ diferente) o una única zona de disponibilidad. Elegí varios AZs.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">Elija la región, VPC y grupo de seguridad del clúster en el que se pondrá en marcha. En esta sección, también se asignan las zonas de disponibilidad por nodo (y mediador), así como las subredes que ocupan.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">Elija los métodos de conexión tanto para los nodos como para el mediador.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">El mediador requiere comunicación con las API de AWS. No se requiere una dirección IP pública mientras se pueda acceder a las API después de que se haya puesto en marcha la instancia del mediador EC2.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">Documentación en cloud de NetApp</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">Las direcciones IP flotantes se usan para permitir el acceso a las diferentes direcciones IP que usa Cloud Volumes ONTAP, incluidas las IP de administración de clústeres y servicio de datos. Deben ser direcciones que no se puedan enrutar ya dentro de su red y que se agreguen a tablas de rutas en su entorno AWS. Estos son necesarios para habilitar direcciones IP constantes para un par de alta disponibilidad durante la conmutación por error. Puede encontrar más información acerca de las direcciones IP flotantes en el<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">Seleccione a qué tablas de rutas se agregan las direcciones IP flotantes. Los clientes utilizan estas tablas de ruta para comunicarse con Cloud Volumes ONTAP.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">Elija si habilitar el cifrado gestionado de AWS o AWS KMS para cifrar los discos raíz, de arranque y de datos de ONTAP.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">Elija su modelo de licencias. Si no sabe qué elegir, póngase en contacto con su representante de NetApp.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">Seleccione la configuración que mejor se ajuste a su caso de uso. Esto se relaciona con las consideraciones de tamaño que se tratan en la página de requisitos previos.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">Opcionalmente, cree un volumen. Esto no es necesario, ya que los siguientes pasos utilizan SnapMirror, que nos crea los volúmenes.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">Revise las selecciones que se han realizado y marque las casillas para verificar que entiende que Cloud Manager pone en marcha recursos en su entorno AWS. Al terminar, haga clic en Go.</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP inicia ahora su proceso de puesta en marcha. Cloud Manager utiliza las API de AWS y las pilas de formación de cloud para poner en marcha Cloud Volumes ONTAP. A continuación, configura el sistema de acuerdo con sus especificaciones, lo que le proporciona un sistema listo para usar que se puede utilizar al instante. El tiempo de este proceso varía en función de las selecciones realizadas.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">Puede supervisar el progreso navegando hasta la línea de tiempo.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">La línea de tiempo actúa como una auditoría de todas las acciones realizadas en Cloud Manager. Puede ver todas las llamadas API que realiza Cloud Manager durante la configuración en AWS y en el clúster de ONTAP. Esto también se puede utilizar de manera eficaz para solucionar cualquier problema que tenga.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">Una vez completada la implementación, aparece el clúster CVO en el lienzo, que es la capacidad actual. El clúster de ONTAP en su estado actual está totalmente configurado para permitir una experiencia realmente lista para usar.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">Configure SnapMirror de las instalaciones al cloud</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">Ahora que tiene un sistema ONTAP de origen y un sistema ONTAP de destino implementados, puede replicar los volúmenes que contienen datos de base de datos en el cloud.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">Matriz de compatibilidad de SnapMirror</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">Para obtener una guía sobre las versiones compatibles de ONTAP para SnapMirror, consulte<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">Haga clic en el sistema ONTAP de origen (en las instalaciones) y arrástrelo y colóquelo en el destino, seleccione replicación &gt; Habilitar o seleccione replicación &gt; Menú &gt; replicar.</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Seleccione Habilitar.</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">U Opciones.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">Replicar.</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">Si no ha arrastrado ni solado, elija el clúster de destino al que se va a replicar.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">Elija el volumen que desea replicar. Replicamos los datos y todos los volúmenes de registro.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">Elija el tipo de disco de destino y la política de organización en niveles. Para la recuperación ante desastres, recomendamos un SSD como tipo de disco y mantener la organización en niveles de los datos. Organización en niveles de datos ordena los datos duplicados en un almacenamiento de objetos de bajo coste y ahorra dinero en discos locales. Cuando se rompe la relación o se clona el volumen, los datos utilizan el almacenamiento local rápido.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">Seleccione el nombre del volumen de destino: Se ha elegido<block ref="47456946fa180c1578446a0fa28fca75" prefix=" " category="inline-code"></block>.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">Seleccione la tasa de transferencia máxima para la replicación. Esto le permite ahorrar ancho de banda si dispone de una conexión de bajo ancho de banda a la nube, como una VPN.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">Defina la política de replicación. Elegimos un duplicado, que toma el conjunto de datos más reciente y lo replica en el volumen de destino. También puede elegir una política diferente en función de sus requisitos.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">Elija la programación para activar la replicación. NetApp recomienda establecer una programación "diaria" de para el volumen de datos y una programación "por hora" para los volúmenes de registro, aunque esto se puede modificar en función de los requisitos.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">Revise la información introducida, haga clic en Go para activar el par de clústeres y la SVM del mismo nivel (si esta es la primera vez que se replica entre los dos clústeres), y, a continuación, implemente e inicialice la relación de SnapMirror.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">Continúe este proceso para los volúmenes de datos y los volúmenes de registro.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">Para comprobar todas sus relaciones, acceda a la pestaña Replication de Cloud Manager. Aquí puede gestionar sus relaciones y comprobar su estado.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">Una vez que se han replicado todos los volúmenes, tiene un estado constante y listo para pasar a los flujos de trabajo de recuperación ante desastres y de desarrollo y pruebas.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. Implemente la instancia de computación de EC2 para las cargas de trabajo de bases de datos</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">Tipo de instancia de EC2</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS ha preconfigurado instancias informáticas de EC2 para distintas cargas de trabajo. La elección del tipo de instancia determina el número de núcleos de CPU, la capacidad de memoria, el tipo de almacenamiento y la capacidad, y el rendimiento de la red. Para los casos de uso, con la excepción de la partición del sistema operativo, el almacenamiento principal para ejecutar la carga de trabajo de la base de datos se asigna desde CVO o el motor de almacenamiento FSX ONTAP. Por lo tanto, los principales factores que se deben tener en cuenta son la elección de los núcleos de CPU, la memoria y el nivel de rendimiento de la red. Aquí pueden encontrar los tipos de instancia típicos de AWS EC2:<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">Configurar el tamaño de la instancia de computación</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">Seleccione el tipo de instancia correcto en función de la carga de trabajo requerida. Entre los factores a tener en cuenta se incluye el número de transacciones de negocio que se deben admitir, el número de usuarios simultáneos, el tamaño de los conjuntos de datos, etc.</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">La implementación de instancias de EC2 se puede iniciar a través de la consola de EC2. Los procedimientos exactos de puesta en marcha superan el alcance de esta solución. Consulte<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> para obtener más detalles.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Configuración de instancias de Linux para carga de trabajo de Oracle</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">Esta sección contiene pasos de configuración adicionales después de implementar una instancia de EC2 Linux.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">Agregue una instancia de Oracle en espera al servidor DNS para la resolución de nombres dentro del dominio de administración de SnapCenter.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">Añada un ID de usuario de gestión de Linux como las credenciales del sistema operativo SnapCenter con permisos sudo sin contraseña. Habilite el ID con la autenticación de contraseña de SSH en la instancia de EC2. (De forma predeterminada, la autenticación de contraseña SSH y sudo sin contraseñas está desactivada en instancias de EC2).</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">Configurar la instalación de Oracle de modo que coincida con la instalación de Oracle en las instalaciones, como los parches de sistema operativo, las versiones y parches de Oracle, etc.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Implementación automatizada de Oracle 19c</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">Los roles de automatización de bases de datos de Ansible de NetApp pueden aprovecharse para configurar instancias de EC2 para casos de uso de desarrollo y pruebas de bases de datos y recuperación ante desastres. El código de automatización puede descargarse del sitio de GitHub público de NetApp:<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. El objetivo consiste en instalar y configurar una pila de software de base de datos en una instancia de EC2 para coincidir con las configuraciones de sistemas operativos y bases de datos locales.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">Configuración de instancias de Windows para carga de trabajo de SQL Server</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">En esta sección se enumeran los pasos de configuración adicionales tras la implementación inicial de una instancia de EC2 de Windows.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">Recupere la contraseña del administrador de Windows para iniciar sesión en una instancia mediante RDP.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Deshabilite el firewall de Windows, únase al host al dominio de Windows SnapCenter y agregue la instancia al servidor DNS para la resolución de nombres.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">Aprovisionar un volumen de registro de SnapCenter para almacenar los archivos de registro de SQL Server.</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Configure iSCSI en el host Windows para montar el volumen y formatear la unidad de disco.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">Automatización de NetApp</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">De nuevo, muchas de las tareas anteriores se pueden automatizar con la solución de automatización de NetApp para SQL Server. Visite el sitio de GitHub público de automatización de NetApp para comprobar las funciones y soluciones recién publicadas:<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">Siguiente: Flujo de trabajo para ráfagas de desarrollo y pruebas al cloud.</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">Tanto si va a centrarse en un cloud híbrido o en un cloud integral con bases de datos con ampliación, Azure NetApp Files ofrece opciones excelentes para poner en marcha y gestionar las cargas de trabajo de las bases de datos, a la vez que reduce el TCO y permite que los requisitos de datos se reduzcan hasta la capa de la aplicación.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">En este documento se tratan recomendaciones para la planificación, el diseño, la optimización y el escalado de implementaciones de Microsoft SQL Server con Azure NetApp Files, que pueden variar en gran medida entre implementaciones. Una solución adecuada depende tanto de los detalles técnicos de la implantación como de los requisitos empresariales que impulsan el proyecto.</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">Puntos</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">Los puntos clave de este documento son:</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">Ahora puede utilizar Azure NetApp Files para alojar la base de datos y el testigo de recurso compartido de archivos para el clúster de SQL Server.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">Puede aumentar los tiempos de respuesta de las aplicaciones y ofrecer una disponibilidad del 99.9999 % para proporcionar acceso a los datos de SQL Server cuando y donde sea necesario.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">Puede simplificar la complejidad general de la puesta en marcha y la gestión continua de SQL Server, como la segmentación de RAID, con redimensionamiento sencillo e instantáneo.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">Puede confiar en las funciones de operaciones inteligentes para ayudarle a poner en marcha bases de datos de SQL Server en cuestión de minutos y acelerar los ciclos de desarrollo.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Si Azure Cloud es el destino, Azure NetApp Files es la solución de almacenamiento adecuada para una puesta en marcha optimizada.</block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794: Bases de datos de Oracle en EF-Series de NetApp</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn, Ebin Kadavy, NetApp</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794 está pensado para ayudar a los administradores de almacenamiento y de bases de datos a poner en marcha correctamente Oracle en almacenamiento EF-Series de NetApp.</block>
  <block id="c6f1106d361e6595d08ff6340c004516" category="paragraph"><block ref="c6f1106d361e6595d08ff6340c004516" category="inline-link-macro-rx"></block></block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">Esta sección proporciona detalles sobre la validación del rendimiento y los resultados de las pruebas de rendimiento de una carga de trabajo OLTP simulada de Swingbench.</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">Validación del rendimiento y resultados de las pruebas de rendimiento</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">Anterior: Gestión de bases de datos de Oracle.</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">El objetivo de esta validación del rendimiento no es establecer ninguna Marca. En su lugar, si sigue los procedimientos de implementación y las prácticas recomendadas como se indica en esta documentación, puede esperar disponer de métricas de rendimiento similares a la puesta en marcha de su base de datos de Oracle en un cloud público.</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Utilizamos un módulo de entrada de pedido de ventas (SOE) de Swingbench para simular una carga de trabajo de tipo OLTP y aplicamos la carga de trabajo en una base de datos de Oracle implementada en una instancia de EC2 M5 con volúmenes de almacenamiento FSX en el protocolo NFS. El perfil de E/S de Swingbench predeterminado está cerca de una división de lectura/escritura de 80/20, que está cerca de un perfil de carga de trabajo de Oracle OLTP real.</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">La carga de trabajo aumenta aumentando el número de usuarios simultáneos en el cliente que realizan la entrada del pedido de ventas, la exploración, las consultas de inventario, etc. Las cifras analizadas fueron de 8, 16, 32, 64 y 128 usuarios simultáneos. El algoritmo que utiliza Swingbench es pesado en el lado del servidor para insertar volúmenes de transacciones razonables y probar los límites del servidor Oracle. Observamos que, con 128 usuarios simultáneos, la utilización de la CPU de la instancia de EC2 alcanzó un límite de capacidad aproximado del 80-90%.</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">En las siguientes secciones se ofrecen detalles de los resultados de configuración y prueba.</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">Configuración del entorno de prueba</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">Implementamos una instancia EC2 M5 con 8vCPU, 32G RAM y 10Gps de ancho de banda de red.</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">Almacenamiento FSX</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">Creamos tres volúmenes de base de datos y montó los volúmenes con NFS en una instancia de EC2 de la siguiente manera:</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/U01 - binario de Oracle</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/U02: Archivos de datos Oracle, archivo de control</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/U03 - Archivos de registro de Oracle, archivo de control</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">Guardamos dos copias de un archivo de control crítico para la redundancia.</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">El sistema de archivos FSX está configurado con una capacidad de 80,000 IOPS y un rendimiento de I/o de 2 GIB.</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Configuración de Oracle</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Instalamos la versión 19c de Oracle con el parche 19.8 de RU. DNFS se habilitó en el servidor.</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">La base de datos se implementó como una base de datos en contenedor con tres PDB. Utilizamos una instancia de PDB para las pruebas de rendimiento. La siguiente figura muestra el ajuste de tamaño del almacenamiento Oracle en los puntos de montaje NFS.</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Configuración de Swingbench</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">Hemos implementado Swingbench 2.6 (la versión más reciente) en un host de Windows con 8vCPU y 32G RAM. Utilizamos la versión 2 del módulo de prueba SOE plsql para el análisis de referencia. El perfil de carga predeterminado proporciona una relación de lectura/escritura de 80/20 para simular la carga de trabajo de transacciones de OLTP en el mundo real.</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">El factor de escala de esquema que utilizamos fue 50, que proporcionó un tamaño de carga de datos inicial de 160G y 30G de asignación de espacio temporal. En este factor de escala, el esquema de SOE proporcionó 1000 almacenes y 50 millones de clientes para la simulación del procesamiento de pedidos en línea.</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">La siguiente captura de pantalla muestra el perfil de carga de trabajo y las métricas de ejecución transaccional típicas de la interfaz de usuario de Windows de Swingbench.</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">Como muestra este gráfico, el nivel de transacción se mantuvo al mismo nivel durante la ejecución de la prueba.</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">Análisis de los resultados de las pruebas</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">Capturamos los resultados de Swingbench para cada ejecución de prueba y obtuvimos los correspondientes informes de Oracle AWR para análisis de rendimiento.</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">Desde el punto de vista del usuario final, observamos métricas clave como el volumen de transacciones y el tiempo de respuesta del usuario. Ambas métricas muestran el número de transacciones que los usuarios pueden ejecutar desde el sistema de entrada de pedidos de venta, dado el número de usuarios simultáneos que inician sesión en el sistema, así como la rapidez con la que los usuarios pueden completar transacciones y recibir respuestas después de introducir su pedido.</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">Desde el final del servidor Oracle, hemos analizado el informe de Oracle AWR para determinar los principales eventos de espera que podrían haber ralentizado las transacciones del usuario. Los 10 principales eventos de espera de Oracle indicaron que, durante las ejecuciones de pruebas de transacciones simuladas de Swingbench, el servidor de Oracle está principalmente vinculado a I/o hasta un 50-60 % del tiempo de la base de datos<block ref="235591872ecf336383513d22098a1fa0" prefix=" " category="inline-code"></block>.<block ref="a249b22faad82bdea2a0930347b9e5ac" prefix=" " category="inline-code"></block> También es un factor que contribuye porque los confirmaciones de transacción hacen que el proceso de registro de Oracle vacíe las E/S de registro de la caché de buffers al archivo de registro en el disco, aunque es un factor menor en el nivel de porcentaje de tiempo-base de datos.</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">Se registraron el volumen de transacciones del usuario, el tiempo de respuesta del usuario y los eventos de espera principales de Oracle en relación con el número de usuarios simultáneos durante una ejecución de transacción. A continuación se muestran los resultados:</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">Este resultado indica que podríamos aumentar constantemente los volúmenes de transacciones de usuario con un mayor número de usuarios simultáneos, a la vez que se mantiene una latencia de I/o baja y el tiempo de respuesta del usuario, lo cual es un rendimiento adecuado para una aplicación de Oracle.</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">La latencia de I/o y el tiempo de respuesta del usuario comenzaron a aumentar algo cuando llegamos a 10 128 usuarios simultáneos. Esto se espera porque la instancia de EC2 está cerca de la capacidad completa de los servidores, tal como se muestra en el siguiente diagrama:</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">De forma similar, el siguiente diagrama muestra la tasa de IOPS y el rendimiento de FSX correspondientes mientras se cumplen los volúmenes de transacciones del usuario en ese momento.</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Factores que deben tenerse en cuenta para la instalación de bases de datos de Oracle.</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">No alcanzamos la capacidad de almacenamiento FSX aprovisionada en IOPS o rendimiento cuando la instancia de EC2 del servidor Oracle se convirtió en el factor limitante. Por lo tanto, debe dimensionar correctamente los recursos informáticos y de almacenamiento en función del volumen de transacciones por aplicaciones del usuario, tal y como mostramos en la sección <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Antes de instalar el conector de Cloud Manager y Cloud Volumes ONTAP y configurar SnapMirror, debemos preparar algo para nuestro entorno de cloud. Esta página describe el trabajo que se debe realizar así como las consideraciones que se deben tener en cuenta al implementar Cloud Volumes ONTAP.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">Requisitos previos para el cloud público</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">Anterior: Requisitos previos en las instalaciones.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Lista de comprobación de requisitos previos de puesta en marcha de Cloud Manager y Cloud Volumes ONTAP</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">Una ubicación de red para un conector</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">documentación sobre cloud</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">Para obtener más información sobre lo que necesita para empezar, visite nuestra<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">Consideraciones</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. ¿Qué es un conector de Cloud Manager?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">En la mayoría de los casos, un administrador de cuenta de Cloud Central debe poner en marcha un conector en la red local o en el cloud. El conector permite a Cloud Manager gestionar recursos y procesos dentro de su entorno de cloud público.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">Para obtener más información sobre conectores, visite nuestra<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Ajuste de tamaño y arquitectura de Cloud Volumes ONTAP</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Al implementar Cloud Volumes ONTAP, se ofrece la opción de un paquete predefinido o de la creación de su propia configuración. A pesar de que muchos de estos valores se pueden cambiar más adelante de forma no disruptiva, existen algunas decisiones clave que deben tomarse antes de la puesta en marcha en función de las cargas de trabajo que se van a poner en marcha en el cloud.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">Herramienta de ajuste de tamaño CVO</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">Cada proveedor de cloud tiene diferentes opciones de puesta en marcha y casi todas las cargas de trabajo tienen sus propias propiedades únicas. NetApp tiene una<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> esto puede ayudar a dimensionar correctamente las puestas en marcha en función de la capacidad y el rendimiento, pero se ha desarrollado a partir de algunos conceptos básicos que vale la pena considerar:</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">Capacidad requerida</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">Capacidad de red de la máquina virtual de cloud</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">Características de rendimiento del almacenamiento en cloud</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">La clave está en planificar una configuración que satisfaga no solo los requisitos de capacidad y rendimiento actuales, sino que también tenga en cuenta el crecimiento futuro. Esto suele denominarse margen adicional de capacidad y margen adicional de rendimiento.</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">Si desea obtener más información, lea la documentación acerca de la planificación correcta para<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, y.<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. ¿Nodo único o alta disponibilidad?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">En todos los clouds, existe la opción de poner en marcha CVO tanto en un único nodo como en un par de alta disponibilidad en clúster con dos nodos. En función del caso de uso, puede que desee poner en marcha un solo nodo para ahorrar costes o un par de alta disponibilidad para proporcionar mayor disponibilidad y redundancia.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">En un caso de uso de recuperación ante desastres o durante el aumento del almacenamiento temporal para las fases de desarrollo y pruebas, los nodos individuales son habituales, ya que el impacto de una interrupción repentina del servicio de la infraestructura es menor. Sin embargo, en cualquier caso de uso de producción, si los datos solo se encuentran en una única ubicación o si el conjunto de datos debe tener más redundancia y disponibilidad, se recomienda una alta disponibilidad.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">Para obtener más información sobre la arquitectura de la alta disponibilidad de cada versión cloud, visite la documentación de<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> y..<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">Siguiente: Información general del comienzo.</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="87561d435f6cd79a59659b543d2991ca" category="summary">En esta sección se describe una arquitectura de la solución de instalación personalizada de RDS con almacenamiento personalizado de Oracle RDS y FSX ONTAP.</block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">En el siguiente diagrama de arquitectura se ilustra la implementación de una base de datos de Oracle de alta disponibilidad en una instancia de AWS EC2 con el servicio de almacenamiento FSX. Se puede configurar un esquema de puesta en marcha similar pero con el modo de espera en otra región para la recuperación ante desastres.</block>
  <block id="312f941d9e8f224f54ae372016e8f35a" category="paragraph">En el entorno, la instancia de computación de Oracle se pone en marcha a través de una consola de instancias de AWS EC2. Hay varios tipos de instancias EC2 disponibles en la consola. NetApp recomienda la puesta en marcha de un tipo de instancia EC2 orientada a bases de datos como una imagen Ami m5 con RedHat Enterprise Linux 8 y un ancho de banda de red de hasta 10 G.</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">Por otro lado, el almacenamiento de bases de datos Oracle en volúmenes FSX se pone en marcha con la consola o CLI de AWS FSX. Los volúmenes binarios, datos o registro de Oracle se presentan y se montan después en un host Linux de instancia de EC2. Cada datos o volumen de registro puede tener varias LUN asignadas en función del protocolo de almacenamiento subyacente empleado.</block>
  <block id="830579b4d0c33e9e4fa1f11c61cb73a7" category="inline-image-macro">En esta imagen se muestra un ejemplo de diagrama de arquitectura que incluye el clúster ha principal: El clúster ha en espera - nodos de gestión - y los nodos de conexión relacionados.</block>
  <block id="73793421735093db194ae82163f894b3" category="paragraph"><block ref="73793421735093db194ae82163f894b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d0f7ae75ed6e0e3b522ecc7cac710b" category="paragraph">Un clúster de almacenamiento FSX ha sido diseñado con doble redundancia, de modo que los clústeres de almacenamiento primario y en espera se implementen en dos zonas de disponibilidad diferentes. Los volúmenes de base de datos se replican desde un clúster FSX principal a un clúster FSX en espera en un intervalo configurable por el usuario para todos los volúmenes binarios de Oracle, datos y registros.</block>
  <block id="0008c12bed67fcf1f82ece8ff10b5c81" category="paragraph">Este entorno de Oracle de alta disponibilidad se gestiona con un nodo de controladora Ansible y una herramienta de interfaz de usuario y un servidor de backup de SnapCenter. La instalación, la configuración y la replicación de Oracle se automatizan con kits de herramientas basados en el libro de estrategia de Ansible. Cualquier actualización del sistema operativo del kernel de la instancia de Oracle EC2 o de las revisiones de Oracle se puede ejecutar en paralelo para mantener la sincronización del sistema principal y en espera. De hecho, la configuración de automatización inicial se puede ampliar con facilidad para realizar algunas tareas de Oracle diarias repetitivas si es necesario.</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter ofrece flujos de trabajo para la recuperación de un momento específico de bases de datos de Oracle o para la clonado de bases de datos en las zonas primaria o en espera, si es necesario. Mediante la interfaz de usuario de SnapCenter, puede configurar la replicación y el backup de las bases de datos de Oracle en el almacenamiento FSX en espera para una alta disponibilidad o recuperación ante desastres en función de sus objetivos de objetivo de tiempo de recuperación o punto de recuperación.</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">La solución proporciona un proceso alternativo que ofrece funcionalidades similares a las que están disponibles en la puesta en marcha de Oracle RAC y Data Guard.</block>
  <block id="1332f9ef53fc751a6087660a11f07ba6" category="paragraph"><block ref="1332f9ef53fc751a6087660a11f07ba6" category="inline-link-macro-rx"></block></block>
  <block id="046c9e52934c311f81497ca664d86a24" category="doc">TR-4764: Prácticas recomendadas para Microsoft SQL Server con EF-Series de NetApp</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">Mitch Blackburn, Pat Sinthutan, NetApp</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">Esta guía de prácticas recomendadas tiene como objetivo ayudar a los administradores de almacenamiento y de bases de datos a poner en marcha Microsoft SQL Server en un sistema de almacenamiento EF-Series de NetApp.</block>
  <block id="730874cec0e792d7ebad5a796a90b3be" category="paragraph"><block ref="730874cec0e792d7ebad5a796a90b3be" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">Esta sección trata la implementación en tiempo real de una propiedad de base de datos de SQL en una configuración de AOAG mediante un volumen SMB de Azure NetApp Files.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">Diseño de referencia de alto nivel y en tiempo real</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">Número de nodos: 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">Número de bases de datos: 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">Número de grupos de disponibilidad: 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">Retención de copias de seguridad: 7 días</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">Archivo de copia de seguridad: 365 días</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">La puesta en marcha de FCI con SQL Server en máquinas virtuales de Azure con una unidad de Azure NetApp Files proporciona un modelo rentable con una única copia de los datos. Esta solución puede evitar problemas de operación de agregar archivos si la ruta de acceso del archivo difiere de la réplica secundaria.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">La siguiente imagen muestra las bases de datos de AOAG distribuidas entre los nodos.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Distribución de datos</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">Los archivos de base de datos de usuario (.mdf) y los archivos de registro de transacciones de bases de datos de usuario (.ldf) junto con tempdb se almacenan en el mismo volumen. El nivel de servicio es Ultra.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">La configuración consta de cuatro nodos y cuatro AG. Las 21 bases de datos (parte de Dynamic AX, SharePoint, RDS connection broker y servicios de indexación) se almacenan en los volúmenes Azure NetApp Files. Las bases de datos se equilibran entre los nodos de AOAG para utilizar los recursos en los nodos de forma efectiva. En el WSFC se agregan cuatro instancias D32 v3, que participan en la configuración de AOAG. Estos cuatro nodos se aprovisionan en la red virtual de Azure y no se migran desde las instalaciones.</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">Si los registros requieren más rendimiento y rendimiento dependiendo de la naturaleza de la aplicación y de las consultas ejecutadas, los archivos de base de datos pueden colocarse en el nivel de servicio Premium y los registros pueden almacenarse en el nivel de servicio Ultra.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">Si los archivos tempdb se han colocado en Azure NetApp Files, el volumen Azure NetApp Files debe separarse de los archivos de la base de datos de usuario. A continuación se muestra un ejemplo de distribución de los archivos de base de datos en AOAG.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Para conservar las ventajas de la protección de datos basada en copias de Snapshot, NetApp recomienda no combinar los datos y los datos de registro en el mismo volumen.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">Una operación de adición de archivos realizada en la réplica principal puede producir un error en las bases de datos secundarias si la ruta de acceso del archivo de una base de datos secundaria difiere de la ruta de acceso de la base de datos primaria correspondiente. Esto puede suceder si la ruta de acceso al recurso compartido es diferente en los nodos primario y secundario (debido a cuentas de equipo diferentes). Este error puede provocar la suspensión de las bases de datos secundarias. Si no se puede predecir el patrón de crecimiento o rendimiento y el plan es añadir ficheros más adelante, un cluster de recuperación tras fallos de SQL Server con Azure NetApp Files es una solución aceptable. Para la mayoría de las implementaciones, Azure NetApp Files cumple con los requisitos de rendimiento.</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">Migración</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">Existen varias formas de migrar una base de datos de usuario de SQL Server en las instalaciones a SQL Server en una máquina virtual de Azure. La migración puede estar en línea o sin conexión. Las opciones elegidas dependen de la versión de SQL Server, los requisitos empresariales y los SLA definidos dentro de la organización. Para minimizar el tiempo de inactividad durante el proceso de migración de bases de datos, NetApp recomienda utilizar la opción AlwaysOn o la opción de replicación transaccional. Si no es posible utilizar estos métodos, puede migrar la base de datos manualmente.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">El método más sencillo y probado para mover bases de datos entre máquinas es la copia de seguridad y la restauración. Normalmente, se puede comenzar con un backup de base de datos seguido por una copia del backup de la base de datos en Azure. Luego puede restaurar la base de datos. Para obtener el mejor rendimiento de transferencia de datos, migre los archivos de base de datos a la máquina virtual de Azure mediante un archivo de backup comprimido. El diseño de alto nivel al que se hace referencia en este documento utiliza el enfoque de backup al almacenamiento de archivos de Azure con la sincronización de archivos de Azure y, después, restaurar a Azure NetApp Files.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Se puede usar la migración de Azure para detectar, evaluar y migrar cargas de trabajo de SQL Server.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">Para realizar una migración, realice los siguientes pasos de alto nivel:</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">Configure la conectividad en función de sus necesidades.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">Realizar un backup completo de una base de datos en una ubicación de recurso compartido de archivos en las instalaciones.</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Copie los archivos de backup en un recurso compartido de archivos de Azure con sincronización de archivos de Azure.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">Aprovisione la máquina virtual con la versión deseada de SQL Server.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">Copie los archivos de backup en la máquina virtual con el<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> desde un símbolo del sistema.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">Restaurar todas las bases de datos a SQL Server en máquinas virtuales de Azure.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">Para restaurar 21 bases de datos, tardaron aproximadamente nueve horas. Este enfoque es específico de este escenario. Sin embargo, puede utilizar otras técnicas de migración que se enumeran a continuación en función de su situación y requisitos.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">Otras opciones de migración para mover datos de un servidor SQL Server local a Azure NetApp Files son las siguientes:</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">Desvincule los archivos de datos o de registro, cópielos en el almacenamiento de Azure Blob y, a continuación, conéctelos a SQL Server en la máquina virtual de Azure con un recurso compartido de archivos ANF montado en la URL.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Agregar el Asistente para réplica de Azure</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Si va a utilizar la implementación del grupo de disponibilidad siempre disponible en sus instalaciones, utilice<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> Para crear una réplica en Azure y, a continuación, realizar conmutación al nodo de respaldo.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">replicación transaccional</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">Utilice SQL Server<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Para configurar la instancia de Azure SQL Server como suscriptor, deshabilite la replicación y apunte a los usuarios a la instancia de la base de datos de Azure.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Envíe el disco duro mediante el servicio de importación/exportación de Windows.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">Backup y recuperación</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">El backup y la recuperación son aspectos importantes de cualquier instalación de SQL Server. Es obligatorio disponer de una red de seguridad adecuada para poder recuperarse rápidamente de diferentes situaciones de pérdida y fallo de datos junto con soluciones de alta disponibilidad como AOAG. SQL Server Database Quiesce Tool, Azure Backup (streaming) o cualquier herramienta de backup de terceros como CommVault pueden utilizarse para realizar un backup consistente con las aplicaciones de las bases de datos,</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">Herramienta SCSQLAPI</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">La tecnología Snapshot de Azure NetApp Files le permite crear fácilmente una copia de un momento específico de las bases de datos del usuario sin que ello afecte al rendimiento ni al uso de la red. Esta tecnología también permite restaurar una copia snapshot en un volumen nuevo o revertir rápidamente el volumen afectado al estado que tenía cuando se creó la copia snapshot con la función de reversión de volumen. El proceso de copia Snapshot de Azure NetApp Files es muy rápido y eficiente, lo que permite realizar varios backups diarios, a diferencia del backup en streaming que ofrece el backup de Azure. Con múltiples copias Snapshot posibles en un día determinado, los tiempos de objetivo de punto de recuperación y objetivo de tiempo de recuperación se pueden reducir significativamente. Para agregar consistencia de las aplicaciones de modo que los datos estén intactos y vaciados correctamente al disco antes de que se haga la copia de Snapshot, utilice la herramienta de inactividad de la base de datos de SQL Server <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; El acceso a este enlace requiere las credenciales de inicio de sesión SSO de NetApp). Esta herramienta se puede ejecutar desde PowerShell, lo que a su vez hace a la base de datos de SQL Server y, a su vez, puede realizar copias snapshot del almacenamiento coherentes con las aplicaciones para realizar backups.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">*Notas: *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">La herramienta SCSQLAPI sólo admite las versiones 2016 y 2017 de SQL Server.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">La herramienta SCSQLAPI sólo funciona con una base de datos a la vez.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">Aísle los archivos de cada base de datos colocándolos en un volumen de Azure NetApp Files independiente.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Backup de Azure</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">Debido a las enormes limitaciones de API de SCSQL,<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> Se utilizó para la protección de datos con el fin de cumplir los requisitos de los acuerdos de nivel de servicios. Ofrece un backup basado en streaming de SQL Server ejecutándose en máquinas virtuales de Azure y Azure NetApp Files. Azure Backup permite un objetivo de punto de recuperación de 15 minutos con backups de registros frecuentes y recuperación tras fallos hasta un segundo.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">Supervisión</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files se integra con Azure Monitor para los datos de series temporales y proporciona métricas sobre almacenamiento asignado, uso del almacenamiento real, IOPS de volumen, rendimiento, bytes de lectura de disco/s, bytes de escritura en disco/s, lecturas en disco/s y escrituras en disco/s, y latencia asociada. Estos datos se pueden utilizar para identificar cuellos de botella con alertas y para realizar comprobaciones de estado para verificar que la implementación de SQL Server se está ejecutando en una configuración óptima.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">En este HLD, ScienceLogic se utiliza para supervisar Azure NetApp Files exponiendo las métricas utilizando el principal de servicio adecuado. La siguiente imagen es un ejemplo de la opción métrica Azure NetApp Files.</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">DevTest usando clones gruesos</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Con Azure NetApp Files, puede crear copias instantáneas de bases de datos para probar la funcionalidad que debería implementarse utilizando la estructura y el contenido actuales de la base de datos durante los ciclos de desarrollo de aplicaciones, para usar las herramientas de extracción y manipulación de datos al rellenar almacenes de datos, o incluso para recuperar datos que se eliminaron o se modificaron por error. Este proceso no implica copiar datos de contenedores de Azure Blob, lo cual hace que sea muy eficiente. Una vez restaurado el volumen, puede utilizarse para operaciones de lectura/escritura, lo que reduce significativamente la validación y el plazo de comercialización. Esto debe usarse junto con SCSQLAPI para mantener la coherencia de las aplicaciones. Este método ofrece otra técnica de optimización de costes continua junto con Azure NetApp Files aprovechando la opción Restaurar en nuevo volumen.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">El volumen creado a partir de la copia de Snapshot con la opción Restore New Volume consume capacidad del pool de capacidad.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">Es posible eliminar los volúmenes clonados mediante REST o interfaz de línea de comandos de Azure para evitar costes adicionales (en caso de que se deba aumentar el pool de capacidad).</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">Opciones de almacenamiento híbrido</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">Aunque NetApp recomienda utilizar el mismo almacenamiento para todos los nodos en los grupos de disponibilidad de SQL Server, existen casos en los que se pueden utilizar varias opciones de almacenamiento. Este escenario es posible en Azure NetApp Files en el que un nodo de AOAG está conectado con un recurso compartido de archivos de SMB de Azure NetApp Files y el segundo nodo está conectado con un disco Premium de Azure. En estas instancias, asegúrese de que el recurso compartido de SMB de Azure NetApp Files contiene la copia primaria de las bases de datos de usuario y que se utilice el disco Premium como copia secundaria.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">En estas implementaciones, para evitar cualquier problema con la conmutación al nodo de respaldo, asegúrese de que la disponibilidad continua esté habilitada en el volumen del bloque de mensajes del servidor. Al no tener ningún atributo disponible de forma continua, la base de datos puede fallar si hay algún mantenimiento en segundo plano en la capa de almacenamiento.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">Mantenga la copia principal de la base de datos en el recurso compartido de archivos de SMB de Azure NetApp Files.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">Continuidad del negocio</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">La recuperación ante desastres suele ser un elemento secundario en cualquier instalación. Sin embargo, debe abordarse la recuperación ante desastres durante la fase inicial de diseño y puesta en marcha para evitar que se produzca ningún impacto en su negocio. Con Azure NetApp Files, la funcionalidad de replicación entre regiones (CRR, por sus siglas en inglés) se puede usar para replicar los datos de volúmenes a nivel de bloque en la región emparejada, con el fin de afrontar cualquier interrupción regional inesperada. El volumen de destino habilitado para CRR se puede utilizar para operaciones de lectura, lo que lo convierte en un candidato ideal para las simulaciones de recuperación ante desastres. Además, el destino de CRR se puede asignar con el nivel de servicio más bajo (por ejemplo, Estándar) para reducir el TCO general. En caso de conmutación por error, la replicación puede romperse, lo cual permite que el volumen correspondiente sea capaz de lectura/escritura. Además, el nivel de servicio del volumen puede cambiarse gracias al uso de la funcionalidad de nivel de servicio dinámico para reducir de manera significativa el coste de la recuperación ante desastres. Esta es otra función única de Azure NetApp Files con replicación de bloques en Azure.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">Archivado de copias snapshot a largo plazo</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">Muchas organizaciones deben realizar una retención a largo plazo de los datos de copias Snapshot a partir de archivos de bases de datos como un requisito obligatorio de cumplimiento de normativas. Aunque este proceso no se utiliza en este HLD, se puede realizar fácilmente usando un sencillo script por lotes<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> Para copiar el directorio de instantáneas al contenedor de Azure Blob. La secuencia de comandos por lotes se puede activar en función de una programación específica mediante tareas programadas. El proceso es sencillo, incluye los siguientes pasos:</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">Descargue el archivo ejecutable AzCopy V10. No hay nada que instalar porque es un<block ref="98e83379d45538379c2ac4e47c3be81d" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">Autorice AzCopy utilizando un token SAS a nivel de contenedor con los permisos correspondientes.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">Después de autorizar AzCopy, comienza la transferencia de datos.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">En archivos por lotes, asegúrese de escapar de los caracteres % que aparecen en tokens SAS. Esto se puede hacer agregando un carácter adicional % junto a los caracteres % existentes en la cadena de token SAS.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">Se requiere transferencia segura</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">La<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> La configuración de una cuenta de almacenamiento determina si la conexión a una cuenta de almacenamiento está protegida con Transport Layer Security (TLS). Esta configuración está habilitada de forma predeterminada. En el siguiente ejemplo de secuencia de comandos por lotes se copian recursivamente los datos del directorio de copia Snapshot a un contenedor Blob designado:</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">El siguiente ejemplo de cmd se ejecuta en PowerShell:</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Pronto estará disponible una función de backup similar para retención a largo plazo en Azure NetApp Files.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">El script por lotes se puede utilizar en cualquier escenario que requiera que los datos se copien en un contenedor Blob de cualquier región.</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">Con la remodelación del volumen y el cambio del nivel de servicio dinámico, que es totalmente transparente para la base de datos, Azure NetApp Files permite optimizaciones de costes continuas en Azure. Esta funcionalidad se utiliza en esta gran variedad de HLD para evitar el sobreaprovisionamiento del almacenamiento adicional para gestionar los picos de carga de trabajo.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">El cambio de tamaño del volumen se puede lograr fácilmente mediante la creación de una función de Azure junto con los registros de alertas de Azure.</block>
  <block id="03b125f503e8b797be1fe5a21a10d220" category="summary">En esta sección se describe cómo proteger su base de datos de Oracle con la herramienta azacsnap y el backup de snapshots, la restauración y las snapshots en niveles en Azure BLOB.</block>
  <block id="b47faaf85acf415e557bd0b669342659" category="doc">Proteja su base de datos de Oracle en el cloud de Azure</block>
  <block id="cec4dbc9c066ab7b22ef743151be75eb" category="paragraph"><block ref="cec4dbc9c066ab7b22ef743151be75eb" category="inline-link-macro-rx"></block></block>
  <block id="06a2961d48a854a133ddfe05c7912732" category="section-title">Realizar backups de bases de datos de Oracle con snapshot mediante la herramienta AzAcSnap</block>
  <block id="30462dbcf926561966ea824afd44e355" category="paragraph">La herramienta Snapshot coherente con las aplicaciones de Azure (AzAcSnap) es una herramienta de línea de comandos que permite la protección de datos de bases de datos de terceros al manejar toda la orquestación necesaria para ponerlas en un estado coherente con las aplicaciones antes de tomar una instantánea de almacenamiento, después de la cual devuelve las bases de datos a un estado operativo.</block>
  <block id="07612935f16f2665ef52f490f9b1f43b" category="paragraph">En el caso de Oracle, se coloca la base de datos en modo de backup para realizar una instantánea y, a continuación, sacar la base de datos del modo de backup.</block>
  <block id="070d0b63c9af5e43d43102c1869d4262" category="section-title">Backup de datos y volúmenes de registros</block>
  <block id="7dd57abd8929da4f18cc94d1940161a1" category="paragraph">El backup se puede configurar en el host del servidor de bases de datos con un script de shell simple que ejecuta el comando snapshot. A continuación, se puede programar la ejecución del script desde crontab.</block>
  <block id="087916fda35dba838b68193ed8bc3aeb" category="paragraph">Generalmente, la frecuencia de backup depende del objetivo de tiempo de recuperación y el objetivo de punto de recuperación que desee. La creación frecuente de copias Snapshot consume más espacio de almacenamiento. Existe un compensación entre la frecuencia de backup y el consumo de espacio.</block>
  <block id="e2ece357797b760af1c814632edcf99d" category="paragraph">Los volúmenes de datos suelen consumir más espacio de almacenamiento que los volúmenes de registro. Por lo tanto, se pueden realizar copias Snapshot en volúmenes de datos cada pocas horas y realizar copias Snapshot más frecuentes en volúmenes de registro cada 15 a 30 minutos.</block>
  <block id="2a2c2eb0d2bde8c24cc55a11862ca857" category="paragraph">Consulte los siguientes ejemplos de secuencias de comandos y programación de backup.</block>
  <block id="e048ccd48425229cea678849ba68a190" category="paragraph">Para snapshots de volumen de datos:</block>
  <block id="f0d6345b8e5345f55c21610283eaeedd" category="paragraph">Para las copias de Snapshot de volumen de registro:</block>
  <block id="68b7e37ef318c0e56eabf3e1aded4216" category="paragraph">Crontab: 15,30,45 * * * * /home/azacsnap/snap_log.sh 0 */2 * * * /home/azacsnap/snap_data.sh</block>
  <block id="adf4ba1e0f3190afb18557f038ae1ecf" category="admonition">Al configurar el backup<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> archivo de configuración, agregar todos los volúmenes de datos, incluido el volumen binario a.<block ref="0fb9dff864caebba259b119756a2ce17" prefix=" " category="inline-code"></block> y todos los volúmenes de registro en<block ref="5e5fb0a2540d102aeebc3dac60712494" prefix=" " category="inline-code"></block>. La retención máxima de copias de Snapshot es de 250 copias.</block>
  <block id="a93091ed018686dcf478589ba04fd6f6" category="section-title">Validar las copias Snapshot</block>
  <block id="8a46f2968d5dc184634cff75cd1b8b8e" category="paragraph">Vaya al portal de Azure &gt; Azure NetApp Files/Volumes para comprobar si las snapshots se han creado correctamente.</block>
  <block id="3542e11f657b779fcef8cc387987e9f2" category="inline-image-macro">Esta captura de pantalla muestra dos archivos en la lista de instantáneas.</block>
  <block id="c2dd243538b072e19882bdcd6ac2c6c9" category="inline-image-macro">Esta captura de pantalla muestra ocho archivos en la lista de instantáneas.</block>
  <block id="af143d815dcd69aae3ff8d8bdde9fd58" category="paragraph"><block ref="bf87ea8d7de67f1fdc628b6bb4b400e5" category="inline-image-macro-rx" type="image"></block>
<block ref="1d682e6513772285b95199f0646e28da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7479b02641600cb6142d8594c1360d11" category="section-title">Recuperación y restauración de Oracle desde un backup local</block>
  <block id="76265d8fce7f282b6ff5a8581df8879c" category="paragraph">Una de las ventajas clave del backup snapshot es que existe de forma conjunta con los volúmenes de base de datos de origen y que los volúmenes de base de datos primaria pueden revertirse casi instantáneamente.</block>
  <block id="878609e3e12819fffdd7247406f655be" category="section-title">Restauración y recuperación de Oracle en el servidor primario</block>
  <block id="8733b7b64c8d2c32caa423c7eb2955fc" category="paragraph">El siguiente ejemplo muestra cómo restaurar y recuperar una base de datos de Oracle desde la consola de Azure y la CLI en el mismo host de Oracle.</block>
  <block id="aa30a622663e0f34541394e008fe82cd" category="list-text">Cree una tabla de pruebas en la base de datos que se va a restaurar. [oracle@acao-ora01 ~]$ sqlplus / as sysdba</block>
  <block id="ea16560565f3889db4dabf938628b462" category="paragraph">SQL*Plus: Versión 19.0.0.0.0 - producción el Mon Sep 12 19:02:35 2022 Versión 19.8.0.0.0</block>
  <block id="0409b2fce118cc126a532dea158d2943" category="paragraph">SQL&gt; CREATE TABLE testsnapshot( id integer, event varchar(100), dt timestamp);</block>
  <block id="bec6da77877c0793c1d3eb6c6896e98e" category="paragraph">Tabla creada.</block>
  <block id="a5b83945adfd5370663cb2d9c4f31d09" category="paragraph">SQL&gt; insertar en los valores de la instantánea de prueba(1,'insertar un marcador de datos para validar la restauración de instantánea',sysdate);</block>
  <block id="6ba18fa8fa7d170dfd8fc80f0f3d39f7" category="paragraph">se creó 1 fila.</block>
  <block id="d1d2dcb121f8bf8fd39724ea075c6409" category="paragraph">SQL&gt; COMMIT;</block>
  <block id="a92090dde5e820fde0a68705ee3f2bd0" category="paragraph">Confirmación completada.</block>
  <block id="fd9736dfc88a182f9cb6e5f6a2b97487" category="paragraph">SQL&gt; SELECT * from testsnapshot;</block>
  <block id="2817b9cf9fc0cd0d8bf9fb03acbfc93f" category="list-text">Coloque la tabla después de los backups de Snapshot.</block>
  <block id="07b56c53a9fec8c477afb0cb5f2394af" category="paragraph">[oracle@acao-ora01 ~]$ sqlplus / as sysdba</block>
  <block id="dcd4d50ecf59b4752c161f0ddc44df44" category="paragraph">SQL*Plus: Versión 19.0.0.0.0 - producción el Tue Sep 13 14:20:22 2022 Versión 19.8.0.0.0</block>
  <block id="bee0f13528c2f6f5b67053dc1e942328" category="paragraph">Prueba de tabla de caída de SQL&gt;;</block>
  <block id="cd85f26775e453b2177d5fcc6265b31d" category="paragraph">Tabla borrada.</block>
  <block id="07e18ec921a195478cdbab47d8d68d89" category="paragraph">SQL&gt; SELECT * from testsnapshot; seleccione * from testsnapshot * ERROR en la línea 1: ORA-00942: No existe una tabla o vista</block>
  <block id="f06f4fbf6e3e0e45b0d4b241ceaf19c9" category="paragraph">SQL&gt; cierre inmediato; base de datos cerrada. Base de datos desmontada. Cierre de la instancia DE ORACLE. SQL&gt; salir desconectado de Oracle Database 19c Enterprise Edition Versión 19.0.0.0.0 - Versión de producción 19.8.0.0.0</block>
  <block id="09d4fe137595af1cc975247ba704462d" category="list-text">En la consola de Azure NetApp Files, restaure el volumen de registro a la última snapshot disponible. Seleccione *volumen de reversión*.</block>
  <block id="33ba8417b2640d4172513bbf9cbc3e55" category="inline-image-macro">Esta captura de pantalla muestra el método de reversión de instantánea para volúmenes en el panel ANF.</block>
  <block id="546b967f1ce32832a90c77282f0cdf2b" category="paragraph"><block ref="546b967f1ce32832a90c77282f0cdf2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b728fe18b10b9b611a1d3ab6acc0df9" category="list-text">Confirme la reversión de volumen y haga clic en *revertir* para completar la reversión del volumen a la última copia de seguridad disponible.</block>
  <block id="5c7deeb27ad1e0e4c1d6d52b2a2a1bfc" category="inline-image-macro">El "¿está seguro de que desea hacer esto?" página para la nueva versión de instantánea.</block>
  <block id="ef80226ab5a9d2865852e606297da2cf" category="paragraph"><block ref="ef80226ab5a9d2865852e606297da2cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18b9906dd2c95b12fdb987b7c2aa9917" category="list-text">Repita los mismos pasos para el volumen de datos y compruebe que el backup contenga la tabla que se va a recuperar.</block>
  <block id="a38e609b2fd5c2dee1b4ccb1cbbac7d4" category="inline-image-macro">Esta captura de pantalla muestra el método de reversión de instantánea para volúmenes de datos en el panel ANF.</block>
  <block id="f0d819988fad0119995986a2bdfd9ad6" category="paragraph"><block ref="f0d819988fad0119995986a2bdfd9ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc824d4f774a64498f954eb2ebbc093b" category="list-text">Vuelva a confirmar la versión del volumen y haga clic en "Revert".</block>
  <block id="5e2296a09eabbd34b62da3492091ff33" category="inline-image-macro">El "¿está seguro de que desea hacer esto?" página para la reversión de la copia de snapshot de volumen de datos.</block>
  <block id="af5f9a99ee2d86856d0e2477e417dc4c" category="paragraph"><block ref="af5f9a99ee2d86856d0e2477e417dc4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="170b40e31285910539e0d464f2bf33a6" category="list-text">Resincronizcar los archivos de control si tiene varias copias de ellos y reemplazar el archivo de control antiguo con la última copia disponible.</block>
  <block id="952cd3804f479f3c31f123d064ccbdf5" category="paragraph">[oracle@acao-ora01 ~]$ mv /u02/oradata/ORATST/Control01.ctl /u02/oradata/ORATST/Control01.ctl.bk [oracle@acao-ora01 ~]$ cp /u03/orareco/ORATST/Control02/OATR02/ORET2/ATT2/ATT2/ATT2/ATRATT2/O2/O2/2003/OORT2/O2/OORT2/O</block>
  <block id="bd99bc18393147b05e3f350eb6a61f47" category="list-text">Inicie sesión en el equipo virtual del servidor de Oracle y ejecute la recuperación de bases de datos con sqlplus.</block>
  <block id="125ab5cbfb90c4a6d038bcca4da6fdc4" category="paragraph">SQL*Plus: Versión 19.0.0.0.0 - producción el Tue Sep 13 15:10:17 2022 Versión 19.8.0.0.0</block>
  <block id="010621501012cd31b6666d17dad683d2" category="paragraph">Conectado a una instancia inactiva.</block>
  <block id="6bd3f70e5ab38ca26f8cabd390e15fc0" category="paragraph">SQL&gt; Startup Mount; se ha iniciado LA instancia DE ORACLE.</block>
  <block id="424459a4363a5afdd1e45d31fcd11efe" category="paragraph">Área global total del sistema 6442448984 bytes Tamaño fijo 8910936 bytes Tamaño variable 1090519040 bytes búferes de base de datos 5335154688 bytes búferes de Redo 7864320 bytes montados en la base de datos. SQL&gt; recuperar la base de datos utilizando el archivo de control de copia de seguridad hasta cancelar; ORA-00279: Cambio 3188523 generado a las 09/13/2022 10:00:09 necesario para el subproceso 1 ORA-00289: Sugerencia : /u03/orareco/ORATST/archivmog/2022_09_13/o1_mf_1_43 43__22rnjq9q_ arco para el cambio de secuencia #00280-3188523</block>
  <block id="db9afd3f7adaff3fe1135208fa6b6a09" category="paragraph">Especificar registro: {&lt;RET&gt;=sugerido | nombre de archivo | AUTOMÁTICO | CANCELAR}</block>
  <block id="abc467423916c8ee7c16f566b4ab4ca8" category="paragraph">ORA-00279: Cambio 3188862 generado a las 09/13/2022 10:01:20 necesario para el subproceso 1 ORA-00289: Sugerencia : /u03/orareco/ORATST/archivvelog/2022_09_13/o1_mf_1_44__29f2lgb5_.Arc ORA-00280: El cambio 3188862 2022 43 para el subproceso 1 está en la secuencia #00278/44 09/no se necesita más tiempo_1/13/error</block>
  <block id="479d2dfa77fdcde3bfd41fcdebbca1ff" category="paragraph">ORA-00279: Cambio 3193117 generado a las 09/13/2022 12:00:08 necesario para el subproceso 1 ORA-00289: Sugerencia : /u03/orareco/ORATST/archivvelog/2022_09_13/o1_mf_1_45__29h6qyw_.Arc ORA-00280: El cambio 3193117 para el subproceso 1 está en la secuencia #45/00278/g_1/2022 44/g_13/g_09/g_1/g_/no se necesita más</block>
  <block id="c76ff2f7e10a42adf7faec8f9e6faeab" category="paragraph">ORA-00279: Cambio 3193440 generado a las 09/13/2022 12:01:20 necesario para el subproceso 1 ORA-00289: Sugerencia : /u03/orareco/ORATST/archivvelog/2022_09_13/o1_mf_1_46_%u_.ORA Arc-00280: El cambio 3193440 para el subproceso 1 está en la secuencia #46-00278: U_otorg_1/no se necesita más tiempo_13/atorag_1/2022/orag_1/09/oq_OQ_/oreoq_1/oq_OQ_1/oq_OQ_/oreoq_45/oq_OQ_OQ_</block>
  <block id="0e98028493ec8c4a1d181c0d71c3ec7b" category="paragraph">Especificar registro: {&lt;RET&gt;=Suggested | filename | AUTO | CANCEL} cancelar recuperación de medios cancelada. SQL&gt; ALTER Database open resetlogs;</block>
  <block id="f6c9ea366c01da7d664a8c7c3813e0bd" category="paragraph">Base de datos alterada.</block>
  <block id="8ad5254ade1fed8d3ccc482196b4c36c" category="paragraph">Esta pantalla muestra que la tabla borrada se ha recuperado utilizando copias de seguridad de instantánea locales.</block>
  <block id="34d73a671fa85d8d86ba1eff63b238d8" category="paragraph"><block ref="34d73a671fa85d8d86ba1eff63b238d8" category="inline-link-macro-rx"></block></block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">Este whitepaper proporciona un resumen y validación de una solución para la alta disponibilidad y la recuperación ante desastres de la base de datos Oracle RDS personalizada de AWS, aprovechando el servicio de almacenamiento FSX de AWS en una puesta en marcha de varias zonas de disponibilidad.</block>
  <block id="0c55b956af322a2409f5dd75af116fee" category="doc">WP-7357: Introducción a las prácticas recomendadas de la implementación de bases de datos Oracle en EC2 y FSX</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">Allen Cao, Niyaz Mohamed, Jeffrey Steiner, NetApp</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">Muchas bases de datos empresariales críticas para la misión de Oracle siguen alojadas en las instalaciones, y muchas empresas tratan de migrar estas bases de datos de Oracle a un cloud público. A menudo, estas bases de datos de Oracle están centradas en aplicaciones y, por ello, requieren configuraciones específicas del usuario, una funcionalidad que falta en muchas ofertas de cloud público de base de datos como servicio. Por lo tanto, el panorama actual de las bases de datos exige una solución de base de datos de Oracle basada en el cloud público creada a partir de un servicio de almacenamiento y computación escalable de alto rendimiento que pueda satisfacer requisitos particulares. Las instancias de computación de AWS EC2 y el servicio de almacenamiento FSX de AWS pueden ser las piezas faltantes de este rompecabezas que puede aprovechar para crear y migrar sus cargas de trabajo de bases de datos de Oracle esenciales a un cloud público.</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud (Amazon EC2) es un servicio web que proporciona capacidad informática segura y resistente en el cloud. Está diseñado para facilitar el cloud computing a escala web a las empresas. La sencilla interfaz de servicio web de Amazon EC2 permite obtener y configurar capacidad con una fricción mínima. Le ofrece un control completo de sus recursos informáticos y le permite ejecutar el entorno informático probado de Amazon.</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX para ONTAP es un servicio de almacenamiento de AWS que utiliza el almacenamiento de bloques y archivos ONTAP de NetApp, líder del sector, que expone NFS, SMB e iSCSI. Con un motor de almacenamiento tan potente, nunca ha sido tan fácil reubicar las aplicaciones de bases de datos de Oracle esenciales en AWS con tiempos de respuesta inferiores al milisegundo, múltiples Gbps de rendimiento y más de 100,000 000 IOPS por instancia de base de datos. Y aún mejor, el servicio de almacenamiento FSX incluye la funcionalidad de replicación nativa que le permite migrar fácilmente su base de datos Oracle local a AWS o replicar su base de datos Oracle crítica en una zona de disponibilidad secundaria de AWS para alta disponibilidad o recuperación ante desastres.</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">El objetivo de esta documentación es proporcionar procesos paso a paso, procedimientos y orientación de prácticas recomendadas sobre cómo poner en marcha y configurar una base de datos de Oracle con almacenamiento FSX y una instancia de EC2 que ofrece un rendimiento similar a un sistema local. NetApp también proporciona un kit de herramientas de automatización que automatiza la mayoría de las tareas necesarias para la implementación, la configuración y la gestión de la carga de trabajo de la base de datos de Oracle en el cloud público de AWS.</block>
  <block id="eef7539c8eab25bfe5c089aab85ec418" category="paragraph">Para obtener más información sobre la solución y el caso de uso, eche un vistazo al siguiente vídeo general:</block>
  <block id="0df1fe5dfbca17caa87c91ffea49223a" category="inline-link-macro">Modernice su base de datos de Oracle con el cloud híbrido en AWS y FSX ONTAP, Part1 - caso práctico y arquitectura de solución</block>
  <block id="adf8d1fc36b4704904a6251fde19535e" category="paragraph"><block ref="bab032e290776958656c886d774a2bf6" category="inline-link-macro-rx"></block></block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="4020b36b638694a9834cb01b53b25ffe" category="doc">Procedimientos detallados de puesta en marcha de Oracle en AWS EC2 y FSX</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">Implemente una instancia de EC2 Linux para Oracle a través de la consola EC2</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">Si no tiene experiencia en AWS, primero tiene que configurar un entorno AWS. La pestaña de documentación en la página de destino del sitio web de AWS proporciona enlaces de instrucciones de EC2 sobre cómo se implementa una instancia de Linux EC2 que se puede utilizar para alojar la base de datos Oracle a través de la consola EC2 de AWS. La siguiente sección es un resumen de estos pasos. Para obtener más detalles, consulte la documentación específica de AWS EC2 vinculado.</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">Configurar el entorno AWS EC2</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">Debe crear una cuenta de AWS para aprovisionar los recursos necesarios para ejecutar el entorno de Oracle en el servicio EC2 y FSX. En la siguiente documentación de AWS se ofrecen los detalles necesarios:</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Configure para usar Amazon EC2</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">Temas clave:</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">Regístrese en AWS.</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">Cree un par de claves.</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">Cree un grupo de seguridad.</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">Habilitar varias zonas de disponibilidad en atributos de cuenta de AWS</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">Para una configuración de alta disponibilidad de Oracle como se muestra en el diagrama de arquitectura, debe habilitar al menos cuatro zonas de disponibilidad en una región. Las múltiples zonas de disponibilidad también pueden situarse en distintas regiones con el fin de satisfacer las distancias necesarias para la recuperación ante desastres.</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">Creación y conexión a una instancia EC2 para alojar la base de datos Oracle</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Comience a utilizar instancias de Amazon EC2 Linux</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">Consulte el tutorial <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> para ver los procedimientos detallados de puesta en marcha y las prácticas recomendadas.</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">Descripción general.</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">Requisitos previos.</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">Paso 1: Iniciar una instancia.</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">Paso 2: Conéctese a su instancia.</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">Paso 3: Limpie su instancia.</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">Las siguientes capturas en pantalla muestran el despliegue de una instancia de Linux tipo m5 con la consola EC2 para ejecutar Oracle.</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">En la consola de EC2, haga clic en el botón amarillo Iniciar instancia para iniciar el flujo de trabajo de implementación de instancias de EC2.</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">En el paso 1, seleccione "Red Hat Enterprise Linux 8 (HVM), SSD Volume Type - ami-0b0af3577fe5e3532 (x86 de 64 bits) / ami-01fc429821bf1f4b4 (ARM de 64 bits)".</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">En el paso 2, seleccione un tipo de instancia m5 con la asignación de CPU y memoria adecuada basada en la carga de trabajo de la base de datos Oracle. Haga clic en "Siguiente: Configure Instance Details".</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">En el paso 3, elija el VPC y la subred donde se debe colocar la instancia y habilite la asignación de IP pública. Haga clic en "Next: Add Storage".</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">En el paso 4, asigne suficiente espacio para el disco raíz. Es posible que necesite espacio para agregar un intercambio. De forma predeterminada, la instancia de EC2 asigna un espacio de intercambio cero, lo cual no es óptimo para ejecutar Oracle.</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">En el paso 5, agregue una etiqueta para la identificación de instancia si es necesario.</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">En el paso 6, seleccione un grupo de seguridad existente o cree uno nuevo con la directiva de entrada y salida deseada para la instancia.</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">En el paso 7, revise el resumen de configuración de la instancia y haga clic en Iniciar para iniciar la implementación de la instancia. Se le pedirá que cree un par de claves o seleccione un par de claves para acceder a la instancia.</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">Inicie sesión en la instancia de EC2 con un par de claves SSH. Realice cambios en el nombre de clave y la dirección IP de la instancia según corresponda.</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">Debe crear dos instancias EC2 como servidores Oracle primarios y en espera en su zona de disponibilidad designada como se muestra en el diagrama de arquitectura.</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Aprovisionar FSX para los sistemas de archivos ONTAP para el almacenamiento de bases de datos Oracle</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">La puesta en marcha de instancias de EC2 asigna un volumen raíz de EBS al sistema operativo. FSX para sistemas de archivos ONTAP proporciona volúmenes de almacenamiento de bases de datos de Oracle, como volúmenes binarios, datos y registros de Oracle. Los volúmenes NFS de almacenamiento FSX se pueden aprovisionar desde la consola AWS FSX o desde la instalación de Oracle, y la automatización de la configuración que asigna los volúmenes como el usuario configura en un archivo de parámetros de automatización.</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">Administrar FSX para sistemas de archivos ONTAP</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">Se hace referencia a esta documentación<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> Para crear FSX para sistemas de archivos ONTAP.</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">Consideraciones clave:</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">Capacidad de almacenamiento SSD. Mínimo de 1024 GIB, máximo de 192 TIB.</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">IOPS de SSD aprovisionadas. En función de los requisitos de carga de trabajo, un máximo de 80,000 IOPS de SSD por sistema de archivos.</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">Capacidad de rendimiento.</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">Establezca la contraseña de administrador fsxadmin/vsadmin. Necesario para la automatización de la configuración de FSX.</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">Backup y mantenimiento. Desactive los backups diarios automáticos; el backup de almacenamiento de base de datos se ejecuta mediante la programación de SnapCenter.</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">Recupere la dirección IP de gestión de SVM, así como las direcciones de acceso específicas del protocolo desde la página de detalles de SVM. Necesario para la automatización de la configuración de FSX.</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">Consulte los siguientes procedimientos paso a paso para configurar un clúster FSX de alta disponibilidad principal o en espera.</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">En la consola FSX, haga clic en Crear sistema de archivos para iniciar el flujo de trabajo de provisión de FSX.</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">Seleccione Amazon FSX para NetApp ONTAP. A continuación, haga clic en Siguiente.</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">Seleccione creación estándar y, en Detalles del sistema de archivos, asigne un nombre al sistema de archivos, Multi-AZ ha. En función de la carga de trabajo de su base de datos, seleccione Automatic o User-Provisioning IOPS con hasta 80,000 SSD IOPS. El almacenamiento FSX incluye un almacenamiento en caché NVMe de hasta 2 TIB en el entorno de administración que puede proporcionar una IOPS medida aún mayor.</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">En la sección Network &amp; Security, seleccione VPC, grupo de seguridad y subredes. Deben crearse antes de la implementación de FSX. En función de la función del clúster FSX (principal o en espera), coloque los nodos de almacenamiento FSX en las zonas correspondientes.</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">En la sección Security &amp; Encryption (Seguridad y cifrado), acepte el valor predeterminado e introduzca la contraseña fsxadmin.</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">Introduzca el nombre de SVM y la contraseña de vsadmin.</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">Deje la configuración de volumen en blanco; no es necesario crear un volumen en este momento.</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Revise la página Summary y haga clic en Create File System para completar la provisión del sistema de archivos FSX.</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Aprovisionamiento de volúmenes de bases de datos para bases de datos de Oracle</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">Gestión de FSX para volúmenes de ONTAP: Creación de un volumen</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">Consulte <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">Ajuste el tamaño de los volúmenes de base de datos según corresponda.</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">Al deshabilitar la política de organización en niveles del pool de capacidad para la configuración del rendimiento.</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">Habilitar Oracle dNFS para volúmenes de almacenamiento NFS.</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">Configurar multivía para volúmenes de almacenamiento iSCSI.</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">Creación de un volumen de base de datos desde la consola FSX</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">Desde la consola FSX de AWS, puede crear tres volúmenes para el almacenamiento de archivos de base de datos de Oracle: Uno para el binario de Oracle, uno para los datos de Oracle y otro para el registro de Oracle. Asegúrese de que el nombre del volumen coincida con el nombre del host de Oracle (definido en el archivo hosts del kit de herramientas de automatización) para conseguir una identificación adecuada. En este ejemplo, utilizamos db1 como nombre de host de Oracle EC2 en lugar de un nombre de host típico basado en la dirección IP para una instancia de EC2.</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">La creación de LUN iSCSI no es compatible actualmente con la consola FSX. Para la implementación de LUN iSCSI para Oracle, se pueden crear volúmenes y LUN utilizando la automatización para ONTAP con el kit de herramientas de automatización de NetApp.</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">Instalar y configurar Oracle en una instancia de EC2 con volúmenes de base de datos FSX</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">El equipo de automatización de NetApp proporciona un kit de automatización para ejecutar la instalación y la configuración de Oracle en instancias de EC2 de acuerdo con las prácticas recomendadas. La versión actual del kit de automatización admite Oracle 19c en NFS con el parche de RU predeterminado 19.8. El kit de automatización se puede adaptar fácilmente para otros parches RU si es necesario.</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">Prepare una controladora de Ansible para ejecutar la automatización</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">Siga las instrucciones de la sección "<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>" Para aprovisionar una instancia pequeña de EC2 Linux con el fin de ejecutar la controladora de Ansible. En lugar de utilizar RedHat, Amazon Linux t2.Large con 2vCPU y 8G RAM debería ser suficiente.</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">Recupere el kit de herramientas de automatización de la puesta en marcha de Oracle de</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">Inicie sesión en la instancia de la controladora EC2 Ansible aprovisionada desde el paso 1 como usuario ec2 y desde el directorio inicial del usuario ec2, ejecute el<block ref="aebfab4ae394171a00d2e86fff2ff38b" prefix=" " category="inline-code"></block> para clonar una copia del código de automatización.</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">Ejecutar la puesta en marcha automatizada de Oracle 19c con el kit de herramientas de automatización</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">Consulte estas instrucciones detalladas <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> Para poner en marcha Oracle 19c con automatización CLI. Hay un pequeño cambio en la sintaxis de comandos para la ejecución de la tableta, ya que utiliza un par de claves SSH en lugar de una contraseña para la autenticación del acceso al host. La siguiente lista es un resumen de alto nivel:</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">De forma predeterminada, una instancia de EC2 utiliza un par de claves SSH para la autenticación de acceso. Desde los directorios raíz de automatización de la controladora de Ansible<block ref="4a1bfa90833e8fe6c82ca6f61f31d147" prefix=" " category="inline-code"></block>, y.<block ref="a1d1fcb426260f0fdb7febffa690e21c" prefix=" " category="inline-code"></block>, Haga una copia de la clave SSH<block ref="956c187b3d0c7dcff5b113900e032874" prefix=" " category="inline-code"></block> Para el host Oracle puesto en marcha en el paso "<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>."</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">Inicie sesión en el host de la base de datos de instancia de EC2 como ec2-user e instale la biblioteca python3.</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">¿Cómo puedo asignar memoria para que funcione como espacio de intercambio en una instancia de Amazon EC2 utilizando un archivo de intercambio?</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">Cree un espacio de intercambio de 16 G desde la unidad de disco raíz. De forma predeterminada, una instancia de EC2 crea un espacio de intercambio cero. Siga esta documentación de AWS: <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>.</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Vuelva a la controladora Ansible <block ref="e97a9e3bee0cbfb89ba75f3695725fba" prefix="(" category="inline-code"></block>), y ejecute la tableta preclone playbook con los requisitos y.<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block> etiquetas.</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">Cambie a la<block ref="127b3ddd6eac38dd05a00b88b9348ff5" prefix=" " category="inline-code"></block> directorio, lea el archivo README y rellene el archivo global<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> archivo con los parámetros globales relevantes.</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">Rellene el<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> archivo con los parámetros relevantes en la<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Ejecute la tableta playbook para Linux y pulse Intro cuando se le solicite la contraseña de vsadmin.</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Ejecute la tableta playbook para Oracle y pulse ENTER cuando se le solicite la contraseña vsadmin.</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">Cambie el bit de permiso del archivo de claves SSH a 400 si es necesario. Cambie el host de Oracle <block ref="e15cba2a55d1c830968665125de5abf6" prefix="(" category="inline-code"></block> en la<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Archivo) Dirección IP de la dirección pública de la instancia de EC2.</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">Configuración de SnapMirror entre el clúster de alta disponibilidad FSX principal y en espera</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">Para lograr una alta disponibilidad y recuperación ante desastres, puede configurar la replicación de SnapMirror entre el clúster de almacenamiento FSX primario y en espera. A diferencia de otros servicios de almacenamiento en cloud, FSX permite a un usuario controlar y gestionar la replicación del almacenamiento con la frecuencia y el rendimiento de replicación deseados. También permite a los usuarios probar ha/DR sin que ello afecte a la disponibilidad.</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">Los siguientes pasos muestran cómo configurar la replicación entre un clúster de almacenamiento FSX primario y en espera.</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">Configurar la relación de clústeres principal y en espera. Inicie sesión en el clúster principal como usuario fsxadmin y ejecute el siguiente comando. Este proceso de creación recíproco ejecuta el comando create en el clúster primario y en el clúster en espera. Sustituya<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> con el nombre apropiado para su entorno.</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">Configure vServer peering entre el clúster principal y el clúster en espera. Inicie sesión en el clúster principal como usuario de vsadmin y ejecute el siguiente comando. Sustituya<block ref="f826cd2f4a01fe594ea3f06fc8e9a764" prefix=" " category="inline-code"></block>,<block ref="73483be5a30a2604d22183209c74149e" prefix=" " category="inline-code"></block>,<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> con los nombres adecuados para su entorno.</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">Verifique que los peerings del cluster y del Vserver estén configurados correctamente.</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">Cree volúmenes NFS de destino en el clúster FSX en espera para cada volumen de origen del clúster FSX principal. Sustituya el nombre del volumen según sea necesario para su entorno.</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">También puede crear volúmenes iSCSI y LUN para el binario de Oracle, los datos de Oracle y el registro de Oracle si se utiliza el protocolo iSCSI para acceder a los datos. Deje aproximadamente un 10% de espacio libre en los volúmenes para las snapshots.</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">vol create -volume dr_db1_log -aggr1 -size 250G -state online -policy default -unix-permisions ---rwxr-xr-x -type RW</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">Para LUN iSCSI, cree un mapa para el iniciador de host de Oracle para cada LUN, utilizando el LUN binario como ejemplo. Sustituya el igroup por un nombre adecuado para su entorno e incremente el lun-id para cada LUN adicional.</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">Cree una relación de SnapMirror entre los volúmenes de bases de datos primaria y en espera. Sustituya el nombre de SVM adecuado para su entorno</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">Esta configuración de SnapMirror puede automatizarse con el kit de herramientas de automatización de NetApp para los volúmenes de base de datos NFS. El kit de herramientas está disponible para su descarga desde el sitio público de GitHub de NetApp.</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">Lea detenidamente las instrucciones del README antes de intentar la configuración y la prueba de conmutación por error.</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">La replicación del binario de Oracle desde el clúster primario a uno en espera puede tener implicaciones para la licencia de Oracle. Póngase en contacto con su representante de licencia de Oracle para obtener más información. La alternativa es instalar y configurar Oracle en el momento de la recuperación y la conmutación por error.</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">Puesta en marcha de SnapCenter</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">Instalación de SnapCenter</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">Instalación del servidor SnapCenter</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">Siga <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> Para instalar el servidor SnapCenter. Esta documentación trata cómo instalar un servidor SnapCenter independiente. Una versión SaaS de SnapCenter se encuentra en fase de revisión beta y podría estar disponible próximamente. Consulte a su representante de NetApp para obtener información sobre la disponibilidad si es necesario.</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">Configurar el plugin de SnapCenter para el host Oracle EC2</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">Tras la instalación automatizada de SnapCenter, inicie sesión en SnapCenter como usuario administrativo para el host de Windows en el que está instalado el servidor SnapCenter.</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">En el menú del lado izquierdo, haga clic en Configuración y, a continuación, en Credential y New para añadir credenciales de usuario ec2 para la instalación del complemento SnapCenter.</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">Restablezca la contraseña de usuario ec2 y habilite la autenticación SSH de contraseña mediante la edición de<block ref="07b421e5f5e0300b1a0fd6cc22745306" prefix=" " category="inline-code"></block> Archivo en el host de la instancia de EC2.</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">Compruebe que esté seleccionada la casilla de comprobación "Use sudo Privileges". Solo tiene que restablecer la contraseña de usuario ec2 en el paso anterior.</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">Añada el nombre del servidor SnapCenter y la dirección IP al archivo host de la instancia de EC2 para solucionar el nombre.</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">En el host de Windows del servidor SnapCenter, agregue la dirección IP del host de la instancia EC2 al archivo de host de Windows<block ref="803976de87f6862821bd3c4d94e0ff2b" prefix=" " category="inline-code"></block>.</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">En el menú del lado izquierdo, seleccione hosts &gt; Managed hosts y, a continuación, haga clic en Add para añadir el host de instancia de EC2 a SnapCenter.</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">Compruebe Oracle Database y, antes de enviar, haga clic en más opciones.</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">Compruebe las comprobaciones Omitir preinstalación. Confirme omitiendo comprobaciones previas a la instalación y, a continuación, haga clic en Enviar después de guardar.</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">Se le pedirá que confirme la huella digital y, a continuación, haga clic en Confirm and Submit.</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">Después de configurar correctamente el plugin, el estado general del host gestionado se muestra como en ejecución.</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Configurar la política de backup para la base de datos de Oracle</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="inline-link-macro">Configure la política de backup de la base de datos en SnapCenter</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">Consulte esta sección <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Para obtener más detalles sobre la configuración de la política de backup de base de datos Oracle.</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">Generalmente, se necesita crear una política para el backup completo de una base de datos de Oracle de Snapshot y una política para el backup de snapshots de solo registro de archivo de Oracle.</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">Puede habilitar la eliminación de registros de archivo de Oracle en la política de backup para controlar el espacio de archivado de registros. Marque la opción "Actualizar SnapMirror después de crear una copia Snapshot local" en "Seleccionar la opción de replicación secundaria" cuando necesite replicar a una ubicación en espera para alta disponibilidad o recuperación ante desastres.</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Configurar el backup y la programación de la base de datos de Oracle</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">El usuario puede configurar un backup de bases de datos en SnapCenter por separado o como un grupo de recursos. El intervalo de backup depende de los objetivos de objetivo de tiempo de recuperación y objetivo de punto de recuperación. NetApp recomienda ejecutar un backup completo de bases de datos cada pocas horas y archivar el backup de registros a una mayor frecuencia, como 10-15 minutos para lograr una recuperación rápida.</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="inline-link-macro">Implemente una política de backup para proteger la base de datos</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">Consulte la sección Oracle de <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> para obtener procesos detallados paso a paso para implementar la política de respaldo creada en la sección <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> y para la programación de tareas de backup.</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">La siguiente imagen muestra un ejemplo de los grupos de recursos configurados para realizar backup de una base de datos Oracle.</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">Siguiente: Gestión de bases de datos.</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155: Bases de datos Oracle 19c RAC en un centro de datos FlexPod con Cisco UCS y AFF A800 de NetApp sobre FC: Guía de diseño y puesta en marcha</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">Allen Cao, NetApp</block>
  <block id="ffaaa5a04a78a6ce5d807980dbf83e64" category="paragraph">Esta guía de diseño y puesta en marcha para bases de datos RAC Oracle 19c en un centro de datos FlexPod con Cisco UCS y AFF A800 over FC de NetApp proporciona detalles del diseño de la solución y procesos de puesta en marcha paso a paso para alojar bases de datos Oracle RAC en la infraestructura de centro de datos FlexPod más reciente con Oracle Linux 8.2 Sistema operativo y núcleo compatible con Red Hat.</block>
  <block id="3b872d3a96131109e4700e3031e4b158" category="inline-link-macro">NVA-1155: Bases de datos Oracle 19c RAC en un centro de datos FlexPod con Cisco UCS y AFF A800 de NetApp sobre FC</block>
  <block id="202f51b1cd08b9562681a95f87429702" category="paragraph"><block ref="202f51b1cd08b9562681a95f87429702" category="inline-link-macro-rx"></block></block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">Las soluciones de bases de datos empresariales de NetApp constituyen un conjunto de funcionalidades tecnológicas y estratégicas que demuestran las funcionalidades del almacenamiento de NetApp en las principales bases de datos empresariales.</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">Soluciones de bases de datos empresariales de NetApp</block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">En esta sección se proporcionan detalles sobre los factores que deben tenerse en cuenta al poner en marcha la base de datos de Oracle en la instancia de AWS EC2 y el almacenamiento FSX.</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">En las siguientes secciones se describen los aspectos clave que se deben tener en cuenta al poner en marcha una base de datos de Oracle en un cloud público de AWS en una instancia de EC2 con almacenamiento FSX.</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">Seleccionar el tamaño correcto de máquina virtual es importante para optimizar el rendimiento de una base de datos relacional en un cloud público. Para obtener un mejor rendimiento, NetApp recomienda utilizar una instancia de la serie EC2 M5 para la puesta en marcha de Oracle, que está optimizada para cargas de trabajo de bases de datos. También se utiliza el mismo tipo de instancia para activar una instancia de RDS para Oracle por AWS.</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">Elija la combinación de vCPU y RAM correcta en función de las características de la carga de trabajo.</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">Agregar espacio de intercambio a una máquina virtual. La implementación predeterminada de la instancia de EC2 no crea un espacio de intercambio, lo cual no es óptimo para una base de datos.</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">En el caso del almacenamiento NFS, la distribución de volúmenes recomendada es tres volúmenes: Uno para los binarios de Oracle, otro para los datos de Oracle y un archivo de control duplicado, y otro para el registro activo, el registro archivado y el archivo de control de Oracle.</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">Para el almacenamiento iSCSI, el diseño de volumen recomendado es de tres volúmenes: Uno para el binario de Oracle; uno para los datos de Oracle y un archivo de control duplicado; y otro para el registro activo de Oracle, el registro archivado y el archivo de control. Sin embargo, lo ideal es que cada volumen de datos y registro contenga cuatro LUN. Los LUN se equilibran perfectamente en los nodos de clúster de alta disponibilidad.</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">Para IOPS y rendimiento del almacenamiento, puede elegir el umbral para la tasa de IOPS y el rendimiento aprovisionados para el clúster de almacenamiento FSX, y estos parámetros pueden ajustarse sobre la marcha cuando cambie la carga de trabajo.</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">La configuración de IOPS automática es de tres IOPS por GIB de capacidad de almacenamiento asignada o almacenamiento definido por el usuario hasta 80,000.</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">El nivel de rendimiento aumenta de la siguiente manera: 128, 256, 512, 1024 y 2045 Mbps.</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link-macro">Rendimiento de Amazon FSX para ONTAP de NetApp</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">Revise la <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> Documentación para ajustar el tamaño de rendimiento e IOPS.</block>
  <block id="b6e1b7fd7aad364a8ad758d8ae8ba50d" category="paragraph">Linux, el sistema operativo más común, incluye funcionalidades NFS nativas. Oracle ofrece el cliente NFS directo (dNFS) integrado de forma nativa en Oracle. Oracle tiene compatibilidad con NFSv3 durante más de 20 años y NFSv4 es compatible con Oracle 12.1.0.2 y versiones posteriores. La puesta en marcha automatizada de Oracle mediante el kit de herramientas de automatización de NetApp configura automáticamente dNFS en NFSv3.</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">Para obtener un rendimiento óptimo y evitar problemas de rendimiento, ajuste los parámetros del kernel que controlan las tablas de ranuras TCP a 128.</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">En la siguiente tabla se ofrecen opciones de montaje NFS recomendadas para NFSv3 de Linux: Una única instancia.</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">Como se indica en la arquitectura de la solución, la alta disponibilidad se basa en la replicación a nivel de almacenamiento. Por lo tanto, la puesta en marcha y la disponibilidad de Oracle depende de la rapidez con la que pueda llevarse a cabo la informática y el almacenamiento. Consulte los siguientes factores clave:</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">Tener una instancia de computación en espera lista y sincronizada con el principal mediante una actualización en paralelo de Ansible para ambos hosts.</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">Replique el volumen binario desde el volumen primario para fines en espera de forma que no tenga que instalar Oracle en el último minuto ni averiguar qué es necesario instalar y aplicar las revisiones.</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">La frecuencia de replicación determina la rapidez con la que se puede recuperar la base de datos de Oracle para que el servicio esté disponible. Hay un compensación entre la frecuencia de replicación y el consumo de almacenamiento.</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">Aproveche la automatización para que la recuperación y pase al modo de espera sea rápida y libre de errores humanos. NetApp ofrece un kit de herramientas de automatización con este fin.</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">Esta página describe la protección de datos automatizada de Oracle19c en el almacenamiento ONTAP de NetApp.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">Procedimiento de puesta en marcha paso a paso</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">Protección de datos Oracle AWX/Tower</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">Crear el inventario, el grupo, los hosts y las credenciales para su entorno</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">En esta sección se describe la configuración del inventario, los grupos, los hosts y las credenciales de acceso en AWX/Ansible Tower, que preparan el entorno para consumir soluciones automatizadas de NetApp.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Desplácese hasta Recursos → inventarios → Agregar y haga clic en Agregar inventario.</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">Escriba el nombre y los detalles de la organización y haga clic en Guardar.</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">En la página inventarios, haga clic en el inventario creado.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Acceda al submenú grupos y haga clic en Agregar.</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">Introduzca el nombre oracle para el primer grupo y haga clic en Guardar.</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">Repita el proceso para un segundo grupo denominado dr_oracle.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">Seleccione el grupo oracle creado, vaya al submenú hosts y haga clic en Add New Host.</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">Proporcione la dirección IP de la dirección IP de administración del host Oracle de origen y haga clic en Guardar.</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">Este proceso debe repetirse para el grupo dr_oracle y agregar el nombre de host/IP de administración del host DR/destino de Oracle.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">A continuación se muestran instrucciones para crear los tipos de credenciales y credenciales de On-Prem with ONTAP o CVO en AWS.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">En el entorno local</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">Configure las credenciales.</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">Cree tipos de credenciales. En el caso de las soluciones que implican ONTAP, debe configurar el tipo de credencial de modo que coincida con las entradas de nombre de usuario y contraseña.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Desplácese hasta Administration → Credential Types y haga clic en Add.</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">Pegue el siguiente contenido en Configuración de entrada:</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Pegue el siguiente contenido en Configuración del inyector y, a continuación, haga clic en Guardar:</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">Crear credenciales para ONTAP</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Desplácese hasta Resources → Credentials y haga clic en Add.</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">Introduzca los detalles de nombre y organización para los credenciales de ONTAP</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">Seleccione el tipo de credencial que se creó en el paso anterior.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">En Type Details, introduzca el nombre de usuario y la contraseña para los clústeres de origen y destino.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">Haga clic en Guardar</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Crear credenciales para Oracle</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Introduzca el nombre y los detalles de la organización de Oracle</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">Seleccione el tipo de credencial máquina.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">En Type Details, introduzca el nombre de usuario y la contraseña para los hosts de Oracle.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">Seleccione el método de escalamiento de privilegios correcto e introduzca el nombre de usuario y la contraseña.</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">Repita el proceso si es necesario para una credencial diferente para el host dr_oracle.</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">Crear tipos de credenciales. En el caso de las soluciones que implican ONTAP, debe configurar el tipo de credencial para que coincida con las entradas de nombre de usuario y contraseña, también añadiremos entradas para Cloud Central y AWS.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Pegue el siguiente contenido en Injector Configuration y haga clic en Save:</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">Cree credenciales para ONTAP/CVO/AWS</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">En Type Details, introduzca el nombre de usuario y la contraseña de los clústeres de origen y CVO, Cloud Central/Manager, AWS Access/Secret Key y Cloud Central Refresh Token.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Crear credenciales para Oracle (origen)</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Introduzca los detalles de nombre y organización del host de Oracle</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Crear credenciales para el destino Oracle</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">Introduzca los detalles de nombre y organización para el host de recuperación ante desastres de Oracle</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">En Type Details, introduzca el nombre de usuario (ec2-user o si lo ha cambiado de valor predeterminado introduzca ese valor) y la clave privada SSH</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">Seleccione el método de escalado de privilegios correcto (sudo) e introduzca el nombre de usuario y la contraseña si es necesario.</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">Cree un proyecto</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Vaya a Recursos → proyectos y haga clic en Agregar.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Seleccione Git en el campo Source Control Credential Type.</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">introduzca <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> Como URL de control de origen.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">Es posible que el proyecto tenga que sincronizarse ocasionalmente cuando cambia el código fuente.</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">Configurar variables globales</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">Las variables definidas en esta sección se aplican a todos los hosts de Oracle, las bases de datos y el clúster de ONTAP.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">Introduzca los parámetros específicos de su entorno en las siguientes variables globales integradas o formas var.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">Los elementos en azul deben cambiarse para que coincidan con su entorno.</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">Libros de estrategia de automatización</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">Hay cuatro libros de estrategia separados que se deben ejecutar.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">Libro de estrategia para configurar su entorno, en las instalaciones o CVO.</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">PlayBook para replicar los binarios y bases de datos de Oracle según un calendario</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">PlayBook para replicar los registros de Oracle según una programación</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">Libro de estrategia para recuperar la base de datos en un host de destino</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">Configuración de ONTAP/CVO</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">Configuración de ONTAP y CVO</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*Configurar e iniciar la plantilla de trabajo.*</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">Cree la plantilla de trabajo.</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">Introduzca el nombre ONTAP/CVO Setup</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">Seleccione el tipo de trabajo; Run configura el sistema en función de una tableta playbook.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Seleccione el inventario, el proyecto, el libro de estrategia y las credenciales correspondientes.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">Seleccione el libro de estrategia ontap_setup.yml para un entorno en las instalaciones o seleccione cvo_setup.yml para replicar a una instancia de CVO.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">Pegue las variables globales copiadas del paso 4 en el campo variables de plantilla en la pestaña AYLMA.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">Utilizaremos esta plantilla y la copiaremos para los otros libros de estrategia.</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">Replicación para volúmenes binarios y bases de datos</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">Programación del libro de aplicaciones de replicación de bases de datos y binarios</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">Copie la plantilla de trabajo creada previamente.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">Encuentre la plantilla de configuración de ONTAP/CVO y haga clic con el botón derecho del ratón en Copiar plantilla</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">Haga clic en Editar plantilla en la plantilla copiada y cambie el nombre a Libro de aplicaciones de replicación de bases de datos y binarios.</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">Mantenga el mismo inventario, proyecto y credenciales para la plantilla.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">Seleccione la ora_replication_cg.yml como la tableta playbook que se va a ejecutar.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">Las variables seguirán siendo las mismas, pero se deberá establecer la dirección IP del clúster CVO en la variable dst_cluster_ip.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">Programar la plantilla de trabajo.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">Haga clic en la plantilla Binary and Database Replication PlayBook y, a continuación, haga clic en Schedules en el conjunto superior de opciones.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">Haga clic en Agregar, agregue el nombre Programación para la replicación binaria y de bases de datos, elija la fecha y hora de inicio al principio de la hora, elija su zona horaria local y frecuencia de ejecución. La frecuencia de ejecución se suele actualizar la replicación de SnapMirror.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">Se creará una programación independiente para la replicación de volúmenes de registro, de modo que se pueda replicar con una cadencia más frecuente.</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">Replicación para volúmenes de registro</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">Programación de la aplicación Log Replication PlayBook</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">Haga clic en Editar plantilla en la plantilla copiada y cambie el nombre a Log Replication PlayBook.</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">Seleccione ora_replication_logs.yml como la tableta playbook que se va a ejecutar.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Haga clic en la plantilla Log Replication PlayBook y, a continuación, haga clic en programas en el conjunto superior de opciones.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">Haga clic en Add, Add Name Schedule for Log Replication, elija la fecha y la hora de inicio al principio de la hora, elija su zona horaria local y la frecuencia de ejecución. La frecuencia de ejecución se suele actualizar la replicación de SnapMirror.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">Se recomienda establecer la programación del registro para que se actualice cada hora a fin de garantizar la recuperación de la última actualización por hora.</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">Restaurar y recuperar una base de datos</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">Haga clic en Editar plantilla en la plantilla copiada y cambie el nombre a Restaurar y recuperar libro de aplicaciones.</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">Seleccione la ora_recovery.yml como la tableta playbook que se va a ejecutar.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">Este libro de estrategia no se ejecutará hasta que esté listo para restaurar su base de datos en el sitio remoto.</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Recuperación de la base de datos Oracle</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">Los volúmenes de datos de bases de datos Oracle en las instalaciones se protegen mediante la replicación de SnapMirror de NetApp en un clúster de ONTAP redundante en un centro de datos secundario o Cloud Volume ONTAP en el cloud público. En un entorno de recuperación ante desastres totalmente configurado, las instancias informáticas de recuperación en un centro de datos secundario o cloud público están en espera y listas para recuperar la base de datos de producción en caso de desastre. Las instancias de computación en espera se mantienen sincronizadas con las instancias en las instalaciones mediante la ejecución de actualizaciones de paraellel en la revisión del kernel del sistema operativo o la actualización en un paso de bloqueo.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">En esta solución demostrada, el volumen binario de Oracle se replica en la instancia de destino y se monta en la instancia de destino para poner en marcha la pila de software de Oracle. Este enfoque de recuperación de Oracle se ha aprovechado de una instalación nueva de Oracle en el último minuto que se haya producido un desastre. Garantiza que la instalación de Oracle está completamente sincronizada con la instalación actual del software de producción local, los niveles de parches, etc. Sin embargo, esto puede tener o no implicaciones adicionales de licencia de software para el volumen binario de Oracle replicado en el sitio de recuperación dependiendo de cómo se estructure la licencia de software con Oracle. Se recomienda al usuario que consulte con el personal de licencias de software para evaluar los requisitos potenciales de licencias de Oracle antes de decidir utilizar el mismo enfoque.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">El host Oracle en espera en el destino se configura con las configuraciones de requisitos previos de Oracle.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">Los SnapMirrors están rotos y los volúmenes se pueden escribir y montar en el host de Oracle en espera.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">El módulo de recuperación de Oracle realiza las siguientes tareas para recuperar e iniciar Oracle en el sitio de recuperación después de que todos los volúmenes de base de datos estén montados en la instancia de computación en espera.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">Sincronice el archivo de control: Implementamos archivos de control de Oracle duplicados en diferentes volúmenes de base de datos para proteger el archivo de control de la base de datos crucial. Una está en el volumen de datos y otra está en el volumen de registro. Dado que los volúmenes de registros y datos se replican con una frecuencia diferente, estos se desincronizan en el momento de la recuperación.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Volver a vincular binario de Oracle: Puesto que el binario de Oracle se reubica en un nuevo host, necesita una nueva tinta.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Recuperación de la base de datos Oracle: El mecanismo de recuperación recupera el último número de cambio de sistema del último registro archivado disponible en el volumen de registro Oracle del archivo de control y recupera la base de datos Oracle para recuperar todas las transacciones comerciales que se pudieron replicar en el sitio de recuperación ante desastres en el momento del fallo. A continuación, la base de datos se inicia en una nueva encarnación para realizar conexiones de usuario y transacciones empresariales en el sitio de recuperación.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Antes de ejecutar el libro de estrategia en recuperación, asegúrese de que dispone de lo siguiente: Asegúrese de que copia en /etc/oratab y /etc/oraInst.loc desde el host Oracle de origen al host de destino</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">Introducción y sección requisitos</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">En esta sección se tratan los pasos necesarios para preparar y poner en marcha la base de datos Oracle19c con la CLI. Asegúrese de haber revisado el <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> y preparar su entorno de acuerdo con sus necesidades.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Descargar Oracle19c repo</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">Edite el archivo hosts</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">Complete lo siguiente antes de la implementación:</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">Edite el directorio na_oracle19c_deploy del archivo de host.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">En [ONTAP], cambie la dirección IP a la IP de administración del clúster.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">En el grupo [oracle], agregue los nombres de los hosts oracle. El nombre de host se debe resolver a su dirección IP a través de DNS o del archivo hosts, o bien debe especificarse en el host.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">Después de completar estos pasos, guarde los cambios.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">En el ejemplo siguiente se muestra un archivo host:</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">En este ejemplo se ejecuta el libro de aplicaciones y se implementa oracle 19c en dos servidores oracle DB simultáneamente. También puede realizar pruebas con un solo servidor de base de datos. En ese caso, sólo es necesario configurar un archivo de variable de host.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">El libro de estrategia se ejecuta de la misma manera independientemente de la cantidad de hosts y bases de datos de Oracle que se implementen.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">Edite el archivo host_name.yml en host_var</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">Cada host de Oracle tiene su archivo de variable de host identificado por su nombre de host que contiene variables específicas del host. Es posible especificar cualquier nombre para el host. Edite y copie el<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Desde la sección Host VARS Config y péguela en su deseado<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">Host VARS Config</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">Edite el archivo var.yml</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">La<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> File consolida todas las variables específicas de un entorno (ONTAP, Linux u Oracle) para la puesta en marcha de Oracle.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">Edite y copie las variables de la sección VARS y pegue estas variables en su<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="section-title">VAR</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">Ejecute el libro de estrategia</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">Después de completar los requisitos previos de entorno necesarios y copiar las variables en<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> y..<block ref="97513b66e909abfd622924972387a816" prefix=" " category="inline-code"></block>, ya está listo para implementar los libros de estrategia.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">debe cambiarse &lt;username&gt; para adecuarse a su entorno.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">Ponga en marcha una base de datos adicional en el mismo host de Oracle</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">La parte Oracle del playbook crea una única base de datos de contenedor Oracle en un servidor Oracle por ejecución. Para crear una base de datos de contenedores adicional en el mismo servidor, lleve a cabo los siguientes pasos:</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">Revise las variables host_var.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">Vuelva al paso 3 - edite el<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> archivo debajo<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Cambie el SID de Oracle a una cadena de nomenclatura diferente.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">Cambie el puerto de escucha a un número diferente.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">Si ha instalado EM Express, cambie el puerto de EM Express a otro número.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">Copie y pegue las variables de host revisadas en el archivo de variable de host Oracle en<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">Ejecute el libro de estrategia con<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block> etiquetar como se muestra arriba en la <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="section-title">Validar la instalación de Oracle</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">Se enumerarán los procesos de oracle si la instalación se ha completado como se esperaba y oracle DB ha iniciado</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost ~]$ sqlplus / as sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL*Plus: Versión 19.0.0.0.0 - producción el Jue 6 12:52:51 2021 Versión 19.8.0.0.0</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; SELECT name, log_mode from v$database; NAME LOG_MODE ----------- ------------- CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; mostrar pdb</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname form a30 SQL&gt; col rname form a30 SQL&gt; seleccione svrname, dirname, nfsversion de v$dnfs_Servers;</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">NOMBRE DE DIRECTORIO DE SVRNAME NFSVERSION ----------------------------------------- ------------------------------------ --------------------- 172.21.126.200 /rhelora03_u02 NFSv3.0 172.21.126.200 /rhelora03_u03 NFSv3.0 172.21.126.200 /rhelora03_u01 NFSv3.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle@localhost ~]$ sqlplus system@//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL*Plus: Versión 19.0.0.0.0 - producción el Jue 6 13:19:57 2021 Versión 19.8.0.0.0</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">Introducir contraseña: Última hora de inicio de sesión correcta: Mié May 05 2021 17:11:11 -04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show user USER IS "SYSTEM" SQL&gt; show con_name CON_NAME CDB2_PDB1</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">La comunidad de automatización de soluciones de NetApp admite el canal de Slack</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">Si necesita ayuda con el kit de herramientas, por favor únase al <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> y busque el canal de automatización de soluciones para publicar sus preguntas o preguntas.</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">Este documento describe una puesta en marcha en tiempo real de SQL Server Always On Availability Group (AOAG) en Azure NetApp Files aprovechando las máquinas virtuales de Azure.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897: SQL Server en Azure NetApp Files: Vista de la puesta en marcha real</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">Las organizaciones DE TECNOLOGÍA se enfrentan a cambios constantes. Gartner afirma que casi el 75 % de todas las bases de datos requerirán de almacenamiento basado en cloud en 2022. Como sistema de gestión de bases de datos relacionales (RDBMS) líder, Microsoft SQL Server es la elección preferida para las aplicaciones y organizaciones diseñadas para plataformas de Windows que utilizan SQL Server para todo tipo de tareas, desde la planificación de recursos empresariales (ERP) a los análisis y la gestión de contenidos. SQL Server ha ayudado a revolucionar la forma en que las empresas gestionan enormes conjuntos de datos y potencian sus aplicaciones para cumplir con las demandas de rendimiento del esquema y de las consultas.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">La mayoría de las organizaciones DE TECNOLOGÍA siguen un enfoque de «cloud primero». Los clientes en una fase de transformación evalúan su entorno DE TI actual y, posteriormente, migran las cargas de trabajo de sus bases de datos al cloud en función de un ejercicio de evaluación y detección. Algunos factores que impulsan a los clientes hacia la migración al cloud son la elasticidad/ráfaga, la salida del centro de datos, la consolidación del centro de datos, los escenarios de fin de la vida útil, las fusiones, adquisiciones, etc. El motivo de la migración puede variar en función de cada organización y sus respectivas prioridades empresariales. A la hora de trasladarse a cloud, elegir el almacenamiento en cloud adecuado es muy importante para aprovechar el poder de la puesta en marcha de cloud de las bases de datos de SQL Server.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">Caso de uso</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">Mover la unidad de SQL Server a Azure e integrar SQL Server con la amplia gama de funciones de plataforma como servicio (PaaS) de Azure, como Azure Data Factory, Azure IoT Hub y Azure Machine Learning, crean un enorme valor empresarial para respaldar la transformación digital. Al adoptar el cloud, también la unidad de negocio respectiva puede centrarse en la productividad y proporcionar nuevas funciones y mejoras más rápidamente (caso de uso de DevTest) que si se basa en el modelo de gastos de capital o en los modelos de cloud privado tradicionales. Este documento describe una puesta en marcha en tiempo real de SQL Server Always On Availability Group (AOAG) en Azure NetApp Files aprovechando las máquinas virtuales de Azure.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files proporciona almacenamiento de clase empresarial con recursos compartidos de archivos disponibles de forma continua. Las bases de datos de producción de SQL Server necesitan recursos compartidos constantemente disponibles en el recurso compartido de archivos SMB para garantizar que el nodo siempre tiene acceso al almacenamiento de bases de datos, incluidos durante situaciones disruptivas como actualizaciones o fallos de controladoras. Los recursos compartidos de archivos de disponibilidad continua eliminan la necesidad de replicar datos entre nodos de almacenamiento. Azure NetApp Files utiliza escalabilidad horizontal, controladores persistentes y recuperación tras fallos transparente de SMB 3.0 para admitir operaciones no disruptivas (NDO) en eventos de tiempo de inactividad planificados y no planificados, incluidas una gran cantidad de tareas administrativas.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">Al planificar las migraciones en cloud, siempre debe evaluar el mejor método de uso. El método más común y sencillo para la migración de aplicaciones es el realojamiento (también conocido como lift and shift). El escenario de ejemplo que se proporciona en este documento utiliza el método de rehosting. SQL Server en máquinas virtuales Azure con Azure NetApp Files le permite utilizar versiones completas de SQL Server en el cloud sin tener que gestionar el hardware en las instalaciones. Las máquinas virtuales de SQL Server (VM) también simplifican los costes de licencia cuando se paga por uso y ofrecen elasticidad y capacidades de ruptura para escenarios de desarrollo, pruebas y actualización de estado.</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">Las organizaciones están automatizando sus entornos para conseguir eficiencias, acelerar las puestas en marcha y reducir el esfuerzo manual. Se están utilizando herramientas de gestión de configuraciones como Ansible para optimizar las operaciones de las bases de datos empresariales. En esta solución, demostramos cómo puede usar Ansible para automatizar la protección de datos de Oracle con ONTAP de NetApp. Al permitir que los administradores de almacenamiento, los administradores de sistemas y los administradores de bases de datos configuran de forma constante y rápida la replicación de datos en un centro de datos externo o en un cloud público, puede disfrutar de las siguientes ventajas:</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">Reducir el tiempo de configuración de la replicación entre clústeres, la creación de instancias de CVO y la recuperación de las bases de datos Oracle</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">Proporciona un flujo de trabajo de recuperación de bases de datos para probar con facilidad un supuesto de recuperación ante desastres.</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">De las instalaciones a la replicación en las instalaciones</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">Crear LIF de interconexión de clústeres en el origen y el destino</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">Establecimiento de agrupación en cluster y Vserver</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Crear e inicializar SnapMirror de volúmenes de Oracle</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Cree un programa de replicación a través de AWX/Tower para archivos binarios, bases de datos y registros de Oracle</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">Restaure la base de datos de Oracle en el destino y coloque la base de datos en línea</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">De forma local a CVO en AWS</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">Cree el conector AWS</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">Cree una instancia de CVO en AWS</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Agregue clúster local a Cloud Manager</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">Crear LIF de interconexión de clústeres en el origen</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">Parte 1: Por determinar</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">Parte 2: Por determinar</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">aquí para empezar con la solución</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">Una vez que esté listo, haga clic en <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="41f2543265fcbcf566ce925409c1bfbb" category="summary">Esta sección proporciona información detallada sobre cómo migrar la base de datos Oracle de las instalaciones a Azure NetApp Files y viceversa.</block>
  <block id="3b99478aefcc6039ddcb29f19ce3f1ee" category="doc">Migración de bases de datos desde las instalaciones al cloud de Azure</block>
  <block id="964310198f864c746c945ff1c6fffe3f" category="inline-link-macro">Anterior: Protección de bases de datos.</block>
  <block id="413dcfd081f137889743981159ac9abe" category="paragraph"><block ref="413dcfd081f137889743981159ac9abe" category="inline-link-macro-rx"></block></block>
  <block id="3c2b924258f32094eb64883db57a778a" category="paragraph">Como resultado de la decisión de Oracle de eliminar las bases de datos de instancia única, muchas organizaciones han convertido bases de datos de Oracle de instancia única en bases de datos de contenedores multitenant. Esto permite la fácil reubicación de un subconjunto de bases de datos de contenedor llamadas PDB a cloud con la opción de disponibilidad máxima, que minimiza el tiempo de inactividad durante la migración.</block>
  <block id="a221bb2d4b0b28bb7e9aa40527e36333" category="paragraph">Sin embargo, si todavía tiene una única instancia de una base de datos de Oracle, primero puede convertirse en una base de datos de contenedor multitenant en su lugar antes de intentar reubicar la PDB.</block>
  <block id="3312d9383c6e42558bb6c7ffa86498b5" category="paragraph">En las siguientes secciones se ofrecen detalles sobre la migración de las bases de datos de Oracle en las instalaciones al cloud de Azure en cualquiera de estos casos.</block>
  <block id="b65ba7cc82289837e3a44b6025b8a104" category="paragraph">Si aún tiene una base de datos de Oracle de una instancia, debe convertirse en una base de datos de contenedor multitenant tanto si desea migrarla al cloud como si no, ya que Oracle dejará de admitir bases de datos de instancia única pronto.</block>
  <block id="60a4157f0722b484d4ce9ec02662db31" category="paragraph">En los siguientes procedimientos se conecta una base de datos de instancia única a una base de datos de contenedor como una base de datos o una PDB conectables.</block>
  <block id="aefccbe3e9382cbdd83d84fee06a408d" category="list-text">Cree una base de datos de contenedor de shell en el mismo host que la base de datos de instancia única en un servidor independiente<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>.</block>
  <block id="182e093a477c76844c12680be3deb7a4" category="list-text">Cierre la base de datos de instancia única y reiníciela en modo de sólo lectura.</block>
  <block id="48270a516aeb2dd47c2b7f5d897c3182" category="list-text">Ejecute el<block ref="707fc638546e97f4dca068fcf2fbe277" prefix=" " category="inline-code"></block> procedimiento para generar los metadatos de la base de datos.</block>
  <block id="61c2d2d903cc3e2bc374cc66b3a1572d" category="list-text">Cierre la base de datos de instancia única.</block>
  <block id="d0e90ac40083de7010746f1c7afa8680" category="list-text">Inicie la base de datos contenedora.</block>
  <block id="c9b14b140c5af8df85a71e71e823fcd9" category="list-text">Ejecute el<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> Función para determinar si la CDB no es compatible con la CDB.</block>
  <block id="b4579eff709cfd4a9e9d9b3c7823a470" category="paragraph">Si la salida es SÍ, la base de datos no CDB es compatible y puede continuar con el paso siguiente.</block>
  <block id="b788542aadbeda07cae67fad51f01ecf" category="paragraph">Si la salida es NO, la base de datos que no es CDB no es compatible y puede comprobar la<block ref="40bcd9431704d488bfba8de25bdd0469" prefix=" " category="inline-code"></block> ver para ver por qué no es compatible. Todas las violaciones deben corregirse antes de continuar. Por ejemplo, cualquier error de coincidencia de versión o parche debe resolverse ejecutando una actualización o la utilidad opatch. Después de corregir las violaciones, ejecute<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> De nuevo para asegurarse de que la CDB no es compatible con la CDB.</block>
  <block id="3dc81f6d88ee2f38ca30676e4b371634" category="list-text">Conecte la instancia única que no es CDB.</block>
  <block id="10a9ce9a6e151e6ff04bee976e0cb1de" category="admonition">Si no hay espacio suficiente en el host, el<block ref="4777c7eb130280b37f5b4b3abde7c586" prefix=" " category="inline-code"></block> Se puede usar la opción para crear la PDB. En ese caso, no se puede utilizar una sola instancia que no sea CDB después del plugin como una PDB debido a que se usaron los archivos de datos originales para la PDB. Asegúrese de crear una copia de seguridad antes de la conversión para que haya algo que volver a caer en caso de que algo vaya mal.</block>
  <block id="03d9f2c68151dce9edd03b346e5b110c" category="list-text">Empiece con la actualización de PDB después de la conversión si la versión entre la base de datos no CDB de instancia única de origen y la CDB de destino son diferentes. Para la conversión de la misma versión, se puede omitir este paso.</block>
  <block id="81954d0087f2bc7590c39792b2d3ff79" category="paragraph">Revise el archivo de registro de actualización en la<block ref="8940bd010306ed7bc730469a2815003c" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="65f9a981d9b9caaa37a227c9d787c280" category="list-text">Abra la base de datos conectable, compruebe las violaciones del plug-in pdb y vuelva a compilar los objetos no válidos.</block>
  <block id="f4d5586e12195159e664b1f0a78cccd3" category="list-text">Ejecución<block ref="30636d635a272a80dff68679e08f1c7a" prefix=" " category="inline-code"></block> para actualizar el diccionario de datos.</block>
  <block id="182d7c995640cc8ef16b728a670fbe58" category="paragraph">Cierre y reinicie la base de datos del contenedor. la ncdb se sale del modo restringido.</block>
  <block id="d6af386b8be94481db3de6778b3fc24a" category="section-title">Migrar bases de datos de Oracle locales a Azure con la reubicación de PDB</block>
  <block id="da5d44e97cbc406251573e1664b5e1f0" category="paragraph">La reubicación de PDB de Oracle con la opción de disponibilidad máxima utiliza la tecnología de clonado en activo de PDB, lo que permite la disponibilidad de la PDB de origen mientras se copia la PDB en el destino. Tras la conmutación de sitios, las sesiones y las conexiones se redirigen automáticamente a la PDB de destino. Así, el tiempo de inactividad se minimiza independientemente del tamaño de la PDB que se va a reubicar. NetApp proporciona un kit de herramientas basado en Ansible que automatiza el procedimiento de migración.</block>
  <block id="a8efacce1c06e5f64504448dec25740a" category="list-text">Cree una CDB en el cloud público de Azure en una máquina virtual de Azure con el mismo nivel de versión y revisión.</block>
  <block id="0f09a4e81820f79a89d0b433bb0de6ca" category="list-text">Desde la controladora de Ansible, clone una copia del kit de herramientas de automatización.</block>
  <block id="33abd0ac6a3fb7ef8c104725e8360e85" category="list-text">Lea la instrucción del archivo README.</block>
  <block id="59082266ab8171963eb8785041055ee1" category="list-text">Configure los archivos variables de host de Ansible para los servidores Oracle de origen y de destino y el archivo de configuración del host del servidor de base de datos para la resolución de nombres.</block>
  <block id="166811e58fa2fd17b3ab3305ca4b1948" category="list-text">Instale los requisitos previos de la controladora Ansible en la controladora Ansible.</block>
  <block id="e40dd1f176a77cef20eb421dee4fea9f" category="list-text">Ejecute las tareas previas a la migración en el servidor local.</block>
  <block id="aba7f3209eb8c49aca729c7368fb42fe" category="admonition">El usuario admin es el usuario de gestión en el host del servidor Oracle local con privilegios sudo. El usuario administrador se autentica con una contraseña.</block>
  <block id="a1da14dd2e192d36a7fe7bae327c2b23" category="list-text">Ejecute la reubicación de PDB de Oracle desde las instalaciones al host de Oracle de Azure de destino.</block>
  <block id="39f1871870cabd138bd313c450662e67" category="admonition">La controladora de Ansible puede ubicarse tanto en las instalaciones como en el cloud de Azure. La controladora necesita conectividad al host del servidor de Oracle local y al host de Oracle VM de Azure. El puerto de la base de datos de Oracle (como 1521) está abierto entre el host del servidor de Oracle local y el host de Oracle VM de Azure.</block>
  <block id="63a48a0f7ee4b39ef32c11b92acc2baa" category="section-title">Opciones de migración de bases de datos de Oracle adicionales</block>
  <block id="7619081ba13aebf0c83d5660f9bf01bb" category="inline-link-macro">Proceso de decisión de migración de bases de datos de Oracle</block>
  <block id="0257ad9cf0c221fcf0c611f835c027ca" category="paragraph">Consulte la documentación de Microsoft para obtener más opciones de migración: <block ref="421a85ebca6e289a6eff559e7e35faf8" category="inline-link-macro-rx"></block>.</block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">Esta solución se ha diseñado para ejecutarse en un entorno AWX/Tower o mediante la interfaz de línea de comandos en un host de control de Ansible.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">La plantilla de trabajo se ejecuta en tres fases especificando etiquetas para ontap_config, linux_config y oracle_config.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">CLI a través del host de control de Ansible</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">Haga clic aquí para RHEL 7/8 o CentOS 7/8</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Aquí para Ubuntu/Debian</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Para configurar el host Linux, de modo que pueda usarse como host de control de Ansible<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>, o.<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Una vez configurado el host de control de Ansible, puede clonar el repositorio de Ansible Automation.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">Edite el archivo hosts con las IP y/o los nombres de host de la gestión del clúster de ONTAP y las IP de gestión de servidores de Oracle.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">Rellene las variables específicas de su entorno y cópielas y péguelas en el<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">Cada host Oracle tiene un archivo de variable identificado por su nombre de host que contiene variables específicas del host.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">Después de completar todos los archivos variables, puede ejecutar la tableta playbook en tres fases especificando etiquetas para<block ref="0aadb2735557202c6ab978c489e2b6e9" prefix=" " category="inline-code"></block>,<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block>, y.<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block>.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">El host AWX/Tower o Linux será el host de control de Ansible</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP versión 9.3 - 9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Archivos de instalación de Oracle en servidores Oracle</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">*ontap_config*</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Creación de SVM basada en NFS para Oracle</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">Creación de una política de exportación</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Creación de volúmenes para Oracle</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">Creación de LIF NFS</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">Cree puntos de montaje y monte volúmenes NFS</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">Verificar los montajes NFS</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">Configuración específica del SO</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Cree directorios de Oracle</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">Configurar hugepages</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">Desactive SELinux y el daemon de firewall</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">Activar e iniciar el servicio chronyd</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">aumente el límite duro del descriptor de archivo</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">Cree el archivo de sesión pam.d</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">*oracle_config*</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Instalación de software de Oracle</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Cree el listener de Oracle</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Crear bases de datos de Oracle</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Configuración del entorno de Oracle</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">Guarde el estado de PDB</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">Habilitar el modo de archivo de instancias</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">Habilite el cliente DNFS</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">Habilite el inicio y apagado automático de la base de datos entre reinicios del sistema operativo</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">Para simplificar la automatización, hemos predefinido muchos parámetros de puesta en marcha de Oracle necesarios con valores predeterminados. Por lo general, no es necesario cambiar los parámetros predeterminados para la mayoría de las implementaciones. Un usuario más avanzado puede realizar cambios en los parámetros predeterminados con precaución. Los parámetros predeterminados se encuentran en cada carpeta de funciones en el directorio por defecto.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">Instrucciones de puesta en funcionamiento</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">Antes de comenzar, descargue los siguientes archivos de instalación y revisión de Oracle y colóquelos en<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> directorio con acceso de lectura, escritura y ejecución para todos los usuarios en cada servidor de base de datos que se va a implementar. Las tareas de automatización buscan los archivos de instalación con nombre en ese directorio en particular para la instalación y configuración de Oracle.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">Aquí encontrará información detallada sobre los procedimientos de despliegue de AWX/Tower</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">Aquí para la puesta en marcha de la CLI</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">Una vez que esté listo, haga clic en <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> o. <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">Las tareas descritas en esta sección deben completarse en las instalaciones para preparar el entorno de carga de trabajo de bases de datos de cloud híbrido de SnapCenter.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">Requisitos previos en las instalaciones</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">Anterior: Requisitos previos de la configuración.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">Las siguientes tareas deben completarse en las instalaciones para preparar el entorno de cargas de trabajo de bases de datos del cloud híbrido de SnapCenter.</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">La herramienta SnapCenter de NetApp es una aplicación basada en Windows que se ejecuta normalmente en un entorno de dominio de Windows, aunque también es posible instalar un grupo de trabajo. Se basa en una arquitectura de varios niveles que incluye un servidor de gestión centralizado (el servidor SnapCenter) y un complemento de SnapCenter en los hosts de servidores de bases de datos para cargas de trabajo de bases de datos. Estas son algunas consideraciones clave para la puesta en marcha del cloud híbrido.</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">*Implementación de una sola instancia o de alta disponibilidad.* la implementación de alta disponibilidad ofrece redundancia en caso de un fallo del servidor de instancia de SnapCenter.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">*Resolución de nombres.* se debe configurar DNS en el servidor SnapCenter para resolver todos los hosts de base de datos, así como en la SVM de almacenamiento para la búsqueda directa e inversa. El DNS también debe configurarse en los servidores de bases de datos para resolver el servidor SnapCenter y la SVM de almacenamiento para la búsqueda directa e inversa.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">*Configuración de control de acceso basado en funciones (RBAC).* para cargas de trabajo mixtas de bases de datos, es posible que desee utilizar RBAC para separar la responsabilidad de la administración de una plataforma de base de datos diferente, como un administrador para bases de datos Oracle o un administrador para SQL Server. Se deben conceder los permisos necesarios para el usuario administrador de la base de datos.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">*Active la estrategia de copia de seguridad basada en directivas.* para aplicar la consistencia y fiabilidad de las copias de seguridad.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">*Abra los puertos de red necesarios en el firewall.* para que el servidor SnapCenter en las instalaciones se comunique con los agentes instalados en el host de la base de datos en la nube.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">*Los puertos deben estar abiertos para permitir el tráfico SnapMirror entre el cloud público y en las instalaciones*. El servidor SnapCenter confía en SnapMirror de ONTAP para replicar los backups de Snapshot in situ en las SVM de almacenamiento CVO en el cloud.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">Flujo de trabajo de instalación de SnapCenter</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">Tras una planificación y consideración cuidadosas previas a la instalación, haga clic en esto <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> Para obtener más información acerca de la instalación y configuración de SnapCenter.</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">El rendimiento del almacenamiento desempeña un papel importante en el rendimiento general de las bases de datos y las aplicaciones. Un sistema de almacenamiento bien diseñado no solo puede mejorar el rendimiento de las bases de datos, sino que también facilita la gestión de los procesos de backup y recuperación de bases de datos. Se deben tener en cuenta varios factores al definir la distribución de almacenamiento, como el tamaño de la base de datos, la tasa de cambio esperado de los datos y la frecuencia con la que se realizan backups.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">La conexión directa de LUN de almacenamiento al equipo virtual «guest» mediante NFS o iSCSI para cargas de trabajo de bases de datos virtualizadas suele proporcionar un mejor rendimiento que el almacenamiento asignado a través de VMDK. NetApp recomienda el diseño del almacenamiento para una base de datos de SQL Server grande en las LUN descritas en la siguiente figura.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">La siguiente figura muestra la distribución de almacenamiento recomendada por NetApp para bases de datos de SQL Server pequeñas o medianas en LUN.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">El directorio de registro se dedica a SnapCenter para realizar un paquete acumulativo de registros de transacciones para la recuperación de la base de datos. Para una base de datos extra grande, se pueden asignar varios LUN a un volumen para mejorar el rendimiento.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Para cargas de trabajo de bases de datos de Oracle, SnapCenter admite entornos de base de datos respaldados por almacenamiento ONTAP que están montados en el host como dispositivos físicos o virtuales. Puede alojar toda la base de datos en un único dispositivo de almacenamiento o en varios en función de la importancia del entorno. Normalmente, los clientes aíslan los archivos de datos del almacenamiento dedicado de todos los demás archivos, como los archivos de control, los archivos de recuperación y los archivos de registro de archivos. De este modo, los administradores pueden restaurar rápidamente (SnapRestore de un solo archivo de ONTAP) o clonar una base de datos crítica de gran tamaño (a escala de petabytes) mediante la tecnología Snapshot en unos pocos segundos o minutos.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">En el caso de cargas de trabajo críticas que sean sensibles a la latencia, se debe poner en marcha un volumen de almacenamiento dedicado en diferentes tipos de archivos de Oracle para lograr la mejor latencia posible. Para una base de datos grande, se deben asignar varios LUN (NetApp recomienda hasta ocho) por volumen a los archivos de datos.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">En el caso de bases de datos de Oracle más pequeñas, SnapCenter admite diseños de almacenamiento compartido en los que puede alojar varias bases de datos o parte de una base de datos en el mismo volumen de almacenamiento o una LUN. Como ejemplo de este diseño, es posible alojar archivos de datos de todas las bases de datos en un grupo de discos +DATA ASM o un grupo de volúmenes. El resto de los archivos (archivos de recuperación, registro de archivo y de control) se puede alojar en otro grupo de discos o grupo de volúmenes dedicado (LVM). A continuación se ilustra un escenario de despliegue de este tipo.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Para facilitar la reubicación de las bases de datos de Oracle, el binario de Oracle debe instalarse en un LUN independiente que se incluya en la política de backup normal. Esto garantiza que, en caso de reubicación de la base de datos a un nuevo host de servidor, la pila de Oracle se pueda iniciar para la recuperación sin ningún problema potencial debido a un binario de Oracle que no está sincronizado.</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter es un software con licencia de NetApp. Por lo general se incluye en una licencia ONTAP en las instalaciones. Sin embargo, para la puesta en marcha de cloud híbrido, también es necesaria una licencia de cloud para SnapCenter para añadir CVO a SnapCenter como destino de replicación de datos objetivo. Consulte los siguientes enlaces de las licencias estándar basadas en capacidad de SnapCenter para obtener más información:</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">Licencias basadas en capacidad estándar de SnapCenter</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">En una operación de base de datos híbrida que requiere una base de datos de producción en las instalaciones que sea estable al cloud para desarrollo y pruebas y recuperación ante desastres, es importante tener en cuenta la relación con redes y seguridad cuando se configura el entorno y se conecta al cloud público desde un centro de datos en las instalaciones.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">Los clouds públicos normalmente utilizan un cloud privado virtual (VPC) para aislar a diferentes usuarios dentro de una plataforma de cloud público. Dentro de un VPC individual, la seguridad se controla mediante medidas como los grupos de seguridad que se pueden configurar de acuerdo con las necesidades del usuario para el bloqueo de un VPC.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">La conectividad del centro de datos local al VPC se puede proteger a través de un túnel VPN. En la puerta de enlace VPN, la seguridad se puede reforzar mediante reglas NAT y firewall que bloquean los intentos de establecer conexiones de red desde los hosts de Internet a los hosts dentro del centro de datos corporativo.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">Para conocer las consideraciones de redes y seguridad, revise las reglas de CVO entrantes y salientes pertinentes para el cloud público que elija:</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">Reglas de grupo de seguridad para CVO - AWS</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">Reglas de grupo de seguridad para CVO - Azure</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">Reglas de firewall para CVO - GCP</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Uso de la automatización de Ansible para sincronizar instancias de bases de datos entre las instalaciones y el cloud, opcional</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">Para simplificar la gestión de un entorno de bases de datos de cloud híbrido, NetApp recomienda encarecidamente, pero no requiere que ponga en marcha una controladora Ansible para automatizar algunas tareas de gestión, como mantener las instancias informáticas locales y en el cloud sincronizadas. Esto es especialmente importante porque una instancia de computación fuera de sincronización en el cloud puede hacer que la base de datos recuperada en el cloud sea propensa a errores debido a que faltan paquetes del kernel y otros problemas.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">También se puede usar la funcionalidad de automatización de una controladora de Ansible para aumentar el número de SnapCenter a fin de realizar ciertas tareas, como dividir la instancia de SnapMirror para activar la copia de datos de recuperación ante desastres para producción.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">Configuración de la controladora Red Hat/CentOS Ansible</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Configuración de la controladora Ubuntu/Debian Ansible</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">Siga estas instrucciones para configurar el nodo de control de Ansible para máquinas RedHat o CentOS: <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. Siga estas instrucciones para configurar el nodo de control de Ansible para máquinas Ubuntu o Debian: <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">Siguiente: Cloud público.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">Implementación de AWX/Tower base de datos de Oracle 19c</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. Cree el inventario, el grupo, los hosts y las credenciales para su entorno</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">Si hay alguna variable de inventario, péguela en el campo variables.</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">Introduzca el nombre del grupo para ONTAP, pegue las variables de grupo (si las hubiera) y haga clic en Guardar.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Repita el proceso para otro grupo para Oracle.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">Seleccione el grupo ONTAP creado, vaya al submenú hosts y haga clic en Add New Host.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">Proporcione la dirección IP de la IP de gestión del clúster de ONTAP, pegue las variables de host (si las hubiera) y haga clic en Guardar.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Este proceso debe repetirse para el nombre de host/IP de gestión del grupo Oracle y hosts Oracle.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">Crear tipos de credenciales. En el caso de las soluciones que implican ONTAP, debe configurar el tipo de credencial de modo que coincida con las entradas de nombre de usuario y contraseña.</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">Pegue el siguiente contenido en Configuración del inyector:</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">Introduzca el nombre y los detalles de la organización de ONTAP.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">Seleccione el tipo de credencial personalizada que ha creado para ONTAP.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">En Type Details, introduzca el nombre de usuario, la contraseña y vsadmin_Password.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">Haga clic en Back to Credential y haga clic en Add.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Introduzca el nombre y los detalles de la organización de Oracle.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. Cree un proyecto</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">introduzca <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> Como URL de control de origen.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Configurar Oracle host_var</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">Las variables definidas en esta sección se aplican a cada servidor y base de datos Oracle individuales.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">Introduzca los parámetros específicos del entorno en las siguientes variables de host de Oracle integradas o de host_var.</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">Rellene todas las variables de los campos azules.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">Después de completar la entrada de variables, haga clic en el botón Copiar del formulario para copiar todas las variables que se van a transferir a AWX o Tower.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">Vuelva a AWX o Tower y vaya a Resources → hosts, y seleccione y abra la página de configuración del servidor Oracle.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">En la ficha Detalles, haga clic en editar y pegue las variables copiadas del paso 1 al campo variables bajo la ficha AYLMA.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">Repita este proceso con todos los servidores Oracle adicionales del sistema.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. Configurar variables globales</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">Rellene todas las variables en campos azules.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">Después de completar la entrada de variables, haga clic en el botón Copiar del formulario para copiar todas las variables que se van a transferir a AWX o Tower en la siguiente plantilla de trabajo.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. Configure e inicie la plantilla de trabajo.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">Introduzca el nombre y la descripción</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">Seleccione el tipo de trabajo; Run configura el sistema en función de una tableta playbook y Check realiza una ejecución en seco de una tableta playbook sin configurar realmente el sistema.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">Seleccione all_playbook.yml como la tableta PlayBook predeterminada que se va a ejecutar.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">Active la casilla solicitar al iniciar en el campo Etiquetas de trabajo.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">Cuando se le solicite al iniciar las etiquetas de trabajo, escriba requerimientos_config. Puede que tenga que hacer clic en la línea Create Job Tag situada debajo de requisitos_config para introducir la etiqueta de trabajo.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requerimientos_config asegura que tiene las bibliotecas correctas para ejecutar las otras funciones.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">Haga clic en Siguiente y luego en Iniciar para iniciar el trabajo.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">Haga clic en Ver → trabajos para supervisar la salida y el progreso del trabajo.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">Cuando se le solicite en el inicio de Job Tags, escriba ontap_config. Es posible que deba hacer clic en la línea Create "Job Tag" justo debajo de ontap_config para introducir la etiqueta del trabajo.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">Haga clic en Ver → trabajos para supervisar la salida y el progreso del trabajo</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">Una vez completado el rol ontap_config, vuelva a ejecutar el proceso para linux_config.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">Seleccione la plantilla deseada y haga clic en Iniciar.</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Cuando se le solicite al iniciar el tipo de etiquetas de trabajo en linux_config, es posible que deba seleccionar la línea Crear "etiqueta de trabajo" situada justo debajo de linux_config para introducir la etiqueta de trabajo.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">Seleccione Ver → trabajos para supervisar la salida y el progreso del trabajo.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Una vez completado el rol linux_config, vuelva a ejecutar el proceso para oracle_config.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">Vaya a Recursos → Plantillas.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">Cuando se le solicite al iniciar las etiquetas de trabajo, escriba oracle_config. Es posible que deba seleccionar la línea Crear "Job Tag" situada justo debajo de oracle_config para introducir la etiqueta de trabajo.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. Implementar una base de datos adicional en el mismo host Oracle</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">La parte Oracle del playbook crea una única base de datos de contenedor Oracle en un servidor Oracle por ejecución. Para crear bases de datos de contenedores adicionales en el mismo servidor, lleve a cabo los siguientes pasos.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">Revisar las variables host_var.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">Vuelva al paso 2: Configure Oracle host_var.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">Si está instalando EM Express, cambie el puerto de EM Express a un número diferente.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">Copie y pegue las variables de host revisadas en el campo variables de host de Oracle de la pestaña Detalles de configuración de host.</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">Inicie la plantilla de trabajo de implementación con sólo la etiqueta oracle_config.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">En esta sección se proporciona un resumen de las tareas que deben completarse para cumplir los requisitos previos, tal como se describen en la sección anterior. En la siguiente sección, se proporciona una lista de tareas de alto nivel para las operaciones de cloud público y en las instalaciones. Se puede acceder a los procesos y procedimientos detallados haciendo clic en los enlaces correspondientes.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">Información general del inicio</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">Anterior: Requisitos previos para el cloud público.</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">Configure el usuario administrador de la base de datos en SnapCenter</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">Requisitos previos de instalación del plugin de SnapCenter</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">Instalación del complemento de host de SnapCenter</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">Descubrimiento de recursos DE BASE de datos</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">Configurar la conexión entre iguales de clústeres de almacenamiento y la replicación de volúmenes de base de datos</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">Añada la SVM de almacenamiento de base de datos de CVO a SnapCenter</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">Validar el backup</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">Comprobación previa al vuelo</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">Pasos para implementar Cloud Manager y Cloud Volumes ONTAP en AWS</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">Ponga en marcha la instancia de EC2 para cargas de trabajo de bases de datos</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">Haga clic en los siguientes enlaces para obtener información detallada:</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">Cloud público: AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">Acerca de este repositorio</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">Breve introducción al repositorio de soluciones de NetApp: Dónde encontrar soluciones específicas y cómo utilizar este repositorio.</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">Navegación por el repositorio</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">La navegación del repositorio está gestionada por la barra lateral principal, que se presenta en el lado izquierdo de la página. Las soluciones se clasifican en áreas técnicas de mayor nivel definidas como las "torres tecnológicas" de las soluciones de NetApp.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Visión General de las torres tecnológicas</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">*Sección*</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*Página de aterrizaje de Contenido*</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">Colección de soluciones basadas en IA. La página de destino de IA ofrece contenido muy popular presentado en «azulejos» específicos.</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">Contenido de IA</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">Colección de soluciones modernas de análisis de datos (p. ej., Splunk SmartStore, Apache Spark, etc.). La moderna página de destino de los análisis de datos ofrece contenido popular presentado en «iconos» específicos.</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">Contenido moderno de análisis de datos</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">Define NetApp en un modelo de multicloud híbrido, incluidas las opciones de VMware en el cloud público y almacenamiento de NetApp en cada uno de los proveedores a hiperescala. La página de destino del multicloud híbrido ofrece contenido popular presentado en «azulejos» específicos.</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">Multicloud híbrido con contenido de VMware</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">Colección de soluciones centrales de virtualización, que incluye la virtualización de puestos de trabajo. La página de destino de la virtualización ofrece contenido popular presentado en «mosaicos» específicos del contenido.</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">Contenido de virtualización</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">Colección de soluciones basadas en contenedores. La página de destino de la virtualización ofrece contenido popular presentado en «mosaicos» específicos del contenido.</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">Contenido de contenedores</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">Bases de datos y aplicaciones empresariales</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">Recopilación de aplicaciones empresariales y soluciones de bases de datos. La página de destino de SAP y SAP HANA ofrece contenido popular presentado en "mosaico" específico del contenido. Las soluciones de base de datos Oracle y SQL Server también se tratan en esta sección.</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">Contenido de SAP y SAP HANA</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="cell">Migración y protección de datos</block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">Colección de migración de datos, protección de datos y soluciones de seguridad de datos.</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Información general sobre los primeros pasos con la automatización de soluciones con Red Hat Ansible.</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Cambiar registro</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">registro de cambios</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">Todos los cambios importantes en el repositorio (nuevas soluciones, actualizaciones importantes, nuevos vídeos, demostraciones, etc.) se realizan a través del <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>.</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">Comentarios</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">Utilice <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> para solicitar cambios en el contenido o proporcionar comentarios sobre él. Por favor, sea lo más específico posible para asegurarse de que sus comentarios son tratados apropiadamente.</block>
  <block id="10408567d24e2dd65731b1e2f0508a5d" category="doc">Plugin de SnapCenter de NetApp para VMware vSphere: Requisitos previos de la solución</block>
  <block id="0a70bb0111bccb302f68cc327b0527f8" category="inline-link-macro">Anterior: Información adicional - Plugin de SnapCenter para VMware vSphere - implementación.</block>
  <block id="dc69c4899210bca949880d9753e92b35" category="paragraph"><block ref="dc69c4899210bca949880d9753e92b35" category="inline-link-macro-rx"></block></block>
  <block id="8eaab69b7b060fb16ac9ba9484edb36e" category="inline-link-macro">Siguiente: Información adicional - plugin de SnapCenter para VMware vSphere - flujo de trabajo de backup.</block>
  <block id="4602e4aeb078cfce115f5bcaf3d65ba7" category="paragraph"><block ref="4602e4aeb078cfce115f5bcaf3d65ba7" category="inline-link-macro-rx"></block></block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Con la transición del dispositivo virtual anterior, las herramientas de ONTAP incorporan una gran cantidad de nuevas funciones, límites más altos y nueva compatibilidad con vVols.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nuevas funcionalidades con SRM y las herramientas de ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Versiones más recientes de vSphere y Site Recovery Manager</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">Con el lanzamiento de SRM 8.3 y versiones posteriores y la versión 9.7.1 y posteriores de las herramientas de ONTAP, ahora puede proteger máquinas virtuales que se ejecuten en VMware vSphere 7.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp ha compartido una estrecha colaboración con VMware durante casi dos décadas y se esfuerza por ofrecer soporte para las últimas versiones de Lo antes posible.. Consulte siempre la herramienta de matriz de interoperabilidad (IMT) de NetApp para ver las combinaciones de software más recientes cualificadas.</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">Puede encontrar el IMT de NetApp<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">Compatibilidad con vVols (y por qué es importante SPBM, incluso SRM)</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">A partir de la versión 8.3, SRM ahora admite la gestión basada en políticas de almacenamiento (SPBM) de la replicación aprovechando vVols y la replicación basada en cabinas. Para ello, se actualizó el servidor SRM para incluir un nuevo servicio de proveedor SRM vVols, que se comunica con el servicio SMS del servidor vCenter para tareas relacionadas con VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Una ventaja de esta arquitectura es que el SRA ya no es necesario porque todo se gestiona con VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">La SPBM es una potente herramienta en el cuadro de herramientas de vSphere que permite servicios de almacenamiento simplificados, predecibles y constantes para el consumo mediante marcos de automatización en entornos de cloud privado e híbrido. Básicamente, SPBM permite definir clases de servicio que satisfacen las necesidades de su diversa base de clientes. SRM ahora le permite exponer capacidades de replicación a sus clientes para cargas de trabajo críticas que requieren una orquestación y automatización sólidas para la recuperación ante desastres estándares del sector.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">Compatibilidad con vVols Architecture 2.3 para servidores SRM basados en dispositivos</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Ahora, los servidores de SRM basados en el SO fotones son compatibles, además de las plataformas basadas en Windows heredadas.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Ahora puede instalar adaptadores SRA independientemente del tipo de servidor SRM preferido.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Compatibilidad con IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 ahora es compatible con las siguientes limitaciones:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 o posterior</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">No es compatible con SRM 8.2 (8.1, 8.3 y 8. 4 son compatibles)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Herramienta de matriz de interoperabilidad</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Compruebe la<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> para las versiones cualificadas más recientes.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Mejor rendimiento</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">El rendimiento operativo es un requisito clave para la ejecución de tareas del SRM. Para satisfacer los requisitos de los objetivos de tiempo de recuperación y de punto de recuperación modernos, el SRA con herramientas de ONTAP ha añadido dos mejoras nuevas.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Soporte para operaciones de reprotección simultáneas.* primero introducido en SRA 9.7.1, habilitar esta función permite ejecutar reprotección en dos o más planes de recuperación simultáneamente, reduciendo así el tiempo necesario para volver a proteger los almacenes de datos después de una migración por error y permanecer dentro de los parámetros RTO y RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*Herramientas de ONTAP 9.8 agrega un nuevo modo optimizado sólo para NAS.* cuando utiliza cuentas y conexiones de ámbito SVM a clústeres de ONTAP con sólo almacenes de datos basados en NFS, puede habilitar el modo optimizado sólo para NAS para obtener el máximo rendimiento en entornos compatibles.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Mayor escala</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Las herramientas de ONTAP SRA ahora pueden admitir hasta 500 grupos de protección (PGS) cuando se usa con SRM 8.3 y versiones posteriores.</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Replicación síncrona</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Una nueva función que se espera tanto y que se prevé que será SnapMirror Synchronous (SM-S) con ONTAP 9.5 y posterior, que ofrece una solución de replicación de datos de RPO cero para sus aplicaciones críticas. SM-S requiere las herramientas ONTAP 9.8 o posterior.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Soporte para API de REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configuración del servidor SRA ahora puede gestionarse mediante API DE REST. Se ha añadido una interfaz de usuario de Swagger para ayudar a crear sus flujos de trabajo de automatización y se puede encontrar en el dispositivo de herramientas de ONTAP en<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">Documentación de productos VMware<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">Documentación de productos de NetApp<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">Esta página ofrece una introducción a los vídeos y tutoriales.</block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">Vídeos y demostraciones sobre cloud híbrido, virtualización y contenedores</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">Vea los siguientes vídeos y demostraciones en los que se destacan características específicas de las soluciones de cloud híbrido, virtualización y contenedores.</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">Herramientas de ONTAP de NetApp para VMware vSphere</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">Herramientas de ONTAP para VMware: Información general</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">Aprovisionamiento de almacén de datos iSCSI de VMware con ONTAP</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">Aprovisionamiento del almacén de datos NFS de VMware con ONTAP</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">VMware Cloud en AWS con AWS FSX para ONTAP de NetApp</block>
  <block id="1709b8b454125c7d55fd44e302c8aee3" category="example-title">Migración de VMware Cloud en AWS con FSxN o VMware HCX</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">Azure VMware Services en Azure con Azure NetApp Files (ANF)</block>
  <block id="875970986c8d6a0d19f47ed744bf33e1" category="example-title">Migración de la solución VMware para Azure con ANF, VMware HCX</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="example-title">Plugin de SnapCenter para VMware vSphere</block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">El software SnapCenter de NetApp es una plataforma empresarial fácil de usar para coordinar y administrar de un modo seguro la protección de datos en todas las aplicaciones, bases de datos y sistemas de archivos.</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">El plugin de SnapCenter para VMware vSphere permite ejecutar operaciones de backup, restauración y conexión para máquinas virtuales, así como operaciones de backup y montaje para almacenes de datos que se registran en SnapCenter directamente en VMware vCenter.</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link-macro">Información general sobre el plugin de SnapCenter de NetApp para VMware vSphere</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">Para obtener más información sobre el plugin de SnapCenter para VMware vSphere, consulte <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>.</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">Plugin de SnapCenter para VMware vSphere: Requisitos previos de la solución</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">Plugin de SnapCenter para VMware vSphere: Implementación</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">Plugin de SnapCenter para VMware vSphere: Flujo de trabajo de backup</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">Plugin de SnapCenter para VMware vSphere: Flujo de trabajo de restauración</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - flujo de trabajo de restauración SQL</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="example-title">NetApp con VMware Tanzania</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzania permite a los clientes poner en marcha, administrar y gestionar su entorno de Kubernetes a través de vSphere o de VMware Cloud Foundation. Esta cartera de productos de VMware permite a los clientes gestionar todos sus clústeres de Kubernetes relevantes desde un único plano de control al elegir la edición de VMware Tanzu que mejor se adapte a sus necesidades.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">Descripción general de VMware Tanzania</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">Si quiere más información sobre VMware Tanzania, consulte<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. Esta revisión incluye casos de uso, adiciones disponibles y mucho más sobre VMware Tanzu.</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">Cómo usar vVols con NetApp y VMware Tanzu Basic, parte 1</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">Cómo usar vVols con NetApp y VMware Tanzu Basic, parte 2</block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">Cómo utilizar vVols con NetApp y VMware Tanzu Basic, parte 3</block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="example-title">NetApp con Red Hat OpenShift</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">Red Hat OpenShift, una plataforma de Kubernetes para empresas, le permite ejecutar aplicaciones basadas en contenedores con una estrategia de cloud híbrido abierta. Red Hat OpenShift, disponible como servicio de nube en clouds públicos líderes o como software autogestionado, ofrece a los clientes la flexibilidad que necesitan al diseñar su solución basada en contenedores.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Visión general de Red Hat OpenShift</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Para obtener más información sobre Red Hat OpenShift, consulte este tema<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. También puede consultar la documentación del producto y las opciones de implementación para obtener más información sobre Red Hat OpenShift.</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">Migración de cargas de trabajo: Red Hat OpenShift con NetApp</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Esta página describe las prácticas recomendadas para implementar una solución de almacenamiento ONTAP de NetApp en un entorno de VMware vSphere.</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Almacenes de datos y protocolos</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">Funciones de almacén de datos y protocolo de vSphere</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Se utilizan siete protocolos para conectar VMware vSphere a almacenes de datos en un sistema que ejecuta el software ONTAP:</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP e iSCSI son protocolos de bloque que usan el sistema de archivos de máquina virtual de vSphere (VMFS) para almacenar máquinas virtuales en LUN de ONTAP o espacios de nombres NVMe que se encuentran en un volumen ONTAP FlexVol. Tenga en cuenta que, a partir de vSphere 7.0, VMware ya no es compatible con el software FCoE en entornos de producción. NFS es un protocolo de archivos que coloca equipos virtuales en almacenes de datos (que son simplemente volúmenes de ONTAP) sin necesidad de VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS también se puede utilizar directamente de un sistema operativo invitado a ONTAP.</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">Máximos de configuración de VMware</block>
  <block id="7469c178e150e10730dcab1094765f10" category="paragraph">En las siguientes tablas, se presentan las funciones de almacén de datos tradicional compatibles con vSphere con ONTAP. Esta información no se aplica a almacenes de datos vVols, pero, generalmente, se aplica a vSphere 6.x y versiones posteriores mediante versiones ONTAP compatibles. También puede consultar<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> En versiones específicas de vSphere para confirmar límites específicos.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Característica/función</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formato</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">Asignación de dispositivo sin formato (RDM) o VMFS</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS o RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Número máximo de almacenes de datos o LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN por host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN por servidor</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 nombres por servidor</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 monta el NFS predeterminado. MaxVolumes tiene 8 años. Utilice las herramientas de ONTAP para VMware vSphere para aumentar a 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Tamaño máximo de almacén de datos</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB de volumen FlexVol o superior con volumen FlexGroup</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Tamaño máximo de archivo del almacén de datos</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="fe299bb060ce245b8fe190de21d3978e" category="cell">16 TB o 62 TB con ONTAP 9.12.1RC1 y posterior con archivos grandes habilitados</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profundidad de cola óptima por LUN o sistema de archivos</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Autonegociar</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link">Host ESXi recomendado y otra configuración de ONTAP</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Consulte NFS.MaxQueueDepth en<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">En la siguiente tabla se enumeran las funcionalidades relacionadas con el almacenamiento de VMware admitidas.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacidad/función</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">VMotion de almacenamiento</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">Ha de VMware</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Planificador de recursos distribuidos de almacenamiento (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Software de backup compatible con VMware vStorage APIs for Data Protection (VADP)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) o clustering de recuperación tras fallos en un equipo virtual</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Sí*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">No admitido</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolerancia a fallos</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Gestor de recuperación de sitios</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">No**</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">Sólo v3**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Equipos virtuales con thin provisioning (discos virtuales)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Sí, esta configuración es la predeterminada para todas las máquinas virtuales de NFS cuando no se utiliza VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Accesos múltiples nativos de VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Sí, utilizando el nuevo complemento de alto rendimiento (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">En la siguiente tabla se enumeran las funciones de gestión de almacenamiento de ONTAP admitidas.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Deduplicación de datos</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Ahorro en la cabina</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">De ahorro en el almacén de datos</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Aprovisionamiento ligero</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Almacén de datos o RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Almacén de datos</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Redimensión de almacén de datos</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Crezca solo</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Crecer, crecimiento automático y reducción</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Complementos de SnapCenter para aplicaciones Windows y Linux (en invitado)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Supervisión y configuración del host mediante herramientas de ONTAP para VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Aprovisionar mediante las herramientas de ONTAP para VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">En la siguiente tabla se enumeran las funciones de backup admitidas.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">Copias Snapshot de ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM compatible con backups replicados</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">SnapMirror para volúmenes</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Acceso a imagen VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Software de backup compatible con VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Explorador del software de backup habilitado para VADP, vSphere Client y almacén de datos de vSphere Web Client</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Acceso de nivel de ficheros VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Software de backup compatible con VADP, solo Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Software de backup compatible con VADP y aplicaciones de terceros</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularidad de NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Almacén de datos o máquina virtual</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configuración de clústeres de conmutación por error de Windows Server</block>
  <block id="5663fa28fe2a703e07072185e3a90a94" category="paragraph">*NetApp recomienda utilizar iSCSI en sistemas invitados para clústeres de Microsoft en lugar de VMDK habilitados para varios escritores en un almacén de datos VMFS. Este enfoque es totalmente compatible con Microsoft y VMware, ofrece una gran flexibilidad con ONTAP (sistemas de SnapMirror a ONTAP en las instalaciones o en el cloud), es fácil de configurar y automatizar y puede protegerse con SnapCenter. VSphere 7 añade una nueva opción de VMDK en clúster. Esto es diferente de los VMDK habilitados para varias ediciones, que requieren un almacén de datos presentado a través del protocolo FC que tiene habilitada la compatibilidad con VMDK en cluster. Se aplican otras restricciones. Vea la de VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentación para directrices de configuración.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**Los almacenes de datos que usan NVMe-of y NFS v4.1 requieren la replicación de vSphere. SRM no admite la replicación basada en cabinas.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Seleccionar un protocolo de almacenamiento</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Los sistemas que ejecutan el software ONTAP admiten todos los protocolos de almacenamiento más importantes, por lo que los clientes pueden elegir cuál es la mejor opción para su entorno, en función de la infraestructura de red y la capacidad del personal actuales y planificadas. Por lo general, las pruebas de NetApp han mostrado poca diferencia entre protocolos que se ejecutan a velocidades de línea similares, por lo que es mejor centrarse en su infraestructura de red y en las capacidades del personal sobre el rendimiento del protocolo bruto.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Los siguientes factores pueden ser útiles a la hora de considerar una opción de protocolo:</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">*Entorno actual del cliente.* aunque los equipos DE TI generalmente tienen experiencia en la gestión de la infraestructura IP Ethernet, no todos son expertos en la administración de una estructura SAN FC. Sin embargo, puede que el uso de una red IP de uso general que no esté diseñada para el tráfico de almacenamiento no funcione bien. Considere la infraestructura de red de que dispone, las mejoras planificadas y las capacidades y la disponibilidad del personal para gestionarlos.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Facilidad de configuración.* más allá de la configuración inicial de la estructura FC (conmutadores y cableado adicionales, zonificación y verificación de interoperabilidad de HBA y firmware), los protocolos de bloque también requieren la creación y asignación de LUN y descubrimiento y formato por parte del SO invitado. Una vez creados y exportados los volúmenes de NFS, el host ESXi los monta y está listo para usarse. NFS no tiene ninguna cualificación de hardware o firmware especial que gestionar.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Facilidad de administración.* con los protocolos SAN, si se necesita más espacio, se necesitan varios pasos, incluyendo el crecimiento de una LUN, el reexamen para descubrir el nuevo tamaño, y luego el crecimiento del sistema de archivos). A pesar de que es posible aumentar una LUN, reducir el tamaño de una LUN no es así, y recuperar el espacio no utilizado puede requerir esfuerzo adicional. NFS permite ajustar fácilmente el tamaño, y el sistema de almacenamiento puede automatizar este ajuste de tamaño. SAN ofrece una reclamación de espacio mediante comandos TRIM/UNMAP del sistema operativo invitado, lo que permite que el espacio de los archivos eliminados se devuelva a la matriz. Este tipo de recuperación de espacio es más difícil con los almacenes de datos NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Transparencia del espacio de almacenamiento.* la utilización del almacenamiento suele ser más fácil de ver en entornos NFS, ya que Thin Provisioning devuelve ahorros inmediatamente. Del mismo modo, los ahorros en deduplicación y clonado están disponibles inmediatamente para otras máquinas virtuales en el mismo almacén de datos o para otros volúmenes del sistema de almacenamiento. La densidad de las máquinas virtuales también es superior en un almacén de datos NFS, que puede mejorar el ahorro de la deduplicación y reducir los costes de gestión al tener menos almacenes de datos que gestionar.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Distribución de almacenes de datos</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">Los sistemas de almacenamiento ONTAP ofrecen una gran flexibilidad a la hora de crear almacenes de datos para equipos virtuales y discos virtuales. Aunque se aplican muchas prácticas recomendadas de ONTAP al usar VSC para aprovisionar almacenes de datos para vSphere (que se enumeran en la sección <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>), aquí hay algunas directrices adicionales a considerar:</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">La puesta en marcha de vSphere con almacenes de datos NFS de ONTAP da como resultado una implementación de alto rendimiento y fácil de gestionar que proporciona ratios de máquina virtual a almacén de datos que no pueden obtenerse con protocolos de almacenamiento basados en bloques. Esta arquitectura puede provocar un aumento diez veces en la densidad de los almacenes de datos con una reducción correlacionada en el número de almacenes de datos. Aunque un almacén de datos de mayor tamaño puede beneficiar la eficiencia de almacenamiento y proporcionar beneficios operativos, considere el uso de al menos cuatro almacenes de datos (volúmenes de FlexVol) para almacenar las máquinas virtuales en una sola controladora de ONTAP a fin de obtener el máximo rendimiento de los recursos de hardware. Este enfoque también permite establecer almacenes de datos con diferentes políticas de recuperación. Algunas se pueden hacer backups o replicarse con una frecuencia mayor que otras en función de las necesidades de las empresas. No se necesitan varios almacenes de datos en los volúmenes de FlexGroup para mejorar el rendimiento, ya que se escalan por diseño.</block>
  <block id="241f8fed1e3a823fcd4d0c1eb705b1a2" category="list-text">NetApp recomienda utilizar los volúmenes FlexVol y, a partir de los volúmenes FlexGroup de ONTAP 9.8, los almacenes de datos NFS. Por lo general, no se recomiendan otros contenedores de almacenamiento de ONTAP, como qtrees, porque actualmente no son compatibles con las herramientas de ONTAP para VMware vSphere. La puesta en marcha de almacenes de datos como varios qtrees en un único volumen puede resultar útil para entornos altamente automatizados que puedan beneficiarse de cuotas a nivel de almacén de datos o clones de archivos de equipos virtuales.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Un buen tamaño para un almacén de datos con volúmenes FlexVol es de entre 4 y 8 TB. Este tamaño es un buen punto de equilibrio entre rendimiento, facilidad de gestión y protección de datos. Empiece con poco (digamos, 4 TB) y crezca el almacén de datos según sea necesario (hasta el máximo de 100 TB). Los almacenes de datos más pequeños son más rápidos de recuperar desde un backup o después de un desastre y se pueden mover rápidamente en el clúster. Considere la posibilidad de utilizar el ajuste de tamaño automático de ONTAP para aumentar y reducir automáticamente el volumen a medida que se modifique el espacio utilizado. Las herramientas de ONTAP para el Asistente de aprovisionamiento de almacenes de datos de VMware vSphere utilizan autosize de forma predeterminada para los nuevos almacenes de datos. System Manager o la línea de comandos pueden personalizarse los umbrales de crecimiento y reducción, y el tamaño máximo y mínimo.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">De forma alternativa, los almacenes de datos VMFS se pueden configurar con LUN a las que se accede mediante FC, iSCSI o FCoE. VMFS permite que cada servidor ESX acceda a las LUN tradicionales de forma simultánea en un clúster. Los almacenes de datos VMFS pueden tener un tamaño de hasta 64 TB y constan de hasta 32 LUN de 2 TB (VMFS 3) o una única LUN de 64 TB (VMFS 5). El tamaño máximo de LUN de ONTAP es de 16 TB en la mayoría de los sistemas y de 128 TB en los sistemas de cabinas All-SAN. Por lo tanto, es posible crear un almacén de datos VMFS 5 de tamaño máximo en la mayoría de los sistemas ONTAP utilizando cuatro LUN de 16 TB. Aunque es posible obtener un beneficio en el rendimiento de las cargas de trabajo con un gran volumen de I/o con varias LUN (con sistemas FAS o AFF de gama alta), esta ventaja se ve compensada por la mayor complejidad de gestión para crear, gestionar y proteger las LUN de almacenes de datos y un mayor riesgo para la disponibilidad. NetApp suele recomendar el uso de una única LUN de gran tamaño para cada almacén de datos y únicamente span si hay una necesidad especial de ir más allá de un almacén de datos de 16 TB. Como sucede con NFS, considere el uso de varios almacenes de datos (volúmenes) para maximizar el rendimiento en una única controladora de ONTAP.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Los sistemas operativos invitados (SO) antiguos necesitaban alineación con el sistema de almacenamiento para obtener el mejor rendimiento y eficiencia del almacenamiento. Sin embargo, los sistemas operativos modernos admitidos por el proveedor de distribuidores de Microsoft y Linux como Red Hat ya no requieren ajustes para alinear la partición del sistema de archivos con los bloques del sistema de almacenamiento subyacente en un entorno virtual. Si utiliza un sistema operativo antiguo que puede requerir alineación, busque artículos en la base de conocimientos de soporte de NetApp usando "alineación de máquinas virtuales" o solicite una copia de TR-3747 a través de un contacto de partners o de ventas de NetApp.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">Evite el uso de utilidades de desfragmentación en el SO invitado, ya que esto no ofrece ninguna ventaja de rendimiento y afecta a la eficiencia del almacenamiento y al uso del espacio de copia snapshot. Considere también desactivar la indización de búsquedas en el sistema operativo invitado para escritorios virtuales.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ha dirigido el sector mediante funciones innovadoras de eficiencia del almacenamiento, que le permiten sacar el máximo partido a su espacio en disco utilizable. Los sistemas AFF llevan esta eficiencia aún más allá gracias a la compresión y la deduplicación inline predeterminadas. Los datos se deduplican en todos los volúmenes de un agregado, por lo que ya no necesita agrupar sistemas operativos similares y aplicaciones similares en un único almacén de datos para optimizar el ahorro.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633: Bases de datos de Oracle en Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">En algunos casos, es posible que ni siquiera se necesite un almacén de datos. Para obtener el mejor rendimiento y la mejor capacidad de gestión, evite usar un almacén de datos para aplicaciones con un alto volumen de I/o como bases de datos y algunas aplicaciones. En su lugar, piense en sistemas de archivos que son propiedad del invitado, como sistemas de archivos NFS o iSCSI gestionados por el invitado o con RDM. Para obtener orientación específica sobre las aplicaciones, consulte los informes técnicos de NetApp para su aplicación. Por ejemplo:<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> dispone de una sección sobre la virtualización con detalles útiles.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Los discos de primera clase (o discos virtuales mejorados) permiten discos gestionados por vCenter independientemente de una máquina virtual con vSphere 6.5 y versiones posteriores. Aunque son gestionados principalmente por la API, pueden ser útiles con vVols, sobre todo cuando las herramientas de OpenStack o Kubernetes las gestionan. Son compatibles tanto con ONTAP como con herramientas de ONTAP para VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migración de almacenes de datos y máquinas virtuales</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Al migrar las máquinas virtuales desde un almacén de datos existente en otro sistema de almacenamiento a ONTAP, estas son algunas prácticas que deben tenerse en cuenta:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Use Storage vMotion para mover la mayoría de los equipos virtuales a ONTAP. Este método no solo no es disruptivo para la ejecución de equipos virtuales, sino que también permite funciones de eficiencia del almacenamiento de ONTAP como deduplicación y compresión inline para procesar los datos a medida que migran. Considere usar funcionalidades de vCenter para seleccionar varias máquinas virtuales de la lista de inventario y programar la migración (utilice la tecla Ctrl mientras hace clic en acciones) en un momento adecuado.</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">Aunque podría planificar con cuidado la migración a los almacenes de datos de destino adecuados, a menudo es más sencillo migrar de forma masiva y luego organizarse más tarde, según sea necesario. Si tiene necesidades de protección de datos específicas, como diferentes programaciones de Snapshot, puede usar este enfoque para guiar la migración a diferentes almacenes de datos.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La mayoría de los equipos virtuales y su almacenamiento pueden migrarse mientras se están ejecutando (en caliente), pero es posible que la migración de almacenamiento conectado (no en el almacén de datos), como ISO, LUN o volúmenes NFS desde otro sistema de almacenamiento requiera una migración de datos fría.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">Los equipos virtuales que necesitan una migración más cuidadosa incluyen las bases de datos y las aplicaciones que utilizan almacenamiento conectado. En general, considere el uso de las herramientas de la aplicación para gestionar la migración. Para Oracle, considere la posibilidad de utilizar herramientas de Oracle como RMAN o ASM para migrar los archivos de base de datos. Consulte<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> si quiere más información. Del mismo modo, para SQL Server, plantéese utilizar SQL Server Management Studio o herramientas de NetApp, como SnapManager para SQL Server o SnapCenter.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">Herramientas de ONTAP para VMware vSphere</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">Las mejores prácticas más importantes cuando se usa vSphere con sistemas que ejecutan el software ONTAP son instalar y utilizar las herramientas de ONTAP para el complemento VMware vSphere (antes llamado Virtual Storage Console). Este complemento de vCenter simplifica la gestión del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, ya sea mediante SAN o NAS. Utiliza prácticas recomendadas para el aprovisionamiento de almacenes de datos y optimiza la configuración del host ESXi para los tiempos de espera de multivía y HBA (que se describen en el apéndice B). Como se trata de un complemento de vCenter, está disponible para todos los clientes web de vSphere que se conectan al servidor vCenter.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">El plugin también le ayuda a utilizar otras herramientas ONTAP en entornos de vSphere. Permite instalar el plugin de NFS para VAAI de VMware, lo que permite la descarga de copias en ONTAP para operaciones de clonado de la máquina virtual, reserva de espacio para archivos de disco virtual gruesos y descarga de copias Snapshot de ONTAP.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">El complemento también es la interfaz de gestión para muchas funciones del proveedor VASA para ONTAP, que admite la gestión basada en políticas de almacenamiento con vVols. Una vez registradas las herramientas de ONTAP para VMware vSphere, utilícelo para crear perfiles de funcionalidad de almacenamiento, asignarlas al almacenamiento y garantizar el cumplimiento de los perfiles por parte del almacén de datos con el tiempo. El proveedor de VASA también proporciona una interfaz para crear y gestionar almacenes de datos de VVol.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">En general, NetApp recomienda el uso de las herramientas de ONTAP para la interfaz de VMware vSphere en vCenter con el fin de aprovisionar almacenes de datos tradicionales y vVols, para garantizar que se sigan las prácticas recomendadas.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Redes generales</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configuración de ajustes de red cuando se usa vSphere con sistemas que ejecutan el software ONTAP es sencilla y similar a la de otra configuración de red. Estas son algunas cosas a tener en cuenta:</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">Hay que separar el tráfico de la red de almacenamiento de otras redes. Se puede lograr una red independiente a través de una VLAN dedicada o switches independientes para el almacenamiento. Si la red de almacenamiento comparte rutas físicas como los enlaces ascendentes, puede que necesite calidad de servicio o puertos adicionales para garantizar el ancho de banda suficiente. No conecte los hosts directamente al almacenamiento; utilice los switches para tener rutas redundantes y permita que VMware ha funcione sin intervención.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Las tramas gigantes se pueden utilizar si se desean y admiten en la red, especialmente si se utiliza iSCSI. Si se usan, asegúrese de que estén configurados de la misma forma en todos los dispositivos de red, VLAN, etc., en la ruta entre el almacenamiento y el host ESXi. De lo contrario, puede que observe problemas de rendimiento o conexión. La MTU también debe establecerse de forma idéntica en el switch virtual ESXi, el puerto de VMkernel y, además, en los puertos físicos o los grupos de interfaces de cada nodo ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp solo recomienda deshabilitar el control de flujo de red en los puertos de red de clúster dentro de un clúster de ONTAP. NetApp no ofrece otras recomendaciones para seguir las prácticas recomendadas para los puertos de red restantes que se usan para el tráfico de datos. Debe activar o desactivar según sea necesario. Consulte<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> para obtener más fondo sobre el control de flujo.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Cuando las cabinas de almacenamiento ESXi y ONTAP están conectadas a redes de almacenamiento Ethernet, NetApp recomienda configurar los puertos Ethernet a los que se conectan estos sistemas como puertos periféricos del protocolo de árbol de expansión rápido (RSTP) o mediante la función PortFast de Cisco. NetApp recomienda habilitar la función de enlace troncal Spanning-Tree PortFast en entornos que utilizan la función Cisco PortFast y que tienen la conexión de enlaces VLAN 802.1Q habilitada tanto para el servidor ESXi como para las cabinas de almacenamiento ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp recomienda las siguientes prácticas recomendadas para la agregación de enlaces:</block>
  <block id="040ffbbbbeda558bdae1e07f5371b4f5" category="list-text">Utilice switches que admitan la agregación de vínculos de puertos en dos chasis de switch separados mediante un método de grupo de agregación de vínculos multichasis, como Virtual PortChannel (VPC) de Cisco.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Deshabilite LACP para los puertos del switch conectados a ESXi a menos que utilice dvSwitch 5.1 o una versión posterior con LACP configurado.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">LACP se utiliza para crear agregados de enlaces para sistemas de almacenamiento ONTAP con grupos de interfaces dinámicas multimodo con hash IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Use una política de agrupación de hash IP en ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">En la siguiente tabla se ofrece un resumen de los elementos de configuración de red e indica dónde se aplican los ajustes.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Elemento</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Conmutador</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Dirección IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Agregación de enlaces</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Switch virtual</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">No*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel y grupos de puertos de máquina virtual</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Control de flujo</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Árbol expansivo</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (para tramas gigantes)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Conmutador virtual y puerto de VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Sí (configurado como máx.)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Sí (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Grupos de conmutación por error</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Sí (crear)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Sí (seleccione)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Las LIF de SVM se conectan a puertos, grupos de interfaces o interfaces VLAN que tienen VLAN, MTU y otras configuraciones. Sin embargo, la configuración no se gestiona a nivel de SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Estos dispositivos tienen direcciones IP propias para la administración, pero estas direcciones no se utilizan en el contexto de las redes de almacenamiento ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">En vSphere hay tres formas de usar LUN de almacenamiento basado en bloques:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Con almacenes de datos VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Con asignación de dispositivos sin formato (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">A medida que una LUN accede y está controlada por un iniciador de software desde un SO invitado de máquina virtual</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS es un sistema de archivos en clúster de alto rendimiento que proporciona almacenes de datos que son pools de almacenamiento compartido. Los almacenes de datos VMFS pueden configurarse con LUN a las que se accede mediante espacios de nombres FC, iSCSI, FCoE o NVMe a los que se accede mediante el protocolo NVMe/FC. VMFS permite que cada servidor ESX acceda a las LUN tradicionales de forma simultánea en un clúster. El tamaño máximo de LUN de ONTAP suele ser de 16 TB; por tanto, se crea un almacén de datos VMFS 5 de tamaño máximo de 64 TB (consulte la primera tabla de esta sección) mediante cuatro LUN de 16 TB (los sistemas de cabinas SAN admiten el tamaño máximo de LUN de VMFS de 64 TB). Como la arquitectura de LUN de ONTAP no cuenta con pequeñas profundidades de cola individuales, los almacenes de datos VMFS en ONTAP pueden escalarse a un mayor grado que con las arquitecturas de cabinas tradicionales de forma relativamente sencilla.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere incluye compatibilidad incorporada para múltiples rutas a los dispositivos de almacenamiento, conocida como multivía nativa (NMP). NMP puede detectar el tipo de almacenamiento para los sistemas de almacenamiento compatibles y configura automáticamente la pila NMP para admitir las funcionalidades del sistema de almacenamiento en uso.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Tanto NMP como ONTAP de NetApp son compatibles con ALUA (Asymmetric Logical Unit Access) para negociar rutas optimizadas y no optimizadas. En ONTAP, una ruta optimizada para ALUA sigue una ruta de datos directa mediante un puerto de destino en el nodo que aloja la LUN a la que se está accediendo. De forma predeterminada, ALUA está activado tanto en vSphere como en ONTAP. El NMP reconoce el clúster ONTAP como ALUA y utiliza el complemento de tipo de cabina de almacenamiento ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) y selecciona el complemento de selección de ruta de operación por turnos <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 admite hasta 256 LUN y hasta 1,024 rutas totales a LUN. ESXi no ve ningún LUN o ruta que supere estos límites. Suponiendo el número máximo de LUN, el límite de rutas permite cuatro rutas por LUN. En un clúster de ONTAP mayor, es posible alcanzar el límite de ruta antes del límite de LUN. Para solucionar esta limitación, ONTAP admite una asignación de LUN selectiva (SLM) en la versión 8.3 y posteriores.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="631e164314a103fe3183b00b759057b2" category="paragraph">SLM limita los nodos que anuncian rutas a un LUN determinado. NetApp es una práctica recomendada tener al menos un LIF por nodo por SVM y usar SLM para limitar las rutas anunciadas al nodo que aloja la LUN y su partner de alta disponibilidad. Aunque existen otras rutas, no se anuncian de manera predeterminada. Es posible modificar las rutas anunciadas con los argumentos de nodo de informes Agregar y quitar dentro de SLM. Tenga en cuenta que las LUN creadas en versiones anteriores a la 8.3 anuncian todas las rutas y necesitan modificarse para anunciar únicamente las rutas a la pareja de alta disponibilidad del host. Para obtener más información sobre SLM, consulte la sección 5.9 de<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. El método anterior de conjuntos de puertos también puede utilizarse para reducir aún más las rutas disponibles para una LUN. Los conjuntos de puertos ayudan a reducir el número de rutas visibles a través de las cuales los iniciadores de un igroup pueden ver LUN.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM está habilitado de forma predeterminada. A menos que utilice conjuntos de puertos, no se requiere ninguna configuración adicional.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Para LUN creados antes de Data ONTAP 8.3, ejecute manualmente la ejecución de SLM<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando para quitar los nodos de generación de informes de LUN y restringir el acceso de las LUN al nodo de propiedad de LUN y a su partner de alta disponibilidad.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Los protocolos de bloque (iSCSI, FC y FCoE) acceden a las LUN utilizando los ID de LUN y los números de serie, junto con nombres únicos. FC y FCoE utilizan nombres globales (WWN y WWPN); iSCSI utiliza nombres completos de iSCSI (IQN). La ruta a las LUN del interior del almacenamiento no tiene sentido para los protocolos de bloque y no se presenta en ningún lugar del protocolo. Por lo tanto, no es necesario montar de forma interna un volumen que solo contiene LUN; por lo tanto, no es necesaria una ruta de unión para los volúmenes que contengan LUN usadas en los almacenes de datos. El subsistema NVMe en ONTAP funciona de manera similar.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Otras prácticas recomendadas a tener en cuenta:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Asegúrese de que se crea una interfaz lógica (LIF) para cada SVM en cada nodo del clúster de ONTAP para garantizar la máxima disponibilidad y movilidad. La práctica recomendada para SAN de ONTAP es usar dos puertos físicos y LIF por nodo, uno para cada estructura. ALUA se utiliza para analizar las rutas e identificar las rutas activas optimizadas (directas) en comparación con las rutas activas no optimizadas. ALUA se utiliza para FC, FCoE e iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">En el caso de las redes iSCSI, utilice varias interfaces de red de VMkernel en distintas subredes de la red con la agrupación de NIC cuando haya varios switches virtuales. También puede utilizar varias NIC físicas conectadas a varios switches físicos para proporcionar alta disponibilidad y mayor rendimiento. En la figura siguiente se proporciona un ejemplo de conectividad multivía. En ONTAP, configure un grupo de interfaces de un único modo para realizar la conmutación al nodo de respaldo con dos o más enlaces conectados a dos o más switches, o bien utilice LACP u otra tecnología de agregación de enlaces con grupos de interfaces multimodo para proporcionar alta disponibilidad y las ventajas de la agregación de enlaces.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Si el protocolo de autenticación por desafío mutuo (CHAP) se utiliza en ESXi para la autenticación de destino, también debe configurarse en ONTAP mediante la CLI <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) O con System Manager (edite Initiator Security en almacenamiento &gt; SVM &gt; SVM Settings &gt; Protocols &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilice las herramientas de ONTAP para VMware vSphere para crear y gestionar LUN y iGroups. El plugin determina automáticamente los WWPN de los servidores y crea iGroups adecuados. También configura las LUN de acuerdo con las prácticas recomendadas y las asigna a los iGroups correctos.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">modo de compatibilidad físico y virtual</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilizar RDM con cuidado porque es más difícil de gestionar y además utilizan rutas limitadas como se ha descrito anteriormente. Las LUN de ONTAP son compatibles con ambos<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guía de configuración de hosts ONTAP NVMe/FC</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Para obtener más información sobre cómo usar NVMe/FC con vSphere 7.0, consulte este tema<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> y..<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>.En la siguiente figura, se muestra la conectividad multivía de un host de vSphere a un LUN de ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere permite a los clientes utilizar cabinas NFS de nivel empresarial para proporcionar acceso simultáneo a los almacenes de datos en todos los nodos de un clúster ESXi. Como hemos mencionado en la sección de almacenes de datos, existen algunas ventajas de facilidad de uso y visibilidad de la eficiencia del almacenamiento al usar NFS con vSphere.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Las siguientes prácticas recomendadas se recomiendan al usar NFS de ONTAP con vSphere:</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">Utilice una sola interfaz lógica (LIF) para cada SVM en cada nodo del clúster de ONTAP. Ya no son necesarias las recomendaciones anteriores de una LIF por almacén de datos. Aunque el acceso directo (LIF y almacenes de datos en el mismo nodo) es mejor, no se preocupe por el acceso indirecto, ya que el efecto sobre el rendimiento suele ser mínimo (microsegundos).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware ha sido compatible con NFSv3 desde VMware Infrastructure 3. VSphere 6.0 ha añadido compatibilidad con NFSv4.1, lo cual permite algunas funcionalidades avanzadas, como la seguridad de Kerberos. Donde NFSv3 utiliza el bloqueo del lado del cliente, NFSv4.1 utiliza el bloqueo del lado del servidor. Aunque un volumen ONTAP se puede exportar mediante ambos protocolos, ESXi solo se puede montar a través de un único protocolo. Este montaje de protocolo único no excluye que otros hosts ESXi monten el mismo almacén de datos a través de una versión diferente. Asegúrese de especificar la versión del protocolo que se va a utilizar al montar para que todos los hosts utilicen la misma versión y, por lo tanto, el mismo estilo de bloqueo. No mezcle versiones de NFS entre hosts. Si es posible, utilice perfiles de host para comprobar el cumplimiento.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Dado que no existe ninguna conversión automática de almacenes de datos entre NFSv3 y NFSv4.1, cree un nuevo almacén de datos NFSv4.1 y utilice Storage vMotion para migrar las máquinas virtuales al nuevo almacén de datos.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Herramienta de matriz de interoperabilidad de NetApp</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Consulte las notas de la tabla de interoperabilidad de NFS v4.1 en el<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Para los niveles de parches específicos de ESXi que se requieren para soporte.</block>
  <block id="d8119941da55a672db49a624330ea7f0" category="list-text">Los hosts de vSphere utilizan políticas de exportación de NFS para controlar el acceso. Puede usar una política con varios volúmenes (almacenes de datos). Con NFSv3, ESXi utiliza el estilo de seguridad sys (UNIX) y requiere la opción de montaje raíz para ejecutar las máquinas virtuales. En ONTAP, esta opción se denomina superusuario y cuando se utiliza la opción superusuario, no es necesario especificar el ID de usuario anónimo. Tenga en cuenta que las reglas de política de exportación con valores diferentes para<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> y..<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Puede causar problemas de detección de SVM con las herramientas de ONTAP. A continuación se muestra una política de ejemplo:</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Protocolo de acceso: Nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Especificación de coincidencia de cliente: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Regla DE ACCESO DE RO: Sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">Regla de acceso RW: Sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anónimo</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superusuario: Sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Si se utiliza el plugin de NetApp NFS para VMware VAAI, se debe establecer el protocolo como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> cuando se crea o se modifica la regla de política de exportación. El protocolo NFSv4 se requiere para que la copia VAAI se descargue para que funcione y especifique el protocolo como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Incluye automáticamente tanto las versiones NFSv3 como NFSv4.</block>
  <block id="49bb4e84b97bfe104e9fe7eb7df07a38" category="list-text">Los volúmenes de almacenes de datos NFS se unen desde el volumen raíz de la SVM; por lo tanto, ESXi también debe tener acceso al volumen raíz para navegar y montar volúmenes de almacenes de datos. La política de exportación del volumen raíz, y para todos los demás volúmenes en los que esté anidada la unión del volumen de almacenes de datos, debe incluir una regla o reglas para los servidores ESXi que les conceden acceso de solo lectura. A continuación se muestra una directiva de ejemplo para el volumen raíz, también mediante el complemento VAAI:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Protocolo de acceso: nfs (que incluye nfs3 y nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">Regla de acceso RW: Nunca (mejor seguridad para el volumen raíz)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superusuario: Sys (también necesario para el volumen raíz con VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Use las herramientas de ONTAP para VMware vSphere (las mejores prácticas más importantes):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilice herramientas de ONTAP para VMware vSphere para aprovisionar almacenes de datos, ya que simplifica la gestión de políticas de exportación de forma automática.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Cuando se crean almacenes de datos para clústeres de VMware con el plugin, seleccione el clúster en lugar de un único servidor ESX. Esta opción la activa para montar automáticamente el almacén de datos en todos los hosts del clúster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilice la función de montaje de plugins para aplicar almacenes de datos existentes a servidores nuevos.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Si no se utilizan las herramientas de ONTAP para VMware vSphere, utilice una única política de exportación para todos los servidores o para cada cluster de servidores donde se necesite un control de acceso adicional.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Aunque ONTAP ofrece una estructura de espacio de nombres de volúmenes flexibles para organizar los volúmenes en un árbol mediante uniones, este enfoque no tiene valor para vSphere. Crea un directorio para cada equipo virtual en la raíz del almacén de datos, independientemente de la jerarquía de espacio de nombres del almacenamiento. Por lo tanto, la práctica recomendada es simplemente montar la ruta de unión para volúmenes para vSphere en el volumen raíz de la SVM, que es la forma en que las herramientas de ONTAP para VMware vSphere aprovisiona almacenes de datos. No tener rutas de unión anidadas también significa que ningún volumen depende de ningún otro volumen que no sea el volumen raíz y que el hecho de desconectar un volumen o destruirlo, incluso intencionalmente, no afecta la ruta a otros volúmenes.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">El tamaño de bloque de 4K se ajusta a las particiones NTFS en almacenes de datos NFS. En la siguiente figura, se muestra la conectividad de un host vSphere a un almacén de datos NFS de ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">En la siguiente tabla, se enumeran las versiones de NFS y las funciones compatibles.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funciones de vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion y Storage vMotion</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolerancia a fallos</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Perfiles de host</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS de almacenamiento</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Control de la actividad de I/o de almacenamiento</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volúmenes virtuales</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Aceleración de hardware (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Autenticación Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Sí (mejorada con vSphere 6.5 y versiones posteriores para ser compatible con AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Compatibilidad con accesos múltiples</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 añade compatibilidad para almacenes de datos de FlexGroup en vSphere, junto con las herramientas de ONTAP para la versión de VMware vSphere 9.8. FlexGroup simplifica la creación de grandes almacenes de datos y crea automáticamente una serie de volúmenes constituyentes para obtener el máximo rendimiento de un sistema ONTAP. Utilice FlexGroup con vSphere para un único almacén de datos vSphere escalable con la potencia de un clúster ONTAP completo.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">Además de las pruebas exhaustivas del sistema con las cargas de trabajo de vSphere, ONTAP 9.8 también añade un nuevo mecanismo de descarga de copias para los almacenes de datos de FlexGroup. Esto utiliza un motor de copia mejorado para copiar archivos entre componentes en segundo plano y permitir el acceso tanto en el origen como en el destino. Las múltiples copias utilizan clones de archivos disponibles al instante y con gestión eficiente del espacio dentro de un componente cuando es necesario, según la escala.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 también añade nuevas métricas de rendimiento basadas en archivos (IOPS, rendimiento y latencia) para archivos FlexGroup. Estas métricas pueden verse en las herramientas de ONTAP para la consola de VMware vSphere e informes de VM. Las herramientas de ONTAP para el complemento VMware vSphere también le permiten establecer reglas de calidad de servicio (QoS) con una combinación de IOPS máximo o mínimo. Estos conjuntos se pueden establecer en todas las máquinas virtuales de un almacén de datos o individualmente para máquinas virtuales específicas.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">A continuación figuran algunas de las mejores prácticas que ha desarrollado NetApp:</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Use los valores predeterminados de aprovisionamiento de FlexGroup. Aunque se recomiendan las herramientas de ONTAP para VMware vSphere porque crea y monta FlexGroup en vSphere, ONTAP System Manager o la línea de comandos puede utilizarse para necesidades especiales. Incluso entonces, utilice valores predeterminados como el número de miembros constituyentes por nodo porque esto es lo que se ha probado con vSphere.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Al ajustar el tamaño a un almacén de datos FlexGroup, tenga en cuenta que FlexGroup consta de varios volúmenes FlexVol más pequeños que crean un espacio de nombres mayor. Por lo tanto, el tamaño del almacén de datos para que sea al menos 8 veces el tamaño de la máquina virtual más grande. Por ejemplo, si tiene una máquina virtual de 6 TB en el entorno, ajuste el tamaño del almacén de datos FlexGroup no menor que 48 TB.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Permita que FlexGroup gestione el espacio en almacenes de datos. AutoSize y Elastic Sizing se han probado con almacenes de datos vSphere. Si el almacén de datos se aproximara a la capacidad completa, use las herramientas de ONTAP para VMware vSphere u otra herramienta para ajustar el tamaño del volumen de FlexGroup. FlexGroup mantiene la capacidad y la inodos equilibrados a través de los componentes, dando prioridad a los archivos de una carpeta (VM) al mismo componente si la capacidad lo permite.</block>
  <block id="1abaee3673de53b378351ee9dc679daa" category="list-text">VMware y NetApp no admiten actualmente un enfoque de red multivía común. Para NFSv4.1, NetApp admite pNFS, mientras que VMware admite la conexión de enlaces de sesiones. NFSv3 no admite varias rutas físicas a un volumen. En el caso de FlexGroup con ONTAP 9.8, nuestra mejor práctica recomendada es que las herramientas de ONTAP para VMware vSphere puedan realizar el montaje único, ya que el efecto del acceso indirecto suele ser mínimo (microsegundos). Es posible utilizar DNS round-robin para distribuir hosts ESXi a través de LIF en diferentes nodos del FlexGroup, pero esto requeriría que el FlexGroup se cree y monte sin herramientas ONTAP para VMware vSphere. Por lo tanto, las funciones de gestión del rendimiento no estarán disponibles.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">Se ha probado la compatibilidad con almacenes de datos FlexGroup vSphere de hasta 1500 equipos virtuales con la versión 9.8.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Use el plugin de NFS para VAAI de VMware para la descarga de copias. Tenga en cuenta que, aunque la clonación se mejora en un almacén de datos FlexGroup, ONTAP no ofrece ventajas significativas en cuanto a rendimiento frente a la copia de host ESXi al copiar equipos virtuales entre volúmenes de FlexVol o FlexGroup.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Utilice las herramientas de ONTAP para VMware vSphere 9.8 para supervisar el rendimiento de las máquinas virtuales de FlexGroup mediante métricas de ONTAP (panel e informes de máquinas virtuales) y para gestionar la calidad de servicio en máquinas virtuales individuales. Estas métricas no están disponibles a través de los comandos o las API de ONTAP.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">Puede establecerse calidad de servicio (IOPS máx./mín.) en máquinas virtuales individuales o en todas las máquinas virtuales de un almacén de datos en ese momento. La configuración de la calidad de servicio en todas las máquinas virtuales sustituye cualquier configuración independiente por cada máquina virtual. Los ajustes no amplían en el futuro a máquinas virtuales nuevas o migradas; establezca la calidad de servicio en las nuevas máquinas virtuales o vuelva a aplicar la calidad de servicio a todas las máquinas virtuales del almacén de datos.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">El plugin de SnapCenter para VMware vSphere versión 4.4 admite el backup y la recuperación de máquinas virtuales en un almacén de datos de FlexGroup en el sistema de almacenamiento principal. Si bien puede utilizarse SnapMirror manualmente para replicar un FlexGroup en un sistema secundario, SCV 4.4 no gestiona las copias secundarias.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">ONTAP de NetApp es una solución de almacenamiento líder para entornos VMware vSphere desde su introducción al centro de datos moderno en 2002, y continúa agregando funcionalidades innovadoras para simplificar la gestión y reducir costes.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900: VMware Site Recovery Manager con NetApp ONTAP 9</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP para vSphere</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">ONTAP de NetApp es una solución de almacenamiento líder para entornos VMware vSphere desde su introducción al centro de datos moderno en 2002, y continúa agregando funcionalidades innovadoras para simplificar la gestión y reducir costes. Este documento presenta la solución ONTAP para VMware Site Recovery Manager (SRM), el software de recuperación ante desastres (DR) líder del sector de VMware, que incluye la información de producto más reciente y las mejores prácticas para optimizar la puesta en marcha, reducir el riesgo y simplificar la gestión continua.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Las prácticas recomendadas complementan otros documentos como guías y herramientas de compatibilidad. Se desarrollan según pruebas de laboratorio y una amplia experiencia de campo por parte de ingenieros y clientes de NetApp. En algunos casos, las prácticas recomendadas pueden no ser la opción adecuada para su entorno; sin embargo, generalmente son las soluciones más sencillas que satisfacen las necesidades del mayor número de clientes.</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">Este documento se centra en las funcionalidades de las versiones recientes de ONTAP 9, cuando se utiliza en combinación con versiones compatibles de las herramientas de ONTAP para VMware vSphere (que incluye el adaptador de replicación de almacenamiento [SRA] y el proveedor VASA [VP] de NetApp, así como VMware Site Recovery Manager 8. 4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">¿Por qué usar ONTAP con SRM?</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">Las plataformas de gestión de datos de NetApp que incorpora el software ONTAP son algunas de las soluciones de almacenamiento más ampliamente adoptadas para SRM. Existen muchos motivos: Una plataforma de gestión de datos segura de alto rendimiento (juntos NAS y SAN) con protocolo unificado que proporciona una eficiencia del almacenamiento definida por el sector, multi-tenancy, controles de calidad del servicio, protección de datos con copias Snapshot con gestión eficiente del espacio y replicación con SnapMirror. Todos ellos aprovechan la integración nativa en el multicloud híbrido para la protección de las cargas de trabajo de VMware y una gran cantidad de herramientas de automatización y orquestación a su alcance.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">Al utilizar SnapMirror para la replicación basada en cabinas, aprovecha una de las tecnologías más probadas y maduras de ONTAP. SnapMirror le ofrece la ventaja de las transferencias de datos seguras y altamente eficientes, con la copia solo de los bloques del sistema de archivos modificados, no de máquinas virtuales completas ni de almacenes de datos. Incluso esos bloques aprovechan el ahorro de espacio, como la deduplicación, la compresión y la compactación. Los sistemas ONTAP modernos ahora utilizan SnapMirror sin versiones, lo que le ofrece la flexibilidad de seleccionar sus clústeres de origen y destino. SnapMirror se ha convertido en una de las herramientas más potentes disponibles para la recuperación ante desastres.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Tanto si se utilizan almacenes de datos tradicionales NFS, iSCSI o conectados a Fibre Channel (ahora con compatibilidad con almacenes de datos vVols), SRM ofrece una sólida oferta de primera parte que aprovecha las mejores funcionalidades de ONTAP para la planificación y orquestación de la recuperación ante desastres o de la migración al centro de datos.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Aprovechamiento de SRM ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM aprovecha las tecnologías avanzadas de gestión de datos de los sistemas de ONTAP al integrarse con herramientas de ONTAP para VMware vSphere, un dispositivo virtual que incluye tres componentes principales:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">El complemento de vCenter, anteriormente conocido como Virtual Storage Console (VSC), simplifica las funciones de gestión y eficiencia del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, tanto si usa SAN como NAS. Utiliza prácticas recomendadas para aprovisionar almacenes de datos y optimiza la configuración de host ESXi para entornos de almacenamiento en bloques y NFS. Para todas estas ventajas, NetApp recomienda este plugin cuando se usa vSphere en sistemas que ejecutan el software ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">El proveedor VASA para ONTAP admite el marco de trabajo VMware vStorage APIs for Storage Awareness (VASA). EL proveedor DE VASA conecta vCenter Server con ONTAP para ayudar en el aprovisionamiento y la supervisión del almacenamiento de máquinas virtuales. Permite admitir volúmenes virtuales de VMware (vVols) y gestionar perfiles de funcionalidad del almacenamiento (incluidas funcionalidades de replicación vVols) y rendimiento vVols individual. También proporciona alarmas para controlar la capacidad y el cumplimiento de los perfiles. Si se utiliza junto con SRM, el proveedor VASA para ONTAP permite el soporte para máquinas virtuales basadas en vVols sin necesidad de instalar un adaptador de SRA en el servidor SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">El SRA se usa junto con el SRM para gestionar la replicación de datos de máquinas virtuales entre sitios de producción y recuperación ante desastres para almacenes de datos VMFS tradicionales y NFS, y también para las pruebas no disruptivas de réplicas de recuperación ante desastres. Ayuda a automatizar las tareas de identificación, recuperación y protección. Incluye tanto un dispositivo de servidor SRA como adaptadores SRA para el servidor SRM de Windows y el dispositivo SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Después de instalar y configurar los adaptadores SRA en el servidor SRM para proteger almacenes de datos que no son vVols y/o habilitar la replicación vVols en la configuración del proveedor VASA, puede iniciar la tarea de configurar el entorno de vSphere para la recuperación ante desastres.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">El SRA y el proveedor VASA ofrece una interfaz de comandos y control para que el servidor SRM gestione los FlexVols de ONTAP que contienen las máquinas virtuales de VMware, así como la replicación de SnapMirror que las protege.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">A partir del SRM 8.3, se introdujo una nueva ruta de control del proveedor vVols de SRM, que permite comunicarse con el servidor vCenter y, a través del mismo, con el proveedor VASA sin necesidad de un SRA. Esto permitió que el servidor SRM aprovechara un control mucho más profundo sobre el clúster de ONTAP del que era posible antes, ya que VASA ofrece una API completa para la integración estrechamente vinculada.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM puede probar su plan de recuperación ante desastres sin interrupciones con la tecnología FlexClone patentada de NetApp para crear clones casi instantáneos de sus almacenes de datos protegidos en su centro de recuperación ante desastres. SRM crea una zona aislada para probar con seguridad de modo que su organización y sus clientes estén protegidos en caso de un verdadero desastre, lo que le da confianza en que sus organizaciones pueden ejecutar una conmutación por error durante un desastre.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">En caso de verdadero desastre o incluso de una migración planificada, SRM permite enviar cualquier cambio de última hora al conjunto de datos mediante una actualización final de SnapMirror (si lo decide). A continuación, interrumpe el reflejo y monta el almacén de datos en los hosts de recuperación ante desastres. En ese momento, las máquinas virtuales pueden encenderse automáticamente en cualquier orden de acuerdo con la estrategia planificada previamente.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM con ONTAP y otros casos de uso: Cloud híbrido y migración</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Almacenamiento privado de NetApp en Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">La integración de su puesta en marcha de SRM con las capacidades de gestión de datos avanzadas de ONTAP posibilita una ampliación y un rendimiento mucho mejores en comparación con las opciones de almacenamiento local. Mucho más que eso, aporta la flexibilidad del cloud híbrido. El cloud híbrido le permite ahorrar dinero al organizar en niveles los bloques de datos no utilizados de su cabina de alto rendimiento en su proveedor a hiperescala preferido mediante FabricPool, que podría ser un almacén de S3 en las instalaciones, como StorageGRID de NetApp. También puede utilizar SnapMirror para sistemas basados en el perímetro con ONTAP Select definido por software o recuperación ante desastres basada en cloud usando Cloud Volumes ONTAP (CVO) o.<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Para Amazon Web Services (AWS), Microsoft Azure y Google Cloud Platform (GCP) para crear una pila de servicios de computación, redes y almacenamiento totalmente integrada en el cloud.</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">Entonces, podría llevar a cabo una conmutación por error de prueba dentro del centro de datos de un proveedor de servicios cloud con un espacio de almacenamiento casi cero gracias a FlexClone. La protección de su empresa ahora puede costar menos que nunca.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM también puede utilizarse para ejecutar migraciones planificadas aprovechando SnapMirror para transferir de forma eficiente sus máquinas virtuales desde un centro de datos a otro o incluso dentro del mismo centro de datos, ya sea el suyo o mediante cualquier otro proveedor de servicios para partners de NetApp.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager es una oferta de recuperación ante desastres que proporciona orquestación automatizada y pruebas no disruptivas de planes de recuperación centralizados para simplificar la gestión de recuperación ante desastres de todas las aplicaciones virtualizadas.</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">Al poner en marcha Site Recovery Manager en sistemas ONTAP de NetApp, puede reducir de forma drástica el coste y la complejidad de la recuperación ante desastres. Con dispositivos de almacenamiento de alto rendimiento, fáciles de gestionar y escalables, y sólidas ofertas de software, NetApp ofrece soluciones flexibles de gestión de datos y almacenamiento para dar soporte a entornos vSphere.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">Las mejores prácticas y recomendaciones que se ofrecen en esta guía no son una solución única para todos. Este documento contiene una colección de prácticas recomendadas y recomendaciones que proporcionan directrices para planificar, implementar y gestionar planes de recuperación ante desastres de SRM. Póngase en contacto con un experto local de VMware de NetApp cuando planifique e implemente entornos de recuperación de sitio de VMware vCenter en el almacenamiento de NetApp. Los expertos de VMware de NetApp pueden identificar rápidamente las necesidades y exigencias de cualquier entorno vSphere y pueden ajustar la solución de almacenamiento según corresponda.</block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">Esta página describe las eficiencias del almacenamiento de ONTAP.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">Eficiencias del almacenamiento de ONTAP</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Acerca de las eficiencias del almacenamiento</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">Aunque NetApp fue el primero en ofrecer deduplicación para cargas de trabajo de producción, esta innovación no fue la primera o la última en esta área. Comenzó con las copias Snapshot de ONTAP, un mecanismo de protección de datos con gestión eficiente del espacio sin efecto del rendimiento, junto con la tecnología FlexClone para realizar de forma instantánea copias de lectura/escritura de máquinas virtuales para su uso en producción y backup. NetApp siguió ofreciendo funcionalidades inline, que incluían deduplicación, compresión y deduplicación de bloque cero, para sacar el máximo partido de almacenamiento de SSD de elevado coste. Más recientemente, ONTAP añadió compactación para reforzar nuestras eficiencias de almacenamiento.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">*Deduplicación en línea de bloque cero.* elimina el espacio que se desperdicia en los bloques completamente cero.</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">*Compresión en línea.* comprime bloques de datos para reducir la cantidad de almacenamiento físico necesario.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">*Deduplicación en línea.* elimina los bloques entrantes con los bloques existentes en el disco.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">*Compactación de datos en línea.* empaqueta operaciones de E/S y archivos más pequeños en cada bloque físico.</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">Eficiencias del almacenamiento</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">Puede ejecutar la deduplicación, la compresión y la compactación de datos de forma conjunta o de forma independiente para lograr un ahorro de espacio óptimo en un volumen de FlexVol. La combinación de estas funcionalidades ha dado como resultado que los clientes observan un ahorro de hasta 5:1 para VSI y de hasta 30:1 para la infraestructura de puestos de trabajo virtuales.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">Usar la deduplicación, la compresión y la compactación de datos para aumentar la eficiencia del almacenamiento</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">Para obtener más información sobre la eficiencia del almacenamiento de ONTAP, consulte<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> En el centro de documentación de ONTAP 9.</block>
  <block id="6f3666cf392f9aa79924b94f433b64ed" category="doc">Plugin de SnapCenter de NetApp para VMware vSphere: Implementación en VMware</block>
  <block id="a1dd31a3dca44eb1fe27b895521130ae" category="inline-link-macro">Siguiente: Información adicional - Plugin de SnapCenter para VMware vSphere - requisitos previos de la solución.</block>
  <block id="874d68c7d23e9e2e452ff6efaf757dee" category="paragraph"><block ref="874d68c7d23e9e2e452ff6efaf757dee" category="inline-link-macro-rx"></block></block>
  <block id="e7f47d4d003703cc37a3f472bf362522" category="doc">Plugin de SnapCenter de NetApp para VMware vSphere: Flujo de trabajo de backup</block>
  <block id="b80c59ad5be93a14a5e884c9617272bd" category="inline-link-macro">Anterior: Información adicional - plugin de SnapCenter para VMware vSphere - requisitos previos de la solución.</block>
  <block id="b8c179b73c48ccf857c179c753fc7866" category="paragraph"><block ref="b8c179b73c48ccf857c179c753fc7866" category="inline-link-macro-rx"></block></block>
  <block id="7889fbe4fe01425f9ecdef9442f812b8" category="inline-link-macro">Siguiente: Información adicional - plugin de SnapCenter para VMware vSphere - flujo de trabajo de restauración.</block>
  <block id="907647e9678147c153e1b1f855122048" category="paragraph"><block ref="907647e9678147c153e1b1f855122048" category="inline-link-macro-rx"></block></block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">Esta página proporciona los pasos para implementar un almacenamiento ONTAP NVMe/FC de NetApp para un almacén de datos VMFS en un entorno de VMware vSphere.</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">Almacén de datos VMFS de vSphere: NVMe/FC con ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">Acerca de esta tarea</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">En esta sección se describe la creación de un almacén de datos VMFS con almacenamiento ONTAP mediante NVMe/FC.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">Para el aprovisionamiento automatizado, utilice uno de los siguientes scripts: <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, o. <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">Lo que necesita</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">Se necesitan habilidades básicas para gestionar un entorno de vSphere y ONTAP.</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">Comprensión básica de NVMe/FC</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">Un sistema de almacenamiento ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) que ejecuta {ontap_version}</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">Credenciales de ONTAP (nombre de SVM, ID de usuario y contraseña)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">WWPN de ONTAP para información sobre el host, el destino y las SVM y la LUN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">Una hoja de datos de configuración de FC completada</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">VCenter Server</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">Información de hosts de vSphere ({vsphere_version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">Switch(es) de estructura</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">Con los puertos de datos FC de ONTAP y los hosts de vSphere conectados.</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">Con la función de virtualización N_Port ID (NPIV) habilitada.</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">Cree una sola zona de destino de iniciador.</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">Cree una zona para cada iniciador (zona iniciador única).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">Para cada zona, incluya un destino que sea la interfaz lógica ONTAP FC (WWPN) para las SVM. Debe haber al menos dos interfaces lógicas por nodo por SVM. No utilice el WWPN de los puertos físicos.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">Aprovisione el almacén de datos VMFS</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">Compruebe la compatibilidad con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">Compruebe que la configuración de NVMe/FC sea compatible.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">Tareas de ONTAP</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">Comprobar la licencia de ONTAP para FCP.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>Utilice la<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Y compruebe si aparece NVMe_of. Uso<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> para añadir una licencia.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">Compruebe que el protocolo NVMe esté habilitado en la SVM.</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">Configure SVM para NVMe.</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">Compruebe que las interfaces lógicas de NVMe/FC estén disponibles en las SVM.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">Uso<block ref="e38d07be71f760e81ec7c17103cd57db" prefix=" " category="inline-code"></block> Para comprobar el adaptador FCP.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">Cuando se crea una SVM con la interfaz gráfica de usuario, las interfaces lógicas se forman parte de ese proceso.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">Para cambiar el nombre de la interfaz de red, utilice el comando<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">Cree el espacio de nombres y el subsistema NVMe</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">Tareas de VMware vSphere</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">Información del adaptador de almacenamiento</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">Compruebe que los controladores HBA están instalados. Los HBA compatibles con VMware tienen los controladores instalados de fábrica y deben ser visibles en <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">Realice tareas de instalación y validación del controlador vSphere NVMe host</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">Crear almacén de datos VMFS</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">Esta página describe las ventajas de automatizar la funcionalidad básica de ONTAP en un entorno VMware vSphere.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">Introducción a la automatización para ONTAP y vSphere</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">Automatización de VMware</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">La automatización ha sido un aspecto integral de la gestión de entornos VMware desde los primeros días de VMware ESX. La capacidad de poner en marcha infraestructura como código y ampliar las prácticas en operaciones de cloud privado ayuda a paliar las cuestiones relacionadas con el escalado, la flexibilidad, el aprovisionamiento automático y la eficiencia.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">La automatización se puede organizar en las siguientes categorías:</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">*Implementación de infraestructura virtual*</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">*Operaciones de máquina invitada*</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">*Operaciones en la nube*</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">Los administradores tienen a su disposición muchas opciones en lo que respecta a la automatización de su infraestructura. Ya sea mediante el uso de funciones nativas de vSphere como Perfiles de host o especificaciones de personalización para máquinas virtuales hasta las API disponibles en los componentes de software, los sistemas operativos y los sistemas de almacenamiento de NetApp, existe una documentación y guía significativas disponibles.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 y versiones posteriores admiten ciertas funciones de API de VMware vSphere para la integración de cabinas (VAAI) cuando el host ESX ejecuta ESX 4.1 o versiones posteriores. VAAI es un conjunto de API que permiten la comunicación entre hosts ESXi de VMware vSphere y dispositivos de almacenamiento. Estas funciones ayudan a descargar las operaciones del host ESX al sistema de almacenamiento y aumentan el rendimiento de la red. El host ESX habilita las funciones automáticamente en el entorno correcto. Puede determinar la extensión hasta la cual el sistema utiliza las funciones de VAAI si se comprueban las estadísticas contenidas en los contadores VAAI.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">El punto de partida más común para automatizar la puesta en marcha de un entorno VMware es el aprovisionamiento de almacenes de datos basados en bloques o archivos. Es importante trazar el mapa de los requisitos de las tareas reales antes de desarrollar la automatización correspondiente.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">Si quiere más información sobre la automatización de los entornos VMware, consulte los siguientes recursos:</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">ThePub de NetApp</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. Gestión y automatización de la configuración de NetApp.</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">La comunidad de Ansible Galaxy para VMware</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. Una colección de recursos de Ansible para VMware.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">Recursos de VMware {code}</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. Los recursos necesarios para diseñar soluciones para el centro de datos definido mediante software, incluidos foros, estándares de diseño, código de muestra y herramientas de desarrollo.</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">Introducción a ONTAP para administradores de vSphere</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">¿Por qué elegir ONTAP para vSphere?</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">ONTAP de NetApp simplifica las operaciones de almacenamiento y gestión de datos y complementa claramente los entornos VMware, ya sea con la implementación en las instalaciones o en el cloud. La mejor protección de datos de NetApp, innovaciones en eficiencia del almacenamiento y un excelente rendimiento en arquitecturas de VMware basadas tanto en SAN COMO en NAS son algunos de los motivos por los que decenas de miles de clientes han seleccionado ONTAP como solución de almacenamiento para puestas en marcha de vSphere.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp proporciona numerosos complementos, validaciones y calificaciones de VMware de varios productos VMware para responder a los clientes que se enfrentan a los retos únicos de administrar un entorno de virtualización. NetApp logra el almacenamiento y la gestión de datos lo que VMware hace para la virtualización, lo que permite a los clientes centrarse en sus competencias principales en lugar de gestionar el almacenamiento físico. Esta 20 alianza entre VMware y NetApp continúa evolucionando y añadiendo valor al cliente a medida que surgen nuevas tecnologías, como VMware Cloud Foundation y Tanzu, al tiempo que continúa dando soporte a las bases de vSphere.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">Algunos de los factores clave que valoran los clientes son:</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">*Almacenamiento unificado*</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">*Eficiencia del almacenamiento*</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">*Gestión basada en normativas de almacenamiento y volúmenes virtuales*</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">*Cloud híbrido*</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">Si desea obtener más información sobre las soluciones de NetApp y VMware admitidas, consulte los siguientes recursos:</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">La herramienta de matriz de interoperabilidad de NetApp</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). La IMT define los componentes y versiones cualificadas que puede utilizar para crear configuraciones FC/FCoE, iSCSI, NFS y CIFS.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">Guía de compatibilidad de VMware</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. En la guía de compatibilidad de VMware se muestra la compatibilidad del sistema, la E/S, el almacenamiento/SAN y el backup con VMware Infrastructure y los productos de software</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">Herramientas de ONTAP de NetApp para VMware</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. Las herramientas de ONTAP para VMware vSphere son un único complemento de vCenter Server que incluye las extensiones VSC, VASA Provider y el adaptador de replicación de almacenamiento (SRA).</block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">En este documento se trata la seguridad de productos de las herramientas de ONTAP para VMware vSphere.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">Artículo técnico WP-7353: Herramientas de ONTAP para VMware vSphere: Seguridad de los productos</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tulledge, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Actividades de desarrollo seguras</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">El departamento de ingeniería de software con herramientas de ONTAP de NetApp para VMware vSphere realiza las siguientes actividades de desarrollo seguro:</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modelado de amenazas.* el propósito del modelado de amenazas es descubrir defectos de seguridad en una característica, componente o producto al principio del ciclo de vida del desarrollo del software. Un modelo de amenaza es una representación estructurada de toda la información que afecta la seguridad de una aplicación. En esencia, es una visión de la aplicación y su entorno a través del objetivo de la seguridad.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Pruebas de seguridad de aplicaciones dinámicas (DAST).* esta tecnología está diseñada para detectar condiciones vulnerables en aplicaciones en su estado de funcionamiento. DAST prueba las interfaces HTTP y HTML expuestas de las aplicaciones web.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Moneda de código de terceros.* como parte del desarrollo de software con software de código abierto (OSS), debe tratar las vulnerabilidades de seguridad que pueden estar asociadas con cualquier OSS incorporado en su producto. Esto es un esfuerzo continuo porque una nueva versión de OSS podría tener una vulnerabilidad recién descubierta reportada en cualquier momento.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Análisis de vulnerabilidades.* el propósito del análisis de vulnerabilidades es detectar vulnerabilidades de seguridad comunes y conocidas en los productos de NetApp antes de que se lancen a los clientes.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* Pruebas de penetración.* la prueba de penetración es el proceso de evaluar un sistema, una aplicación web o una red para encontrar vulnerabilidades de seguridad que podrían ser explotadas por un atacante. Las pruebas de penetración (pruebas de Pen) en NetApp las realiza un grupo de empresas de terceros aprobadas y fiables. Su alcance de prueba incluye el lanzamiento de ataques contra una aplicación o software similar a intrusos hostiles o piratas informáticos que utilizan métodos o herramientas de explotación sofisticados.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Funciones de seguridad de los productos</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">Las herramientas de NetApp ONTAP para VMware vSphere incluyen las siguientes funciones de seguridad en cada versión.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Banner de inicio de sesión.* SSH está desactivado de forma predeterminada y sólo permite inicios de sesión de una vez si está activado desde la consola de VM. Se muestra el siguiente banner de inicio de sesión una vez que el usuario introduce un nombre de usuario en la solicitud de inicio de sesión:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*ADVERTENCIA:* el acceso no autorizado a este sistema está prohibido y será procesado por ley. Al acceder a este sistema, acepta que sus acciones pueden supervisarse si se sospecha un uso no autorizado.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Una vez que el usuario completa el inicio de sesión a través del canal SSH, se muestra el siguiente texto:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Control de acceso basado en roles (RBAC).* dos tipos de controles RBAC están asociados con las herramientas ONTAP:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilegios nativos de vCenter Server</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilegios específicos del plugin de vCenter. Para obtener más información, consulte<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canales de comunicaciones cifrados.* toda comunicación externa ocurre a través de HTTPS utilizando la versión 1.2 de TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Exposición mínima del puerto.* sólo los puertos necesarios están abiertos en el firewall.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">En la siguiente tabla se describen los detalles de los puertos abiertos.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">Puerto TCP v4/v6 #</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Dirección</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Función</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">entrante</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Conexiones HTTPS para la API de REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Conexiones HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Conexiones HTTPS utilizadas para conexiones SOAP a través de https este puerto se debe abrir para permitir que un cliente se conecte al servidor API de herramientas ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (deshabilitado de forma predeterminada)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Conexiones HTTPS - VP y SRA - conexiones internas sólo del bucle invertido</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Conexiones HTTPS: VP y SRA utilizadas para SOAP a través de conexiones https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP paquetes de captura SNMP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">exclusivamente para uso interno</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Puerto de base de datos Derby, sólo entre este equipo y él mismo, no se aceptan conexiones externas -- sólo conexiones internas</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidireccional</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Se utiliza para las conexiones a clústeres de ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">artículo de base de conocimientos</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Compatibilidad con certificados firmados por la entidad de certificación (CA).* las herramientas de ONTAP para VMware vSphere admiten certificados firmados por CA. Vea esto<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Registro de auditoría.* los paquetes de soporte se pueden descargar y son extremadamente detallados. Las herramientas de ONTAP registran toda la actividad de inicio de sesión y cierre de sesión de los usuarios en un archivo de registro independiente. Las llamadas de API VASA se registran en un registro de auditoría de VASA dedicado (cxf.log local).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Políticas de contraseña.* se siguen las siguientes directivas de contraseñas:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Las contraseñas no han iniciado sesión en ningún archivo de registro.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Las contraseñas no se comunican en texto sin formato.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Las contraseñas se configuran durante el propio proceso de instalación.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">El historial de contraseñas es un parámetro configurable.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">La antigüedad mínima de la contraseña se establece en 24 horas.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">El proceso de finalización automática de los campos de contraseña está desactivado.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Las herramientas de ONTAP cifran toda la información de credenciales almacenada mediante el hash SHA256.</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">Noviembre de 2021</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">Póngase en contacto con nosotros</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">¿Tiene comentarios acerca de este informe técnico?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">Envíanos una dirección doccomments@netapp.com e incluya TR-4597 en la línea del asunto.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Volúmenes virtuales (vVols) y gestión basada en políticas de almacenamiento (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">Acerca de vVols y SPBM</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp fue un partner de diseño inicial de VMware en el desarrollo de vSphere Virtual Volumes (vVols), que ofrecía información sobre la arquitectura y compatibilidad temprana con vVols y VMware vSphere APIs for Storage Awareness (VASA). Este método no solo llevó a cabo la gestión de almacenamiento granular de máquinas virtuales a VMFS, sino que también admitió la automatización del aprovisionamiento de almacenamiento a través de la gestión basada en políticas de almacenamiento (SPBM).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">La SPBM proporciona un marco que funciona como capa de abstracción entre los servicios de almacenamiento disponibles para su entorno de virtualización y los elementos de almacenamiento aprovisionados mediante políticas. Este enfoque permite a los arquitectos de almacenamiento diseñar pools de almacenamiento con distintas funcionalidades que pueden consumir fácilmente los administradores de máquinas virtuales. A continuación, los administradores pueden igualar los requisitos de carga de trabajo de las máquinas virtuales con los pools de almacenamiento aprovisionados, lo que permite controlar de forma granular diversos ajustes a nivel de máquinas virtuales o discos virtuales.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP es líder en el sector del almacenamiento a escala de vVols, ya que admite cientos de miles de vVols en un único cluster, mientras que las cabinas empresariales y los proveedores de cabinas flash más pequeños admiten hasta varios miles de vVols por cabina. NetApp también impulsa la evolución de la gestión granular de máquinas virtuales con próximas funcionalidades para admitir vVols 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: VMware vSphere Virtual Volumes con ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Para obtener más información sobre VMware vSphere Virtual Volumes, SPBM y ONTAP, consulte<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">Almacenamiento unificado de ONTAP</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">Acerca de Unified Storage</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">Los sistemas que ejecutan el software ONTAP están unificados de varias maneras importantes. En un principio, este enfoque hacía referencia a la compatibilidad con protocolos NAS y SAN en un solo sistema de almacenamiento. ONTAP sigue siendo la plataforma líder para SAN junto con su solidez original en NAS. Una máquina virtual de almacenamiento (SVM) es una construcción lógica que permite a los clientes acceder a sistemas que ejecutan el software ONTAP. Las SVM pueden servir datos de forma simultánea mediante varios protocolos de acceso a los datos a través de interfaces lógicas (LIF). Los SVM proporcionan acceso a los datos de nivel de archivo mediante protocolos NAS, como CIFS y NFS, y acceso a datos de nivel de bloque mediante protocolos SAN, como iSCSI, FC/FCoE y NVMe. Las SVM pueden servir datos a clientes SAN y NAS de forma independiente a la vez.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">Almacenamiento unificado</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">En el mundo de vSphere, este enfoque también podría significar un sistema unificado para una infraestructura de puestos de trabajo virtuales (VDI) junto con una infraestructura de servidores virtuales (VSI). Los sistemas que ejecutan el software ONTAP suelen ser menos caros para VSI que las cabinas empresariales tradicionales y, al mismo tiempo, cuentan con funcionalidades avanzadas de eficiencia del almacenamiento para manejar VDI en el mismo sistema. ONTAP también unifica varios medios de almacenamiento, desde SSD a SATA, y puede ampliarlos fácilmente al cloud. No es necesario comprar una cabina flash para el rendimiento, una cabina SATA para archivos y sistemas independientes para el cloud. ONTAP los une a todos.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualización del almacenamiento</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Para obtener más información sobre las SVM, el almacenamiento unificado y el acceso de cliente, consulte<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> En el centro de documentación de ONTAP 9.</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">En esta página, se proporcionan los pasos para poner en marcha un almacén de datos de ONTAP NFS versión 3 de NetApp en un entorno de VMware vSphere.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">Almacén de datos NFS de vSphere: Versión 3 con ONTAP</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">Creación de un almacén de datos de NFS versión 3 con almacenamiento NAS de ONTAP.</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">Las habilidades básicas necesarias para gestionar un entorno de vSphere y ONTAP.</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">Un sistema de almacenamiento de ONTAP (FAS/AFF/CVO/ONTAP Select/Servicio de volumen de cloud/Azure NetApp Files) con ONTAP 9.8 o posterior</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">Credenciales de ONTAP (nombre de SVM, ID de usuario, contraseña)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">Información sobre el puerto de red de ONTAP, SVM y LUN para NFS</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">Una hoja de trabajo de configuración de NFS completada</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">Credenciales de vCenter Server</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">Información sobre los hosts de vSphere para vSphere 7.0 o una versión posterior</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">Información de IP del adaptador de VMkernel de NFS</block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">Switches de red</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">Con los puertos de datos de red del sistema ONTAP y los hosts de vSphere conectados</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">VLAN configuradas para NFS</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(Opcional) agregación de enlaces configurada para los puertos de datos de red ONTAP</block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">Herramienta ONTAP para VMware vSphere puesta en marcha, configurada y lista para usar</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">Pasos</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">Compruebe la compatibilidad con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">Compruebe que la configuración de NFS es compatible.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">Complete las siguientes tareas de ONTAP y vSphere.</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">Comprobar la licencia de ONTAP para NFS.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">Utilice la<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Y compruebe que NFS aparece en la lista.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">Uso<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> para añadir una licencia.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">Siga el flujo de trabajo de configuración de NFS.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">Siga el flujo de trabajo de configuración del cliente NFS para vSphere.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">Referencia</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">Funciones de protocolo y almacén de datos de vSphere: NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">El futuro</block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">Una vez completadas estas tareas, el almacén de datos NFS estará listo para consumir para aprovisionar máquinas virtuales.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">El software ONTAP de NetApp lleva casi dos décadas siendo una solución de almacenamiento líder para entornos VMware vSphere y sigue agregando funcionalidades innovadoras que simplifican la gestión y reducen los costes. Este documento presenta la solución ONTAP para vSphere, e incluye la información de producto más reciente y las prácticas recomendadas para simplificar la puesta en marcha, reducir el riesgo y simplificar la gestión.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597: VMware vSphere para ONTAP</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">Karl Konnerth, NetApp</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Las prácticas recomendadas complementan otros documentos, como guías y listas de compatibilidad. Se desarrollan según pruebas de laboratorio y una amplia experiencia de campo por parte de ingenieros y clientes de NetApp. Puede que no sean las únicas prácticas compatibles que funcionan en todos los entornos, pero suelen ser las soluciones más sencillas que satisfacen las necesidades de la mayoría de los clientes.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="inline-link-macro">Información específica de las versiones de ONTAP y vSphere</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">Este documento se centra en las funcionalidades incluidas en versiones recientes de ONTAP (9.x) ejecutándose en vSphere 6.0 o posteriores. Consulte la sección <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> para obtener detalles relacionados con versiones específicas.</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">Existen muchos motivos por los que decenas de miles de clientes han seleccionado ONTAP como solución de almacenamiento para vSphere, como un sistema de almacenamiento unificado que admite los protocolos SAN y NAS, funcionalidades de protección de datos sólidas mediante copias Snapshot de NetApp con gestión eficiente del espacio, y una gran cantidad de herramientas que le ayudarán a gestionar los datos de aplicaciones. El uso de un sistema de almacenamiento independiente del hipervisor permite descargar numerosas funciones y maximizar su inversión en sistemas de host vSphere. Este método no solo garantiza que los recursos del host se centren en las cargas de trabajo de las aplicaciones, sino que también evita efectos de rendimiento aleatorios en las aplicaciones de operaciones de almacenamiento.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">El uso de ONTAP junto con vSphere es una excelente combinación que le permite reducir los gastos en hardware del host y software de VMware. También puede proteger sus datos con un coste menor y un alto rendimiento constante. Dado que las cargas de trabajo virtualizadas son móviles, puede explorar distintos enfoques mediante Storage vMotion para mover equipos virtuales entre almacenes de datos de VMFS, NFS o vVols, todo ello en el mismo sistema de almacenamiento.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Estos son algunos de los factores clave que valoran los clientes en la actualidad:</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">*Almacenamiento unificado.* los sistemas que ejecutan el software ONTAP están unificados de varias maneras significativas. En un principio, este enfoque hacía referencia a los protocolos NAS y SAN, y ONTAP sigue siendo la plataforma líder para SAN junto con su fortaleza original en NAS. En el mundo de vSphere, este enfoque también podría significar un sistema unificado para una infraestructura de puestos de trabajo virtuales (VDI) junto con una infraestructura de servidores virtuales (VSI). Los sistemas que ejecutan el software ONTAP suelen ser menos caros para VSI que las cabinas empresariales tradicionales y, al mismo tiempo, cuentan con funcionalidades avanzadas de eficiencia del almacenamiento para manejar VDI en el mismo sistema. ONTAP también unifica varios medios de almacenamiento, desde SSD a SATA, y puede ampliarlos fácilmente al cloud. No es necesario comprar una cabina flash para el rendimiento, una cabina SATA para archivos y sistemas independientes para el cloud. ONTAP los une a todos.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">* Volúmenes virtuales y gestión basada en políticas de almacenamiento.* NetApp fue un primer partner de diseño con VMware en el desarrollo de vSphere Virtual Volumes (vVols), que ofrecía información sobre la arquitectura y una compatibilidad temprana con vVols y VMware vSphere APIs for Storage Awareness (VASA). Este enfoque no solo llevó a cabo una gestión del almacenamiento de máquinas virtuales granular a VMFS, sino que también admitió la automatización del aprovisionamiento de almacenamiento a través de la gestión basada en políticas de almacenamiento. Este enfoque permite a los arquitectos de almacenamiento diseñar pools de almacenamiento con distintas funcionalidades que pueden consumir fácilmente los administradores de máquinas virtuales. ONTAP es líder en el sector del almacenamiento a escala VVol, por lo que admite cientos de miles de vVols en un único clúster, mientras que las cabinas empresariales y los proveedores de cabinas flash más pequeños admiten hasta varios miles de vVols por cabina. NetApp también está impulsando la evolución de la gestión granular de equipos virtuales con próximas funcionalidades para admitir vVols 3.0.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*Eficiencia del almacenamiento.* aunque NetApp fue el primero en ofrecer deduplicación para cargas de trabajo de producción, esta innovación no fue la primera ni la última en esta área. Comenzó con las copias Snapshot de ONTAP, un mecanismo de protección de datos con gestión eficiente del espacio sin efecto del rendimiento, junto con la tecnología FlexClone para realizar de forma instantánea copias de lectura/escritura de máquinas virtuales para su uso en producción y backup. NetApp siguió ofreciendo funcionalidades inline, que incluían deduplicación, compresión y deduplicación de bloque cero, para sacar el máximo partido de almacenamiento de SSD de elevado coste. Más recientemente, ONTAP añadió la capacidad de empaquetar las operaciones de I/o y archivos más pequeños en un bloque de discos mediante la compactación. La combinación de estas funcionalidades ha dado como resultado que los clientes observan un ahorro de hasta 5:1 para VSI y de hasta 30:1 para la infraestructura de puestos de trabajo virtuales.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud híbrido.* tanto si se utiliza para un cloud privado en las instalaciones, una infraestructura de cloud público o un cloud híbrido que combina lo mejor de ambos, las soluciones ONTAP le ayudan a crear su Data Fabric para optimizar y optimizar la gestión de datos. Empiece con sistemas all-flash de alto rendimiento y, a continuación, apítelos con sistemas de disco o de almacenamiento en cloud para protección de datos y cloud computing. Elija entre clouds de Azure, AWS, IBM o Google para optimizar costes y evitar la restricción. Aproveche el soporte avanzado para OpenStack y las tecnologías de contenedor según sea necesario. NetApp también ofrece backup basado en cloud (SnapMirror Cloud, Cloud Backup Service y Cloud Sync) y herramientas de organización en niveles del almacenamiento y archivado (FabricPool) para ONTAP para ayudar a reducir los gastos operativos y aprovechar el amplio alcance del cloud.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">*Y mucho más.* saque partido del rendimiento extremo de las cabinas AFF A-Series de NetApp para acelerar su infraestructura virtualizada a la vez que gestiona los costes. Disfrute de operaciones no disruptivas, desde el mantenimiento hasta las actualizaciones, pasando por la sustitución completa de su sistema de almacenamiento, mediante clústeres ONTAP de escalado horizontal. Proteja los datos en reposo con funcionalidades de cifrado de NetApp sin coste adicional. Asegúrese de que el rendimiento cumple los niveles de servicio empresarial a través de funcionalidades de calidad de servicio de gran precisión. Todos forman parte de la amplia gama de capacidades que incluye ONTAP, el software de gestión de datos empresariales líder del sector.</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355: El complemento SnapCenter para VMware vSphere: Seguridad de productos</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">La ingeniería de software del complemento SnapCenter de NetApp para VMware vSphere utiliza las siguientes actividades de desarrollo seguro:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Pruebas de seguridad de aplicaciones dinámicas (DAST).* Tecnologías diseñadas para detectar condiciones vulnerables en aplicaciones en estado en ejecución. DAST prueba las interfaces HTTP y HTML expuestas de las aplicaciones web.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Moneda de código de terceros.* como parte del desarrollo de software y el uso de software de código abierto (OSS), es importante abordar las vulnerabilidades de seguridad que pueden estar asociadas con OSS que se han incorporado a su producto. Se trata de un esfuerzo continuo, ya que la versión del componente OSS puede tener una vulnerabilidad recién descubierta reportada en cualquier momento.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* Pruebas de penetración.* la prueba de penetración es el proceso de evaluar un sistema, una aplicación web o una red para encontrar vulnerabilidades de seguridad que podrían ser explotadas por un atacante. Las pruebas de penetración (pruebas de Pen) en NetApp las realiza un grupo de empresas de terceros aprobadas y fiables. El alcance de su prueba incluye el lanzamiento de ataques contra una aplicación o software como intrusos hostiles o hackers que utilizan métodos o herramientas de explotación sofisticados.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Actividad de respuesta a incidentes de seguridad del producto.* las vulnerabilidades de seguridad se descubren tanto interna como externamente a la empresa y pueden representar un grave riesgo para la reputación de NetApp si no se tratan de manera oportuna. Para facilitar este proceso, un equipo de respuesta a incidentes de seguridad de productos (PSIRT) informa y realiza un seguimiento de las vulnerabilidades.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">El plugin de SnapCenter de NetApp para VMware vSphere incluye las siguientes funciones de seguridad en cada versión:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Acceso restringido al shell.* SSH está desactivado de forma predeterminada, y sólo se permiten inicios de sesión una vez si están habilitados desde la consola de VM.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Advertencia de acceso en el banner de inicio de sesión.* se muestra el siguiente banner de inicio de sesión después de que el usuario introduzca un nombre de usuario en el indicador de inicio de sesión:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Una vez que el usuario completa el inicio de sesión a través del canal SSH, se muestra la siguiente salida:</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*Control de acceso basado en roles (RBAC).* dos tipos de controles RBAC están asociados con las herramientas ONTAP de NetApp:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilegios nativos de vCenter Server.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Control de acceso basado en roles (RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilegios específicos del complemento de VMware vCenter. Para obtener más información, consulte<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canales de comunicaciones cifrados.* toda comunicación externa ocurre a través de HTTPS utilizando TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">En la siguiente tabla se proporcionan los detalles de los puertos abiertos.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Número de puerto TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Conexiones HTTPS para interfaz gráfica de usuario de OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (deshabilitado de forma predeterminada)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (sólo conexiones internas; las conexiones externas están deshabilitadas de forma predeterminada)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (servicios de protección de datos)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Cómo crear o importar un certificado SSL al plugin de SnapCenter para VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Compatibilidad con certificados firmados por entidad de certificación (CA).* el plugin de SnapCenter para VMware vSphere es compatible con la función de certificados firmados por CA. Consulte<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Políticas de contraseña.* las siguientes directivas de contraseñas están en vigor:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Toda la información de credenciales se almacena mediante el hash SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Imagen del sistema operativo base.* el producto se entrega con el SO base Debian para OVA con acceso restringido y acceso al shell desactivado. Esto reduce el espacio necesario para los ataques. Todos los sistemas operativos base de la versión SnapCenter se actualizan con los parches de seguridad más recientes disponibles para obtener la máxima cobertura de seguridad.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp desarrolla funciones de software y parches de seguridad con respecto al dispositivo del plugin de SnapCenter para VMware vSphere y, a continuación, se los libera a los clientes como una plataforma de software integrada. Dado que estos dispositivos incluyen dependencias específicas de sistemas suboperativos de Linux y nuestro software exclusivo, NetApp recomienda no realizar cambios en el sistema operativo de subsistema, ya que esto tiene un gran potencial para afectar al dispositivo de NetApp. Esto podría afectar a la capacidad de NetApp para dar soporte al dispositivo. NetApp recomienda probar e implementar nuestra última versión de código para los dispositivos, ya que se los publica para resolver cualquier problema relacionado con la seguridad.</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">Marzo de 2022</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp ha desarrollado un conjunto de configuraciones de tiempo de espera de HBA y multivía de host ESXi para un comportamiento adecuado con ONTAP según las pruebas de NetApp. Se pueden establecer fácilmente usando las herramientas de ONTAP para VMware vSphere. En la consola Summary, haga clic en Edit Settings en el portlet Host Systems o haga clic con el botón derecho en el host en vCenter y, a continuación, desplácese hasta ONTAP tools &gt; Set recommended Values. Esta es la configuración del host recomendada actualmente con la versión 9.8.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Configuración del host*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valor recomendado por NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Se requiere reinicio*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configuración avanzada de ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAccelerated Locking</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">Dejar como establecido (el valor predeterminado de VMware es 1)</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">Dejar según conjunto (el valor predeterminado de VMware es 0, pero no se necesita para VMFS6). Para obtener más información, consulte <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Ajustes NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 o posterior; establezca esta opción en 32. El resto de configuraciones de NFS se establecen en 30</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Configure 512 MB para la mayoría de las versiones de vSphere 6.X. Establezca 1024 MB para 6.5U3, 6.7U3 y 7.0 o superior.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 o posterior; establezca esta opción en 256 todas las demás configuraciones de NFS; establezca esta configuración en 64.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 o posterior; establezca esta opción en 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 o posterior; establezca esta opción en 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Establezca en 10 para todas las configuraciones NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Establezca en 12 para todas las configuraciones NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Establezca en 5 para todas las configuraciones NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 o posterior; establezca esta opción en 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Configuración de FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Política de selección de rutas</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Establezca el valor RR (round robin) cuando se utilicen rutas FC con ALUA. Establezca COMO FIJO para todas las demás configuraciones. Al establecer este valor en RR, se ayuda a proporcionar un equilibrio de carga en todas las rutas activas/optimizadas. El valor FIJO es para configuraciones antiguas que no pertenecen a ALUA y ayuda a evitar las operaciones de I/o del proxy En otras palabras, ayuda a evitar que las operaciones de I/o vayan al otro nodo de una pareja de alta disponibilidad (ha) en un entorno con Data ONTAP en 7-Mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Establezca en 32 para todas las configuraciones. Si configura este valor, se evitan los errores de I/O.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Establezca en 8 para todas las configuraciones. Si configura este valor, se evitan los errores de I/O.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Tiempos de espera de FC HBA de Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Se utiliza el valor predeterminado.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Tiempos de espera de HBA FC de QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Configuración iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Establezca el valor RR (round robin) para todas las rutas iSCSI. Al establecer este valor en RR, se ayuda a proporcionar un equilibrio de carga en todas las rutas activas/optimizadas.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Establezca en 32 para todas las configuraciones. Si configura este valor, se evitan los errores de I/O.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1: Es posible que la opción de configuración avanzada de NFS MaxQueueDepth no funcione según lo previsto al usar VMware vSphere ESXi 7.0.1 y VMware vSphere ESXi 7.0.2. Consulte <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Las herramientas de ONTAP también especifican determinada configuración predeterminada al crear volúmenes de ONTAP FlexVol y LUN:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Herramienta ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Ajuste predeterminado*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Reserva de Snapshot (-Porcentaje-espacio de instantáneas)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Reserva fraccionaria (-reserva fraccionaria)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Actualización del tiempo de acceso (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falso</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Lectura mínima (lectura mínima)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">Copias snapshot programadas</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Eficiencia del almacenamiento</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Ninguno (con thin provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Tamaño automático del volumen</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">aumentar_reducción</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Reserva de espacio de LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Deshabilitado</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Asignación de espacio de LUN</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">Otras consideraciones de configuración multivía del host</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">Aunque no está configurada actualmente por las herramientas disponibles de ONTAP, NetApp sugiere tener en cuenta estas opciones de configuración:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">En entornos de alto rendimiento o al probar el rendimiento con un único almacén de datos LUN, considere la posibilidad de cambiar la configuración del equilibrio de carga de la normativa de selección de rutas (PSP_RR_VMW) por turnos desde la configuración predeterminada de IOPS de 1000 a un valor de 1. Consulte la base de conocimientos de VMware<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> para obtener más información.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Complementos y políticas de selección de rutas</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">En vSphere 6.7 Update 1, VMware introdujo un nuevo mecanismo de equilibrio de carga de latencia para Round Robin PSP. La nueva opción considera el ancho de banda de I/o y la latencia de ruta al seleccionar la ruta óptima para I/O. Puede que se beneficie de utilizarlo en entornos con conectividad de ruta no equivalente, como casos en los que haya más saltos de red en una ruta que otra o cuando se utilice un sistema de cabinas All SAN de NetApp. Consulte<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">En esta sección se proporcionan directrices sobre las funcionalidades compatibles con versiones específicas de ONTAP y vSphere. NetApp recomienda confirmar una combinación específica de lanzamientos con la matriz de interoperabilidad de NetApp.</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matriz de interoperabilidad de NetApp</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">En esta sección se proporcionan directrices sobre las funcionalidades compatibles con versiones específicas de ONTAP y vSphere. NetApp recomienda confirmar una combinación específica de versiones con el<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">Lanzamientos de ONTAP</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">En el momento de la publicación, NetApp ofrece soporte completo para las siguientes familias de versiones:</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">Compatibilidad de vSphere y ESXi</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">ONTAP de NetApp tiene una amplia compatibilidad con hosts ESXi de vSphere. Las cuatro familias de versiones principales que acabamos de describir (9.5, 9.6, 9.7 y 9.8) son totalmente compatibles como plataformas de almacenamiento de datos para las versiones recientes de vSphere, incluidas las 6.0, 6.5 y 7.0 (incluidas actualizaciones de estas versiones). La interoperabilidad NFS v3 se define de forma general y NetApp admite cualquier cliente, incluidos hipervisores, que cumpla con el estándar NFS v3. La compatibilidad con NFSv4.1 se limita a vSphere 6.0 a 7.0.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">En el caso de entornos SAN, NetApp realiza una amplia prueba de componentes SAN. En general, NetApp admite servidores de montaje en rack X86-64 y servidores Cisco UCS estándar junto con adaptadores Ethernet estándar para conexiones iSCSI. Los entornos FC, FCoE y NVMe/FC tienen un soporte más definido en forma específica debido al firmware y los controladores de HBA necesarios.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">Compruebe siempre la<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> confirmar la compatibilidad con una configuración de hardware y software específica.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plugin NFS para VAAI de VMware</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">Este plugin para hosts ESXi ayuda a descargar las operaciones a ONTAP mediante VAAI. La versión más reciente, 1.1.2, incluye compatibilidad con almacenes de datos NFSv4.1, incluida la compatibilidad con Kerberos (krb5 y krb5i). Es compatible con ESXi 6.0, 6.5 y 7.0 junto con ONTAP 9.5-9.8.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">Proveedor de VASA</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">El proveedor VASA de NetApp admite el aprovisionamiento y la gestión de VVol (consulte la sección 3.7). En las versiones recientes de VASA Provider, se admiten ESXi 6.0, 6.5 y 7.0 junto con ONTAP 9.5-9.8.</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">Las herramientas de ONTAP para VMware vSphere son claves para gestionar el almacenamiento de ONTAP junto con vSphere (su uso es una mejor práctica). La última versión, 9.8, es compatible con vSphere 6.5 y 7.0 junto con ONTAP 9.5-9.8.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Con ONTAP, el concepto de las máquinas virtuales de almacenamiento (SVM) proporciona una segmentación estricta en entornos multi-tenant seguros.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Mejores prácticas de puesta en marcha</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Distribución y segmentación de SVM para SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Con ONTAP, el concepto de las máquinas virtuales de almacenamiento (SVM) proporciona una segmentación estricta en entornos multi-tenant seguros. Los usuarios de SVM en una SVM no pueden acceder a los recursos ni gestionarlos desde otra. De este modo, puede aprovechar la tecnología ONTAP creando SVM independientes para diferentes unidades de negocio que gestionan sus propios flujos de trabajo de SRM en el mismo clúster para mejorar la eficiencia general del almacenamiento.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Considere la posibilidad de gestionar ONTAP mediante cuentas de ámbito SVM y LIF de administración de SVM para no solo mejorar los controles de seguridad, sino también mejorar el rendimiento. El rendimiento es inherentemente mayor cuando se usan conexiones de ámbito SVM porque el SRA no es necesario para procesar todos los recursos de todo un clúster, incluidos los recursos físicos. En su lugar, solo debe comprender los activos lógicos que se abstraen a una SVM en particular.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Al usar solo protocolos NAS (sin acceso SAN), puede incluso aprovechar el nuevo modo NAS optimizado configurando el siguiente parámetro (tenga en cuenta que el nombre es tal, ya que SRA y VASA utilizan los mismos servicios de back-end en el dispositivo):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Inicie sesión en el panel de control en<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Y haga clic en interfaz CLI basada en Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Ejecute el comando<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Ejecute el comando<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Ejecute el comando<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementar herramientas de ONTAP y consideraciones para vVols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Si tiene pensado utilizar SRM con vVols, debe gestionar el almacenamiento utilizando las credenciales de ámbito del clúster y una LIF de gestión de clústeres. Esto se debe a que el proveedor de VASA debe comprender la arquitectura física subyacente para satisfacer las políticas requiere normativas de almacenamiento de VM. Por ejemplo, si tiene una política que requiere almacenamiento all-flash, el proveedor VASA debe poder ver qué sistemas son all-flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Otra práctica recomendada para la implementación es no almacenar nunca el dispositivo de herramientas ONTAP en un almacén de datos vVols que gestiona. Esto podría provocar una situación en la que no se puede encender el proveedor VASA porque no se puede crear el VVol de intercambio para el dispositivo porque el dispositivo está sin conexión.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Prácticas recomendadas para gestionar sistemas ONTAP 9</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">Como se ha mencionado anteriormente, puede gestionar clústeres de ONTAP utilizando credenciales de ámbito de clúster o de SVM y LIF de gestión. Para obtener un rendimiento óptimo, es posible que desee considerar el uso de credenciales con ámbito SVM siempre que no utilice vVols. Sin embargo, al hacerlo, debe conocer algunos requisitos y perder algunas funciones.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">La cuenta de SVM predeterminada de vsadmin no tiene el nivel de acceso requerido para realizar tareas de las herramientas de ONTAP. Por lo tanto, debe crear una nueva cuenta de SVM.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">Si utiliza ONTAP 9.8 o posterior, NetApp recomienda crear una cuenta de usuario con el control de acceso basado en roles menos privilegiado mediante el menú de usuarios de ONTAP System Manager junto con el archivo JSON disponible en el dispositivo de herramientas de ONTAP en<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Use la contraseña de administrador para descargar el archivo JSON. Puede utilizarse para cuentas de SVM o de ámbito de clúster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Toolchest del sitio de soporte de NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Si utiliza ONTAP 9.6 o una versión anterior, debe utilizar la herramienta RBAC User Creator (RUC) disponible en<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Debido a que el complemento de interfaz de usuario de vCenter, el proveedor VASA y el servidor SRA son servicios completamente integrados, debe añadir almacenamiento al adaptador del SRA del SRM de la misma forma que añada almacenamiento en la interfaz de usuario del para vCenter para las herramientas de ONTAP. De lo contrario, es posible que el servidor SRA no reconozca las solicitudes que se envían desde el SRM a través del adaptador SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">No se realiza la comprobación de la ruta de NFS cuando se utilizan las credenciales de ámbito de SVM. Esto se debe a que la ubicación física se abstrae de forma lógica de la SVM. Sin embargo, este no es un motivo de preocupación, ya que los sistemas ONTAP modernos ya no sufren una disminución notable del rendimiento cuando se utilizan rutas indirectas.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Es posible que no se informe del ahorro de espacio agregado debido a la eficiencia del almacenamiento.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Si es compatible, los duplicados de uso compartido de carga no se pueden actualizar.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Es posible que no se realicen registros de EMS en sistemas ONTAP gestionados con credenciales de ámbito de SVM.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos o sitios web.</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: VMware vSphere para ONTAP<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: VMware vSphere Virtual Volumes con ONTAP<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">TR-4015 Guía de mejores prácticas para la configuración de SnapMirror para ONTAP 9<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC User Creator para ONTAP<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">Herramientas de ONTAP para recursos de VMware vSphere<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">Documentación de VMware Site Recovery Manager<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">Consulte la<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> En el sitio de soporte de NetApp, con el fin de validar que las versiones exactas del producto y las funciones descritas en este documento son compatibles con su entorno concreto. La cabina IMT de NetApp define los componentes y las versiones del producto que pueden utilizarse para crear configuraciones que sean compatibles con NetApp. Los resultados específicos dependen de la instalación que realice cada cliente de acuerdo con las especificaciones publicadas.</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">En esta página, se proporcionan los pasos para poner en marcha un almacén de datos de ONTAP NFS versión 4 de NetApp en un entorno de VMware vSphere.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">Almacén de datos NFS de vSphere: Versión 4.1 con ONTAP</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">En esta sección se describe la creación de un almacén de datos de NFS versión 4.1 con almacenamiento NAS de ONTAP.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">Las habilidades básicas necesarias para gestionar un entorno de vSphere y ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">Sistema de almacenamiento ONTAP (FAS/AFF/CVO/ONTAP Select/Servicio de volumen de cloud/Azure NetApp Files) con {ontap_version}</block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">Información de los hosts de vSphere {vsphere_version}</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">Con los puertos de datos de red del sistema ONTAP, los hosts de vSphere y los están conectados</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">Herramientas de ONTAP para VMware vSphere puestas en marcha, configuradas y listas para usar</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Herramienta de matriz de interoperabilidad (IMT).</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">Compruebe la compatibilidad con<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">Complete las tareas de ONTAP y vSphere que se proporcionan a continuación.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">Comprobar la licencia de ONTAP para NFS</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">Úselos<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando para comprobar si NFS aparece en la lista.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">Siga el flujo de trabajo de configuración de NFS</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">Tareas de VMware vSphere</block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">Siga el flujo de trabajo de configuración del cliente de NFS para vSphere.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">Esta página proporciona los pasos para implementar un almacén de datos VMFS iSCSI en un entorno de VMware vSphere en un almacenamiento ONTAP de NetApp.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">Aprovisionamiento de almacenamiento en bloques vSphere tradicional con ONTAP</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere admite las siguientes opciones de almacenes de datos VMFS con la compatibilidad con el protocolo SAN de ONTAP indicada.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">Opciones de almacén de datos VMFS</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">Compatibilidad con el protocolo SAN de ONTAP</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel (FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">sí</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">Fibre Channel sobre Ethernet (FCoE)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">Extensiones iSCSI para RDMA (Iser)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">no</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe sobre estructura con FC (NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">NVMe over Fabric con RDMA sobre Ethernet convergente (NVMe/roce)</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">Si se requiere Iser o VMFS NVMe/roce, compruebe los sistemas de almacenamiento basados en SANtricity.</block>
  <block id="d3b0a496a8cf35e38aa2e2195dec2f94" category="doc">Plugin de SnapCenter de NetApp para VMware vSphere - flujo de trabajo de restauración</block>
  <block id="eee0a010c96cd5f8a48024b64979138a" category="inline-link-macro">Anterior: Información adicional - plugin de SnapCenter para VMware vSphere - flujo de trabajo de backup.</block>
  <block id="db5a03b9e1de0d20dc54468940b207eb" category="paragraph"><block ref="db5a03b9e1de0d20dc54468940b207eb" category="inline-link-macro-rx"></block></block>
  <block id="5f01983db70d04ee21145e7d21902fb2" category="inline-link-macro">Siguiente: Información adicional - plugin de SnapCenter para VMware vSphere - flujo de trabajo de restauración de SQL.</block>
  <block id="724a2f2542f99df4a44d9ad7cfb15363" category="paragraph"><block ref="724a2f2542f99df4a44d9ad7cfb15363" category="inline-link-macro-rx"></block></block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">Empiece a usar NetApp y VMware</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware en NetApp: ¡Su viaje empieza aquí!</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">Si está listo para comenzar a transformar el entorno de VMware, consulte la descripción general de la solución más reciente, consulte nuestras soluciones técnicas y demostraciones de productos más recientes. Si está listo para dar el siguiente paso, involucre a la comunidad de expertos de NetApp y VMware para ayudarle a planificar y ejecutar las iniciativas de modernización del centro de datos, cloud híbrido o aplicaciones en contenedores.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">Contacto</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">¿No está seguro de por dónde empezar? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> Miembro de los expertos de VMware de NetApp.</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">Formato PDF</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">El contenido presentado en esta página también está disponible para su descarga en <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp y VMware: Mejor juntos</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">link=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">Obtenga más información sobre las soluciones de NetApp y VMware</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp &amp;amp; VMware: Mejor juntos</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">Descripción general de las funciones más recientes de ONTAP 9.8 para VMware</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">Aprovechamiento del complemento de SnapCenter para VMware vSphere</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">La redefinición del rendimiento de VMware con NetApp y NVMe</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">Un mundo de bajo rendimiento para VMware Cloud en AWS</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">Presentación de VMware Tanzu con NetApp</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">Infraestructura de puestos de trabajo virtuales (VDI): Entrega de estaciones de trabajo de empleados bajo demanda</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">VMware en AWS: Opciones de arquitectura y servicio</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">Programación con las API Cloud Volumes Service de NetApp para optimizar la experiencia de AWS</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes: Ejecuta K8s en vSphere y Tanzu</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">Cree su propio Data Fabric virtualizado</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">Consulte nuestras últimas soluciones de NetApp para VMware</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">VMware vSphere with ONTAP : Soluciones de NetApp</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">VMware vSphere Virtual Volumes con ONTAP</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">Diseño de cargas de trabajo de VMware vSphere NVMe actuales de NetApp &amp;amp; validación</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">Solución Flash conectada al cloud nVMF de NetApp para VMware &amp;amp; SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">Acelere su transición a Kubernetes con VMware Tanzu &amp;amp; ONTAP</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">Reduzca el coste de ejecutar VMware Cloud en AWS</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">Explore demostraciones en vídeo de las últimas soluciones de VMware</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">Prácticas recomendadas para VMware vSphere y ONTAP de NetApp</block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">Su entorno VMware: Vamos a utilizarlo en NVMe-of con ONTAP</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">Recuperación ante desastres de vVols con herramientas de ONTAP y SRM de VMware</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">Backup y recuperación de VMware para Data Fabric</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">Implemente una infraestructura flexible de aplicaciones modernizadas y de cloud híbrido para VMware</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">Vídeos</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">Arquitectura de almacenes de datos de VMware en All Flash FAS de NetApp</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">Migre sus máquinas virtuales de VMware a Google Cloud</block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">Implementación de almacenamiento dinámico persistente de NetApp para VMware Tanzu, parte 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">Implementación de almacenamiento dinámico persistente de NetApp para VMware Tanzu, parte 2</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Implementación de almacenamiento dinámico persistente de NetApp para VMware Tanzu, parte 3</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">Blogs</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud en AWS: Cómo Fujitsu ahorra millones con CVO</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">Participe en los expertos de NetApp y VMware</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">Únase al foro de debate sobre soluciones de VMware</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">Póngase en contacto con el equipo de servicios globales de NetApp para comenzar</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Si es posible, utilice siempre herramientas ONTAP para aprovisionar almacenes de datos y volúmenes. De este modo se garantiza que los volúmenes, rutas de unión, LUN, iGroups, políticas de exportación, y otros ajustes se configuran de forma compatible.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Mejores prácticas operativas</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">El SRM admite iSCSI, Fibre Channel y NFS versión 3 con ONTAP 9 al usar la replicación basada en cabinas a través de SRA. SRM no admite la replicación basada en cabinas para NFS versión 4.1 con almacenes de datos tradicionales o vVols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Para confirmar la conectividad, siempre compruebe que puede montar y desmontar un almacén de datos de prueba nuevo en el sitio de recuperación ante desastres del clúster de ONTAP de destino. Pruebe cada protocolo que pretenda utilizar para la conectividad de almacenes de datos. Una práctica recomendada es usar las herramientas de ONTAP para crear su almacén de datos de prueba, ya que está haciendo toda la automatización del almacén de datos según las indicaciones del SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">Los protocolos SAN deben ser homogéneos para cada sitio. Puede mezclar NFS y SAN, pero los protocolos SAN no deben mezclarse dentro de un sitio. Por ejemplo, puede utilizar FCP en el sitio A y iSCSI en el sitio B. No debe usar FCP e iSCSI en el sitio A. El motivo es que el SRA no crea iGroups mixtos en el sitio de recuperación y el SRM no filtra la lista de iniciadores dada al SRA.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">Se recomienda utilizar guías anteriores para crear LIF a localidad de datos. Es decir, monte siempre un almacén de datos con una LIF ubicada en el nodo que posee físicamente el volumen. Esto ya no es un requisito en las versiones modernas de ONTAP 9. Siempre que sea posible y, si se dan las credenciales de ámbito del clúster, las herramientas de ONTAP seguirán eligiendo equilibrar la carga en las LIF locales de los datos, pero no es un requisito de alta disponibilidad o rendimiento.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">ONTAP 9 de NetApp se puede configurar para eliminar automáticamente copias snapshot con el fin de conservar el tiempo de actividad en caso de que no haya espacio disponible cuando la opción autosize no puede proporcionar suficiente capacidad de emergencia. El valor predeterminado de esta funcionalidad no elimina automáticamente las copias de Snapshot creadas por SnapMirror. Si se eliminan copias Snapshot de SnapMirror, el SRA de NetApp no puede revertir y resincronizar la replicación del volumen afectado. Para evitar que ONTAP elimine copias Snapshot de SnapMirror, configure la funcionalidad de eliminación automática de Snapshot que debe intentar.</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">el ajuste de tamaño automático de volumen debe estar establecido en<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Para volúmenes que contienen almacenes de datos SAN y<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Para almacenes de datos NFS. Consulte la<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> para una sintaxis específica.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM y vVols</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">A partir de SRM 8.3, se admite la protección de equipos virtuales con almacenes de datos vVols. Las programaciones de SnapMirror se exponen a políticas de almacenamiento de máquinas virtuales por parte del proveedor VASA cuando la replicación de vVols está habilitada en el menú de configuración de herramientas de ONTAP, como se muestra en las siguientes capturas de pantalla.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">En el siguiente ejemplo se muestra la habilitación de la replicación de vVols.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La siguiente captura de pantalla proporciona un ejemplo de las programaciones de SnapMirror que se muestran en el asistente Create VM Storage Policy.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">El proveedor de VASA de ONTAP admite la conmutación por error a un almacenamiento diferente. Por ejemplo, el sistema puede conmutar al respaldo de ONTAP Select en una ubicación perimetral a un sistema AFF en el centro de datos principal. Independientemente de la similitud de almacenamiento, siempre debe configurar las asignaciones de políticas de almacenamiento y las asignaciones inversa de las políticas de almacenamiento de máquinas virtuales habilitadas para la replicación para garantizar que los servicios proporcionados en el sitio de recuperación cumplan las expectativas y los requisitos. La siguiente captura de pantalla resalta una asignación de directivas de ejemplo.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Cree volúmenes replicados para almacenes de datos vVols</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">A diferencia de los almacenes de datos vVols anteriores, los almacenes de datos vVols replicados deben crearse desde el principio con la replicación habilitada, y deben utilizar volúmenes que se han creado previamente en los sistemas ONTAP con relaciones de SnapMirror. Esto requiere configurar previamente elementos como cluster peering y SVM peering. Estas actividades las debe realizar el administrador de ONTAP, ya que esto facilita una separación estricta de responsabilidades entre quienes gestionan los sistemas de ONTAP en varios sitios y los principales responsables de las operaciones de vSphere.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">Esto viene con un nuevo requisito en nombre del administrador de vSphere. Dado que los volúmenes se crean fuera del ámbito de las herramientas de ONTAP, no conoce los cambios que ha realizado el administrador de ONTAP hasta el periodo de repetición de la detección programado periódicamente. Por este motivo, se recomienda ejecutar la redetección siempre que se cree una relación de volúmenes o SnapMirror que se utilice con vVols. Simplemente haga clic con el botón derecho en el host o clúster y seleccione ONTAP Tools de NetApp &gt; Update Host and Storage Data, tal y como se muestra en la siguiente captura de pantalla.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Hay que tener cuidado cuando se trata de vVols y SRM. No mezcle nunca máquinas virtuales protegidas y sin protección en el mismo almacén de datos vVols. La razón es que, cuando utiliza SRM para conmutar por error a su sitio de recuperación ante desastres, solo se conecta a las máquinas virtuales que forman parte del grupo de protección en caso de desastre. Por lo tanto, cuando se vuelve a proteger (SnapMirror de recuperación ante desastres se vuelve a proteger a producción), es posible que sobrescriba los equipos virtuales que no se dieron el error y contengan datos valiosos.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Acerca de parejas de cabinas</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">Se crea un gestor de cabinas para cada pareja de cabinas. Con las herramientas SRM y ONTAP, el emparejamiento de cabinas se realiza con el ámbito de una SVM, incluso si utiliza credenciales de clúster. Esto le permite segmentar los flujos de trabajo de recuperación ante desastres entre inquilinos en función de los cuales se hayan asignado a gestionar las SVM. Es posible crear varios administradores de cabinas para un clúster determinado y tienen una naturaleza asimétrica. Es posible fan out o fan in entre diferentes clústeres de ONTAP 9. Por ejemplo, puede tener SVM-A y SVM-B en el clúster-1 que replica en SVM-C en el clúster-2, SVM-D en el clúster-3 o viceversa.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Al configurar parejas de cabinas en SRM, siempre debe añadirlas a SRM de la misma forma que las añadió a las herramientas de ONTAP, lo que significa que deben usar el mismo nombre de usuario, contraseña y LIF de gestión. Este requisito garantiza que el SRA se comunique correctamente con la matriz. La siguiente captura de pantalla ilustra cómo puede aparecer un clúster en las herramientas de ONTAP y cómo se puede añadir a un administrador de cabinas.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Acerca de los grupos de replicación</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Los grupos de replicación contienen colecciones lógicas de máquinas virtuales que se recuperan juntas. Las herramientas de ONTAP VASA Provider crean automáticamente grupos de replicación por usted. Dado que la replicación de SnapMirror de ONTAP se produce en el nivel de volumen, todas las máquinas virtuales de un volumen se encuentran en el mismo grupo de replicación.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">La consideración de los grupos de replicación es diversa y cómo se distribuyen los equipos virtuales entre los volúmenes de FlexVol. La agrupación de máquinas virtuales similares en el mismo volumen puede aumentar la eficiencia de almacenamiento con sistemas ONTAP antiguos que carecen de deduplicación en el nivel de agregados, pero la agrupación aumenta el tamaño del volumen y reduce la concurrencia de I/o del volumen. El mejor equilibrio entre rendimiento y eficiencia del almacenamiento puede lograrse en sistemas ONTAP modernos distribuyendo las máquinas virtuales entre volúmenes de FlexVol en el mismo agregado, aprovechando la deduplicación a nivel de agregado y aumentando la paralelización de I/o entre varios volúmenes. Puede recuperar las máquinas virtuales en los volúmenes juntos porque un grupo de protección (tratado a continuación) puede contener varios grupos de replicación. El inconveniente de esta distribución es que los bloques se pueden transmitir por la red varias veces, ya que SnapMirror para volúmenes no tiene en cuenta la deduplicación agregada.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Un aspecto final que se debe tener en cuenta para los grupos de replicación es que cada uno de ellos es, por su naturaleza, un grupo de consistencia lógico (que no se debe confundir con los grupos de consistencia SRM). Esto se debe a que todas las máquinas virtuales del volumen se transfieren juntas con la misma copia de Snapshot. Si tiene equipos virtuales que deben ser coherentes entre sí, considere almacenarlos en el mismo FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">Acerca de los grupos de protección</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Los grupos de protección definen las máquinas virtuales y los almacenes de datos en grupos que se recuperan conjuntamente del sitio protegido. El sitio protegido es donde existen las máquinas virtuales configuradas en un grupo de protección durante las operaciones normales de estado constante. Es importante tener en cuenta que, aunque SRM puede mostrar varios administradores de cabinas para un grupo de protección, un grupo de protección no puede abarcar varios administradores de cabinas. Por este motivo, no debe abarcar los archivos de equipos virtuales entre almacenes de datos en diferentes SVM.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Acerca de los planes de recuperación</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Los planes de recuperación definen qué grupos de protección se recuperan en el mismo proceso. Se pueden configurar varios grupos de protección en el mismo plan de recuperación. Además, para ofrecer más opciones para la ejecución de planes de recuperación, se puede incluir un solo grupo de protección en varios planes de recuperación.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Los planes de recuperación permiten a los administradores de SRM definir flujos de trabajo de recuperación asignando las máquinas virtuales a un grupo de prioridad de 1 (más alta) a 5 (más baja), siendo 3 (medio) el valor predeterminado. Dentro de un grupo de prioridad, las máquinas virtuales pueden configurarse para las dependencias.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">Por ejemplo, su empresa puede tener una aplicación esencial de nivel 1 que depende de un servidor Microsoft SQL para su base de datos. Por lo tanto, se deciden colocar las máquinas virtuales en el grupo de prioridad 1. Dentro del grupo de prioridad 1, comienza a planificar el pedido para que se traigan los servicios. Probablemente desee que su controlador de dominio de Microsoft Windows se inicie antes de su servidor Microsoft SQL, que tendría que estar en línea antes de su servidor de aplicaciones, etc. Es posible añadir todas estas máquinas virtuales al grupo de prioridad y, luego, configurar las dependencias, ya que solo se aplican las dependencias dentro de un grupo de prioridad dado.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp recomienda encarecidamente trabajar con sus equipos de aplicaciones para comprender el orden de las operaciones necesarias en un escenario de conmutación por error y construir sus planes de recuperación según corresponda.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Probar la recuperación tras fallos</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">Como práctica recomendada, realice siempre una conmutación al nodo de respaldo de prueba cuando se realice un cambio en la configuración de un almacenamiento de equipo virtual protegido. Esto garantiza que, en caso de desastre, pueda confiar en que Site Recovery Manager pueda restaurar los servicios dentro del objetivo de tiempo de recuperación previsto.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp también recomienda confirmar la funcionalidad de aplicaciones «en invitado» ocasionalmente, especialmente tras reconfigurar el almacenamiento de máquinas virtuales.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Cuando se realiza una operación de recuperación de pruebas, se crea una red privada de burbuja de pruebas en el host ESXi para los equipos virtuales. Sin embargo, esta red no está conectada automáticamente a ningún adaptador de red físico y, por lo tanto, no proporciona conectividad entre los hosts ESXi. Para permitir la comunicación entre máquinas virtuales que se ejecutan en diferentes hosts ESXi durante las pruebas de recuperación ante desastres, se crea una red privada física entre los hosts ESXi en el sitio de recuperación ante desastres. Para verificar que la red de prueba es privada, la red de burbuja de prueba se puede separar físicamente o mediante VLAN o etiquetado VLAN. Esta red debe separarse de la red de producción porque, a medida que se recuperan los equipos virtuales, no se pueden colocar en la red de producción con direcciones IP que puedan entrar en conflicto con los sistemas de producción reales. Cuando se crea un plan de recuperación en SRM, es posible seleccionar la red de pruebas creada como la red privada para conectar los equipos virtuales a durante la prueba.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Una vez que la prueba se ha validado y ya no es necesaria, realice una operación de limpieza. La ejecución de la limpieza devuelve las máquinas virtuales protegidas a su estado inicial y restablece el plan de recuperación al estado Ready.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Consideraciones sobre la conmutación por error</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Hay otros factores que se deben tener en cuenta a la hora de conmutar por error un sitio además del orden de las operaciones mencionado en esta guía.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Un problema que puede tener que lidiar es las diferencias de redes entre sitios. Es posible que algunos entornos puedan usar las mismas direcciones IP de red en el sitio primario y en el sitio de recuperación tras desastres. Esta capacidad se conoce como una configuración de red LAN virtual (VLAN) ampliada o extendida. Es posible que otros entornos tengan que utilizar diferentes direcciones IP de red (por ejemplo, diferentes VLAN) en el sitio principal con respecto al sitio de recuperación ante desastres.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware ofrece varias formas de resolver este problema. En primer lugar, las tecnologías de virtualización de redes como el centro de datos NSX-T de VMware abstraen toda la pila de redes de las capas 2 a 7 del entorno operativo, permitiendo soluciones más portátiles. Puede obtener más información acerca de las opciones de NSX-T con SRM<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM también le permite cambiar la configuración de red de un equipo virtual mientras se recupera. Esta reconfiguración incluye la configuración como direcciones IP, dirección de puerta de enlace y configuración del servidor DNS. Se pueden especificar diferentes configuraciones de red, que se aplican a las VM individuales a medida que se recuperan, en la configuración de la propiedad de una VM en el plan de recuperación.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">Para configurar SRM de modo que aplique diferentes ajustes de red a varios equipos virtuales sin tener que editar las propiedades de cada uno del plan de recuperación, VMware ofrece una herramienta llamada DR-ip-customizer. Para obtener información sobre cómo utilizar esta utilidad, consulte la documentación de VMware<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Vuelva a proteger</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Después de una recuperación, el sitio de recuperación se convierte en el nuevo sitio de producción. Dado que la operación de recuperación rompió la replicación de SnapMirror, el nuevo sitio de producción no está protegido contra ningún desastre futuro. Una mejor práctica es proteger el nuevo site de producción en otro site inmediatamente después de una recuperación. Si el sitio de producción original está operativo, el administrador de VMware puede utilizar el sitio de producción original como un nuevo sitio de recuperación para proteger el nuevo sitio de producción, invirtiendo efectivamente la dirección de la protección. La reprotección solo está disponible en fallos no catastróficos. Por lo tanto, en algún momento deben recuperarse los servidores vCenter Server, los servidores ESXi, los servidores SRM y las bases de datos correspondientes originales. Si no están disponibles, deben crearse un nuevo grupo de protección y un nuevo plan de recuperación.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Conmutación tras recuperación</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Una operación de conmutación tras recuperación es fundamentalmente una conmutación por error en una dirección diferente a la anterior. Como práctica recomendada, compruebe que el sitio original vuelve a los niveles aceptables de funcionalidad antes de intentar realizar la conmutación tras recuperación o, en otras palabras, la conmutación por error al sitio original. Si la instalación original sigue en peligro, deberá retrasar la conmutación tras recuperación hasta que se solucione el fallo lo suficiente.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Otra práctica recomendada para la conmutación tras recuperación es siempre realizar una conmutación al nodo de respaldo de prueba después de completar la reprotección y antes de llevar a cabo la conmutación tras recuperación final. Esto verifica que los sistemas en el sitio original pueden completar la operación.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Volver a proteger el sitio original</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">Después de la conmutación por recuperación, debe confirmar con todos los titulares de las apuestas que sus servicios se han devuelto a la normalidad antes de volver a ejecutar la reprotección,</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">La ejecución de la reprotección después de la conmutación tras recuperación hace que el entorno vuelva a estar en el estado que estaba al principio, cuando la replicación de SnapMirror se ejecuta de nuevo desde el centro de producción al centro de recuperación.</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">Esta página describe las funciones del cloud híbrido disponibles para ONTAP y VMware vSphere.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">Cloud híbrido con ONTAP y vSphere</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">Acerca del cloud híbrido</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">Tanto si se utiliza para un cloud privado en las instalaciones, una infraestructura de cloud público o un cloud híbrido que combine lo mejor de ambos, las soluciones de ONTAP le ayudan a crear su tejido de datos para optimizar y optimizar la gestión de datos. Empiece por sistemas all-flash de alto rendimiento y, a continuación, apítelos con sistemas de disco o de almacenamiento en cloud para protección de datos y computación en cloud.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Elija entre clouds de Azure, AWS, IBM o Google para optimizar costes y evitar la restricción. Aproveche el soporte avanzado para OpenStack y las tecnologías de contenedor según sea necesario.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">La protección de datos es lo primero que los clientes intentan hacer cuando comienzan su transición al cloud. La protección puede ser tan sencilla como la replicación asíncrona de datos clave o tan compleja como un sitio de backup en caliente completo. La protección de datos se basa principalmente en la tecnología SnapMirror de NetApp.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">Algunos clientes deciden mover cargas de trabajo completas al cloud. Esto puede ser más complicado que simplemente usar el cloud para la protección de datos, pero ONTAP facilita el movimiento, ya que no tiene que reescribir las aplicaciones para que usen el almacenamiento basado en cloud. ONTAP en el cloud funciona igual que ONTAP en las instalaciones. Su sistema ONTAP en las instalaciones ofrece funciones de eficiencia de datos que le permiten almacenar más datos en menos espacio físico y colocar por niveles los datos usados en raras ocasiones en un almacenamiento de menor coste. Tanto si usa una configuración de cloud híbrido como si mueve toda una carga de trabajo al cloud, ONTAP maximiza el rendimiento y la eficiencia del almacenamiento.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">NetApp también ofrece backup basado en cloud (SnapMirror Cloud, Cloud Backup Service y Cloud Sync) y herramientas de organización en niveles del almacenamiento y archivado (FabricPool) para ONTAP para ayudar a reducir los gastos operativos y aprovechar el amplio alcance del cloud.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">La siguiente figura proporciona un ejemplo de caso de uso de cloud híbrido.</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP y el cloud</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">Para obtener más información sobre los clouds híbridos y ONTAP, consulte<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> En el centro de documentación de ONTAP 9.</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP admite los principales protocolos de almacenamiento utilizados para la virtualización, como iSCSI, Fibre Channel (FC), Fibre Channel sobre Ethernet (FCoE) o memoria no volátil exprés sobre Fibre Channel (NVMe/FC) para entornos SAN, así como NFS (v3 y v4.1) y SMB o S3 para conexiones «guest». Los clientes pueden elegir qué funciona mejor para su entorno y pueden combinar los protocolos que necesiten en un único sistema.</block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">Funcionalidades de ONTAP para vSphere</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">Protocolos</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP admite los principales protocolos de almacenamiento utilizados para la virtualización, como iSCSI, Fibre Channel (FC), Fibre Channel sobre Ethernet (FCoE) o memoria no volátil exprés sobre Fibre Channel (NVMe/FC) para entornos SAN, así como NFS (v3 y v4.1) y SMB o S3 para conexiones «guest». Los clientes pueden elegir qué funciona mejor para su entorno y pueden combinar los protocolos que necesiten en un único sistema. Por ejemplo, se puede aumentar el uso general de almacenes de datos NFS con unos pocos LUN iSCSI o recursos compartidos «guest».</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">Existen muchas funciones de ONTAP que son útiles para gestionar las cargas de trabajo virtualizadas. En la siguiente sección se describen algunos de los que requieren licencias de producto adicionales. A continuación, se describen otros paquetes como herramientas independientes, algunos para ONTAP y otros para toda la cartera de NetApp.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">A continuación encontrará más información sobre funciones básicas de ONTAP:</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">*Copias Snapshot de NetApp.* ONTAP ofrece copias Snapshot instantáneas de un equipo virtual o un almacén de datos sin efectos sobre el rendimiento al crear o utilizar una copia Snapshot. Pueden utilizarse para crear un punto de restauración para un equipo virtual antes de aplicar revisiones o para una protección de datos sencilla. Tenga en cuenta que estas copias son diferentes de las copias Snapshot de VMware (consistencia). La forma más sencilla de realizar una copia Snapshot de ONTAP es usar el plugin de SnapCenter para VMware vSphere para realizar backup de máquinas virtuales y almacenes de datos.</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">*Eficacia del almacenamiento.* ONTAP admite deduplicación y compresión en línea y en segundo plano, deduplicación de bloque cero y compactación de datos.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">*Movimiento de volúmenes y LUN.* permite el movimiento sin interrupciones de volúmenes y LUN compatibles con almacenes de datos vSphere y vVols dentro del clúster ONTAP para equilibrar el rendimiento y la capacidad o para ofrecer mantenimiento y actualizaciones sin interrupciones.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">*QoS.* QoS permite administrar el rendimiento en una LUN, volumen o archivo individuales. Esta función puede utilizarse para limitar un equipo virtual desconocido o intimidato para asegurarse de que un equipo virtual importante dispone de suficientes recursos de rendimiento.</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">*Cifrado de volúmenes de NetApp y cifrado de agregados de NetApp* las opciones de cifrado de NetApp ofrecen un sencillo cifrado basado en software para proteger los datos en reposo.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">*FabricPool.* esta función organiza automáticamente en niveles los datos más inactivos a nivel de bloque en un almacén de objetos independiente, liberando así un costoso almacenamiento flash.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">API de REST de ONTAP</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Módulos de Ansible</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">* RESTO y Ansible.* uso<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> para automatizar la gestión del almacenamiento y los datos, y.<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> Para gestionar la configuración de los sistemas ONTAP.</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">Tenga en cuenta que algunas funciones de ONTAP no son adecuadas para cargas de trabajo vSphere. Por ejemplo, la tecnología FlexGroup anterior a ONTAP 9.8 no contaba con asistencia completa para clonado y no se probó con vSphere (consulte la sección FlexGroup para obtener la información más reciente sobre su uso con vSphere). La tecnología FlexCache tampoco es óptima para vSphere, ya que está diseñada para las cargas de trabajo de lectura mayoría. Las escrituras pueden ser problemáticas cuando la caché se desconecta del origen, lo que provoca errores en el almacén de datos NFS en ambos lados.</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">Licencias de ONTAP</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">Algunas funciones de ONTAP que son valiosas para gestionar cargas de trabajo virtualizadas requieren una licencia adicional, ya sea disponible sin coste adicional, en un paquete de licencias o a la carta. Para muchos clientes, el método más rentable es utilizar un paquete de licencia. A continuación se muestran las licencias clave de vSphere y cómo se utilizan:</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">*FlexClone.* FlexClone permite clonar al instante volúmenes y archivos ONTAP con un uso eficiente del espacio. Este clonado se utiliza cuando se descargan las operaciones en el sistema de almacenamiento mediante las API de almacenamiento VMware vSphere – integración de cabina (VAAI), para la verificación y recuperación de backups (software SnapCenter), y para el clonado de vVols y copias Snapshot. Así es como se usan:</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI es compatible con ONTAP para realizar copias descargados en función de las operaciones de clonado y migración de vSphere (Storage vMotion). La licencia de FlexClone permite clones rápidos dentro de un volumen FlexVol de NetApp, pero, si no tiene licencia, sigue permitiendo los clones mediante copias de bloques más lentas.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">Se requiere una licencia de FlexClone para la funcionalidad vVols. Permite el clonado de vVols en un único almacén de datos o entre almacenes de datos, y permite realizar copias de vVols, gestionadas por vSphere, que se descargan en el sistema de almacenamiento.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">El adaptador de replicación de almacenamiento (SRA) se usa con el administrador de recuperación de sitio de VMware y se necesita una licencia de FlexClone para probar la recuperación tanto en entornos NAS COMO SAN. Los SRA se pueden usar sin FlexClone para los flujos de trabajo de detección, recuperación y protección adicional.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">*SnapRestore.* la tecnología SnapRestore permite la recuperación instantánea de un volumen en su lugar sin copiar datos. Es necesario gracias a las herramientas de backup y recuperación de NetApp, como SnapCenter, donde se utiliza para montar el almacén de datos con fines de verificación y restauración.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">*SnapMirror* la tecnología SnapMirror permite una replicación sencilla y rápida de datos entre sistemas ONTAP en las instalaciones y en el cloud. SnapMirror admite la flexibilidad de versión de la replicación lógica con el rendimiento de la replicación de bloques, enviando solo los datos modificados al sistema secundario. Los datos pueden protegerse con políticas de mirroring y/o almacén, lo que permite la recuperación ante desastres y la retención de datos a largo plazo para backup. SnapMirror admite relaciones tanto asíncronas como síncronas, y ONTAP 9.8 incorpora una conmutación transparente de las aplicaciones con la continuidad empresarial de SnapMirror.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">Se requiere SnapMirror para la replicación de SRA con Site Recovery Manager. También es necesario que SnapCenter permita la replicación de copias de Snapshot en un sistema de almacenamiento secundario.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">*El software SnapCenter.* SnapCenter ofrece una plataforma unificada y escalable y un conjunto de complementos para la protección de datos y la gestión de clones coherentes con las aplicaciones. Se incluye una licencia de SnapCenter con los paquetes de licencia de protección de datos para sistemas AFF y FAS. El plugin de SnapCenter para VMware vSphere es un producto gratuito si utiliza los siguientes sistemas de almacenamiento: FAS, AFF, Cloud Volumes ONTAP o ONTAP Select. Sin embargo, se necesitan licencias de SnapRestore y FlexClone.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">*MetroCluster.* NetApp MetroCluster es una solución de replicación síncrona que combina alta disponibilidad y recuperación ante desastres en recintos universitarios o áreas metropolitanas para obtener protección frente a desastres en el sitio y fallos de hardware. Proporciona soluciones con recuperación transparente tras fallos, sin pérdida de datos (RPO 0) y recuperación rápida (RTO en minutos). Se utiliza en entornos vSphere como parte de una configuración de vSphere Metro Storage Cluster.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">Herramientas de virtualización para ONTAP</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp ofrece varias herramientas de software independientes que se pueden utilizar junto con ONTAP y vSphere para gestionar su entorno virtualizado. Las siguientes herramientas se incluyen con la licencia de ONTAP sin coste adicional. Consulte la figura 1 para obtener una descripción de cómo funcionan estas herramientas juntas en su entorno vSphere.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Las herramientas de ONTAP para VMware vSphere son un conjunto de herramientas para usar el almacenamiento de ONTAP junto con vSphere. El complemento de vCenter, anteriormente conocido como Virtual Storage Console (VSC), simplifica las funciones de gestión y eficiencia del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, tanto si usa SAN como NAS. Utiliza prácticas recomendadas para aprovisionar almacenes de datos y optimiza la configuración de host ESXi para entornos de almacenamiento en bloques y NFS. Para todas estas ventajas, NetApp recomienda usar estas herramientas de ONTAP como práctica recomendada cuando se usa vSphere con sistemas que ejecutan el software ONTAP. Incluye un dispositivo de servidor, extensiones de interfaz de usuario para vCenter, proveedor VASA y Storage Replication Adapter. Casi todo lo que incluye las herramientas de ONTAP se puede automatizar mediante API de REST sencillas, consumibles gracias a las herramientas de automatización más modernas.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*Extensiones de la interfaz de usuario de vCenter.* las extensiones de la interfaz de usuario de las herramientas de ONTAP simplifican el trabajo de los equipos de operaciones y los administradores de vCenter al incorporar menús contextuales fáciles de usar para gestionar hosts y almacenamiento, portlets informativos y capacidades de alerta nativas directamente en la interfaz de usuario de vCenter para optimizar los flujos de trabajo.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*Proveedor VASA para ONTAP.* el Proveedor VASA para ONTAP es compatible con el marco de trabajo VMware vStorage APIs for Storage Awareness (VASA). Se suministra como parte de las herramientas de ONTAP para VMware vSphere como un dispositivo virtual único para facilitar la puesta en marcha. EL proveedor DE VASA conecta vCenter Server con ONTAP para ayudar en el aprovisionamiento y la supervisión del almacenamiento de máquinas virtuales. Permite el soporte de VMware Virtual Volumes (vVols), la gestión de los perfiles de las funcionalidades del almacenamiento y el rendimiento vVols individual, y las alarmas para supervisar la capacidad y el cumplimiento de los perfiles.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* el SRA se utiliza junto con VMware Site Recovery Manager (SRM) para gestionar la replicación de datos entre sitios de producción y de recuperación ante desastres y probar las réplicas de recuperación ante desastres de forma no disruptiva. Ayuda a automatizar las tareas de identificación, recuperación y protección. Incluye tanto un dispositivo de servidor SRA como adaptadores SRA para el servidor SRM de Windows y el dispositivo SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figura siguiente muestra las herramientas de ONTAP para vSphere.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">El plugin de NetApp NFS para VMware VAAI es un plugin para hosts ESXi que permite usar funciones VAAI con almacenes de datos NFS en ONTAP. Admite la descarga de copias para operaciones de clonado, la reserva de espacio para archivos gruesos de discos virtuales y la descarga de copias de Snapshot. La descarga de operaciones de copia en el almacenamiento no es necesariamente más rápida de completarse, pero reduce los requisitos de ancho de banda de red y libera a recursos del host, como ciclos de CPU, búferes y colas. Puede usar las herramientas de ONTAP para VMware vSphere para instalar el plugin en hosts ESXi o, si es compatible, vSphere Lifecycle Manager (VLCM).</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">Esta página proporciona compatibilidad con el almacén de datos NFS en un entorno de VMware vSphere.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">Aprovisionamiento de almacenamiento de archivos tradicional de vSphere con ONTAP</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere admite los siguientes protocolos NFS, los cuales son compatibles con ONTAP.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS Versión 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS Versión 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">Esta comparativa de las versiones del cliente NFS</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">Si necesita ayuda para seleccionar la versión de NFS correcta para vSphere, compruebe <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp ofrece muchas mejores prácticas y soluciones para obtener un entorno de virtualización sólido, tanto en las instalaciones como en el cloud.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">Soluciones de NetApp para la virtualización</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">El flujo de trabajo del SRM es significativamente diferente al usar la replicación de vVols a partir de lo que se usa con el SRA y los almacenes de datos tradicionales.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Solución de problemas de SRM al utilizar la replicación de vVols</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">El flujo de trabajo del SRM es significativamente diferente al usar la replicación de vVols a partir de lo que se usa con el SRA y los almacenes de datos tradicionales. Por ejemplo, no hay ningún concepto de administrador de cabinas. Como tal,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> y..<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> los comandos nunca se ven.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Para la solución de problemas, resulta beneficioso comprender los nuevos flujos de trabajo, que se enumeran a continuación:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Descubre los acuerdos de replicación entre dos dominios de fallo.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Detecta la jerarquía de dominios de fallo.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Detecta los grupos de replicación presentes en los dominios de origen o destino.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Sincroniza los datos entre el origen y el destino.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Detecta las réplicas de punto en tiempo en un destino.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Inicia la conmutación por error de prueba.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Finaliza la conmutación por error de prueba.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Promueve un grupo actualmente en pruebas a la producción.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PapreFailoverReplicationGroup: Prepara para una recuperación ante desastres.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup: Ejecuta la recuperación ante desastres.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Inicia la replicación inversa.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Busca contenedores (junto con hosts o grupos de replicación) que puedan satisfacer una solicitud de aprovisionamiento con una directiva determinada.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata: Descubre los metadatos de todos los recursos del proveedor VASA, la utilización de recursos puede devolverse como respuesta a la función queryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">El error más común que se produce al configurar la replicación de vVols es no descubrir las relaciones de SnapMirror. Esto ocurre porque los volúmenes y las relaciones de SnapMirror se crean fuera del alcance de las herramientas de ONTAP. Por lo tanto, una práctica recomendada es asegurarse de que su relación con SnapMirror esté completamente inicializada y de que ha ejecutado una nueva detección en las herramientas de ONTAP en ambos sitios antes de intentar crear un almacén de datos vVols replicado.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">En ONTAP 9, los componentes físicos de un clúster son visibles para los administradores del clúster, pero no pueden ver directamente las aplicaciones y los hosts que utilizan el clúster.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologías de replicación</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">En ONTAP 9, los componentes físicos de un clúster son visibles para los administradores del clúster, pero no pueden ver directamente las aplicaciones y los hosts que utilizan el clúster. Los componentes físicos proporcionan un conjunto de recursos compartidos desde los cuales se construyen los recursos del clúster lógicos. Las aplicaciones y los hosts solo acceden a los datos a través de SVM que contienen volúmenes y LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Cada SVM de NetApp se trata como una cabina en VMware vCenter Site Recovery Manager. SRM admite ciertas distribuciones de replicación de cabina a cabina (o SVM a SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Una sola máquina virtual no puede poseer datos, Virtual Machine Disk (VMDK) o RDM, en más de una cabina de SRM por los siguientes motivos:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM solo ve la SVM, no una controladora física individual.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Una SVM puede controlar los LUN y los volúmenes que abarcan varios nodos en un clúster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Mejor práctica</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Para determinar la compatibilidad, tenga presente esta regla: Para proteger una máquina virtual con el SRM y el SRA de NetApp, todas las partes de la máquina virtual deben existir en un solo SVM. Esta regla se aplica tanto al sitio protegido como al sitio de recuperación.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Distribuciones de SnapMirror compatibles</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Las siguientes figuras muestran los escenarios de diseño de la relación de SnapMirror compatibles con SRM y SRA. Cada equipo virtual de los volúmenes replicados posee datos en una sola cabina de SRM (SVM) en cada sitio.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Diseños compatibles de Array Manager</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Cuando se utiliza la replicación basada en cabinas (ABR) en SRM, los grupos de protección se aíslan en un solo par de cabina, como se muestra en la siguiente captura de pantalla. En este escenario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> y..<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> están entre iguales<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> y..<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> en el centro de recuperación. Sin embargo, es posible seleccionar solo una de las dos parejas de cabinas al crear un grupo de protección.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Diseños no admitidos</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Las configuraciones no compatibles tienen datos (VMDK o RDM) en varias SVM que son propiedad de una máquina virtual individual. En los ejemplos que se muestran en las siguientes figuras,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> No se puede configurar para protección con SRM debido a<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Tiene datos en dos SVM.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Toda relación de replicación en la que se replica un volumen individual de NetApp desde una SVM de origen a varios destinos en la misma SVM o en distintas SVM se denomina «fan-out» de SnapMirror. SRM no es compatible con fan-out. En el ejemplo que se muestra en la siguiente figura:<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> No se puede configurar para proteger en SRM porque se replica con SnapMirror en dos ubicaciones diferentes.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">Cascada de SnapMirror</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM no admite la configuración en cascada de relaciones de SnapMirror, en las que un volumen de origen se replica en un volumen de destino, y ese volumen de destino también se replica con SnapMirror en otro volumen de destino. En el caso que se muestra en la siguiente figura, SRM no se puede utilizar para la conmutación por error entre sitios.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror y SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">El software SnapVault de NetApp permite el backup a disco de datos empresariales entre sistemas de almacenamiento de NetApp. SnapVault y SnapMirror pueden coexistir en el mismo entorno. Sin embargo, SRM admite la conmutación por error únicamente de las relaciones de SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">El SRA de NetApp admite el<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> tipo de política.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault fue reconstruido desde sus cimientos para ONTAP 8.2. Aunque los antiguos usuarios de Data ONTAP 7-Mode deberían encontrar similitudes, se han mejoras importantes en esta versión de SnapVault. Un avance importante es la capacidad de preservar las eficiencias del almacenamiento en los datos primarios durante las transferencias de SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Un cambio de arquitectura importante es que SnapVault en ONTAP 9 se replica a nivel de volumen, frente a en el nivel de qtree, como es el caso de SnapVault en 7-Mode. Esta configuración significa que el origen de una relación de SnapVault debe ser un volumen y dicho volumen debe replicar en su propio volumen en el sistema secundario SnapVault.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">En un entorno en el que se utiliza SnapVault, se crean copias Snapshot específicamente denominadas en el sistema de almacenamiento principal. En función de la configuración implementada, las copias Snapshot etiquetadas pueden crearse en el sistema principal mediante una programación de SnapVault o una aplicación como Active IQ Unified Manager de NetApp. A continuación, las copias Snapshot denominadas que se crean en el sistema principal se replican en el destino de SnapMirror, y, desde allí, se crean en copias vault en el destino de SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Un volumen de origen se puede crear en una configuración en cascada en la que se replica un volumen a un destino de SnapMirror en el centro de recuperación ante desastres; a partir de ese punto, se realiza la copia en un destino de SnapVault. Un volumen de origen también puede crearse en una relación de dispersión en la que un destino es un destino de SnapMirror y el otro destino es un destino de SnapVault. Sin embargo, el SRA no reconfigura automáticamente la relación de SnapVault para usar el volumen de destino de SnapMirror como origen del almacén cuando se produce la conmutación por error del SRM o la reversión de la replicación.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 Guía de mejores prácticas para la configuración de SnapMirror para ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Para obtener la información más reciente sobre SnapMirror y SnapVault para ONTAP 9, consulte<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Si se emplean SnapVault y SRM en el mismo entorno, NetApp recomienda utilizar una configuración en cascada de SnapMirror a SnapVault en la que los backups de SnapVault se realizan normalmente desde el destino de SnapMirror en el centro de recuperación ante desastres. En caso de desastre, esta configuración hace que el sitio primario sea inaccesible. Si se mantiene el destino de SnapVault en el centro de recuperación, los backups de SnapVault se pueden volver a configurar tras la conmutación por error para que los backups de SnapVault puedan continuar mientras estén en el centro de recuperación.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">En un entorno VMware, cada almacén de datos tiene un identificador único universal (UUID) y cada máquina virtual tiene un ID de objeto gestionado único (MOID). SRM no mantiene estos ID durante la conmutación por error o la conmutación tras recuperación. Dado que los UUID de almacenes de datos y los MOIDs de máquinas virtuales no se mantienen durante la conmutación por error por parte de SRM, cualquier aplicación que dependa de estos identificadores se debe volver a configurar tras la conmutación por error de SRM. Una aplicación de ejemplo es Active IQ Unified Manager de NetApp, que coordina la replicación de SnapVault con el entorno vSphere.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La siguiente figura muestra la configuración en cascada de SnapMirror a SnapVault. Si el destino de SnapVault se encuentra en el centro de recuperación ante desastres o en un sitio terciario que no se ve afectado por una interrupción en el centro principal, es posible volver a configurar el entorno para que los backups continúen tras la conmutación por error.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">En la siguiente figura, se muestra la configuración una vez que se ha utilizado SRM para revertir la replicación de SnapMirror al centro principal. También se ha reconfigurado el entorno para que los backups SnapVault se realicen desde el origen de SnapMirror. Esta configuración es una configuración de dispersión de SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Después de que el SRM realiza la conmutación tras recuperación y una segunda reversión de las relaciones de SnapMirror, los datos de producción vuelven a estar en el sitio principal. Estos datos ahora están protegidos del mismo modo que antes la conmutación al centro de recuperación ante desastres, mediante backups de SnapMirror y SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Uso de Qtrees en entornos de Site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Los qtrees son directorios especiales que permiten aplicar cuotas del sistema de archivos para NAS. ONTAP 9 permite la creación de qtrees y pueden existir qtrees en los volúmenes replicados con SnapMirror. Sin embargo, SnapMirror no permite la replicación de qtrees individuales o a nivel de qtree. Toda la replicación de SnapMirror se realiza únicamente a nivel de volumen. Por este motivo, NetApp no recomienda el uso de qtrees con SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Entornos FC e iSCSI mixtos</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Con los protocolos SAN compatibles (Fibre Channel, FCoE e iSCI), ONTAP 9 ofrece servicios LUN, esto es, la capacidad de crear y asignar LUN a los hosts conectados. Dado que el clúster se compone de varias controladoras, existen varias rutas lógicas que se gestionan mediante I/o multivía con cualquier LUN individual. En los hosts se utiliza ALUA (Asymmetric LUN Access) para que se seleccione la ruta optimizada a cada LUN Si la ruta optimizada a cualquier LUN cambia (por ejemplo, debido a que se mueve el volumen que lo contiene), ONTAP 9 reconoce automáticamente y se ajusta de forma no disruptiva para este cambio. Si la ruta optimizada deja de estar disponible, ONTAP puede cambiar a otra ruta disponible sin interrupciones.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">El SRM de VMware y el SRA de NetApp admiten el uso del protocolo FC en un sitio y el protocolo iSCSI en el otro sitio. Sin embargo, no admite el hecho de haber una combinación de almacenes de datos conectados a FC y almacenes de datos conectados a iSCSI en el mismo host ESXi o en hosts diferentes en el mismo clúster. Esta configuración no es compatible con SRM porque, durante la conmutación por error de SRM o la conmutación por error de prueba, SRM incluye todos los iniciadores de FC e iSCSI de los hosts ESXi que están en la solicitud.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">El SRM y el SRA admiten protocolos mixtos de FC e iSCSI entre los sitios protegidos y de recuperación. Sin embargo, cada sitio debe configurarse con un solo protocolo, ya sea FC o iSCSI, y no con ambos protocolos en el mismo sitio. Si existe un requisito de tener configurados tanto los protocolos FC como iSCSI en el mismo sitio, NetApp recomienda que algunos hosts utilicen iSCSI y otros hosts utilicen FC. En este caso, NetApp también recomienda configurar las asignaciones de recursos de SRM para que las máquinas virtuales se configuren para conmutar al nodo de respaldo en un grupo de hosts u otro.</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">Esta página proporciona los pasos para implementar un almacén de datos VMFS FC en un entorno de VMware vSphere en un sistema ONTAP.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">Almacén de datos VMFS de vSphere: Back-end de almacenamiento de Fibre Channel con ONTAP</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">En esta sección se describe la creación de un almacén de datos VMFS con el almacenamiento Fibre Channel (FC) de ONTAP.</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">Las habilidades básicas necesarias para gestionar un entorno de vSphere y ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">Un sistema de almacenamiento ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) que ejecuta {ontap_version}</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">WWPN de ONTAP con información sobre el host, el destino y la SVM y LUN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">La hoja de datos de configuración de FC completada</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">Información sobre los hosts de vSphere</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vsphere_version}</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">Con los puertos de datos FC de ONTAP conectados y los hosts de vSphere</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">Con la función de virtualización N_Port ID (NPIV) habilitada</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">Cree una zona de destino única de iniciador.</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">Para cada zona, incluya un destino que sea la interfaz lógica ONTAP FC (WWPN) para las SVM. Debe haber al menos dos interfaces lógicas por nodo por SVM. No utilice el WWPN de los puertos físicos.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">Una herramienta ONTAP para VMware vSphere puesta en marcha, configurada y lista para usar.</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">Aprovisionamiento de un almacén de datos VMFS</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">Para aprovisionar un almacén de datos VMFS, complete los siguientes pasos:</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">Compruebe la compatibilidad con<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">Es compatible con la configuración de FCP</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">Compruebe que el <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">Comprobar que tiene una licencia de ONTAP para FCP.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">Utilice la<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando para comprobar que FCP aparece.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">Uso<block ref="79868b45624cf0644299a1019c0f9dc9" prefix=" " category="inline-code"></block> para añadir la licencia.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">Asegúrese de que el protocolo FCP esté habilitado en la SVM.</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">Comprobar el FCP en una SVM existente.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">Configure el FCP en una SVM existente.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">Cree una nueva SVM con FCP.</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">Asegúrese de que las interfaces lógicas FCP estén disponibles en una SVM.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">Cuando se crea una SVM con la interfaz gráfica de usuario, las interfaces lógicas forman parte de ese proceso.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">Para cambiar el nombre de las interfaces de red, utilice<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">Cree y asignar una LUN.</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> Omita este paso si utiliza herramientas de ONTAP para VMware vSphere.</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">Es decir, que están instalados los controladores HBA. Los HBA compatibles con VMware tienen controladores instalados de fábrica y deben estar visibles en la <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">Aprovisione un almacén de datos VMFS con herramientas de ONTAP</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">Almacén de datos VMFS de vSphere: Entorno de administración del almacenamiento iSCSI con ONTAP</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">En esta sección, se describe la creación de un almacén de datos VMFS con almacenamiento ONTAP iSCSI.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">Las habilidades básicas necesarias para gestionar un entorno de vSphere y ONTAP.</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">Información sobre los puertos de red de ONTAP, SVM y LUN para iSCSI</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">Hoja de datos de configuración de iSCSI completada</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">Información IP del adaptador de VMkernel de iSCSI</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">Con los puertos de datos de red del sistema ONTAP y los hosts de vSphere conectados</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">VLAN configuradas para iSCSI</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">Compruebe que la configuración de iSCSI es compatible.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">Compruebe la licencia de ONTAP para iSCSI</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">Utilice la<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando para comprobar si iSCSI aparece.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">Uso<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> para añadir la licencia.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">Compruebe que el protocolo iSCSI está habilitado en la SVM.</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">Confirmar que las interfaces lógicas de red iSCSI están disponibles en la SVM.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">Cuando se crea una SVM mediante la interfaz gráfica de usuario, también se crean interfaces de red iSCSI.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">Utilice la<block ref="ba500174804680d403063e56bca3cea6" prefix=" " category="inline-code"></block> comando para ver o realizar cambios en la interfaz de red.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">Se recomiendan dos interfaces de red iSCSI por nodo.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">Cree una interfaz de red iSCSI.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> Puede usar la política de servicio de bloques de datos predeterminada.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">Comprobar que el servicio de datos iscsi está incluido en la normativa de servicio.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> Puede utilizar<block ref="4e5efd8167f08c488fa3bc6f718e7db8" prefix=" " category="inline-code"></block> para verificar.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">Compruebe que las tramas gigantes están habilitadas.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">Cree y asigne la LUN.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> Omita este paso si utiliza herramientas de ONTAP para VMware vSphere. Repita este paso con cada LUN.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">Verifique que hay al menos un NIC disponible para la VLAN iSCSI. Se prefieren dos NIC para mejorar el rendimiento y la tolerancia a fallos.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">Identifique la cantidad de NIC físicas disponibles en el host vSphere.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">Configure el iniciador de iSCSI.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> Un caso de uso típico es un iniciador iSCSI de software.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">Compruebe que la pila TCPIP para iSCSI está disponible</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">Compruebe que los grupos de puertos iSCSI estén disponibles</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">Normalmente utilizamos un único switch virtual con varios puertos de enlace ascendente.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">Utilice la asignación de adaptador 1:1.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">Compruebe que los adaptadores de VMkernel iSCSI están habilitados para coincidir con el número de NIC y que las IP están asignadas.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">Vincule el adaptador de software iSCSI a los adaptadores de VMkernel iSCSI.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">Aprovisione el almacén de datos VMFS con herramientas de ONTAP</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. Repita este paso para todos los almacenes de datos.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">Comprobar la compatibilidad con la aceleración de hardware.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">Una vez completadas estas tareas, el almacén de datos VMFS estará listo para consumir para aprovisionar máquinas virtuales.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Libro de estrategia de Ansible</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter permite crear políticas de backup que se pueden aplicar a varias tareas. Estas políticas pueden definir programaciones, retención, replicación y otras funcionalidades. Siguen permitiendo una selección opcional de instantáneas coherentes con la máquina virtual, que aprovecha la capacidad del hipervisor para desactivar la E/S antes de tomar una instantánea de VMware.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">Otras funcionalidades para vSphere</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">Protección de datos</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">Realizar backups de sus máquinas virtuales y recuperarlos rápidamente se encuentran entre los grandes puntos fuertes de ONTAP para vSphere, y es fácil gestionar esta capacidad dentro de vCenter con el plugin de SnapCenter para VMware vSphere. Utilice copias Snapshot para realizar copias rápidas de su máquina virtual o su almacén de datos sin que el rendimiento se vea afectado y, a continuación, envíelas a un sistema secundario mediante SnapMirror para obtener protección de datos fuera del sitio a largo plazo. Este método minimiza el espacio de almacenamiento y el ancho de banda de red porque solo almacena la información modificada.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">recomendado</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter permite crear políticas de backup que se pueden aplicar a varias tareas. Estas políticas pueden definir programaciones, retención, replicación y otras funcionalidades. Siguen permitiendo una selección opcional de instantáneas coherentes con la máquina virtual, que aprovecha la capacidad del hipervisor para desactivar la E/S antes de tomar una instantánea de VMware. Sin embargo, debido al efecto sobre el rendimiento de las snapshots de VMware, generalmente no se recomiendan a menos que necesite que el sistema de archivos invitados se coloque en modo inactivo. En su lugar, utilice copias Snapshot de ONTAP para protección general y use herramientas de aplicaciones como los complementos de SnapCenter para proteger datos transaccionales como SQL Server u Oracle. Estas copias Snapshot son distintas de las copias Snapshot de VMware (consistencia) y son adecuadas para la protección a largo plazo. Las copias Snapshot de VMware son solo<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> para uso a corto plazo debido al rendimiento y otros efectos.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Estos complementos ofrecen funcionalidades ampliadas para proteger las bases de datos tanto en entornos físicos como virtuales. Con vSphere, puede usarlos para proteger bases de datos de SQL Server o Oracle donde los datos se almacenan en LUN de RDM, LUN iSCSI conectados directamente al sistema operativo invitado o archivos VMDK en almacenes de datos VMFS o NFS. Los plugins permiten especificar diferentes tipos de backups de bases de datos, admiten backup en línea o sin conexión y protegen los archivos de base de datos junto con los archivos de registros. Además del backup y recuperación, los plugins también admiten la clonado de bases de datos para fines de desarrollo o pruebas.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">En la siguiente figura se muestra un ejemplo de la instalación de SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Para obtener mejores funcionalidades de recuperación ante desastres, considere el uso del SRA de NetApp para ONTAP con el administrador de recuperación del sitio de VMware. Además de admitir la replicación de almacenes de datos en un sitio de recuperación ante desastres, también permite realizar pruebas no disruptivas en el entorno de recuperación ante desastres mediante la clonación de los almacenes de datos replicados. La recuperación de un desastre y la reprotección de la producción después de resolver la interrupción del servicio también son fáciles mediante la automatización incorporada en el SRA.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Finalmente, para obtener el máximo nivel de protección de datos, considere una configuración de VMware vSphere Metro Storage Cluster (VMSC) con MetroCluster de NetApp. VMSC es una solución certificada por VMware que combina la replicación síncrona con la agrupación en clusters basada en arreglos, con los mismos beneficios de un cluster de alta disponibilidad que la distribución en sitios independientes para proteger contra los desastres del sitio. MetroCluster de NetApp ofrece configuraciones rentables para la replicación síncrona con recuperación transparente de fallos de cualquier componente de almacenamiento, así como recuperación con un único comando en caso de desastre en el sitio. El VMSC se describe con mayor detalle en la<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Recuperación de espacio</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">El espacio puede reclamarse para otros usos cuando las máquinas virtuales se eliminen de un almacén de datos. Al utilizar almacenes de datos NFS, el espacio se recupera inmediatamente cuando se elimina una máquina virtual (por supuesto, este método solo tiene sentido cuando el volumen se aprovisiona mediante thin provisioning; es decir, la garantía de volumen no se establece en ninguno). Sin embargo, si se eliminan archivos dentro del sistema operativo invitado de equipo virtual, el espacio no se reclama automáticamente con un almacén de datos NFS. Para almacenes de datos VMFS basados en LUN, ESXi y el sistema operativo invitado pueden emitir primitivos VAAI UNMAP en el almacenamiento (de nuevo, al utilizar thin provisioning) para reclamar espacio. Dependiendo de la versión, este soporte es manual o automático.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">Recuperación del espacio de almacenamiento</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">este</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">En vSphere 5.5 y versiones posteriores, el<block ref="6f8212383775d45bd700d7b24be4f64e" prefix=" " category="inline-code"></block> el comando se sustituye por el<block ref="d92a762ce0274ace04ac012fc760e989" prefix=" " category="inline-code"></block> Comando, que especifica la cantidad de bloques libres (consulte VMware KB<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> para más información). En vSphere 6.5 y versiones posteriores cuando se utiliza VMFS 6, el espacio se debería recuperar automáticamente de forma asíncrona (consulte<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> En la documentación de vSphere), pero también se puede ejecutar manualmente si es necesario. ONTAP admite esta ASIGNACIÓN automática, mientras que las herramientas de ONTAP para VMware vSphere la establecen con baja prioridad. Tenga en cuenta que, al aprovisionar una LUN para su uso como almacén de datos VMFS, debe habilitar manualmente la opción de asignación de espacio en la LUN. Cuando se usan las herramientas de ONTAP para VMware vSphere, la LUN se configura automáticamente para admitir la reclamación de espacio y no se requieren otras acciones. Consulte<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> artículo de la base de conocimientos para obtener más información.</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">Clonado de máquinas virtuales y almacenes de datos</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">El clonado de un objeto de almacenamiento le permite crear rápidamente copias para un uso adicional, como el aprovisionamiento de equipos virtuales adicionales, operaciones de backup/recuperación de datos, etc. En vSphere, es posible clonar una máquina virtual, un disco virtual, VVol o un almacén de datos. Después de que se clona, el objeto se puede personalizar aún más, a menudo mediante un proceso automatizado. VSphere es compatible con ambos clones de copias completas, así como clones enlazados, donde sigue los cambios de forma independiente del objeto original.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">Los clones enlazados son excelentes para ahorrar espacio, pero aumentan la cantidad de I/o que vSphere gestiona para el equipo virtual, lo que afecta al rendimiento de ese equipo virtual y, quizás, al host en general. Por este motivo, los clientes de NetApp suelen utilizar clones basados en sistemas de almacenamiento para obtener lo mejor de ambos mundos: Uso eficiente del almacenamiento y aumento del rendimiento.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La siguiente figura muestra la clonación de ONTAP.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Es posible descargar la clonado en sistemas que ejecutan software ONTAP mediante varios mecanismos, normalmente a nivel de máquina virtual, VVol o almacén de datos. Entre ellos se incluyen los siguientes:</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">VVols utiliza el proveedor de API de vSphere para el reconocimiento del almacenamiento (VASA) de NetApp. Los clones de ONTAP se utilizan para admitir copias Snapshot de VVol gestionadas por vCenter, que gestionan el espacio de manera eficiente con un efecto mínimo de I/o para crearlas y eliminarlas. Las máquinas virtuales también pueden clonarse mediante vCenter y también se descargan en ONTAP, ya sea en un único almacén de datos/volumen o entre almacenes de datos/volúmenes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonado y migración de vSphere mediante API de vSphere: Integración de cabina (VAAI). Es posible descargar las operaciones de clonado de máquinas virtuales en ONTAP tanto en entornos SAN como NAS (NetApp suministra un complemento ESXi para habilitar VAAI para NFS). VSphere solo descarga las operaciones en máquinas virtuales frías (apagadas) en un almacén de datos NAS, mientras que las operaciones en máquinas virtuales activas (clonado y vMotion de almacenamiento) también se descargan para SAN. ONTAP usa el método más eficaz basado en el origen, el destino y las licencias de productos instaladas. Esta funcionalidad también la utiliza VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (usado con VMware Site Recovery Manager). Aquí, se utilizan clones para probar la recuperación de la réplica de recuperación ante desastres de forma no disruptiva.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup y recuperación de datos con herramientas de NetApp como SnapCenter. Los clones de equipos virtuales se utilizan para verificar las operaciones de backup y montar un backup de equipo virtual para que se puedan copiar archivos individuales.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">El clonado descargado de ONTAP puede invocarse con VMware, NetApp y herramientas de terceros. Los clones que se descargan en ONTAP tienen varias ventajas. Ofrecen una gestión eficiente del espacio en la mayoría de los casos, y necesitan almacenamiento solo para los cambios en el objeto; no hay ningún efecto adicional en el rendimiento para leerlos y escribirlos; en algunos casos, el rendimiento mejora si se comparten los bloques en las cachés de alta velocidad. También descargan los ciclos de CPU y las operaciones de I/o de red del servidor ESXi. La descarga de copias en un almacén de datos tradicional mediante un volumen FlexVol puede ser rápida y eficiente con la licencia de FlexClone, pero las copias entre volúmenes FlexVol pueden ser más lentas. Si mantiene las plantillas de equipos virtuales como origen de los clones, considere colocarlas en el volumen del almacén de datos (utilice carpetas o bibliotecas de contenido para organizarlas) para lograr clones rápidos con un uso eficiente del espacio.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">También es posible clonar un volumen o LUN directamente en ONTAP para clonar un almacén de datos. Con almacenes de datos NFS, la tecnología FlexClone puede clonar un volumen completo, y el clon se puede exportar desde ONTAP y montar en ESXi como otro almacén de datos. En almacenes de datos VMFS, ONTAP puede clonar una LUN dentro de un volumen o un volumen entero, incluida una o varias LUN dentro de él. Una LUN que contiene un VMFS debe asignarse a un iGroup de ESXi y, a continuación, volver a firmar la bandeja de ESXi para que se monte y utilice como almacén de datos normal. Para algunos casos de uso temporales, se puede montar un VMFS clonado sin renuncias. Una vez que se ha clonado un almacén de datos, los equipos virtuales del interior se pueden registrar, volver a configurar y personalizar como si se clonaran individualmente.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">En algunos casos, se pueden utilizar otras funciones con licencia para mejorar la clonación, como SnapRestore para backup o FlexClone. Estas licencias se incluyen a menudo en los paquetes de licencias sin coste adicional. Se requiere una licencia de FlexClone para las operaciones de clonado de VVol, así como para admitir copias snapshot gestionadas de un VVol (que se descargan del hipervisor en ONTAP). Una licencia de FlexClone también puede mejorar ciertos clones basados en VAAI cuando se usan en un almacén de datos/volumen (crea copias instantáneas con gestión eficiente del espacio en lugar de copias de bloques). El SRA también usa para probar la recuperación de una réplica de DR, y el SnapCenter para las operaciones de clonado y para buscar copias de backup para restaurar archivos individuales.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">Eficiencia del almacenamiento y thin provisioning</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp ha sido el líder del sector con innovaciones de eficiencia del almacenamiento, como la primera deduplicación para cargas de trabajo principales, y la compactación de datos inline, que mejora la compresión y almacena archivos pequeños y I/o de forma eficiente. ONTAP admite deduplicación en línea y en segundo plano, así como compresión en línea y en segundo plano.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">La siguiente figura muestra el efecto combinado de las funciones de eficiencia del almacenamiento de ONTAP.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">Estas son algunas recomendaciones sobre el uso de la eficiencia del almacenamiento de ONTAP en un entorno vSphere:</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">La cantidad de ahorro obtenido con la deduplicación de datos se basa en la similitud de los datos. Con ONTAP 9.1 y versiones anteriores, la deduplicación de datos operaba a nivel de volumen, pero con la deduplicación de agregados en ONTAP 9.2 y versiones posteriores, los datos se deduplican en todos los volúmenes de un agregado en sistemas AFF. Ya no es necesario agrupar sistemas operativos y aplicaciones similares en un único almacén de datos para maximizar el ahorro.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">Para aprovechar las ventajas de la deduplicación en un entorno de bloques, se deben aplicar thin provisioning a las LUN. A pesar de que el administrador de equipos virtuales todavía puede considerar la LUN como si se utilizara la capacidad aprovisionada, el ahorro de la deduplicación se devuelve al volumen para usarlo con otras necesidades. NetApp recomienda la puesta en marcha de estos LUN en volúmenes de FlexVol que también se aprovisionan mediante thin provisioning (las herramientas de ONTAP para VMware vSphere dimensionan el volumen aproximadamente un 5% mayor que la LUN).</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">También se recomienda thin provisioning (y es el valor predeterminado) para los volúmenes FlexVol NFS. En un entorno NFS, el ahorro de la deduplicación es visible inmediatamente para los administradores de almacenamiento y equipos virtuales con volúmenes con thin provisioning.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">Thin provisioning se aplica también a las máquinas virtuales, donde NetApp recomienda normalmente VMDK con thin provisioning en lugar de gruesos. Cuando se utilice thin provisioning, asegúrese de supervisar el espacio disponible con las herramientas de ONTAP para VMware vSphere, ONTAP u otras herramientas disponibles para evitar problemas de falta de espacio.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">Tenga en cuenta que al usar thin provisioning con sistemas ONTAP no se afecta al rendimiento; los datos se escriben en el espacio disponible para maximizar el rendimiento de escritura y lectura. A pesar de ello, algunos productos, como los clusters de recuperación tras fallos de Microsoft u otras aplicaciones de baja latencia, pueden requerir aprovisionamiento garantizado o fijo, y es sabio seguir estos requisitos para evitar problemas de soporte.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">Para obtener el máximo ahorro de la deduplicación, considere la posibilidad de programar la deduplicación en segundo plano en sistemas basados en disco duro o la deduplicación en segundo plano automática en sistemas AFF. Sin embargo, los procesos programados utilizan recursos del sistema cuando se ejecutan. De esta forma, se podrían programar durante periodos menos activos (como fines de semana) o ejecutar con más frecuencia para reducir la cantidad de datos modificados que se van a procesar. La deduplicación automática en segundo plano en los sistemas AFF tiene mucho menos efecto en las actividades de primer plano. La compresión en segundo plano (para sistemas basados en disco duro) también consume recursos, por lo que solo se debe tener en cuenta para cargas de trabajo secundarias con requisitos de rendimiento limitados.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Artículo de base de conocimientos</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">Los sistemas AFF de NetApp usan principalmente funcionalidades de eficiencia del almacenamiento inline. Cuando se trasladan datos a ellos mediante herramientas de NetApp que utilizan replicación de bloques, como la herramienta de transición de 7-Mode, SnapMirror o el movimiento de volúmenes, puede ser útil ejecutar escáneres de compresión y compactación para maximizar el ahorro en eficiencia. Revise este soporte de NetApp<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> para obtener más detalles.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">Las copias Snapshot pueden bloquear bloques que pueden reducirse mediante compresión o deduplicación. Cuando utilice eficiencia programada en segundo plano o escáneres de una sola vez, asegúrese de que funcionan y finalizan antes de realizar la siguiente copia Snapshot. Revise sus copias Snapshot y retención para asegurarse de que solo tenga las copias Snapshot que necesite, especialmente antes de ejecutar un trabajo de análisis o en segundo plano.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">La tabla siguiente ofrece directrices de eficiencia del almacenamiento para cargas de trabajo virtualizadas en diferentes tipos de almacenamiento ONTAP:</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Carga de trabajo</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Directrices de eficiencia del almacenamiento</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">Unidades de disco duro</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI y SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">Para las cargas de trabajo principales y secundarias, utilice:</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">Compresión en línea adaptativa</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">Deduplicación en línea</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">Deduplicación en segundo plano</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">Compactación de datos inline</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">Para las cargas de trabajo principales, utilice:</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">Para cargas de trabajo secundarias, utilice:</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">Compresión adaptativa de fondo</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">Calidad de servicio (QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">Los sistemas que ejecutan el software ONTAP pueden utilizar la función de calidad de servicio del almacenamiento ONTAP para limitar el rendimiento en Mbps y/o I/o por segundo (IOPS) de diferentes objetos de almacenamiento como archivos, LUN, volúmenes o SVM completas.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">Los límites de rendimiento son útiles para controlar cargas de trabajo desconocidas o de prueba antes de la puesta en marcha a fin de asegurarse de que no afectan a otras cargas de trabajo. También se pueden utilizar para limitar una carga de trabajo abusivas una vez que se identifica. También admite niveles mínimos de servicio basados en IOPS para proporcionar un rendimiento constante para los objetos SAN en ONTAP 9.2 y para los objetos NAS en ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Con un almacén de datos NFS, se puede aplicar una política de calidad de servicio a todo el volumen FlexVol o a archivos VMDK individuales en el mismo. Con almacenes de datos VMFS que utilizan LUN de ONTAP, las políticas de calidad de servicio se pueden aplicar al volumen de FlexVol que contiene los LUN o LUN individuales, pero no archivos VMDK individuales porque ONTAP no reconoce el sistema de archivos VMFS. Al utilizar vVols, se puede establecer una calidad de servicio mínima o máxima en equipos virtuales individuales usando el perfil de capacidad de almacenamiento y la política de almacenamiento de equipos virtuales.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">El límite máximo de rendimiento de calidad de servicio en un objeto se puede establecer en Mbps o IOPS. Si se utilizan ambos, ONTAP aplica el primer límite alcanzado. Una carga de trabajo puede contener varios objetos y una política de calidad de servicio se puede aplicar a una o más cargas de trabajo. Cuando se aplica una política a varias cargas de trabajo, las cargas de trabajo comparten el límite total de la política. No se admiten los objetos anidados (por ejemplo, los archivos de un volumen no pueden tener cada uno su propia política). Los valores mínimos de calidad de servicio solo se pueden establecer en IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Las siguientes herramientas están disponibles en este momento para gestionar las políticas de calidad de servicio de ONTAP y aplicarlas a los objetos:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI de ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">System Manager de ONTAP</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit de herramientas NetApp PowerShell para ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Herramientas de ONTAP para VASA Provider de VMware vSphere</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Para asignar una política de calidad de servicio a un VMDK en NFS, tenga en cuenta las siguientes directrices:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La política debe aplicarse a la<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> que contiene la imagen del disco virtual real, no la<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (archivo de descriptor de disco virtual) o.<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (Archivo descriptor de máquina virtual).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">No aplique políticas a otros archivos del equipo virtual, como archivos de intercambio virtual <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Cuando utilice el cliente web de vSphere para buscar rutas de archivos (Datastore &gt; Files), tenga en cuenta que combina la información del<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> y..<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> y simplemente muestra un archivo con el nombre del<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> pero el tamaño del<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Agregar<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> en el nombre del archivo para obtener la ruta correcta.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Para asignar una normativa de calidad de servicio a un LUN, incluidos VMFS y RDM, la SVM de ONTAP (mostrada como Vserver), la ruta de LUN y el número de serie pueden obtenerse en el menú sistemas de almacenamiento de la página de inicio de ONTAP Tools para VMware vSphere. Seleccione el sistema de almacenamiento (SVM) y, a continuación, Related Objects &gt; SAN. Use este enfoque cuando especifique la calidad de servicio mediante una de las herramientas de ONTAP.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">La calidad de servicio máxima y mínima se puede asignar fácilmente a una máquina virtual basada en VVol con las herramientas de ONTAP para VMware vSphere o Virtual Storage Console 7.1 y versiones posteriores. Cuando cree el perfil de capacidad de almacenamiento para el contenedor VVol, especifique un valor de IOPS máximo o mínimo con la funcionalidad de rendimiento y, a continuación, haga referencia a este SCP con la política de almacenamiento de la máquina virtual. Use esta política cuando cree la máquina virtual o aplique la política a una máquina virtual existente.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Los almacenes de datos de FlexGroup ofrecen funcionalidades de calidad de servicio mejoradas al usar las herramientas de ONTAP para VMware vSphere 9.8 y versiones posteriores. Puede establecer fácilmente la calidad de servicio en todas las máquinas virtuales de un almacén de datos o en máquinas virtuales específicas. Consulte la sección FlexGroup de este informe para obtener más información.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS y VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">QoS de ONTAP y VMware vSphere Storage I/o Control (SIOC) son tecnologías complementarias que los administradores de vSphere y almacenamiento pueden utilizar juntos para gestionar el rendimiento de máquinas virtuales vSphere alojadas en sistemas que ejecutan el software ONTAP. Cada herramienta tiene sus propias fuerzas, como se muestra en la siguiente tabla. Debido a los distintos ámbitos de VMware vCenter y ONTAP, algunos objetos pueden verse y gestionarse mediante un sistema, no el otro.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Propiedad</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">Calidad de servicio de ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Cuando está activo</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La directiva está siempre activa</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Activo cuando existe una contención (latencia por encima del umbral de los almacenes de datos)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Tipo de unidades</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mbps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, recursos compartidos</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Alcance de vCenter o aplicaciones</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Varios entornos de vCenter, otros hipervisores y aplicaciones</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Un único servidor vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">¿Establecer QoS en la máquina virtual?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK solo en NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK en NFS o VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">¿Establecer QoS en el LUN (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">¿Configurar QoS en LUN (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">¿Configurar calidad de servicio en el volumen (almacén de datos NFS)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">¿Configurar la calidad de servicio en SVM (inquilino)?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">¿Enfoque basado en políticas?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Sí, pueden compartirse todas las cargas de trabajo de la política o aplicarse por completo a cada carga de trabajo de la política.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Sí, con vSphere 6.5 y posterior.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Se requiere licencia</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Incluido con ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">Planificador de recursos distribuidos de almacenamiento de VMware</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">El planificador de recursos distribuidos de almacenamiento (SDRS) de VMware es una función de vSphere que coloca los equipos virtuales en el almacenamiento en función de la latencia de I/o actual y el uso del espacio. A continuación, mueve la máquina virtual o los VMDK de forma no disruptiva entre los almacenes de datos de un clúster de almacenes de datos (también conocido como "pod"), seleccionando el mejor almacén de datos en el que colocar la máquina virtual o los VMDK en el clúster de almacenes de datos. Un clúster de almacenes de datos es una colección de almacenes de datos similares que se agregan a una sola unidad de consumo desde el punto de vista del administrador de vSphere.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Cuando se usan SDRS con las herramientas de ONTAP de NetApp para VMware vSphere, primero es necesario crear un almacén de datos con el plugin, utilizar vCenter para crear el clúster de almacenes de datos y, a continuación, añadir el almacén de datos. Una vez creado el clúster de almacenes de datos, es posible añadir almacenes de datos adicionales al clúster de almacenes de datos directamente desde el asistente de aprovisionamiento de la página Details.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Otras prácticas recomendadas de ONTAP para SDRS incluyen lo siguiente:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Todos los almacenes de datos del clúster deben usar el mismo tipo de almacenamiento (como SAS, SATA o SSD), ser todos los almacenes de datos VMFS o NFS y tener la misma configuración de replicación y protección.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Considere el uso de SDR en modo predeterminado (manual). Este enfoque permite revisar las recomendaciones y decidir si se aplican o no. Tenga en cuenta los siguientes efectos de las migraciones de VMDK:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Cuando SDRS mueve VMDK entre almacenes de datos, se pierde cualquier ahorro de espacio con la clonado o deduplicación de ONTAP. Puede volver a ejecutar la deduplicación para recuperar este ahorro.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">Una vez que LOS SDR mueven VMDK, NetApp recomienda volver a crear las copias Snapshot en el almacén de datos de origen porque, de lo contrario, la máquina virtual que se bloquea el espacio.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Mover VMDK entre almacenes de datos en el mismo agregado tiene pocas ventajas y LOS SDRS no tienen visibilidad en otras cargas de trabajo que puedan compartir el agregado.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">Gestión basada en normativas de almacenamiento y vVols</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">Las API de VMware vSphere para la conciencia de almacenamiento (VASA) facilitan que el administrador de almacenamiento pueda configurar almacenes de datos con funcionalidades bien definidas y permiten que el administrador de equipos virtuales las utilice siempre que lo necesite para aprovisionar equipos virtuales sin tener que interactuar entre sí. Vale la pena echar un vistazo a este enfoque para ver cómo puede simplificar sus operaciones de almacenamiento de virtualización y evitar una gran cantidad de tareas triviales.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Antes de VASA, los administradores de máquinas virtuales podían definir políticas de almacenamiento de máquinas virtuales, pero tenían que trabajar con el administrador de almacenamiento para identificar los almacenes de datos adecuados, a menudo utilizando documentación o convenciones de nomenclatura. Con VASA, el administrador de almacenamiento puede definir una serie de capacidades de almacenamiento, como el rendimiento, la clasificación por niveles, el cifrado y la replicación. Un conjunto de funcionalidades para un volumen o un conjunto de volúmenes se denomina perfil de capacidad de almacenamiento (SCP).</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP soporta QoS mínima y/o máxima para los vVols de datos de una VM. La calidad de servicio mínima solo se admite en los sistemas AFF. Las herramientas de ONTAP para VMware vSphere incluyen una consola donde se muestra el rendimiento granular de máquinas virtuales y la capacidad lógica para vVols en sistemas ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La siguiente figura muestra las herramientas de ONTAP para el panel de vVols de VMware vSphere 9.8.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">Una vez definido el perfil de funcionalidad de almacenamiento, puede utilizarse para aprovisionar equipos virtuales mediante la normativa de almacenamiento que identifique sus requisitos. La asignación entre la política de almacenamiento de máquinas virtuales y el perfil de capacidad de almacenamiento de almacenes de datos permite que vCenter muestre una lista de almacenes de datos compatibles que podrá seleccionar. Este enfoque se conoce como gestión basada en políticas de almacenamiento.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA proporciona la tecnología para consultar el almacenamiento y devolver un conjunto de funcionalidades de almacenamiento a vCenter. Los proveedores de VASA proporcionan la traducción entre las API y construcciones del sistema de almacenamiento y las API de VMware que comprende vCenter. El proveedor VASA de NetApp para ONTAP se ofrece como parte de las herramientas de ONTAP para la máquina virtual del dispositivo VMware vSphere, y el complemento de vCenter proporciona la interfaz para aprovisionar y gestionar almacenes de datos VVol, así como la capacidad de definir perfiles de funcionalidad de almacenamiento (CDP).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP admite almacenes de datos de VVol tanto VMFS como NFS. El uso de vVols con almacenes DE datos SAN aporta algunas de las ventajas de NFS, como la granularidad a nivel de equipo virtual. Aquí encontrará algunas prácticas recomendadas para tener en cuenta y información adicional en<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un almacén de datos de VVol puede consistir en varios volúmenes de FlexVol en varios nodos de clúster. El método más sencillo es un único almacén de datos, incluso cuando los volúmenes tienen diferentes funcionalidades. SPBM garantiza que se utiliza un volumen compatible para la máquina virtual. Sin embargo, todos los volúmenes deben formar parte de una única SVM de ONTAP y se debe acceder a ellos mediante un único protocolo. Un LIF por nodo para cada protocolo es suficiente. Evite el uso de varias versiones de ONTAP en un único almacén de datos de VVol, ya que las funcionalidades de almacenamiento pueden variar entre las versiones.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilice las herramientas de ONTAP para el plugin de VMware vSphere para crear y gestionar almacenes de datos de VVol. Además de gestionar el almacén de datos y su perfil, crea automáticamente un extremo de protocolo para acceder a vVols, si es necesario. Si se utilizan LUN, tenga en cuenta que los extremos de protocolo de LUN se asignan mediante los ID de LUN 300 y posteriores. Compruebe que la opción de configuración del sistema avanzado del host ESXi<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Permite un número de ID de LUN que sea mayor que 300 (el valor predeterminado es 1,024). Para realizar este paso, seleccione el host ESXi en vCenter, después la pestaña Configure y busque<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> En la lista Advanced System Settings.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">No instale ni migre VASA Provider, vCenter Server (basado en dispositivos o Windows) ni las herramientas de ONTAP para VMware vSphere en un almacén de datos vVols, ya que estos dependen mutuamente, lo cual limita la capacidad de gestionarlos en caso de una interrupción del suministro eléctrico u otra interrupción del centro de datos.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">Realice un backup regular de la máquina virtual del proveedor de VASA. Como mínimo, cree copias Snapshot cada hora del almacén de datos tradicional que contiene VASA Provider. Para obtener más información sobre la protección y recuperación del proveedor de VASA, consulte este tema<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La siguiente figura muestra los componentes de vVols.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migración al cloud y backup</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Otra ventaja de ONTAP es la amplia compatibilidad con el cloud híbrido, al fusionar sistemas en el cloud privado local con funcionalidades de cloud público. Estas son algunas de las soluciones cloud de NetApp que se pueden usar junto con vSphere:</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">* Cloud Volumes.* NetApp Cloud Volumes Service para AWS o GCP y Azure NetApp Files para ANF proporcionan servicios de almacenamiento gestionado multiprotocolo de alto rendimiento en los principales entornos de cloud público. Los pueden utilizar directamente los invitados de VMware Cloud VM.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">*Cloud Volumes ONTAP.* el software para la gestión de datos Cloud Volumes ONTAP de NetApp proporciona control, protección, flexibilidad y eficiencia para sus datos en el cloud que elija. Cloud Volumes ONTAP es un software de gestión de datos nativo en el cloud e integrado en el software de almacenamiento ONTAP de NetApp. Utilícelo con Cloud Manager para poner en marcha y gestionar instancias de Cloud Volumes ONTAP junto con sus sistemas ONTAP locales. Saque partido de las funcionalidades avanzadas DE SAN iSCSI y NAS junto con la gestión de datos unificada, incluidas las copias de snapshots y la replicación de SnapMirror.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Servicios en la nube.* Utilice Cloud Backup Service o SnapMirror Cloud para proteger los datos de sistemas en las instalaciones mediante almacenamiento en cloud público. Cloud Sync le ayuda a migrar y mantener sus datos sincronizados a través de NAS, almacenes de objetos y almacenamiento Cloud Volumes Service.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">Almacene más copias snapshot de sus equipos virtuales</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">*FabricPool.* FabricPool ofrece una organización en niveles rápida y fácil para los datos de ONTAP. Los bloques fríos en las copias Snapshot se pueden migrar a un almacén de objetos en clouds públicos o un almacén de objetos privado de StorageGRID y se recuperan automáticamente cuando se vuelve a acceder a los datos de ONTAP. También puede usar el nivel de objeto como un tercer nivel de protección para los datos que ya está gestionado por SnapVault. Este enfoque le permite<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> En sistemas de almacenamiento ONTAP principales o secundarios</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* Utilice el almacenamiento definido por software de NetApp para ampliar su cloud privado a través de Internet a instalaciones y oficinas remotas, donde puede utilizar ONTAP Select para ofrecer compatibilidad con servicios de bloques y archivos, así como las mismas funcionalidades de gestión de datos vSphere que tiene en su centro de datos empresarial.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">A la hora de diseñar sus aplicaciones basadas en máquinas virtuales, tenga en cuenta la movilidad del cloud futura. Por ejemplo, en lugar de colocar los archivos de datos y aplicaciones en conjunto, utilizan una exportación de NFS o LUN independiente para los datos. Esto permite migrar la máquina virtual y los datos por separado a los servicios de cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Cifrado para datos de vSphere</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">Hoy en día, hay cada vez más demandas de protección de los datos en reposo mediante el cifrado. Aunque el foco inicial fue en la información financiera y sanitaria, existe un creciente interés en proteger toda la información, ya sea que esté almacenada en archivos, bases de datos u otros tipos de datos.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">Los sistemas que ejecutan el software ONTAP facilitan la protección de cualquier dato con el cifrado en reposo. El cifrado de almacenamiento de NetApp (NSE) utiliza unidades de disco de cifrado automático con ONTAP para proteger datos SAN y NAS. NetApp también ofrece el cifrado de volúmenes de NetApp y el cifrado de agregados de NetApp como un método sencillo basado en software para cifrar volúmenes en cualquier unidad de disco. Este cifrado de software no requiere unidades de disco especiales ni gestores de claves externos y está disponible para los clientes de ONTAP sin coste adicional. Puede realizar una actualización y empezar a utilizarla sin interrupciones en los clientes o las aplicaciones, y ha sido validada según el estándar de nivel 1 de FIPS 140-2-2, incluido el gestor de claves incorporado.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Existen varios métodos para proteger los datos de las aplicaciones virtualizadas que se ejecutan en VMware vSphere. Uno de los métodos consiste en proteger los datos con software dentro de los equipos virtuales a nivel de SO «guest». Los hipervisores más recientes, como vSphere 6.5, ahora admiten el cifrado a nivel de equipo virtual como otra alternativa. Sin embargo, el cifrado del software de NetApp es simple y fácil y tiene estas ventajas:</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">*Sin efecto sobre la CPU del servidor virtual.* algunos entornos de servidor virtual necesitan todos los ciclos de CPU disponibles para sus aplicaciones, aunque las pruebas han demostrado que se necesitan hasta 5 veces los recursos de CPU con cifrado a nivel de hipervisor. Aunque el software de cifrado admita el conjunto de instrucciones AES-ni de Intel para descargar la carga de trabajo de cifrado (como lo hace el cifrado del software de NetApp), es posible que este método no sea factible debido al requisito de nuevas CPU que no sean compatibles con servidores antiguos.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Incluye el gestor de claves incorporado.* el cifrado de software de NetApp incluye un gestor de claves incorporado sin coste adicional, lo que facilita su introducción sin servidores de gestión de claves de alta disponibilidad complejos de adquirir y usar.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*No afecta a la eficiencia del almacenamiento.* las técnicas de eficiencia del almacenamiento como la deduplicación y la compresión se utilizan ampliamente hoy en día y son clave para utilizar medios de disco flash de forma rentable. Sin embargo, por lo general, los datos cifrados no se pueden deduplicar o comprimir. El cifrado de almacenamiento y hardware de NetApp funciona a un nivel inferior y permite el uso completo de funciones de eficiencia del almacenamiento de NetApp, líderes del sector, a diferencia de otros métodos.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Cifrado granular sencillo del almacén de datos.* con el cifrado de volúmenes de NetApp, cada volumen obtiene su propia clave AES de 256 bits. Si necesita cambiarlo, puede hacerlo con un solo comando. Este método es genial si tiene varios clientes o necesita probar el cifrado independiente para diferentes departamentos o aplicaciones. Este cifrado se gestiona a nivel de almacén de datos, lo cual es mucho más fácil que gestionar equipos virtuales individuales.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">Es fácil empezar a usar el cifrado de software. Después de instalar la licencia, solo tiene que configurar el gestor de claves incorporado especificando una frase de acceso y luego crear un volumen nuevo o mover un volumen en el almacenamiento para habilitar el cifrado. NetApp está trabajando para añadir compatibilidad más integrada con funcionalidades de cifrado en futuros lanzamientos de sus herramientas de VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager proporciona visibilidad de los VM en su infraestructura virtual y permite supervisar y solucionar los problemas de almacenamiento y rendimiento en su entorno virtual.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Una infraestructura virtual típica puesta en marcha en ONTAP tiene diversos componentes que se distribuyen en las capas informática, de red y de almacenamiento. Cualquier retraso en el rendimiento de una aplicación de equipo virtual puede producirse debido a una combinación de latencias que deben afrontar los distintos componentes de las capas respectivas.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La siguiente captura de pantalla muestra la vista Máquinas virtuales de Active IQ Unified Manager.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager presenta el subsistema subyacente de un entorno virtual en una vista topológica para determinar si se ha producido un problema de latencia en el nodo de computación, la red o el almacenamiento. La vista también destaca el objeto específico que provoca el desfase en el rendimiento a la hora de dar pasos correctivas y solucionar el problema subyacente.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La siguiente captura de pantalla muestra la topología ampliada de AIUM.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">Esta página proporciona los pasos para implementar un almacén de datos VMFS FCoE en un entorno de VMware vSphere en un almacenamiento ONTAP de NetApp.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">Almacén de datos VMFS de vSphere: Protocolo de almacenamiento Fibre Channel sobre Ethernet con ONTAP</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">En esta sección se describe la creación de un almacén de datos VMFS con el protocolo de transporte Fibre Channel over Ethernet (FCoE) al almacenamiento de ONTAP.</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">Un sistema de almacenamiento ONTAP (FAS/AFF/CVO/ONTAP Select) que ejecuta {ontap_version}</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">Una combinación de FCoE compatible</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">Una hoja de datos de configuración completada</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">Con los puertos de datos FC de ONTAP o los hosts de vSphere conectados</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">Se ha configurado la división en zonas de FC/FCoE</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">Compatibilidad con FCoE</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">Compatibilidad con DCB</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">Tramas gigantes para FCoE</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">Aprovisione un almacén de datos de VMFS</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">Compruebe que la configuración de FCoE es compatible</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">Utilice la<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Comando para verificar que el FCP aparece.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">Compruebe que el protocolo FCP esté habilitado en la SVM.</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">Cree una nueva SVM con el FCP.</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">Comprobar que las interfaces lógicas FCP están disponibles en la SVM.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">Cuando se crea la SVM con la interfaz gráfica de usuario, las interfaces lógicas forman parte de ese proceso.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">Para cambiar el nombre de la interfaz de red, utilice<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">Cree y asigne una LUN</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>; Omita este paso si utiliza las herramientas de ONTAP para VMware vSphere.</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">información del adaptador de almacenamiento</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">Compruebe que los controladores HBA están instalados. Los HBA compatibles con VMware tienen controladores instalados de fábrica y deben estar visibles en la <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="3e23a542d0c1cb3dc87ca41f7ec8dc9c" category="doc">Plugin de SnapCenter de NetApp para VMware vSphere - flujo de trabajo de restauración de SQL Server</block>
  <block id="d16efdedacbd64c8b85d50f0b58e4c60" category="inline-link-macro">Anterior: Información adicional: Plugin de SnapCenter para VMware vSphere - flujo de trabajo de restauración.</block>
  <block id="553f0bde4f032f393b8659c8440bae26" category="paragraph"><block ref="553f0bde4f032f393b8659c8440bae26" category="inline-link-macro-rx"></block></block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">Los avisos legales proporcionan acceso a las declaraciones de copyright, marcas comerciales, patentes y mucho más.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Avisos legales</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Derechos de autor</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marcas comerciales</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, el logotipo de NETAPP y las marcas enumeradas en la página de marcas comerciales de NetApp son marcas comerciales de NetApp, Inc. Los demás nombres de empresas y productos son marcas comerciales de sus respectivos propietarios.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Estadounidenses</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Puede encontrar una lista actual de las patentes propiedad de NetApp en:</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Política de privacidad</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Código abierto</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">Los archivos de notificación proporcionan información sobre los derechos de autor y las licencias de terceros que se utilizan en software de NetApp.</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS admite almacenamiento de NetApp con las siguientes configuraciones:</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="list-text">FSX ONTAP como almacenamiento conectado como invitado</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="list-text">Cloud Volumes ONTAP (CVO) como almacenamiento conectado como invitado</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP como almacén de datos NFS complementario</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">Opciones de almacenamiento de conexión para invitado para VMC</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">Opciones suplementarias de almacén de datos de NFS para VMC</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">Vea el detalles <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>. Vea el detalles <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>.</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">Vea el detalles <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>. Vea el detalles <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>.</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure / AVS</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure admite almacenamiento de NetApp en las siguientes configuraciones:</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="list-text">Azure NetApp Files (ANF) como almacenamiento conectado como invitado</block>
  <block id="dd4fe8081ff6ae9c7e9975937aff6576" category="list-text">Azure NetApp Files (ANF) como almacén de datos NFS complementario</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">Opciones de almacenamiento de Guest Connect para AVS</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">Opciones complementarias de almacén de datos NFS para AVS</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">Vea el detalles <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>. Vea el detalles <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>.</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">Vea el detalles <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>. Vea el detalles <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud es compatible con almacenamiento de NetApp en las siguientes configuraciones:</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="list-text">Cloud Volumes Service (CVS) como almacenamiento conectado como invitado</block>
  <block id="b2bf74ba9b2080c50a7214bcabdb670c" category="list-text">Cloud Volumes Service (CVS) como almacén de datos NFS complementario</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">Opciones de almacenamiento de Guest Connect para GCVE</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">Vea el detalles <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>.</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">Vea el detalles <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>.</block>
  <block id="8031035e3922dbc188f876cc6fb8434d" category="inline-link-macro">Soporte de almacén de datos de Cloud Volumes Service de NetApp para Google Cloud VMware Engine (blog de NetApp)</block>
  <block id="71f1bcf72187cb460ce8534fd5439962" category="inline-link-macro">Cómo usar CVS de NetApp como almacenes de datos para Google Cloud VMware Engine (blog de Google)</block>
  <block id="5ca70e1272bcfe0644f6a52e2d971039" category="paragraph">Más información acerca de <block ref="0d04aae7b3b1a3149a54ebc44d21fc72" category="inline-link-macro-rx"></block> o. <block ref="c1e740ec580b7430a1cc324eec4af172" category="inline-link-macro-rx"></block></block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">Para obtener más información, visite el sitio web de OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">Los sistemas de almacenamiento NetApp Element cubren casos de uso basados en bloques (iSCSI) en un entorno altamente escalable.</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">En esta sección se describe cómo configurar y gestionar VMware Cloud en AWS SDDC y utilizarlo en combinación con las opciones disponibles para conectar el almacenamiento de NetApp.</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">El almacenamiento invitado es el único método compatible para conectar Cloud Volumes ONTAP a VMC de AWS.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">El proceso de configuración puede dividirse en los siguientes pasos:</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">Poner en marcha y configurar VMware Cloud para AWS</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="list-text">Conecte VMware Cloud a FSX ONTAP</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">Pasos de configuración para VMC</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">Vea el detalles <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>.</block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">Vea el detalles <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>.</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">En esta sección se describe cómo configurar y gestionar la solución VMware de Azure y utilizarla en combinación con las opciones disponibles para conectar el almacenamiento de NetApp.</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">El almacenamiento en invitado es el único método compatible para conectar Cloud Volumes ONTAP a la solución VMware Azure.</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="list-text">Registre el proveedor de recursos y cree un cloud privado</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="list-text">Conéctese a una puerta de enlace de red virtual ExpressRoute nueva o existente</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="list-text">Validar la conectividad de red y acceder al cloud privado</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">Pasos de configuración para AVS</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">Vea el detalles <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>.</block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">Vea el detalles <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>.</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">En esta sección se describe cómo configurar y gestionar GCVE y cómo utilizarlo junto con las opciones disponibles para conectar el almacenamiento de NetApp.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">El almacenamiento invitado es el único método compatible para conectar Cloud Volumes ONTAP y Cloud Volumes Services a GCVE.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="list-text">Implementar y configurar GCVE</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="list-text">Active el acceso privado a GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">Pasos de configuración para GCVE</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">Vea el detalles <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>.</block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">Vea el detalles <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">A continuación, cargue los certificados TLS del registro de imágenes en los nodos de OpenShift. Para ello, cree un mapa de configuración en el espacio de nombres de openshift-config mediante los certificados TLS y realice una revisión de la configuración de la imagen del clúster para que el certificado sea de confianza.</block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Cree o obtenga el archivo kubeconfig con acceso de administrador al clúster {k8s_usercluster_name} en el que se va a instalar Astra Control Center.</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">Amazon define la disponibilidad de almacenes de datos NFS complementarios en AWS/VMC. Primero, debe determinar si tanto VMC como FSxN están disponibles en una región específica. A continuación, debe determinar si el almacén de datos NFS complementario FSxN es compatible en esa región.</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">Compruebe la disponibilidad del VMC <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>.</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">La guía de precios de Amazon ofrece información sobre dónde está disponible FSxN (FSX ONTAP). Usted puede encontrar esa información <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">La disponibilidad del almacén de datos NFS complementario FSxN para VMC estará disponible próximamente.</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">Aunque aún se dispone de información, el siguiente gráfico identifica el soporte actual de VMC, FSxN y FSxN como almacén de datos NFS complementario.</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">América</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">*Región de AWS*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">*Disponibilidad VMC*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">*Disponibilidad de ONTAP FSX*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">*Disponibilidad del almacén de datos NFS*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">Este DE EE. UU. (Virginia del Norte)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">Este DE EE. UU. (Ohio)</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">Oeste DE EE. UU. (Norte de California)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">Oeste DE EE. UU. (Oregón)</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud (oeste de EE. UU.)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">Canadá (Central)</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">Sudamérica (São Paulo)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">Última actualización el: 2 de junio de 2022.</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">EMEA</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">Europa (Irlanda)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">Europa (Londres)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">Europa (Frankfurt)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">Europa (París)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">Europa (Milán)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">Europa (Estocolmo)</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">Asia-Pacífico</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">APAC (Sidney)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">APAC (Tokio)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">APAC (Osaka)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">APAC (Singapur)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">APAC (Seúl)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">APAC (Bombay)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">APAC (Yakarta)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">APAC (Hong Kong)</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">Última actualización el: 28 de septiembre de 2022.</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">Google define la disponibilidad de almacenes de datos NFS complementarios en GCP/GCVE. Primero, debe determinar si GCVE y CVS están disponibles en una región específica. A continuación, debe determinar si el almacén de datos NFS complementario CVS es compatible con esa región.</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">Compruebe la disponibilidad de GCVE y CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">Compruebe la disponibilidad del almacén de datos NFS complementario CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">La disponibilidad de almacenes de datos NFS complementarios en Azure/AVS es definida por Microsoft. En primer lugar, es necesario determinar si tanto el AVS como el ANF están disponibles en una región específica. A continuación, debe determinar si el almacén de datos NFS suplementario ANF es compatible con esa región.</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">Compruebe la disponibilidad de AVS y ANF <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>.</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">Compruebe la disponibilidad del almacén de datos NFS complementario ANF <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>.</block>
  <block id="d7fe32206230432c446b09e24ab3f41a" category="doc">TR-4955: Recuperación ante desastres con FSX para ONTAP y VMC (cloud VMware de AWS)</block>
  <block id="e99df6551992d3c39b8c5e87ee8a451f" category="paragraph">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por los datos (por ejemplo, ransomware). Con la tecnología SnapMirror de NetApp, las cargas de trabajo de VMware en las instalaciones se pueden replicar en FSX para ONTAP ejecutándose en AWS.</block>
  <block id="c52f53db08961cb5fa061b55ca6812c7" category="paragraph">Disaster Recovery Orchestrator (DRO, una solución basada en scripts con la interfaz de usuario) se puede usar para recuperar sin problemas las cargas de trabajo replicadas desde las instalaciones a FSX para ONTAP. DRO automatiza la recuperación del nivel de SnapMirror, mediante el registro de VM en VMC, hasta las asignaciones de red directamente en NSX-T. Esta función está incluida en todos los entornos VMC.</block>
  <block id="273c8112241e399eaf04dc840d119fb6" category="image-alt">Este gráfico muestra la estructura y las interconexiones entre un centro de datos en las instalaciones, un cloud VMware en una instancia de AWS SDDC y Amazon FSX para ONTAP de NetApp. Entre ellas se incluyen la replicación de SnapMirror, el tráfico de Operaciones de recuperación ante desastres, Internet o conexión directa y VMware Transit Connect.</block>
  <block id="246c1b44b3a8dc5d7fec2fdc031e49c5" category="section-title">Implemente y configure VMware Cloud en AWS</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">VMware Cloud en AWS</block>
  <block id="f828dbeef2a459e165a6fbd33ccf4781" category="paragraph"><block ref="88a970f127e79f2a50f427561bb2a4f6" category="inline-link-macro-rx"></block> Proporciona una experiencia nativa del cloud para cargas de trabajo basadas en VMware en el ecosistema de AWS. Cada centro de datos definido por software (SDDC) de VMware se ejecuta en un cloud privado virtual de Amazon (VPC) y proporciona una pila completa de VMware (incluido vCenter Server), las redes definidas por software NSX-T, el almacenamiento definido por software VSAN y uno o más hosts ESXi que proporcionan recursos informáticos y de almacenamiento a las cargas de trabajo. Para configurar un entorno VMC en AWS, siga estos pasos <block ref="48c40480356563b3c93ca3177b91e728" category="inline-link-macro-rx"></block>. También se puede utilizar un clúster de luz piloto para la recuperación ante desastres.</block>
  <block id="c3b336e3bd0ee5f4a24fd28ce72d7dea" category="admonition">En la versión inicial, DRO admite un clúster de luces piloto existente. La creación bajo demanda de SDDC estará disponible en una próxima versión.</block>
  <block id="09a69d8335838329a7615e73fa6b1fe0" category="section-title">Aprovisionar y configurar FSX para ONTAP</block>
  <block id="37973daf609f18c7a64511d10e65453e" category="paragraph">Amazon FSX para ONTAP de NetApp es un servicio totalmente gestionado que ofrece un almacenamiento de archivos altamente fiable, escalable, de alto rendimiento y con numerosas funciones incorporado en el popular sistema de archivos ONTAP de NetApp. Siga estos pasos <block ref="a5f36f80544ed8547e72f1f36fb2285b" category="inline-link-macro-rx"></block> Para aprovisionar y configurar FSX para ONTAP.</block>
  <block id="7f38204cc308b0521e747e38f1cb0062" category="section-title">Poner en marcha y configurar SnapMirror a FSX para ONTAP</block>
  <block id="4a6b91648345db53156af03bcc00bde8" category="paragraph">El siguiente paso consiste en utilizar NetApp BlueXP y descubrir la instancia de FSX aprovisionada para ONTAP en AWS y replicar los volúmenes de almacenes de datos deseados de un entorno local a FSX para ONTAP con la frecuencia adecuada y la retención de copias Snapshot de NetApp:</block>
  <block id="6a4903522028d4e4bd24b3880afcf49f" category="image-alt">Este gráfico muestra el mapa de relaciones de lienzo de BlueXP que muestra las diversas interacciones entre los servicios activados.</block>
  <block id="45568e41c66e2e325c210961987178e7" category="paragraph">Siga los pasos de este enlace para configurar BlueXP. También puede utilizar la CLI de ONTAP de NetApp para programar la replicación a continuación de este enlace.</block>
  <block id="07f3fd5642ddcadbf716c250ccf987f0" category="admonition">Una relación de SnapMirror es un requisito previo y debe crearse previamente.</block>
  <block id="8513f47f7075dac35da070dbceb25a2e" category="section-title">Instalación DE DRO</block>
  <block id="9f8fa80dd85e2409bd0b4495b821f0f3" category="paragraph">Para empezar con DRO, utilice el sistema operativo Ubuntu en una instancia EC2 o máquina virtual designada para asegurarse de que cumple los requisitos previos. A continuación, instale el paquete.</block>
  <block id="7bf01cb2204f9dd0fdff029933600264" category="list-text">Asegúrese de que existe conectividad con la instancia de vCenter y los sistemas de almacenamiento de origen y de destino.</block>
  <block id="4c915967cda97460076cfdb71bc58421" category="list-text">La resolución DNS debe estar en su lugar si está utilizando nombres DNS. De lo contrario, se deben usar direcciones IP para las instancias de vCenter y los sistemas de almacenamiento.</block>
  <block id="3cfe50231d6e1ba1b199fc7421fb72e6" category="list-text">Crear un usuario con permisos raíz. También puede usar sudo con una instancia de EC2.</block>
  <block id="6e968857b32243865ebf039c1facf6cf" category="section-title">Requisitos de SO</block>
  <block id="b4fd1d48279ed0bed231fbd3b96a1e3a" category="list-text">Ubuntu 20.04 (LTS) con un mínimo de 2 GB y 4 vCPU</block>
  <block id="184e93a2064767475a538c600a47eb17" category="list-text">Se deben instalar los siguientes paquetes en el equipo virtual del agente designado:</block>
  <block id="1dfe00693fad27f5da719e6aeea58ef6" category="list-text">Composición de Docker</block>
  <block id="31b4674ec2f7760117c224c883183141" category="list-text">JQ</block>
  <block id="240f5270a2e18be8a75b0712b343d07a" category="paragraph">Cambiar permisos en<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block>:<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>.</block>
  <block id="76af5eb969b6b58ab010f271730ae0ee" category="admonition">La<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> el script ejecuta todos los requisitos previos necesarios.</block>
  <block id="478159949d5b4b537a6ca19613ae98bf" category="section-title">Instale el paquete</block>
  <block id="54d75811a77a2a9b1526f372bc0a733e" category="list-text">Descargue el paquete de instalación en la máquina virtual designada:</block>
  <block id="97c5338b12461548bb0ceefccd562486" category="admonition">El agente se puede instalar localmente o dentro de un VPC de AWS.</block>
  <block id="2d2a358ce62dfc056eddea09ea87d1d1" category="list-text">Descomprima el paquete, ejecute el script de implementación e introduzca la IP del host (por ejemplo, 10.10.10.10).</block>
  <block id="4e26021fda30753473246136bacc8094" category="list-text">Desplácese al directorio y ejecute el script de despliegue de la siguiente manera:</block>
  <block id="049e44fe327f7679318c6cf222207da7" category="list-text">Acceda a la interfaz de usuario mediante:</block>
  <block id="b7bd19f19df4ca5ef3102741951e7a1b" category="paragraph">con las siguientes credenciales predeterminadas:</block>
  <block id="d644796f5eb5712add7807df8829ee58" category="admonition">La contraseña se puede cambiar con la opción "Cambiar contraseña".</block>
  <block id="f1f49b31dc9a5d88e8029b9d361b9059" category="image-alt">Pantalla de inicio de sesión en el orquestador de recuperación ante desastres.</block>
  <block id="7b7ad84593d701138003778be3b6079f" category="section-title">Configuración DE DRO</block>
  <block id="e9ff74e9030350261c678f0da3a354ee" category="paragraph">Después de que los FSX para ONTAP y VMC se hayan configurado correctamente, puede empezar a configurar DRO para automatizar la recuperación de las cargas de trabajo en las instalaciones a VMC usando las copias SnapMirror de solo lectura en FSX para ONTAP.</block>
  <block id="0a99b6b57603a6a9f7dc56799a0fdd8e" category="paragraph">NetApp recomienda la puesta en marcha del agente DRO en AWS y también en el mismo VPC, en el que se ponga en marcha FSX para ONTAP (también puede estar conectado por la misma paridad), Para que el agente DRO pueda comunicarse a través de la red con sus componentes locales, así como con los recursos FSX para ONTAP y VMC.</block>
  <block id="c7c5a0daa14b8062f69791fd594efd37" category="paragraph">El primer paso es descubrir y añadir los recursos locales y cloud (tanto vCenter como almacenamiento) a la DRO. Abra DRO en un navegador compatible y utilice el nombre de usuario y la contraseña predeterminados (admin/admin) y Add Sites. También se pueden añadir sitios mediante la opción detectar. Añada las siguientes plataformas:</block>
  <block id="16ee49909b80df9050959890b8f578cb" category="list-text">En las instalaciones de vCenter</block>
  <block id="e7aed9ec7e7600627310e041dbd517f7" category="list-text">Sistema de almacenamiento ONTAP</block>
  <block id="e3691c446d2915370eb25cbc68a6521a" category="list-text">VCenter de VMC</block>
  <block id="36df1b975561708b246ef1801ea416e5" category="list-text">FSX para ONTAP</block>
  <block id="c532da281c4c378954b0254be09c051b" category="image-alt">Descripción temporal de la imagen del marcador de posición.</block>
  <block id="3506b8840bdbadcda795249c636510c4" category="image-alt">Página general DEL sitio DE DRO que contiene sitios de origen y destino.</block>
  <block id="cf5e0df8cb3adb3df51d336ec0b2211a" category="paragraph">Una vez añadida, DRO realiza la detección automática y muestra las máquinas virtuales con las réplicas de SnapMirror correspondientes desde el almacenamiento de origen a FSX para ONTAP. DRO detecta automáticamente las redes y los grupos de puertos utilizados por los equipos virtuales y los rellena.</block>
  <block id="abf7897bce5034c7714d0b7757ccac4c" category="image-alt">Pantalla de detección automática con 219 máquinas virtuales y 10 almacenes de datos.</block>
  <block id="8ad855ec9cdd9c029c645af01c256999" category="paragraph">El siguiente paso es agrupar los equipos virtuales necesarios en grupos funcionales para servir como grupos de recursos.</block>
  <block id="cdac0221d4dabd98123be4284952f872" category="section-title">Agrupaciones de recursos</block>
  <block id="7546309b604714e5c864eef677efcd63" category="paragraph">Después de añadir las plataformas, puede agrupar las máquinas virtuales que desea recuperar en grupos de recursos. LOS grupos de recursos DE DRO permiten agrupar un conjunto de máquinas virtuales dependientes en grupos lógicos que contienen sus órdenes de arranque, retrasos de arranque y validaciones de aplicaciones opcionales que se pueden ejecutar tras la recuperación.</block>
  <block id="265d81bb1af077020a501dcc75af41e1" category="paragraph">Para comenzar a crear grupos de recursos, complete los siguientes pasos:</block>
  <block id="a226ebee500532f5a9b1a5cbcb1db6d9" category="list-text">Acceda a *grupos de recursos* y haga clic en *Crear nuevo grupo de recursos*.</block>
  <block id="cfc3c82954c855841a78a216dec1b32b" category="list-text">En *Nuevo grupo de recursos*, seleccione el sitio de origen en la lista desplegable y haga clic en *Crear*.</block>
  <block id="c47c9ace957accd98c45c515282fb851" category="list-text">Proporcione *Detalles del grupo de recursos* y haga clic en *continuar*.</block>
  <block id="5e4c1f12f71cc535b41e76690fd718e3" category="list-text">Seleccione los equipos virtuales adecuados con la opción de búsqueda.</block>
  <block id="de5c4b583db3aa4040c8d082ee2d1bcd" category="list-text">Seleccione el orden de arranque y el retraso de arranque (segundos) para las máquinas virtuales seleccionadas. Para establecer el orden de encendido, seleccione cada máquina virtual y configure la prioridad para ella. Tres es el valor predeterminado para todas las máquinas virtuales.</block>
  <block id="c32b3a0f06aa80c00476ddcabd88fde1" category="paragraph">Las opciones son estas:</block>
  <block id="a89a043e6faeacde759612c6bfa5cc1c" category="paragraph">1 – la primera máquina virtual que se enciende 3 – valor predeterminado 5 – la última máquina virtual que se enciende</block>
  <block id="84a63bc4997af6ded1933281f4b8babb" category="list-text">Haga clic en *Crear grupo de recursos*.</block>
  <block id="0942dfbe3d3b0a1d41f357604f7e9fb2" category="image-alt">Captura de pantalla de la lista de grupos de recursos con dos entradas: Test y DemoRG1.</block>
  <block id="a8fc43ecd23ee9eb5e9efa5c60cb20b9" category="section-title">Planes de replicación</block>
  <block id="901831e404573eb9a2cc09f43d42e661" category="paragraph">Necesita un plan para recuperar las aplicaciones en caso de un desastre. Seleccione las plataformas de vCenter de origen y destino del menú desplegable y seleccione los grupos de recursos que se incluirán en este plan, junto con la agrupación de cómo deben restaurarse y encenderse las aplicaciones (por ejemplo, controladoras de dominio, después nivel 1, después nivel 2, etc.). Tales planes a veces también se denominan modelos. Para definir el plan de recuperación, vaya a la ficha *Plan de replicación* y haga clic en *Nuevo Plan de replicación*.</block>
  <block id="f2e437ba3d91f90c4bd8d4b35ce32b78" category="paragraph">Para comenzar a crear un plan de replicación, lleve a cabo los siguientes pasos:</block>
  <block id="7e2b1b88ae2fef26c3f9f94bc389f0d1" category="list-text">Acceda a *planes de replicación* y haga clic en *Crear nuevo plan de replicación*.</block>
  <block id="84ef8711a6a318c8bf4b8acfd4f1551c" category="image-alt">Captura de pantalla del plan de replicación que contiene un plan llamado DemoRP.</block>
  <block id="b9493784814dfebf88fc26091f72b601" category="list-text">En *Nuevo Plan de replicación*, proporcione un nombre para el plan y agregue asignaciones de recuperación seleccionando el sitio de origen, vCenter asociada, sitio de destino y vCenter asociada.</block>
  <block id="88cedf638ed2d7e4779e1c47ee7c5ea1" category="image-alt">Captura de pantalla de los detalles del plan de replicación, incluida la asignación de recuperación.</block>
  <block id="d360387ddbca9636208f2b8a948f56b0" category="list-text">Después de completar la asignación de recuperación, seleccione la asignación de clústeres.</block>
  <block id="57e1d9c7da09c1484785ce5de748a5a4" category="list-text">Seleccione *Detalles del grupo de recursos* y haga clic en *continuar*.</block>
  <block id="28a5e1b451c50affbe5e71d787ef2818" category="list-text">Establezca el orden de ejecución del grupo de recursos. Esta opción permite seleccionar la secuencia de operaciones cuando existen varios grupos de recursos.</block>
  <block id="35e931afb6f8f9ea976030c41d20091d" category="list-text">Una vez que haya terminado, seleccione la asignación de red al segmento apropiado. Los segmentos ya se deben aprovisionar dentro de VMC, así que seleccione el segmento adecuado para asignar la VM.</block>
  <block id="4279ce58393302704e1d9f4ef8e18ca2" category="list-text">Según la selección de las máquinas virtuales, las asignaciones de almacenes de datos se seleccionan automáticamente.</block>
  <block id="920e197d79d1f4f66caaef11426066ba" category="admonition">SnapMirror se encuentra en el nivel de volumen. Por lo tanto, todas las máquinas virtuales se replican en el destino de replicación. Asegúrese de seleccionar todas las máquinas virtuales que forman parte del almacén de datos. Si no se seleccionan, solo se procesan las máquinas virtuales que forman parte del plan de replicación.</block>
  <block id="76074b4a55fc86674d98cacd953dd720" category="list-text">Si se especifican los datos del equipo virtual, se puede modificar de forma opcional el tamaño de los parámetros de RAM y CPU del equipo virtual; esto puede resultar muy útil a la hora de recuperar entornos de gran tamaño en clústeres de destino más pequeños o realizar pruebas de recuperación ante desastres sin tener que aprovisionar una infraestructura de VMware física única. Además, puede modificar el orden de arranque y el retraso de arranque (segundos) para todas las máquinas virtuales seleccionadas entre los grupos de recursos. Existe una opción adicional para modificar el orden de arranque si se requieren cambios de los seleccionados durante la selección de orden de arranque del grupo de recursos. De forma predeterminada, se utiliza el orden de arranque seleccionado durante la selección de grupos de recursos; sin embargo, se pueden realizar modificaciones en esta fase.</block>
  <block id="61b06cf38207274281ff2f90f66b49fa" category="list-text">Haga clic en *Crear plan de replicación*.</block>
  <block id="8066d08fcf99bee6a3bb8bc060a5d031" category="paragraph">Una vez creado el plan de replicación, la opción de conmutación por error, la opción de conmutación por error de prueba o la opción de migración se pueden ejercer en función de los requisitos. Durante las opciones de conmutación por error y conmutación al nodo de respaldo, se utiliza la copia Snapshot de SnapMirror más reciente o se puede seleccionar una copia Snapshot específica de una copia Snapshot puntual (según la política de retención de SnapMirror). La opción de momento específico puede ser muy útil si se enfrenta a un evento de corrupción como ransomware, donde las réplicas más recientes ya están comprometidas o cifradas. DRO muestra todos los puntos disponibles en el tiempo. Para activar la conmutación por error o la conmutación por error de prueba con la configuración especificada en el plan de replicación, puede hacer clic en *failover* o *Prueba de conmutación por error*.</block>
  <block id="9f6a9153365f1438c116145bc14ba9a9" category="image-alt">En esta pantalla, se proporcionan los detalles de la snapshot para el volumen, donde se puede elegir entre utilizar la snapshot más reciente y seleccionar una snapshot específica.</block>
  <block id="45c261be0b43693546955e87bd6ac10f" category="paragraph">El plan de replicación se puede supervisar en el menú de tareas:</block>
  <block id="0225a4a711bba4eb595e835ad67356fc" category="image-alt">El menú de tareas muestra todos los trabajos y opciones del plan de replicación, y también le permite ver los registros.</block>
  <block id="8d2831d40faa91653285bd44edc3917d" category="paragraph">Después de activar la conmutación por error, los elementos recuperados pueden verse en el VMC vCenter (máquinas virtuales, redes y almacenes de datos). De forma predeterminada, las máquinas virtuales se recuperan en la carpeta de carga de trabajo.</block>
  <block id="d45215d9339daaa38e8c825812d30a02" category="paragraph">La conmutación por recuperación se puede activar en el nivel de plan de replicación. En el caso de una conmutación por error de prueba, se puede utilizar la opción de eliminación para revertir los cambios y eliminar la relación de FlexClone. La conmutación por recuperación relacionada con la conmutación por error es un proceso de dos pasos. Seleccione el plan de replicación y seleccione *sincronización inversa de datos*.</block>
  <block id="5f3ce61b7a4ffe23687402e421b81e18" category="image-alt">Captura de pantalla de la descripción general del plan de replicación con la opción de sincronización inversa de datos.</block>
  <block id="acd827a33a3e445ce9d2c9d94ff63886" category="paragraph">Una vez finalizada, puede activar la conmutación tras recuperación para volver a la instalación de producción original.</block>
  <block id="0c86039a87483290f146f9170e80b40b" category="image-alt">Captura de pantalla de la descripción general del plan de replicación con el menú desplegable que contiene la opción de conmutación por recuperación.</block>
  <block id="503c1e37074b31fdcd74fbffb13e3983" category="image-alt">Captura de pantalla de la página de resumen de DRO con el sitio de producción original en funcionamiento.</block>
  <block id="0d95c1c8686951d59b82bdc816a93231" category="paragraph">Desde BlueXP de NetApp vemos que el estado de la replicación se ha roto para los volúmenes adecuados (los asignados a VMC como volúmenes de lectura y escritura). Durante la conmutación al nodo de respaldo de prueba, DRO no asigna el volumen de destino o de réplica. En su lugar, realiza una copia FlexClone de la instancia de SnapMirror (o Snapshot) necesaria y expone la instancia de FlexClone, que no consume capacidad física adicional para FSX para ONTAP. Este proceso garantiza que el volumen no se modifique y que los trabajos de réplica puedan continuar incluso durante las pruebas de recuperación ante desastres o los flujos de trabajo de clasificación. Además, este proceso garantiza que, si se producen errores o se recuperan los datos dañados, la recuperación se puede limpiar sin riesgo de destrucción de la réplica.</block>
  <block id="648a04436d5621ca9c7c65c66c55cb79" category="section-title">Recuperación de ransomware</block>
  <block id="f1d63aa61bd9bd59550523eea84313e8" category="paragraph">Recuperarse del ransomware puede ser una tarea abrumadora. En concreto, a las organizaciones DE TI les puede resultar complicado identificar el punto de retorno seguro y, una vez determinado, proteger las cargas de trabajo recuperadas de ataques recurrentes, por ejemplo, de malware en suspensión o aplicaciones vulnerables.</block>
  <block id="c6ceeada99ad37301b94760e7f4bcab8" category="paragraph">DRO aborda estas preocupaciones al permitirle recuperar su sistema desde cualquier momento disponible. También puede recuperar cargas de trabajo en redes funcionales pero aisladas, de tal modo que las aplicaciones puedan funcionar y comunicarse entre sí en una ubicación en la que no estén expuestas al tráfico del norte al sur. Esto le da a su equipo de seguridad un lugar seguro para llevar a cabo los análisis forenses y asegurarse de que no hay malware oculto o dormido.</block>
  <block id="468a6beafe68b7f0e997ea3b22eaf021" category="list-text">El uso de la replicación SnapMirror eficiente y resiliente.</block>
  <block id="8dc2f1e4e39bbf8b271892846d90aee7" category="list-text">Recuperación en cualquier momento disponible con la retención de copias de Snapshot.</block>
  <block id="6aaf12643047ec9787cc07db9f7e812a" category="list-text">Automatización completa de todos los pasos necesarios para recuperar cientos o miles de equipos virtuales a partir de los pasos de almacenamiento, informática, red y validación de aplicaciones.</block>
  <block id="3067ce32bcf775ef4562f0900ee04ccf" category="list-text">Recuperación de la carga de trabajo con la tecnología FlexClone de ONTAP mediante un método que no cambia el volumen replicado.</block>
  <block id="6359f2b426c28e13cbb7b8382496081c" category="list-text">Evita el riesgo de que se dañen los datos para volúmenes o copias Snapshot.</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">Evita interrupciones de replicación durante los flujos de trabajo de pruebas de recuperación ante desastres.</block>
  <block id="cd08b15dd8bc6a19026ca47b4bcd618d" category="list-text">Uso potencial de datos de recuperación ante desastres con recursos de cloud computing para flujos de trabajo más allá de la recuperación ante desastres, como DevTest, pruebas de seguridad, pruebas de parches o actualizaciones, y pruebas de corrección.</block>
  <block id="7d73fdff5300d11e557be0d55023b8e8" category="list-text">Optimización de la CPU y la RAM para ayudar a reducir los costes del cloud al permitir la recuperación en clústeres informáticos más pequeños.</block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">Configuraciones compatibles para el multicloud híbrido de NetApp con VMware</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">Comprender las combinaciones para el soporte del almacenamiento de NetApp en los principales proveedores a hiperescala.</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*Invitado conectado*</block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">*Datastore NFS suplementario*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">*AWS*</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">ONTAP FSM de CVO<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">FSX ONTAP<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">*Azure*</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">CVO ANF<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="ef7615d9ff40c00e9893de8051347a72" category="cell">ANF<block ref="11e701f660af04a4005e56e6ac4b1c05" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">*GCP*</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CLOUD VOLUMES ONTAP<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="b577d5e5fe684be74c0fcbceb61e27d4" category="cell">CVS<block ref="2bc02f38a6be3889a69283e362618186" category="inline-link-macro-rx"></block></block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Ponga en marcha y configure el entorno de virtualización en Azure</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">Como en las instalaciones, la planificación de la solución VMware para Azure es crucial para tener un entorno listo para la producción con éxito a la hora de crear máquinas virtuales y migraciones.</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Para usar la solución VMware de Azure, registre primero el proveedor de recursos dentro de la suscripción identificada:</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Inicie sesión en el portal de Azure.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">En el menú del portal de Azure, seleccione todos los servicios.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">En el cuadro de diálogo todos los servicios, introduzca la suscripción y, a continuación, seleccione Suscripciones.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">Para verlo, seleccione la suscripción en la lista de suscripciones.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">Seleccione proveedores de recursos e introduzca Microsoft.AVS en la búsqueda.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">Si el proveedor de recursos no está registrado, seleccione Register.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">Una vez registrado el proveedor de recursos, cree un cloud privado de Azure VMware Solution mediante el portal de Azure.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">Seleccione Crear un nuevo recurso.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">En el cuadro de texto Buscar en el mercado, introduzca la solución VMware para Azure y selecciónela de los resultados.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">En la página Azure VMware Solution, seleccione Create.</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">En la ficha conceptos básicos, introduzca los valores en los campos y seleccione revisar + Crear.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">Notas:</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">Para un inicio rápido, reúna la información necesaria durante la fase de planificación.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">Seleccione un grupo de recursos existente o cree un nuevo grupo de recursos para el cloud privado. Un grupo de recursos es un contenedor lógico en el que se implementan y gestionan los recursos de Azure.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">Asegúrese de que la dirección CIDR sea única y no se superponga con otras redes virtuales de Azure o en las instalaciones. CIDR representa la red de gestión de nube privada y se utiliza para los servicios de gestión de clúster, como vCenter Server y NSX-T Manager. NetApp recomienda utilizar el espacio de direcciones /22. En este ejemplo, se utiliza 10.21.0.0/22.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">El proceso de aprovisionamiento dura entre 4 y 5 horas, aproximadamente. Una vez completado el proceso, compruebe que la implementación se realizó correctamente accediendo a la nube privada desde el portal de Azure. Se muestra el estado correcto cuando se completa la implementación.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Un cloud privado de una solución VMware Azure requiere una red virtual de Azure. Como la solución VMware Azure no es compatible con vCenter en las instalaciones, se requieren pasos adicionales para integrarse con un entorno local existente. También es necesario configurar un circuito ExpressRoute y una puerta de enlace de red virtual. Mientras se espera a que finalice el aprovisionamiento del clúster, cree una red virtual nueva o utilice una existente para conectarse a la solución VMware Azure.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">Para crear una nueva red virtual de Azure (vnet), seleccione la pestaña Azure vnet Connect. Como alternativa, puede crear una manualmente desde el portal de Azure mediante el asistente Create Virtual Network:</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Acceda a Azure VMware Solution Private Cloud y acceda a Connectivity en la opción Manage.</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Seleccione Azure vnet Connect.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">Para crear un nuevo vnet, seleccione la opción Crear nuevo.</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">Esta función permite conectar una vnet al cloud privado de la solución VMware para Azure. Vnet permite la comunicación entre cargas de trabajo en esta red virtual mediante la creación automática de los componentes necesarios (por ejemplo, buzón de entrada, servicios compartidos como Azure NetApp Files y Cloud Volume ONTAP) al cloud privado creado en la solución Azure VMware sobre ExpressRoute.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">*Nota:* el espacio de dirección vnet no debe superponerse con la nube privada CIDR.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">Proporcione o actualice la información del nuevo vnet y seleccione Aceptar.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">El vnet con el intervalo de direcciones y la subred de puerta de enlace proporcionados se crea en la suscripción designada y el grupo de recursos.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Configure las redes para su cloud privado de VMware en Azure</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">Si crea un vnet manualmente, cree un gateway de red virtual con el SKU y ExpressRoute adecuados como tipo de gateway. Una vez completada la puesta en marcha, conecte la conexión de ExpressRoute a la puerta de enlace de red virtual que contiene el cloud privado de la solución VMware de Azure mediante la clave de autorización. Para obtener más información, consulte <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="example-title">Validar la conexión de la red y acceso al cloud privado de la solución VMware Azure</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">La solución para VMware Azure no le permite gestionar un cloud privado con VMware vCenter en las instalaciones. En su lugar, se requiere el host de salto para conectarse a la instancia de Azure VMware Solution vCenter. Cree un host de salto en el grupo de recursos designado e inicie sesión en Azure VMware Solution vCenter. Este host de saltos debe ser una máquina virtual de Windows en la misma red virtual que se creó para tener conectividad y debe proporcionar acceso tanto a vCenter como a NSX Manager.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">Después de aprovisionar la máquina virtual, utilice la opción Connect para acceder a RDP.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">Inicie sesión en vCenter desde esta máquina virtual de host de salto recién creada mediante el usuario administrador de la nube . Para acceder a las credenciales, vaya al portal de Azure y vaya a Identity (en la opción Manage dentro de la nube privada). Desde aquí, se pueden copiar las URL y las credenciales de usuario del cloud privado vCenter y NSX-T Manager.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">En la máquina virtual Windows, abra un explorador y desplácese hasta la URL del cliente web de vCenter <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> y utilice el nombre de usuario admin como *cloudadmin@vsphere.locloc l* y pegue la contraseña copiada. De igual modo, también es posible acceder al administrador de NSX-T mediante la URL del cliente web <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> utilice el nombre de usuario admin y pegue la contraseña copiada para crear segmentos nuevos o modificar las puertas de enlace del nivel existente.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Las URL del cliente web son diferentes para cada SDDC aprovisionado.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">Configurar de forma conjunta los entornos locales en la solución Azure VMware</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">Ahora se pone en marcha y configura el SDDC de la solución para Azure VMware. Aproveche ExpressRoute Global REACH para conectar el entorno local al cloud privado de la solución VMware para Azure. Para obtener más información, consulte <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">Region Availability – almacén de datos NFS suplementario para ANF</block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por datos como ransomware. Con SnapMirror de NetApp, las cargas de trabajo de VMware en las instalaciones que utilizan el almacenamiento conectado a invitado se pueden replicar a Cloud Volumes ONTAP de NetApp que se ejecuta en Azure.</block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">Recuperación ante desastres con CVO y AVS (almacenamiento conectado a invitado)</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">Autores: Ravi BCB y Niyaz Mohamed, NetApp</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por datos como ransomware. Con SnapMirror de NetApp, las cargas de trabajo de VMware en las instalaciones que utilizan el almacenamiento conectado a invitado se pueden replicar a Cloud Volumes ONTAP de NetApp que se ejecuta en Azure. Así se tratan los datos de aplicaciones; sin embargo, ¿qué ocurre con los equipos virtuales mismos? La recuperación ante desastres debería cubrir todos los componentes dependientes, incluidos equipos virtuales, VMDK, datos de aplicaciones, etc. Para ello, SnapMirror y JetStream pueden utilizarse para recuperar sin problemas cargas de trabajo replicadas de las instalaciones a Cloud Volumes ONTAP utilizando almacenamiento VSAN para VMDK de VM.</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">Este documento proporciona un enfoque paso a paso para configurar y realizar la recuperación ante desastres que utiliza SnapMirror, JetStream y la solución Azure VMware (AVS) de NetApp.</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">Supuestos</block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">Este documento se centra en el almacenamiento invitado para datos de aplicaciones (también conocido como «guest» conectado) y asumimos que el entorno local utiliza SnapCenter para realizar backups coherentes con las aplicaciones.</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">Este documento es aplicable a cualquier solución de backup o recuperación de terceros. Dependiendo de la solución utilizada en el entorno, siga las prácticas recomendadas para crear normativas de backup que cumplan los acuerdos de nivel de servicio de la organización.</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">Para obtener conectividad entre el entorno local y la red virtual de Azure, utilice el alcance global de la ruta Express o una WAN virtual con una puerta de enlace VPN. Los segmentos se deben crear en función del diseño VLAN en las instalaciones.</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">Existen múltiples opciones para conectar los centros de datos en las instalaciones a Azure, lo que nos impide esbozar un flujo de trabajo específico en este documento. Consulte la documentación de Azure para conocer el método de conectividad apropiado entre las instalaciones y Azure.</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">Implementar la solución DR</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">Descripción general de la puesta en marcha de soluciones</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">Asegúrese de que se realiza el backup de los datos de la aplicación mediante SnapCenter con los requisitos de punto de recuperación necesarios.</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">Aprovisione Cloud Volumes ONTAP con el tamaño de instancia correcto usando Cloud Manager dentro de la suscripción y la red virtual adecuadas.</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">Configurar SnapMirror para los volúmenes correspondientes de las aplicaciones.</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">Actualice las políticas de backup en SnapCenter para activar actualizaciones de SnapMirror después de los trabajos programados.</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">Instale el software de recuperación ante desastres JetStream en el centro de datos local y comience la protección de las máquinas virtuales.</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">Instalar el software de recuperación ante desastres JetStream en el cloud privado de Azure VMware Solution.</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">Durante un evento de desastre, rompa la relación de SnapMirror con Cloud Manager y active la conmutación por error de máquinas virtuales a Azure NetApp Files o a almacenes de datos VSAN en el sitio de recuperación ante desastres AVS designado.</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">Vuelva a conectar las LUN ISCSI y los montajes NFS para los equipos virtuales de la aplicación.</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">Invoque la conmutación tras recuperación al sitio protegido mediante la resincronización inversa de SnapMirror una vez que se haya recuperado el sitio principal.</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">Detalles de la implementación</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">Configurar CVO en Azure y replicar volúmenes a CVO</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">Enlace</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">El primer paso es configurar Cloud Volumes ONTAP en Azure <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>) Y replicar los volúmenes deseados en Cloud Volumes ONTAP con las frecuencias y retentions de instantánea deseadas.</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">Configurar los hosts AVS y el acceso a datos CVO</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">Dos factores importantes que se deben tener en cuenta al implementar el SDDC son el tamaño del clúster en la solución Azure VMware y el tiempo que se debe mantener el SDDC en servicio. Estas dos consideraciones clave para una solución de recuperación ante desastres ayudan a reducir los costes operativos generales. SDDC puede ser de tan solo tres hosts, hasta un clúster de varios hosts en una puesta en marcha a escala completa.</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">La decisión de poner en marcha un clúster AVS se basa principalmente en los requisitos de RPO/RTO. Con la solución para Azure VMware, el SDDC se puede aprovisionar justo a tiempo como preparación para pruebas o ante un desastre real. Un SDDC implementado en el tiempo ahorra en costes de host ESXi cuando no se enfrenta a un desastre. Sin embargo, esta forma de puesta en marcha afecta al objetivo de tiempo de recuperación en unas pocas horas, mientras que se aprovisiona SDDC.</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">La opción más común implementada es tener SDDC en funcionamiento en un modo de funcionamiento siempre activo y con luz piloto. Esta opción proporciona una huella pequeña de tres hosts siempre disponibles y también acelera las operaciones de recuperación, ya que proporciona una línea de base en ejecución para las actividades de simulación y comprobaciones de cumplimiento de normativas, lo que evita el riesgo de que se produzca una desviación operativa entre los sitios de producción y de recuperación ante desastres. El grupo piloto se puede escalar verticalmente rápidamente hasta el nivel deseado cuando es necesario para gestionar un evento de recuperación ante desastres real.</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">Para configurar AVS SDDC (ya sea a petición o en modo piloto), consulte<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>. Como requisito previo, verifique que los equipos virtuales invitados que residen en los hosts AVS pueden consumir datos de Cloud Volumes ONTAP una vez establecida la conectividad.</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Una vez que Cloud Volumes ONTAP y AVS se hayan configurado correctamente, comience a configurar JetStream para automatizar la recuperación de las cargas de trabajo en las instalaciones en AVS (VM con VMDK de aplicación y equipos virtuales con almacenamiento en invitado) mediante el mecanismo VAIO y aprovechando SnapMirror para copias de volúmenes de aplicación en Cloud Volumes ONTAP.</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">Instalar JetStream DR en el centro de datos local</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">El software JetStream DR consta de tres componentes principales: JetStream DR Management Server Virtual Appliance (MSA), DR Virtual Appliance (DRVA) y componentes host (paquetes de filtros de I/o). MSA se utiliza para instalar y configurar componentes host en el cluster informático y, a continuación, administrar el software JetStream DR. El proceso de instalación es el siguiente:</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">Compruebe los requisitos previos.</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">Ejecute la herramienta de planificación de la capacidad para realizar recomendaciones de recursos y configuración.</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">Implemente JetStream DR MSA en cada host de vSphere en el clúster designado.</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">Inicie MSA usando su nombre DNS en un explorador.</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">Registre el servidor vCenter con el MSA.</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">Una vez que se haya puesto en marcha JetStream DR MSA y se haya registrado vCenter Server, desplácese hasta el complemento de recuperación ante desastres JetStream con vSphere Web Client. Para ello, vaya a Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">Desde la interfaz DR de JetStream, realice las siguientes tareas:</block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">Configure el clúster con el paquete de filtro de I/O.</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">Añada el almacenamiento de Azure Blob que está situado en el sitio de recuperación.</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">Implemente el número necesario de dispositivos virtuales de recuperación ante desastres (DRVAs) desde la ficha Appliances (dispositivos virtuales).</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">Utilice la herramienta de planificación de la capacidad para calcular el número de DRVAs necesarios.</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">Cree volúmenes de registro de replicación para cada DRVA utilizando el VMDK desde los almacenes de datos disponibles o el pool de almacenamiento iSCSI compartido independiente.</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">En la pestaña Protected Domains, cree la cantidad necesaria de dominios protegidos utilizando información acerca del sitio de Azure Blob Storage, la instancia de DRVA y el registro de replicación. Un dominio protegido define una máquina virtual o un conjunto específico de máquinas virtuales de aplicación dentro del clúster que se protegen en conjunto y asignó un orden de prioridad para las operaciones de conmutación por error y conmutación tras recuperación.</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">Seleccione las máquinas virtuales que se van a proteger y agrupe las máquinas virtuales en grupos de aplicaciones en función de la dependencia. Las definiciones de aplicaciones le permiten agrupar conjuntos de máquinas virtuales en grupos lógicos que contengan sus órdenes de arranque, retrasos de arranque y validaciones de aplicaciones opcionales que se pueden ejecutar tras la recuperación.</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">Asegúrese de que se utilice el mismo modo de protección para todas las máquinas virtuales de un dominio protegido.</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">El modo Write-Back (VMDK) ofrece un mayor rendimiento.</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">Asegúrese de que los volúmenes de registros de replicación se colocan en un almacenamiento de alto rendimiento.</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">Una vez que haya terminado, haga clic en Iniciar protección para el dominio protegido. Esto inicia la replicación de datos de las máquinas virtuales seleccionadas en el almacén BLOB designado.</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">Una vez finalizada la replicación, el estado de protección del equipo virtual se Marca como recuperable.</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">Los runbooks pueden configurarse para agrupar los equipos virtuales (denominados «grupo de recuperación»), establecer la secuencia de órdenes de arranque y modificar la configuración de CPU/memoria junto con las configuraciones de IP.</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">Haga clic en Configuración y, a continuación, en el enlace Configurar libro de ejecución para configurar el grupo de libro de ejecución.</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">Haga clic en el botón Crear grupo para comenzar a crear un nuevo grupo runbook.</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">Si es necesario, en la parte inferior de la pantalla, aplique scripts previos y posteriores personalizados para que se ejecuten automáticamente antes y después del funcionamiento del grupo runbook. Asegúrese de que los scripts de Runbook residen en el servidor de administración.</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">Edite la configuración de la máquina virtual según sea necesario. Especifique los parámetros para recuperar las VM, incluida la secuencia de arranque, el retraso de arranque (especificado en segundos), el número de CPU y la cantidad de memoria que se debe asignar. Cambie la secuencia de arranque de las VM haciendo clic en las flechas arriba o abajo. También se proporcionan opciones para conservar MAC.</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">Las direcciones IP estáticas pueden configurarse manualmente para las máquinas virtuales individuales del grupo. Haga clic en el enlace NIC View de una máquina virtual para configurar manualmente las opciones de su dirección IP.</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">Haga clic en el botón Configure para guardar los ajustes de NIC de los equipos virtuales correspondientes.</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">El estado de los runbooks de conmutación por error y conmutación por recuperación se muestra ahora como configurado. Los grupos de runbooks de conmutación por error y conmutación tras recuperación se crean en parejas utilizando el mismo grupo inicial de máquinas virtuales y configuraciones. Si es necesario, la configuración de cualquier grupo runbook se puede personalizar individualmente haciendo clic en el vínculo Detalles correspondiente y realizando cambios.</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">Instale JetStream DR para AVS en la nube privada</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">Una práctica recomendada para un sitio de recuperación (AVS) es crear un clúster de tres nodos de luz piloto con antelación. Esto permite configurar la infraestructura del centro de recuperación, lo que incluye lo siguiente:</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">Segmentos de red de destino, firewalls, servicios como DHCP y DNS, etc.</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">Instalación de JetStream DR para AVS</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">La configuración de volúmenes ANF como almacenes de datos y mucho más</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR admite un modo RTO casi cero para los dominios de misión crítica. Para estos dominios, el almacenamiento de destino debe estar preinstalado. ANF es un tipo de almacenamiento recomendado en este caso.</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">La configuración de la red, incluida la creación de segmentos, se debe configurar en el clúster AVS para que coincida con los requisitos en las instalaciones.</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">Según los requisitos del acuerdo de nivel de servicio y el objetivo de tiempo de recuperación, puede utilizar la conmutación por error continua o el modo de conmutación por error normal (estándar). Para lograr un objetivo de tiempo de recuperación cercano a cero, debe comenzar una rehidratación continua en el sitio de recuperación.</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Para instalar JetStream DR para AVS en un cloud privado de Azure VMware Solution, utilice el comando Run. En el portal de Azure, vaya a la solución VMware de Azure, seleccione la nube privada y seleccione Ejecutar comando &gt; Paquetes &gt; JSDR.Configuration.</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">El usuario CloudAdmin predeterminado de la solución VMware de Azure no tiene suficientes privilegios para instalar JetStream DR para AVS. La solución Azure VMware permite una instalación simplificada y automatizada de la recuperación ante desastres de JetStream mediante la llamada al comando Azure VMware Solution Run para la recuperación ante desastres de JetStream.</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">La siguiente captura de pantalla muestra la instalación mediante una dirección IP basada en DHCP.</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">Una vez finalizada la instalación de JetStream DR para AVS, actualice el explorador. Para acceder a la interfaz de usuario de recuperación ante desastres de JetStream, vaya a SDDC Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">Añada la cuenta de Azure Blob Storage que se utilizó para proteger el clúster local como sitio de almacenamiento y, a continuación, ejecute la opción Scan Domains.</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">En la ventana emergente de diálogo que aparece, seleccione el dominio protegido que desea importar y, a continuación, haga clic en el vínculo Importar.</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">El dominio se importa para la recuperación. Vaya a la ficha Dominios protegidos y compruebe que el dominio deseado se ha seleccionado o elija el que desee en el menú Seleccionar dominio protegido. Se muestra una lista de las máquinas virtuales recuperables del dominio protegido.</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">Después de importar los dominios protegidos, implemente dispositivos DRVA.</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">Estos pasos también se pueden automatizar mediante planes creados por CPT.</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">Cree volúmenes de registros de replicación con almacenes de datos VSAN o ANF disponibles.</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">Importe los dominios protegidos y configure el va de recuperación para utilizar un almacén de datos ANF para las ubicaciones de las máquinas virtuales.</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">Asegúrese de que DHCP está habilitado en el segmento seleccionado y de que hay suficientes IP disponibles. Las IP dinámicas se utilizan temporalmente mientras se recuperan los dominios. Cada VM que se recupera (incluida la rehidratación continua) requiere una IP dinámica individual. Una vez finalizada la recuperación, se libera la IP y se puede volver a utilizar.</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">Seleccione la opción de conmutación por error adecuada (conmutación por error continua o conmutación por error). En este ejemplo, se selecciona la rehidratación continua (conmutación por error continua).</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">Aunque los modos de conmutación por error continua y conmutación por error varían cuando se realiza la configuración, ambos modos de conmutación por error se configuran siguiendo los mismos pasos. Los pasos de conmutación por error se configuran y se realizan de forma conjunta en respuesta a un evento de desastre. La conmutación por error continua se puede configurar en cualquier momento y luego se puede ejecutar en segundo plano durante el funcionamiento normal del sistema. Una vez ocurrido un evento de desastre, la conmutación al respaldo continua se completa para transferir inmediatamente la propiedad de las máquinas virtuales protegidas al sitio de recuperación (objetivo de tiempo de recuperación cercano a cero).</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">El proceso de conmutación al respaldo continua comienza y su progreso se puede supervisar desde la interfaz de usuario. Al hacer clic en el icono azul de la sección Paso actual se muestra una ventana emergente que muestra los detalles del paso actual del proceso de conmutación por error.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">Conmutación por error y conmutación por recuperación</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">Cuando se produce un desastre en el clúster protegido del entorno local (fallo parcial o completo), puede activarse la conmutación por error para máquinas virtuales mediante Jetstream tras romper la relación de SnapMirror con los volúmenes de aplicaciones correspondientes.</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">Este paso puede automatizarse fácilmente para facilitar el proceso de recuperación.</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">Acceda a Jetstream UI en AVS SDDC (destino) y active la opción de recuperación tras fallos para completar la recuperación tras fallos. La barra de tareas muestra el progreso de las actividades de failover.</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">En la ventana de diálogo que aparece al finalizar la conmutación por error, la tarea de conmutación por error se puede especificar como planificada o se supone que se fuerza.</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">La conmutación por error forzada asume que el sitio principal ya no está accesible y que el sitio de recuperación debería asumir directamente la propiedad del dominio protegido.</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">Una vez finalizada la conmutación por error continua, aparece un mensaje que confirma la finalización de la tarea. Una vez finalizada la tarea, acceda a los equipos virtuales recuperados para configurar sesiones ISCSI o NFS.</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">El modo de recuperación tras fallos cambia a ejecutarse en Failover y el estado del equipo virtual es recuperable. Todas las máquinas virtuales del dominio protegido ahora se ejecutan en el sitio de recuperación con el estado especificado por la configuración de runbook para conmutación por error.</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">Para verificar la configuración de recuperación tras fallos y la infraestructura, JetStream puede utilizarse en modo de prueba (opción de conmutación por error de prueba) para observar la recuperación de máquinas virtuales y sus datos desde el almacén de objetos en un entorno de recuperación de pruebas. Cuando se ejecuta un procedimiento de conmutación por error en el modo de prueba, su operación se asemeja a un proceso de conmutación por error real.</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">Después de recuperar las máquinas virtuales, utilice la recuperación ante desastres de almacenamiento para el almacenamiento invitado. Para demostrar este proceso, se utiliza SQL Server en este ejemplo.</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">Inicie sesión en el SnapCenter VM recuperado en AVS SDDC y habilite el modo de recuperación ante desastres.</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">Acceda a la interfaz de usuario de SnapCenter mediante el comando browserN.</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">En la página Settings, vaya a Settings &gt; Global Settings &gt; Disaster Recovery.</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">Seleccione Enable Disaster Recovery.</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">Haga clic en Apply.</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">Compruebe si el trabajo de recuperación ante desastres está habilitado. Para ello, haga clic en Monitor &gt; Jobs.</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">NetApp SnapCenter 4.6 o posterior deben utilizarse para la recuperación ante desastres de almacenamiento. En las versiones anteriores, se deben utilizar snapshots coherentes con la aplicación (replicados mediante SnapMirror) y se debe ejecutar la recuperación manual en caso de que los backups anteriores se recuperen en el centro de recuperación ante desastres.</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">Asegúrese de que la relación de SnapMirror esté rota.</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Asociar la LUN de Cloud Volumes ONTAP a la máquina virtual invitada de SQL recuperada con las mismas letras de unidad.</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">Abra el iniciador iSCSI, borre la sesión desconectada anterior y añada el nuevo destino junto con la multivía para los volúmenes Cloud Volumes ONTAP replicados.</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">Asegúrese de que todos los discos están conectados utilizando las mismas letras de unidad que se usaron antes de la recuperación ante desastres.</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">Reinicie el servicio del servidor MSSQL.</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">Asegúrese de que los recursos SQL vuelven a estar en línea.</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">En el caso de NFS, asocie los volúmenes con el comando Mount y actualice el<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> entradas.</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">En este momento, pueden ejecutarse las operaciones y el negocio continúa de forma normal.</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">En el extremo de NSX-T, es posible crear una pasarela de nivel 1 dedicada separada para simular escenarios de conmutación por error. De este modo, se garantiza que todas las cargas de trabajo se puedan comunicar entre sí, pero que ningún tráfico pueda enrutarse tanto dentro como fuera del entorno, de modo que las tareas de clasificación, contención o endurecimiento se puedan realizar sin riesgo de contaminación cruzada. Esta operación se encuentra fuera del alcance de este documento, pero se puede realizar fácilmente para simular el aislamiento.</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">Una vez que la instalación principal esté activa y en funcionamiento de nuevo, puede realizar la conmutación tras recuperación. JetStream reanuda la protección de máquinas virtuales y debe revertirse la relación de SnapMirror.</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">Restaure el entorno de sus instalaciones. En función del tipo de incidente de desastre, podría ser necesario restaurar o verificar la configuración del clúster protegido. Si es necesario, puede que sea necesario volver a instalar el software JetStream DR.</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">Acceda al entorno local restaurado, vaya a la interfaz de usuario de recuperación ante desastres de Jetstream y seleccione el dominio protegido adecuado. Una vez que el sitio protegido esté listo para la conmutación tras recuperación, seleccione la opción de conmutación por recuperación en la interfaz de usuario.</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">El plan de conmutación por recuperación generado por CPT también se puede usar para iniciar la devolución de los equipos virtuales y sus datos del almacén de objetos al entorno VMware original.</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">Especifique la demora máxima después de pausar las máquinas virtuales en el sitio de recuperación y reiniciarlas en el sitio protegido. El tiempo necesario para completar este proceso incluye la finalización de la replicación tras detener la conmutación por error de las máquinas virtuales, el tiempo necesario para limpiar el sitio de recuperación y el tiempo necesario para recrear las máquinas virtuales en el sitio protegido. NetApp recomienda 10 minutos.</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">Completar el proceso de conmutación tras recuperación y, a continuación, confirmar la reanudación de la protección de los equipos virtuales y la consistencia de datos.</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">Una vez recuperados los equipos virtuales, desconecte el almacenamiento secundario del host y conéctelo al almacenamiento principal.</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">Compruebe que los recursos de SQL vuelven a estar en línea.</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">Para volver a realizar la conmutación tras recuperación al almacenamiento principal, asegúrese de que la dirección de la relación sigue siendo la misma que antes de la conmutación por error realizando una operación de resincronización inversa.</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">Para conservar las funciones de almacenamiento primario y secundario después de la operación de resincronización inversa, vuelva a realizar la operación de resincronización inversa.</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">Este proceso es aplicable a otras aplicaciones como Oracle, tipos de base de datos similares y cualquier otra aplicación que utilice almacenamiento conectado a «guest».</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">Como siempre, probar los pasos necesarios para recuperar las cargas de trabajo críticas antes de ponerlas en producción.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">Ventajas de esta solución</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">Usa la replicación eficiente y resiliente de SnapMirror.</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">Recupera a cualquier punto disponible en el tiempo con la retención de copias Snapshot de ONTAP.</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">Existe una automatización completa a disposición de todos los pasos necesarios para recuperar de cientos a miles de VM, desde los pasos de almacenamiento, computación, red y validación de aplicaciones.</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter utiliza mecanismos de clonado que no cambian el volumen replicado.</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">Esto evita el riesgo de daños en los datos de los volúmenes y las Snapshot.</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">Aprovecha los datos de recuperación ante desastres para flujos de trabajo que van más allá de la recuperación ante desastres, como las fases de desarrollo y pruebas, pruebas de seguridad, pruebas de parches y actualizaciones, y pruebas para solucionar problemas.</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">La optimización de la CPU y la RAM puede ayudar a reducir los costes del cloud al permitir la recuperación en clústeres informáticos más pequeños.</block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Funcionalidades de NetApp para Azure AVS</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">Obtenga más información acerca de las funcionalidades que NetApp aporta a la solución VMware de Azure (AVS): Desde NetApp como dispositivo de almacenamiento conectado a invitado o un almacén de datos NFS complementario a la migración de flujos de trabajo, ampliando o rebosando al cloud, backup/restauración y recuperación ante desastres.</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">Para ir a la sección del contenido deseado, seleccione una de las siguientes opciones:</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="inline-link-macro">Configuración de AVS en Azure</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="inline-link-macro">Opciones de almacenamiento de NetApp para AVS</block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">Soluciones cloud de NetApp/VMware</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">Al igual que en las instalaciones, la planificación de un entorno de virtualización basado en cloud es crucial para tener un entorno preparado para la producción con éxito a la hora de crear equipos virtuales y migración.</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">El almacenamiento de NetApp se puede utilizar de varias maneras, ya sea como almacenamiento de datos NFS complementario o conectado, en Azure AVS.</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">Opciones de almacenamiento de NetApp admitidas</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">Visite <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">Casos de uso de soluciones</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">Con las soluciones cloud de NetApp y VMware, la puesta en marcha en Azure AVS resulta sencilla en muchos casos de uso. Los casos de ingenieros de sistemas se definen para cada una de las áreas cloud definidas de VMware:</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">Protect (incluye recuperación ante desastres y backup/restauración)</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">Extender</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="list-text">Migración</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Examine las soluciones de NetApp para Azure AVS</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Opción complementaria de almacén de datos NFS en Azure</block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">La compatibilidad con almacenes de datos NFS se introdujo con ESXi versión 3 en implementaciones locales, que amplió en gran medida las funcionalidades de almacenamiento de vSphere.</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">Ejecutar vSphere en NFS es una opción ampliamente adoptada para puestas en marcha de virtualización en las instalaciones porque ofrece un gran rendimiento y estabilidad. Si tiene un almacenamiento conectado a la red (NAS) significativo en un centro de datos en las instalaciones, debería plantearse la puesta en marcha de una solución de VMware para Azure SDDC en Azure con almacenes de datos de archivo de NetApp para superar los retos de capacidad y rendimiento.</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99 %</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files se basa en el software de gestión de datos ONTAP de NetApp, líder en el sector y altamente disponible. Los servicios de Microsoft Azure se agrupan en tres categorías: Fundamental, principal y especializado. Azure NetApp Files se encuentra en la categoría especializada y cuenta con el respaldo de un hardware ya implementado en muchas regiones. Con la característica de alta disponibilidad incorporada, Azure NetApp Files protege los datos de la mayoría de las interrupciones y ofrece un SLA líder del sector de<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> siempre activo.</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Antes de la introducción de la funcionalidad de almacén de datos de Azure NetApp Files, la operación de escalado horizontal para clientes que planean alojar el rendimiento de host y cargas de trabajo con uso intensivo del almacenamiento necesitaba la ampliación de la computación y del almacenamiento.</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">Se deben tener en cuenta los siguientes problemas:</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">No se recomienda equilibrar las configuraciones de clúster en un clúster SDDC. Por tanto, ampliar el almacenamiento significa añadir más hosts, lo que implica más TCO.</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">Solo es posible un entorno VSAN. Por lo tanto, todo el tráfico de almacenamiento compite directamente con las cargas de trabajo de producción.</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">No existe ninguna opción para proporcionar varios niveles de rendimiento con el fin de alinear los requisitos de las aplicaciones, el rendimiento y el coste.</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">Es fácil llegar a los límites de la capacidad de almacenamiento para VSAN que se basa en hosts de clúster.al integrar ofertas de plataforma como servicio (PaaS) nativa de Azure, como Azure NetApp Files como almacén de datos, Los clientes tienen la opción de escalar su almacenamiento de forma independiente y solo pueden añadir nodos informáticos al clúster SDDC según sea necesario. Esta capacidad supera los retos indicados anteriormente.</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">Azure NetApp Files también permite poner en marcha varios almacenes de datos, lo cual ayuda a imitar un modelo de puesta en marcha en las instalaciones. Para ello, se deben colocar los equipos virtuales en el almacén de datos adecuado y asignar el nivel de servicio necesario para cumplir los requisitos de rendimiento de las cargas de trabajo. Gracias a la funcionalidad única de compatibilidad multiprotocolo, el almacenamiento «guest» es una opción adicional para las cargas de trabajo de base de datos como SQL y Oracle, al tiempo que utiliza la funcionalidad complementaria de almacén de datos NFS para alojar los VMDK restantes. Además de esto, la función nativa de copias Snapshot le permite realizar un backup rápido y restauraciones granulares.</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">Póngase en contacto con Azure y los arquitectos de soluciones de NetApp para planificar y ajustar el tamaño del almacenamiento y determinar el número necesario de hosts. NetApp recomienda identificar los requisitos de rendimiento del almacenamiento antes de finalizar la distribución del almacén de datos para las puestas en marcha de pruebas, pruebas de concepto y producción.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">Arquitectura detallada</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">Desde una perspectiva de alto nivel, esta arquitectura describe cómo lograr una conectividad con el cloud híbrido y portabilidad de aplicaciones entre entornos locales y Azure. También describe el uso de Azure NetApp Files como almacén de datos NFS complementario y como una opción de almacenamiento en invitado para máquinas virtuales invitadas alojadas en la solución VMware de Azure.</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="section-title">Ajuste de tamaño</block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">El aspecto más importante de la migración o la recuperación ante desastres es determinar el tamaño correcto para el entorno de destino. Es muy importante comprender cuántos nodos se necesitan para acomodar un ejercicio de ascensor y cambiar de las instalaciones a la solución VMware para Azure.</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">Para ajustar el tamaño, utilice los datos históricos del entorno local con RVTools (opción preferida) u otras herramientas como Live Optics o Azure Migrate. RVTools es una herramienta ideal para capturar el vCPU, vmem, vDisk y toda la información necesaria, incluyendo los equipos virtuales encendidos o apagados, para caracterizar el entorno de destino.</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">Para ejecutar RVtools, lleve a cabo los siguientes pasos:</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">Descargue e instale RVTools.</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">Ejecute RVTools, introduzca la información necesaria para conectarse al vCenter Server local y pulse Login.</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">Exportar el inventario a una hoja de cálculo de Excel.</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">Edite la hoja de datos y elimine los equipos virtuales que no sean candidatos idóneos de la pestaña vInfo. Este método proporciona un claro resultado sobre los requisitos de almacenamiento que se pueden utilizar para ajustar el tamaño del clúster de VMware SDDC de Azure con el número necesario de hosts.</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">Las máquinas virtuales «guest» utilizadas con el almacenamiento «en invitado» se deben calcular por separado. Sin embargo, Azure NetApp Files puede cubrir fácilmente la capacidad de almacenamiento adicional, por lo que mantiene el TCO general bajo.</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Implementar y configurar la solución VMware para Azure</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">Al igual que en las instalaciones, planificar una solución VMware para Azure es crucial para un entorno listo para la producción con éxito a la hora de crear máquinas virtuales y migraciones.</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">En esta sección se describe cómo configurar y gestionar AVS para su uso en combinación con Azure NetApp Files como almacén de datos con almacenamiento en invitado también.</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">El proceso de configuración se puede dividir en tres partes:</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">Registre el proveedor de recursos y cree un cloud privado.</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">Conéctese a una puerta de enlace de red virtual ExpressRoute nueva o existente.</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">Validar la conectividad de red y acceder al cloud privado. Consulte este apartado <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> En un tutorial paso a paso del proceso de aprovisionamiento SDDC de la solución Azure VMware.</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Configure Azure NetApp Files con la solución VMware para Azure</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">La nueva integración entre Azure NetApp Files permite crear almacenes de datos NFS mediante las API del proveedor de recursos de la solución VMware para Azure/CLI con volúmenes Azure NetApp Files y montar los almacenes de datos en los clústeres de su elección en un cloud privado. Además de alojar el equipo virtual y los VMDK de aplicaciones, los volúmenes de archivos de Azure NetApp también se pueden montar a partir de máquinas virtuales creadas en el entorno SDDC de la solución para VMware Azure. Los volúmenes se pueden montar en el cliente Linux y asignar en un cliente Windows, ya que Azure NetApp Files admite los protocolos Server Message Block (SMB) y Network File System (NFS).</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">Para obtener un rendimiento óptimo, implemente Azure NetApp Files en la misma zona de disponibilidad que el cloud privado. Al colocar con la ruta rápida Express, se obtiene el mejor rendimiento con una latencia de red mínima.</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Para adjuntar un volumen de archivos Azure NetApp como almacén de datos VMware de un cloud privado de la solución VMware Azure, asegúrese de cumplir los siguientes requisitos previos.</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">Utilice el inicio de sesión de az y valide que la suscripción está registrada en la función CloudSanExperience del espacio de nombres Microsoft.AVS.</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">Si no está registrado, regístrese.</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">La inscripción puede tardar aproximadamente 15 minutos en completarse.</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">Para comprobar el estado del registro, ejecute el siguiente comando.</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">Si el registro se bloquea en un estado intermedio durante más de 15 minutos, cancele el registro y vuelva a registrar el indicador.</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">Compruebe que la suscripción está registrada en la función AnfDatastoreExperience del espacio de nombres Microsoft.AVS.</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">Compruebe que la extensión vmware esté instalada.</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">Si la extensión ya está instalada, compruebe que la versión es 3.0.0. Si se ha instalado una versión anterior, actualice la extensión.</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">Si la extensión no está instalada, instálela.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="example-title">Cree y monte volúmenes de Azure NetApp Files</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Inicie sesión en el portal de Azure y acceda a Azure NetApp Files. Verifique el acceso al servicio Azure NetApp Files y registre el proveedor de recursos de Azure NetApp Files mediante la<block ref="37ac6d6acd87f35d4712fb725270d9df" prefix=" " category="inline-code"></block><block ref="d6c188468a5654ff07f3d8da04d06877" prefix=" " category="inline-code"></block> comando. Después del registro, cree una cuenta de NetApp. Consulte este apartado<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> para conocer los pasos detallados.</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">Después de crear una cuenta de NetApp, configure pools de capacidad con el tamaño y el nivel de servicio requeridos. Si quiere más información, consulte este documento<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>.</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="cell">Puntos que hay que recordar</block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">NFSv3 es compatible con los almacenes de datos en Azure NetApp Files.</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Configure una subred delegada para Azure NetApp Files y especifique esta subred al crear volúmenes. Si desea obtener información detallada sobre los pasos necesarios para crear una subred delegada, consulte esta sección<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>.</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">Añada un volumen NFS para el almacén de datos mediante el blade de volúmenes bajo el blade de pools de capacidad.</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link">Consideraciones de rendimiento para Azure NetApp Files</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Añada el almacén de datos Azure NetApp Files al cloud privado</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Para añadir un almacén de datos Azure NetApp Files a un cloud privado, complete los siguientes pasos:</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">Una vez registradas las funciones requeridas, conecte un almacén de datos NFS al clúster de cloud privado de la solución de VMware de Azure ejecutando el comando correspondiente.</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Cree un almacén de datos con un volumen ANF existente en el clúster de cloud privado de Azure VMware Solution.</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">C:\4497 2" Users\niyaz&gt;baz vmware datastore list --resource-group anfavsval2 --cluster Cluster-1 --private-cloud ANFDataClus [ { "diskPoolVolume": Null, "NFáf2c"/regates: "Jave2b2bregs 4497"/regenjregates Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001":"/3b2b2b2b2bregs/regiments:/regiments:/regiments:/regims/regenb2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2bregs/regenb2b2b2bregs/regims/regiments:/regiments:"/regiments:"/regenb3b2b2b2b2b2b2bregiments:/regiments:/regiments:/regenb3b3b3b3b3b3b3b3b3b3b2b2b2b3bregiments: { "Disk2 4497" Volume: Null, "id": "/subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/ResourceGroups/anfavsval2/providers/Microsoft.AVS/privateClouds/ANNFDataClus/clusters/Cluster-1/datastores/Agregat2b2b Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002":/regena3b2b2b2b2b2b2b2b2b2b2b2bd/regimuns:", "regiments:"/regena3b3b3b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2bregiments:","/regiments:"/regiments:"/regiments:"/regenb3b3b3b3b3b3b3b3b3b2b2b2b2b2b2b</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">Una vez que se ha establecido la conectividad necesaria, los volúmenes se montan como almacén de datos.</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">Optimización de tamaño y rendimiento</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files admite tres niveles de servicio: Estándar (16 Mbps por terabyte), Premium (64 Mb/s por terabyte) y Ultra (128 MB/s por terabyte). El aprovisionamiento de un tamaño de volumen adecuado es importante para un rendimiento óptimo de la carga de trabajo de la base de datos. Con Azure NetApp Files, el rendimiento de los volúmenes y el límite de rendimiento se determinan según los siguientes factores:</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">Consideraciones de rendimiento</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">Es importante entender que, con NFS versión 3, solo hay un canal activo para la conexión entre el host ESXi y un único destino de almacenamiento. Esto significa que, aunque puede haber conexiones alternativas disponibles para recuperación tras fallos, el ancho de banda para un único almacén de datos y el almacenamiento subyacente se limita a lo que puede proporcionar una única conexión.</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Para aprovechar un ancho de banda más disponible con volúmenes Azure NetApp Files, un host ESXi debe tener varias conexiones a los destinos de almacenamiento. Para abordar este problema, es posible configurar varios almacenes de datos, con cada almacén de datos mediante conexiones independientes entre el host ESXi y el almacenamiento.</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">Para un ancho de banda mayor, como práctica recomendada, cree varios almacenes de datos mediante varios volúmenes ANF, cree VMDK y secte los volúmenes lógicos entre VMDK.</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">La solución Azure VMware permite ocho almacenes de datos NFS de forma predeterminada. Esto se puede aumentar mediante una solicitud de soporte.</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">Aproveche ER fastpath junto con Ultra SKU para un mayor ancho de banda y una menor latencia. Más información</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Con las funciones de red "básicas" de Azure NetApp Files, la conectividad de la solución VMware de Azure está vinculada por el ancho de banda del circuito ExpressRoute y la puerta de enlace ExpressRoute.</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">Puntos que debe recordar</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">Aumentar el tamaño del almacén de datos</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">El cambio de forma del volumen y los cambios dinámicos en el nivel de servicio son totalmente transparentes para el SDDC. En Azure NetApp Files, estas funciones ofrecen mejoras continuas de rendimiento, capacidad y costes. Aumente el tamaño de los almacenes de datos NFS cambiando el tamaño del volumen desde Azure Portal o mediante la interfaz de línea de comandos. Una vez que haya terminado, acceda a vCenter, vaya a la pestaña del almacén de datos, haga clic con el botón derecho en el almacén de datos adecuado y seleccione Refresh Capacity Information. Este método se puede utilizar para aumentar la capacidad del almacén de datos y para aumentar el rendimiento del almacén de datos de forma dinámica y sin tiempos de inactividad. Este proceso también es totalmente transparente para las aplicaciones.</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">La modificación del volumen y la funcionalidad de nivel de servicio dinámico le permiten optimizar los costes mediante el dimensionamiento para las cargas de trabajo de estado constante y, así, evitar el sobreaprovisionamiento.</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">Cargas de trabajo</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">Uno de los casos de uso más comunes es la migración. Use VMware HCX o vMotion para mover máquinas virtuales en las instalaciones. Como alternativa, puede utilizar Rivermeadow para migrar máquinas virtuales a almacenes de datos de Azure NetApp Files.</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="example-title">Protección de datos</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">Realizar backups de equipos virtuales y recuperarlos rápidamente se encuentran entre los grandes puntos fuertes de los almacenes de datos de ANF. Utilice copias de Snapshot para realizar copias rápidas de su máquina virtual o su almacén de datos sin que esto afecte al rendimiento y, a continuación, envíelas al almacenamiento de Azure para protección de datos a largo plazo o a una región secundaria usando replicación entre regiones para fines de recuperación ante desastres. Este método minimiza el espacio de almacenamiento y el ancho de banda de red porque solo almacena la información modificada.</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">Use copias Snapshot de Azure NetApp Files para protección general y use herramientas de aplicaciones para proteger datos transaccionales como SQL Server u Oracle que residen en las máquinas virtuales «guest». Estas copias Snapshot son distintas de las copias Snapshot de VMware (consistencia) y son adecuadas para la protección a largo plazo.</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">Con los almacenes de datos ANF, la opción Restore to New Volume puede utilizarse para clonar un volumen de almacén de datos completo, y el volumen restaurado se puede montar como otro almacén de datos en los hosts dentro de AVS SDDC. Tras montar un almacén de datos, los equipos virtuales del interior se pueden registrar, volver a configurar y personalizar como si se clonaran individualmente.</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">Cloud Backup para máquinas virtuales</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">Cloud Backup para máquinas virtuales ofrece una GUI de cliente web de vSphere en vCenter para proteger las máquinas virtuales y los almacenes de datos de Azure NetApp Files de la solución Azure VMware a través de políticas de backup. Estas políticas pueden definir programaciones, retención y otras funcionalidades. La funcionalidad Cloud Backup para máquinas virtuales se puede implementar con el comando Run.</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">Las directivas de configuración y protección se pueden instalar siguiendo estos pasos:</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">Instale Cloud Backup para máquina virtual en el cloud privado de la solución VMware de Azure mediante el comando Run.</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">Añada credenciales de suscripción al cloud (valor de cliente y secreto) y, a continuación, añada una cuenta de suscripción al cloud (cuenta de NetApp y grupo de recursos asociado) que contenga los recursos que le gustaría proteger.</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">Cree una o varias políticas de backup que gestionen la retención, la frecuencia y otras configuraciones para los backups de grupos de recursos.</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">Cree un contenedor para añadir uno o varios recursos que deban protegerse con políticas de backup.</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">En caso de fallo, restaure toda la máquina virtual o VMDK individuales específicos en la misma ubicación.</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Con la tecnología Snapshot de Azure NetApp Files, los backups y las restauraciones son muy rápidos.</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Recuperación ante desastres con Azure NetApp Files, JetStream DR y solución VMware para Azure</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por los datos (por ejemplo, ransomware). Gracias al marco de trabajo VAIO de VMware, las cargas de trabajo de VMware locales se pueden replicar en el almacenamiento Azure Blob y recuperarse, lo que permite una pérdida de datos mínima o casi nula, y el objetivo de tiempo de recuperación casi nulo. JetStream DR se puede utilizar para recuperar sin problemas las cargas de trabajo replicadas de las instalaciones a AVS y específicamente a Azure NetApp Files. Permite una recuperación ante desastres rentable usando unos recursos mínimos en el sitio de recuperación ante desastres y un almacenamiento en cloud rentable. Jetstream DR automatiza la recuperación en almacenes de datos de ANF mediante el almacenamiento BLOB de Azure. JetStream DR recupera máquinas virtuales independientes o grupos de máquinas virtuales relacionadas en la infraestructura de sitio de recuperación según su asignación de red y proporciona recuperación de un momento específico para la protección de ransomware.</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">Solución DR con ANF, JetStream y AVS</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>.</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">Recuperación ante desastres con ANF y JetStream</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por los datos (por ejemplo, ransomware). Gracias al marco de trabajo VAIO de VMware, las cargas de trabajo de VMware locales se pueden replicar en el almacenamiento Azure Blob y recuperarse, lo que permite una pérdida de datos mínima o casi nula, y el objetivo de tiempo de recuperación casi nulo.</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">JetStream DR se puede utilizar para recuperar sin problemas las cargas de trabajo replicadas de las instalaciones a AVS y específicamente a Azure NetApp Files. Permite una recuperación ante desastres rentable usando unos recursos mínimos en el sitio de recuperación ante desastres y un almacenamiento en cloud rentable. Jetstream DR automatiza la recuperación en almacenes de datos de ANF mediante el almacenamiento BLOB de Azure. JetStream DR recupera máquinas virtuales independientes o grupos de máquinas virtuales relacionadas en la infraestructura de sitio de recuperación según su asignación de red y proporciona recuperación de un momento específico para la protección de ransomware.</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">Este documento proporciona una comprensión de los principios de operaciones de JetStream DR y sus principales componentes.</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">Información general sobre la puesta en marcha de la</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">Instale el software JetStream DR en el centro de datos local.</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">Descargue el paquete de software de recuperación ante desastres JetStream desde Azure Marketplace (ZIP) y ponga en marcha JetStream DR MSA (OVA) en el clúster designado.</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">Configure el clúster con el paquete de filtro de E/S (instale JetStream VIB).</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">Aprovisione Azure Blob (cuenta de almacenamiento de Azure) en la misma región que el clúster de recuperación ante desastres AVS.</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">Ponga en marcha dispositivos DRVA y asigne volúmenes de registro de replicación (VMDK a partir de un almacén de datos existente o almacenamiento iSCSI compartido).</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">Cree dominios protegidos (grupos de máquinas virtuales relacionadas) y asigne DRVAs y Azure Blob Storage/ANF.</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">Inicie la protección.</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">Utilice el comando Run para instalar y configurar JetStream DR.</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">Agregue el mismo contenedor de Azure Blob y descubra dominios mediante la opción Scan Domains.</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">Implementar los dispositivos DRVA necesarios.</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">Importe dominios protegidos y configure ROCvA (recuperación va) para utilizar el almacén de datos ANF en las ubicaciones de los equipos virtuales.</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">Seleccione la opción de conmutación por error adecuada y inicie una rehidratación continua para dominios de objetivo de tiempo de recuperación casi cero o máquinas virtuales.</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">Durante un evento de desastre, active la conmutación por error en los almacenes de datos de Azure NetApp Files en el sitio de recuperación ante desastres AVS designado.</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">Invoque la conmutación por recuperación al sitio protegido después de haber recuperado el sitio protegido.antes de comenzar, asegúrese de que se cumplen los requisitos previos tal y como se indica en este<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> Además, ejecute Bandwidth Testing Tool (BWT) de JetStream Software para evaluar el rendimiento potencial del almacenamiento de Azure Blob y su ancho de banda de replicación cuando se utiliza con el software JetStream DR. Tras los requisitos previos, incluida la conectividad, se han establecido, se han establecido y se han suscrito a JetStream DR para AVS de la<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>. Después de descargar el paquete de software, continúe con el proceso de instalación descrito anteriormente.</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">Cuando planifique e inicie la protección de un gran número de equipos virtuales (por ejemplo, 100+), utilice la herramienta de planificación de capacidad (CPT) del kit de herramientas de automatización de recuperación ante desastres JetStream. Proporcionar una lista de equipos virtuales que se protegerán junto a sus preferencias de grupo de recuperación y tiempo de recuperación, y luego ejecutar CPT.</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT realiza las siguientes funciones:</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">Combinación de máquinas virtuales en dominios de protección según su objetivo de tiempo de recuperación.</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">Definir el número óptimo de DRVAs y sus recursos.</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">Calcular el ancho de banda de replicación requerido.</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">Identificación de las características del volumen de registro de replicación (capacidad, ancho de banda, etc.).</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">Calculando la capacidad de almacenamiento de objetos requerida, etc.</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">La cantidad y el contenido de los dominios prescritos dependen de diversas características de los equipos virtuales, como la tasa media de IOPS, la capacidad total, la prioridad (que define el orden de conmutación por error), el objetivo de tiempo de recuperación, etc.</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">Instalar JetStream DR en el centro de datos local</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">El software Jetstream DR consta de tres componentes principales: Jetstream DR Management Server Virtual Appliance (MSA), DR Virtual Appliance (DRVA) y componentes host (paquetes de filtros de I/o). MSA se utiliza para instalar y configurar componentes host en el cluster informático y, a continuación, administrar el software de recuperación ante desastres JetStream. La siguiente lista proporciona una descripción de alto nivel del proceso de instalación:</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">Cómo instalar JetStream DR para las instalaciones</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">Compruebe los requisitos previos.</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">Ejecute la herramienta de planificación de la capacidad para realizar recomendaciones de recursos y configuración (opcional pero recomendado para pruebas de concepto).</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">Implemente JetStream DR MSA en un host de vSphere en el clúster designado.</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">Registre el servidor vCenter con MSA.para realizar la instalación, complete los siguientes pasos detallados:</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">Una vez que se haya puesto en marcha JetStream DR MSA y se haya registrado vCenter Server, acceda al complemento de recuperación ante desastres JetStream mediante vSphere Web Client. Para ello, vaya a Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">En la interfaz DR de JetStream, seleccione el clúster adecuado.</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">Añada Azure Blob Storage ubicado en el sitio de recuperación.</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">Implemente un dispositivo virtual de recuperación ante desastres (DRVA) desde la ficha Appliances (dispositivos).</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">Los DRVAs se pueden crear automáticamente mediante CPT, pero para las pruebas POC recomendamos configurar y ejecutar manualmente el ciclo DR (iniciar protección &gt; failover &gt; conmutación por recuperación).</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">JetStream DRVA es un dispositivo virtual que facilita las funciones clave del proceso de replicación de datos. Un clúster protegido debe contener al menos un DVAD y, normalmente, un DVAD se configura por host. Cada DRVA puede gestionar varios dominios protegidos.</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">En este ejemplo, se crearon cuatro DRVA para 80 máquinas virtuales.</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">Crear volúmenes de registro de replicación para cada DRVA utilizando VMDK desde los almacenes de datos disponibles o grupos de almacenamiento iSCSI compartidos independientes.</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">En la pestaña protected Domains, cree la cantidad necesaria de dominios protegidos utilizando información acerca del sitio de Azure Blob Storage, la instancia de DRVA y el registro de replicación. Un dominio protegido define una máquina virtual o un conjunto de máquinas virtuales específicos del clúster que se protegen en conjunto y asignó un orden de prioridad a las operaciones de conmutación por error y conmutación tras recuperación.</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">Seleccione las máquinas virtuales que desea proteger e iniciar la protección de máquinas virtuales del dominio protegido. Esto comienza la replicación de datos en el almacén BLOB designado.</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">Compruebe que se utilice el mismo modo de protección para todas las máquinas virtuales de un dominio protegido.</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">El modo Write- Back (VMDK) puede ofrecer un mayor rendimiento.</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">Compruebe que los volúmenes de registro de replicación se colocan en un almacenamiento de alto rendimiento.</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">Los libros de ejecución de conmutación por error se pueden configurar para agrupar los equipos virtuales (denominado Grupo de recuperación), establecer la secuencia de órdenes de arranque y modificar los ajustes de CPU/memoria junto con las configuraciones de IP.</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">Instalar JetStream DR para AVS en un cloud privado de Azure VMware Solution mediante el comando Run</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">Una práctica recomendada para un sitio de recuperación (AVS) es crear un clúster de tres nodos de luz piloto con antelación. Esto permite configurar la infraestructura del centro de recuperación, incluidos los siguientes elementos:</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">Segmentos de red de destino, firewalls, servicios como DHCP y DNS, etc.</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">La configuración de volúmenes ANF como almacenes de datos y la recuperación ante desastres más moreJetStream admite un modo de objetivo de tiempo de recuperación casi cero para dominios críticos de negocio. Para estos dominios, el almacenamiento de destino debe estar preinstalado. ANF es un tipo de almacenamiento recomendado en este caso.</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">En función de los requisitos de SLA y RTO, se puede usar el modo de conmutación por error continua o el modo de conmutación por error regular (estándar). Para lograr un objetivo de tiempo de recuperación cercano a cero, es necesario iniciar una rehidratación continua en el sitio de recuperación.</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">Cómo instalar JetStream DR para AVS en una nube privada</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">Para instalar JetStream DR para AVS en un cloud privado con Azure VMware Solution, realice los siguientes pasos:</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">En el portal de Azure, vaya a la solución Azure VMware, seleccione la nube privada y seleccione Ejecutar comando &gt; Paquetes &gt; JSDR.Configuration.</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">El usuario de CloudAdmin predeterminado en la solución VMware de Azure no tiene suficientes privilegios para instalar JetStream DR para AVS. La solución VMware Azure permite una instalación simplificada y automatizada de la recuperación ante desastres de JetStream mediante la llamada al comando Azure VMware Solution Run para la recuperación ante desastres de JetStream.</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">Desde la interfaz DR de JetStream, añada la cuenta de almacenamiento BLOB de Azure que se utilizó para proteger el clúster local como sitio de almacenamiento y, a continuación, ejecute la opción Scan Domains.</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">Después de importar los dominios protegidos, implemente dispositivos DRVA. En este ejemplo, la rehidratación continua se inicia manualmente desde el sitio de recuperación mediante la IU de recuperación ante desastres de JetStream.</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">Estos pasos también se pueden automatizar mediante planes creados por CPT.</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">Importe los dominios protegidos y configure Recovery VA para utilizar el almacén de datos ANF en las ubicaciones de las máquinas virtuales.</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">Asegúrese de que DHCP esté habilitado en el segmento seleccionado y haya suficientes IP disponibles. Las IP dinámicas se utilizan temporalmente mientras se recuperan los dominios. Cada VM que se recupera (incluida la rehidratación continua) requiere una IP dinámica individual. Una vez finalizada la recuperación, se libera la IP y se puede volver a utilizar.</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">Realizar conmutación por error/conmutación por error</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">Cómo realizar una conmutación por error/conmutación por recuperación</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">Cuando se produce un desastre en el clúster protegido del entorno local (fallo parcial o total), active la conmutación al respaldo.</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT se puede usar para ejecutar el plan de conmutación por error y recuperar las máquinas virtuales de Azure Blob Storage en el sitio de recuperación del clúster AVS.</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">Después de la conmutación al nodo de respaldo (para una rehidratación continua o estándar), cuando se iniciaron las máquinas virtuales protegidas en AVS, la protección se reanuda automáticamente y JetStream DR sigue replicando sus datos en los contenedores originales o adecuados en Azure Blob Storage.</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">La barra de tareas muestra el progreso de las actividades de failover.</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">Una vez finalizada la tarea, el acceso al equipo virtual recuperado y al negocio continúa de forma normal.</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">Una vez que el sitio principal esté activo y en funcionamiento de nuevo, es posible realizar la conmutación tras recuperación. La protección de equipos virtuales se reanuda y se debe comprobar la consistencia de los datos.</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">Restaure el entorno de sus instalaciones. En función del tipo de incidente de desastre, podría ser necesario restaurar o verificar la configuración del clúster protegido. Si es necesario, puede que sea necesario volver a instalar el software JetStream DR.</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">Nota: La<block ref="cad8a6b900ca13dfc8b04dee1f744111" prefix=" " category="inline-code"></block> El script que se proporciona en el kit de herramientas de automatización se puede utilizar para ayudar a limpiar el sitio protegido original de cualquier máquina virtual obsoleta, información de dominio, etc.</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">El plan de conmutación por recuperación generado por CPT también se puede usar para iniciar la devolución de los equipos virtuales y sus datos del almacén de objetos al entorno de VMware original.</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">Especifique la demora máxima después de pausar las máquinas virtuales en el sitio de recuperación y reiniciar en el sitio protegido. Esta vez incluye completar la replicación después de detener las máquinas virtuales en caso de fallo, el tiempo para limpiar el sitio de recuperación y el tiempo para recrear las máquinas virtuales en el sitio protegido. El valor recomendado por NetApp es de 10 minutos.</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">Completar el proceso de conmutación tras recuperación y, a continuación, confirmar la reanudación de la protección de los equipos virtuales y la consistencia de datos.</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Recuperación de Ransomeware</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">Recuperarse del ransomware puede ser una tarea abrumadora. Específicamente, puede resultar difícil para las organizaciones TECNOLÓGICAS determinar el punto de retorno seguro y, una vez determinado, cómo garantizar que las cargas de trabajo recuperadas se protejan de los ataques que vuelvan a producirse (de malware en suspensión o de aplicaciones vulnerables).</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR para AVS junto con los almacenes de datos de Azure NetApp Files pueden resolver estos problemas al permitir que las organizaciones se recuperen de puntos disponibles en el tiempo, de modo que las cargas de trabajo se recuperen en una red funcional y aislada, en caso necesario. La recuperación permite que las aplicaciones funcionen y se comuniquen entre sí mientras no las exponen al tráfico norte-sur, dando así a los equipos de seguridad un lugar seguro para realizar el análisis forense y otra reparación necesaria.</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Soluciones de NetApp para la solución Azure VMware (AVS)</block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">Obtenga más información acerca de las soluciones que NetApp ofrece a Azure.</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware define las cargas de trabajo del cloud en una de estas tres categorías:</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">Protección (incluida tanto recuperación ante desastres como backup/restauración)</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">Consulte las soluciones disponibles en las siguientes secciones.</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">Proteger</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">Recuperación ante desastres con ANF y JetStream (almacén de datos NFS complementario)</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">Recuperación ante desastres con ANF y CVO (almacenamiento conectado de invitado)</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">Migrar cargas de trabajo al almacén de datos Azure NetApp Files mediante VMware HCX</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">¡PRÓXIMAMENTE!</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">Las soluciones de multicloud híbrido de NetApp con VMware son un conjunto de funcionalidades tecnológicas y estratégicas que demuestran las funcionalidades del almacenamiento de NetApp en los principales proveedores a hiperescala de cloud público.</block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">Soluciones de multicloud híbrido de NetApp para Azure / AVS</block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4940: Migre cargas de trabajo al almacén de datos de Azure NetApp Files mediante VMware HCX: Guía de inicio rápido</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">Autores: Ingeniería de soluciones de NetApp</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">Descripción general: Migrar máquinas virtuales con VMware HCX, almacenes de datos de Azure NetApp Files y solución VMware para Azure</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Uno de los casos de uso más comunes de la solución para VMware Azure y el almacén de datos Azure NetApp Files es la migración de las cargas de trabajo de VMware. HCX de VMware es la opción preferida y ofrece diversos mecanismos de migración para mover máquinas virtuales (VM) locales y sus datos a almacenes de datos de Azure NetApp Files.</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX es principalmente una plataforma de migración diseñada para simplificar la migración de aplicaciones, el reequilibrado de las cargas de trabajo e incluso la continuidad de negocio entre clouds. Se incluye como parte de Azure VMware Solution Private Cloud y ofrece muchas formas de migrar cargas de trabajo y se puede utilizar para operaciones de recuperación ante desastres.</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">Este documento proporciona guía paso a paso para aprovisionar almacenes de datos de Azure NetApp Files seguido de la descarga, la puesta en marcha y la configuración de VMware HCX, incluidos todos sus componentes principales en las instalaciones y en el lado de la solución VMware de Azure, incluida la interconexión, la extensión de red y la optimización WAN para habilitar diversos mecanismos de migración de máquinas virtuales.</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX funciona con cualquier tipo de almacén de datos, ya que la migración se realiza a nivel de equipo virtual. Por lo tanto, este documento es aplicable a clientes existentes de NetApp y no de NetApp que tengan previsto poner en marcha Azure NetApp Files con la solución VMware de Azure para una puesta en marcha de cloud VMware rentable.</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">Escalones de alto nivel</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">Esta lista contiene los pasos de alto nivel necesarios para instalar y configurar HCX Cloud Manager en el cloud de Azure e instalar HCX Connector en las instalaciones:</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">Instale HCX a través del portal de Azure.</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">Descargue e implemente el instalador de HCX Connector Open Virtualization Appliance (OVA) en VMware vCenter Server en las instalaciones.</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">Active HCX con la clave de licencia.</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">Empareje el conector VMware HCX en las instalaciones con la solución VMware de Azure HCX Cloud Manager.</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">Configure el perfil de red, el perfil de computación y la malla de servicio.</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(Opcional) lleve a cabo la extensión de red para evitar la reIP durante las migraciones.</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">Valide el estado del dispositivo y asegúrese de que la migración sea posible.</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">Migrar las cargas de trabajo de la máquina virtual.</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">Antes de empezar, asegúrese de que se cumplan los siguientes requisitos previos. Para obtener más información, consulte este tema<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>. Una vez que los requisitos previos, incluida la conectividad, estén vigentes, configure y active HCX generando la clave de licencia desde el portal de la solución VMware de Azure. Después de descargar el instalador de OVA, continúe con el proceso de instalación como se describe a continuación.</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCX Advanced es la opción predeterminada y VMware HCX Enterprise Edition también está disponible a través de un ticket de soporte y se admite sin coste adicional.</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">Enlace a NetApp</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Vínculo de Microsoft</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">Utilice un centro de datos definido por software (SDDC) de la solución Azure VMware existente o cree un cloud privado utilizando este método<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> o esto<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>.</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">Configurar una conexión VPN de sitio a sitio o una conexión de acceso global de ruta Express</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">La migración de equipos virtuales y datos asociados desde el centro de datos integrado con VMware vSphere en las instalaciones requiere conectividad de red del centro de datos al entorno SDDC. Antes de migrar cargas de trabajo,<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> entre el entorno local y el cloud privado correspondiente.</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">La ruta de red desde el entorno local de VMware vCenter Server hasta el cloud privado de la solución VMware para Azure debe admitir la migración de máquinas virtuales mediante vMotion.</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">reglas y puertos del firewall</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">Asegúrese de que es necesario<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Se permiten para el tráfico de vMotion entre la instancia local de vCenter Server y SDDC vCenter. En la nube privada, el enrutamiento de la red de vMotion está configurado de manera predeterminada.</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">El volumen NFS de Azure NetApp Files debe montarse como almacén de datos en la solución VMware de Azure. Siga los pasos detallados en este documento<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Para conectar almacenes de datos de Azure NetApp Files a los hosts de soluciones VMware de Azure.</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">Arquitectura de alto nivel</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">Para realizar las pruebas, el entorno de laboratorio de las instalaciones que se emplean para esta validación se conectó a través de una VPN sitio a sitio, lo que permite la conectividad en las instalaciones con la solución VMware para Azure.</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">Esta imagen muestra la arquitectura de alto nivel utilizada en esta solución.</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">Siga la serie de pasos para completar la implementación de esta solución:</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">Paso 1: Instale HCX a través de Azure Portal mediante la opción Add-ons</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">Para realizar la instalación, lleve a cabo los siguientes pasos:</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Inicie sesión en el portal de Azure y acceda al cloud privado de la solución VMware para Azure.</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">Seleccione el cloud privado adecuado y acceda a Add-ons. Esto se puede hacer navegando a *Administrar &gt; Complementos*.</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">En la sección movilidad de carga de trabajo de HCX, haga clic en *comenzar*.</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">Captura de pantalla de la sección movilidad de la carga de trabajo de HCX.</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">Seleccione la opción *Acepto los términos y condiciones* y haga clic en *Activar e implementar*.</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">La implementación predeterminada es HCX Advanced. Abra una solicitud de soporte para activar la edición Enterprise.</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">La puesta en marcha dura entre 25 y 30 minutos, aproximadamente.</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">Captura de pantalla de la finalización de la sección movilidad de la carga de trabajo de HCX.</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">Paso 2: Ponga en marcha el OVA del instalador en la instancia local de vCenter Server</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">Para que el conector local se conecte al HCX Manager en la solución VMware de Azure, asegúrese de que los puertos de firewall adecuados están abiertos en el entorno local.</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">Para descargar e instalar el conector HCX en el vCenter Server local, complete los siguientes pasos:</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">En el portal de Azure, vaya a la solución VMware para Azure, seleccione el cloud privado y seleccione *gestionar &gt; Complementos &gt; migración* mediante HCX y copie el portal HCX Cloud Manager para descargar el archivo OVA.</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">Utilice las credenciales de usuario predeterminadas de CloudAdmin para acceder al portal HCX.</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">Captura de pantalla del portal de Azure para descargar el archivo OVA de HCX.</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">Después de acceder al portal HCX con mailto:cloudadmin@vsphere.locl[cloudadmin@vsphere.loc/] usando el jumphost, navegue hasta *Administration &gt; System Updates* y haga clic en *Request Download Link*.</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">Descargue o copie el enlace en el OVA y péguelo en un explorador para comenzar el proceso de descarga del archivo OVA de VMware HCX Connector que se implementará en la instancia local de vCenter Server.</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">Error: Captura de pantalla del enlace de descarga de OVA.</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">Una vez descargado el OVA, póngalo en marcha en el entorno local de VMware vSphere mediante la opción *implementar plantilla OVF*.</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">Error: Captura de pantalla para seleccionar la plantilla de OVA correcta.</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">Introduzca toda la información necesaria para la implementación de OVA, haga clic en *Siguiente* y, a continuación, haga clic en *Finalizar* para implementar el OVA del conector HCX de VMware.</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">Encienda el dispositivo virtual manualmente.</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">Guía del usuario de VMware HCX</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">Para obtener instrucciones paso a paso, consulte<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">Paso 3: Active el conector HCX con la clave de licencia</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">Después de implementar el OVA del conector HCX de VMware en las instalaciones e iniciar el dispositivo, lleve a cabo los siguientes pasos para activar el conector HCX. Genere la clave de licencia desde el portal de la solución VMware de Azure y actívela en el administrador HCX de VMware.</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">En el portal de Azure, vaya a la solución para VMware de Azure, seleccione el cloud privado y seleccione *gestionar &gt; Complementos &gt; migración mediante HCX*.</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">En *conectar con las instalaciones mediante las teclas HCX*, haga clic en *Agregar* y copie la clave de activación.</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">Captura de pantalla para agregar claves HCX.</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">Se requiere una llave independiente para cada conector HCX local que esté desplegado.</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">Inicie sesión en el VMware HCX Manager local en<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> uso de las credenciales de administrador.</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">Utilice la contraseña definida durante la implementación de OVA.</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">En la licencia, introduzca la clave copiada del paso 3 y haga clic en *Activar*.</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">El conector HCX de las instalaciones debe tener acceso a Internet.</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">En *Datacenter Location*, proporcione la ubicación más cercana para instalar el VMware HCX Manager en las instalaciones. Haga clic en *continuar*.</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">En *Nombre del sistema*, actualice el nombre y haga clic en *continuar*.</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">Haga clic en *Sí, continuar*.</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">En *Conecte su vCenter*, proporcione el nombre de dominio completo (FQDN) o la dirección IP de vCenter Server y las credenciales adecuadas, y haga clic en *continuar*.</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">Utilice el FQDN para evitar problemas de conectividad más adelante.</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">En *Configurar SSO/PSC*, proporcione la dirección IP o FQDN del controlador de servicios de plataforma y haga clic en *continuar*.</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">Introduzca el nombre de dominio completo o la dirección IP de VMware vCenter Server.</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">Compruebe que la información introducida es correcta y haga clic en *Reiniciar*.</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">Después de reiniciar los servicios, vCenter Server se muestra como verde en la página que aparece. Tanto vCenter Server como SSO deben tener los parámetros de configuración adecuados, que deben ser los mismos que los de la página anterior.</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">Este proceso debe tardar aproximadamente de 10 a 20 minutos y el plugin se añadirá a vCenter Server.</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">Captura de pantalla que muestra el proceso completado.</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">Paso 4: Emparejar el conector VMware HCX en las instalaciones con la solución de VMware Azure HCX Cloud Manager</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">Después de instalar el conector HCX en la solución VMware de Azure y en las instalaciones, configure el cloud privado de VMware HCX Connector para la solución VMware de Azure agregando el emparejamiento. Para configurar el emparejamiento de sitios, lleve a cabo los siguientes pasos:</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">Para crear un par de sitios entre el entorno local de vCenter y el SDDC de la solución VMware para Azure, inicie sesión en la instancia local de vCenter Server y acceda al nuevo complemento HCX vSphere Web Client.</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">Captura de pantalla del complemento HCX vSphere Web Client.</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">En Infraestructura, haga clic en *Agregar un emparejamiento de sitios*.</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">Introduzca la dirección URL o IP de HCX Cloud Manager de la solución Azure VMware y las credenciales del rol CloudAdmin para acceder a la nube privada.</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">Captura de pantalla URL o dirección IP y credenciales para el rol CloudAdmin.</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">Haga clic en *conectar*.</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">El conector HCX de VMware debe poder enrutar a HCX Cloud Manager IP a través del puerto 443.</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">Una vez creado el emparejamiento, el emparejamiento de sitios recién configurado está disponible en el panel de HCX.</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">Captura de pantalla del proceso completado en el panel HCX.</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">Paso 5: Configure el perfil de red, el perfil de computación y la malla de servicio</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">El dispositivo de servicio VMware HCX Interconnect proporciona funcionalidades de replicación y migración basada en vMotion a través de Internet y conexiones privadas al sitio de destino. La interconexión ofrece cifrado, ingeniería de tráfico y movilidad de máquinas virtuales. Para crear un dispositivo de servicio de interconexión, lleve a cabo los siguientes pasos:</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">En Infraestructura, seleccione *interconexión &gt; malla de servicio multisitio &gt; Perfiles de computación &gt; Crear perfil de computación*.</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">Los perfiles informáticos definen los parámetros de implementación, incluidos los dispositivos que se implementan y qué parte del centro de datos de VMware puede acceder al servicio HCX.</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">Captura de pantalla de la página vSphere Client Interconnect.</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">Después de crear el perfil de computación, cree los perfiles de red seleccionando *malla de servicio multisitio &gt; Perfiles de red &gt; Crear perfil de red*.</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">El perfil de red define un rango de direcciones IP y redes que utiliza HCX para sus dispositivos virtuales.</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">Este paso requiere dos o más direcciones IP. Estas direcciones IP se asignan desde la red de gestión a los dispositivos de interconexión.</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">Captura de pantalla de cómo añadir direcciones IP a la página vSphere Client Interconnect.</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">En este momento, se han creado correctamente los perfiles de computación y red.</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">Cree la malla de servicio seleccionando la pestaña *malla de servicio* en la opción *interconexión* y seleccione los sitios SDDC de las instalaciones y Azure.</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">La malla de servicio especifica una pareja de perfiles de red y de computación local y remota.</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">Como parte de este proceso, los dispositivos HCX se implementan y se configuran automáticamente tanto en los sitios de origen como en los de destino con el fin de crear una estructura de transporte segura.</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">Captura de pantalla de la pestaña Service Mesh en la página vSphere Client Interconnect.</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">Este es el paso final de la configuración. Esta operación debería tardar cerca de 30 minutos en completar la puesta en marcha. Una vez configurada la malla de servicio, el entorno está preparado con los túneles IPsec creados correctamente para migrar las VM de carga de trabajo.</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">Captura de pantalla del proceso completado en la página vSphere Client Interconnect.</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">Paso 6: Migrar cargas de trabajo</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">Las cargas de trabajo se pueden migrar de manera bidireccional entre los centros de datos SDC de Azure y en las instalaciones mediante diversas tecnologías de migración HCX de VMware. Los equipos virtuales se pueden mover hacia y desde entidades activadas por HCX de VMware mediante varias tecnologías de migración, como la migración masiva de HCX, HCX vMotion, migración en frío de HCX, el asistente de replicación de HCX vMotion (disponible con la edición de HCX Enterprise) y la migración asistida por SO HCX (disponible con la edición de HCX Enterprise).</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">Tipos de migración HCX de VMware</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">Para obtener más información sobre varios mecanismos de migración de HCX, consulte<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>.</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*Migración masiva*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">En esta sección se detalla el mecanismo de migración masiva. Durante una migración masiva, la funcionalidad de migración masiva de HCX utiliza la replicación de vSphere para migrar archivos de disco al mismo tiempo que vuelve a crear la máquina virtual en la instancia de vSphere HCX de destino.</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">Para iniciar migraciones masivas de máquinas virtuales, complete los siguientes pasos:</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">Acceda a la ficha *migración* en *Servicios &gt; migración*.</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">Captura de pantalla de la sección Migration del cliente vSphere.</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">En *Conexión a sitio remoto*, seleccione la conexión a sitio remoto y seleccione el origen y el destino. En este ejemplo, el destino es el extremo SDDC de la solución Azure para VMware.</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">Haga clic en *Seleccionar VM para migración*. Esto proporciona una lista de todas las máquinas virtuales en las instalaciones. Seleccione las VM basadas en la expresión match:Value y haga clic en *Add*.</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">En la sección *transferencia y colocación*, actualice los campos obligatorios (*Cluster*, *almacenamiento*, *destino* y *Red*), incluido el perfil de migración, y haga clic en *Validar*.</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">Captura de pantalla de la sección transferencia y colocación del cliente vSphere.</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">Una vez completadas las comprobaciones de validación, haga clic en *Ir* para iniciar la migración.</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">Captura de pantalla de inicio de la migración.</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">Durante esta migración, se crea un disco de marcador de posición en el almacén de datos de Azure NetApp Files especificado dentro del vCenter de destino para habilitar la replicación de los datos del disco de la máquina virtual de origen a los discos de marcador de posición. HBR se activa para realizar una sincronización completa en el destino y una vez que se completa la línea de base, se realiza una sincronización incremental en función del ciclo del objetivo de punto de recuperación (RPO). Una vez finalizada la sincronización completa/incremental, la conmutación se activa automáticamente a menos que se defina una programación específica.</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">Una vez finalizada la migración, valide lo mismo accediendo al centro de datos definido por software vCenter de destino.</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">Si desea obtener información adicional y detallada sobre varias opciones de migración y sobre cómo migrar cargas de trabajo de las instalaciones a la solución VMware Azure mediante HCX, consulte<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="73e6478a04a38e6c1af3fd112abd351f" category="paragraph">Para obtener más información sobre este proceso, puede seguir el vídeo detallado del tutorial:</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">Esta es una captura de pantalla de la opción HCX vMotion.</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">Asegúrese de que hay suficiente ancho de banda disponible para gestionar la migración.</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">El almacén de datos ANF de destino debe tener suficiente espacio para gestionar la migración.</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">Tanto si su objetivo es el cloud híbrido como el cloud, y los datos residen en un almacenamiento de cualquier tipo o proveedor en las instalaciones, Azure NetApp Files y HCX ofrecen excelentes opciones para poner en marcha y migrar las cargas de trabajo de la aplicación a la vez que reduce el TCO, ya que los requisitos de datos se adaptan sin problemas a la capa de la aplicación. Sea cual sea el caso práctico, elija la solución VMware de Azure junto con Azure NetApp Files para conocer rápidamente las ventajas del cloud, una infraestructura consistente y operaciones en las instalaciones y varios clouds, portabilidad bidireccional de cargas de trabajo, y capacidad y rendimiento de clase empresarial. Se trata del mismo proceso y procedimientos que ya conoce que se utiliza para conectar el almacenamiento y migrar máquinas virtuales mediante la replicación de VMware vSphere, VMware vMotion o incluso la copia de archivos de red (NFC).</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">Ahora puede utilizar Azure NetApp Files como almacén de datos en SDDC de la solución para VMware Azure.</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">Puede migrar datos de manera sencilla desde las instalaciones a un almacén de datos de Azure NetApp Files.</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">Es posible aumentar y reducir con facilidad el almacén de datos Azure NetApp Files para satisfacer los requisitos de capacidad y rendimiento durante la actividad de migración.</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Documentación de la solución VMware de Azure</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Documentación de Azure NetApp Files</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Opciones de almacenamiento conectado a invitado de NetApp para Azure</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure admite almacenamiento de NetApp conectado como invitado con el servicio Azure NetApp Files (ANF) nativo o con Cloud Volumes ONTAP (CVO).</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp Files (ANF)</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files lleva la gestión de datos y el almacenamiento de clase empresarial a Azure para que pueda gestionar sus cargas de trabajo y aplicaciones fácilmente. Migre sus cargas de trabajo al cloud y ejecútelas sin sacrificar el rendimiento.</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files elimina obstáculos, de forma que puede mover todas sus aplicaciones basadas en archivos al cloud. Por primera vez, no tiene que volver a crear la arquitectura de sus aplicaciones y obtiene almacenamiento persistente para sus aplicaciones sin complejidad.</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">Dado que el servicio se ofrece mediante Microsoft Azure Portal, los usuarios disfrutan de un servicio totalmente gestionado como parte de su contrato empresarial de Microsoft. El soporte líder, gestionado por Microsoft, le ofrece tranquilidad completa. Esta solución única le permite agregar de forma rápida y fácil cargas de trabajo multiprotocolo. Puede compilar e implementar aplicaciones basadas en archivos de Windows y Linux, incluso para entornos heredados.</block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="example-title">Configuración de Azure NetApp Files con la solución VMware para Azure (AVS)</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Los recursos compartidos de Azure NetApp Files se pueden montar a partir de máquinas virtuales que se crean en el entorno SDDC de la solución Azure VMware. Los volúmenes también pueden montarse en el cliente Linux y asignarse en el cliente Windows, ya que Azure NetApp Files admite los protocolos SMB y NFS. Los volúmenes de Azure NetApp Files se pueden configurar en cinco sencillos pasos.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files y Azure VMware Solution deben estar en la misma región de Azure.</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Para crear y montar volúmenes de Azure NetApp Files, complete los siguientes pasos:</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Inicie sesión en el portal de Azure y acceda a Azure NetApp Files. Verifique el acceso al servicio Azure NetApp Files y registre el proveedor de recursos Azure NetApp Files utilizando el comando _az provider register --namespace Microsoft.NetApp –wait_. Una vez completado el registro, cree una cuenta de NetApp.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Recursos compartidos de Azure NetApp Files</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">Para conocer los pasos detallados, consulte <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. Esta página le guiará a través del proceso paso a paso.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">Una vez creada la cuenta de NetApp, configure los pools de capacidad con el tamaño y el nivel de servicio requeridos.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">Para obtener más información, consulte <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Delegar una subred en Azure NetApp Files</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Configure la subred delegada para Azure NetApp Files y especifique esta subred mientras crea los volúmenes. Para obtener información detallada sobre los pasos para crear una subred delegada, consulte <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Añada un volumen SMB utilizando el blade volúmenes bajo el blade de pools de capacidad. Asegúrese de que el conector de Active Directory esté configurado antes de crear el volumen de SMB.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">Haga clic en Review + Create para crear el volumen del SMB.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">Si la aplicación es SQL Server, habilite la disponibilidad continua de SMB.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">Para obtener más información acerca del rendimiento de Azure NetApp Files Volume por tamaño o cuota, consulte <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">Una vez que se ha establecido la conectividad, el volumen se puede montar y utilizar para los datos de la aplicación.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">Para ello, en el portal de Azure, haga clic en el blade de volúmenes y, a continuación, seleccione el volumen que desea montar y acceder a las instrucciones de montaje. Copie la ruta y utilice la opción Map Network Drive para montar el volumen en el equipo virtual que se ejecuta en el centro definido por software de la solución VMware de Azure.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Para montar volúmenes NFS en equipos virtuales Linux que se ejecutan en un SDDC de la solución Azure VMware, utilice este mismo proceso. Usar la funcionalidad de un nuevo estado de los volúmenes o un nivel de servicio dinámico para satisfacer las demandas de las cargas de trabajo.</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">Para obtener más información, consulte <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP (CVO)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP, o CVO, es la solución de gestión de datos en el cloud líder del sector que se basa en el software de almacenamiento ONTAP de NetApp, disponible de forma nativa en Amazon Web Services (AWS), Microsoft Azure y Google Cloud Platform (GCP).</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">Se trata de una versión de ONTAP definida por software que consume almacenamiento nativo del cloud, lo que le permite tener el mismo software de almacenamiento en el cloud y en las instalaciones, lo que reduce la necesidad de volver a formar al personal INFORMÁTICO en todos los métodos nuevos para gestionar sus datos.</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">CVO ofrece a los clientes la capacidad de mover datos del perímetro, al centro de datos, al cloud y al backup sin problemas, de tal modo que su cloud híbrido se aúna, todo ello gestionado con una consola de gestión de panel único, Cloud Manager de NetApp.</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">Por su diseño, CVO ofrece un rendimiento extremo y capacidades de gestión de datos avanzadas para responder incluso a sus aplicaciones más exigentes en el cloud</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="example-title">Implemente el nuevo Cloud Volumes ONTAP en Azure</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Los recursos compartidos y los LUN de Cloud Volumes ONTAP se pueden montar a partir de máquinas virtuales creadas en el entorno SDDC de la solución para Azure VMware. Los volúmenes también pueden montarse en el cliente Linux y en el cliente Windows, ya que Cloud Volumes ONTAP admite los protocolos iSCSI, SMB y NFS. Los volúmenes de Cloud Volumes ONTAP se pueden configurar en unos pocos pasos sencillos.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">Configurar la replicación de datos entre sistemas</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">Para replicar volúmenes de un entorno local al cloud por motivos de recuperación ante desastres o migración, establezca la conectividad de red a Azure, ya sea mediante una VPN sitio a sitio o ExpressRoute. La replicación de datos de las instalaciones a Cloud Volumes ONTAP no se encuentra fuera del alcance de este documento. Para replicar datos entre sistemas Cloud Volumes ONTAP y locales, consulte <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Configuración de Cloud Volumes ONTAP</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">Uso <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Para ajustar el tamaño de las instancias de Cloud Volumes ONTAP de forma precisa. Supervise también el rendimiento local para utilizarlo como entradas en el dimensionador Cloud Volumes ONTAP.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">Inicie sesión en NetApp Cloud Central: Se mostrará la pantalla Fabric View. Localice la pestaña Cloud Volumes ONTAP y seleccione Go to Cloud Manager. Una vez que haya iniciado sesión, aparecerá la pantalla Canvas.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">En la página de inicio de Cloud Manager, haga clic en Add a Working Environment y, a continuación, seleccione Microsoft Azure como cloud y el tipo de configuración del sistema.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Al crear el primer entorno de trabajo de Cloud Volumes ONTAP, Cloud Manager le solicita que implemente un conector.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">Una vez creado el conector, actualice los campos Detalles y credenciales.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">Proporcione los detalles del entorno que se va a crear, incluidos el nombre del entorno y las credenciales de administración. Añada etiquetas de grupo de recursos para el entorno de Azure como un parámetro opcional. Una vez que haya terminado, haga clic en continuar.</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">Seleccione los servicios complementarios para la puesta en marcha de Cloud Volumes ONTAP, incluidos Cloud Data Sense, Cloud Backup y Cloud Insights. Seleccione los servicios y haga clic en Continue.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Configure la ubicación y la conectividad de Azure. Seleccione la región de Azure, el grupo de recursos, vnet y la subred que desee utilizar.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">Seleccione la opción de licencia: Pago por uso o BYOL para usar la licencia existente. En este ejemplo, se utiliza la opción de pago por uso.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">Seleccione entre varios paquetes preconfigurados disponibles para los distintos tipos de cargas de trabajo.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Acepte los dos acuerdos sobre la activación del soporte y la asignación de recursos de Azure.para crear la instancia de Cloud Volumes ONTAP, haga clic en Go.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Una vez que se ha aprovisionado Cloud Volumes ONTAP, se muestra en los entornos de trabajo de la página lienzo.</block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="example-title">Configuraciones adicionales para volúmenes SMB</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">Una vez listo el entorno de trabajo, asegúrese de que el servidor CIFS esté configurado con los parámetros de configuración DNS y Active Directory adecuados. Este paso es necesario para poder crear el volumen de SMB.</block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">La creación del volumen SMB es un proceso sencillo. Seleccione la instancia de CVO para crear el volumen y haga clic en la opción Create Volume. Elija el tamaño adecuado y el gestor de cloud elija el agregado que lo contiene o utilice un mecanismo de asignación avanzado para colocarlo en un agregado concreto. En esta demostración, se ha seleccionado SMB como protocolo.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">Una vez que el volumen se ha aprovisionado, estará disponible en el panel Volumes. Dado que se aprovisiona un recurso compartido de CIFS, conceda a los usuarios o grupos permiso a los archivos y carpetas y compruebe que esos usuarios pueden acceder al recurso compartido y crear un archivo. Este paso no es necesario si el volumen se replica desde un entorno en las instalaciones, ya que los permisos de archivos y carpetas se conservan como parte de la replicación de SnapMirror.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">Una vez creado el volumen, utilice el comando Mount para conectarse al recurso compartido desde la máquina virtual que se ejecuta en los hosts SDDC de Azure VMware Solution.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">Copie la siguiente ruta y utilice la opción Map Network Drive para montar el volumen en el equipo virtual que se ejecuta en el centro de datos definido por software de la solución VMware de Azure.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="example-title">Conectar el LUN a un host</block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">Para conectar el LUN a un host, complete los pasos siguientes:</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">En la página lienzo, haga doble clic en el entorno de trabajo de Cloud Volumes ONTAP para crear y gestionar volúmenes.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Haga clic en Add Volume &gt; New Volume, seleccione iSCSI y haga clic en Create Initiator Group. Haga clic en Continue.</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">Una vez que se haya aprovisionado el volumen, seleccione el volumen y, a continuación, haga clic en IQN de destino. Para copiar el nombre completo de iSCSI (IQN), haga clic en Copy. Configurar una conexión iSCSI desde el host al LUN.</block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Para lograr lo mismo con el host que reside en el centro de datos definido por software de la solución VMware de Azure:</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">RDP a la máquina virtual alojada en el SDDC de la solución Azure VMware.</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">Abra el cuadro de diálogo Propiedades del iniciador iSCSI: Administrador del servidor &gt; Panel &gt; Herramientas &gt; Iniciador iSCSI.</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">En la pestaña Discovery, haga clic en Discover Portal o Add Portal y, a continuación, introduzca la dirección IP del puerto de destino iSCSI.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">En la pestaña Destinos, seleccione el objetivo detectado y haga clic en Iniciar sesión o conectar.</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">Seleccione Activar multivía y, a continuación, seleccione Restaurar automáticamente esta conexión cuando se inicie el equipo o Agregar esta conexión a la lista de destinos favoritos. Haga clic en Avanzado.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">*Nota:* el host Windows debe tener una conexión iSCSI con cada nodo del clúster. El DSM nativo selecciona las mejores rutas que se van a utilizar.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">Las LUN de una máquina virtual de almacenamiento (SVM) aparecen como discos en el host Windows. El host no detecta automáticamente los nuevos discos que se añaden. Active una detección repetida manual para detectar los discos realizando los pasos siguientes:</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Abra la utilidad Administración de equipos de Windows: Inicio &gt; Herramientas administrativas &gt; Administración de equipos.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">Expanda el nodo almacenamiento en el árbol de navegación.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">Haga clic en Administración de discos.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">Haga clic en Acción &gt; discos de reexploración.</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Cuando el host Windows accede por primera vez a una nueva LUN, no tiene sistema de archivos o partición. Inicialice la LUN y, de manera opcional, formatee la LUN con un sistema de archivos realizando los pasos siguientes:</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Inicie Administración de discos de Windows.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">Haga clic con el botón derecho en el LUN y seleccione el disco o el tipo de partición necesarios.</block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">Siga las instrucciones del asistente. En este ejemplo, la unidad E: Está montada</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">Descripción general de las soluciones de almacenes de datos de ANF</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">Todas las organizaciones exitosas se encuentran en el camino de la transformación y la modernización. Como parte de este proceso, las empresas suelen utilizar sus inversiones existentes en VMware a la vez que aprovechan las ventajas de la nube y estudian cómo se pueden implementar procesos de migración, ráfaga, extensión y recuperación tras desastres de la manera más fluida posible. Los clientes que migran a la nube deben evaluar los problemas de elasticidad y ráfaga, salida del centro de datos, consolidación del centro de datos, escenarios de fin de vida, fusiones, adquisiciones, etc. El enfoque adoptado por cada organización puede variar en función de sus prioridades de negocio respectivas. A la hora de elegir las operaciones basadas en cloud, elegir un modelo de bajo coste con el rendimiento adecuado y un impedimento mínimo es uno de los objetivos cruciales. Además de elegir la plataforma adecuada, es especialmente importante coordinar el almacenamiento y el flujo de trabajo para liberar el poder de la puesta en marcha del cloud y la elasticidad.</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Aunque la solución Azure VMware ofrece funcionalidades híbridas únicas a un cliente, las opciones de almacenamiento nativo limitadas han restringido su utilidad para las organizaciones con cargas de trabajo con un gran volumen de almacenamiento. Debido a que el almacenamiento está directamente ligado a los hosts, la única forma de escalar el almacenamiento es añadir más hosts, lo cual puede aumentar los costes entre un 35 % y un 40 % o más para cargas de trabajo con un uso intensivo del almacenamiento. Estas cargas de trabajo necesitan almacenamiento adicional, no una potencia adicional, pero esto implica pagar por hosts adicionales.</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">Consideremos el siguiente escenario: Un cliente requiere seis hosts para la potencia (vCPU/vmem), pero también tienen un requisito fundamental para el almacenamiento. Tras su evaluación, necesitan 12 hosts para satisfacer los requisitos de almacenamiento. Esto aumenta el TCO general porque deben comprar toda la capacidad adicional cuando todo lo que realmente necesitan es más almacenamiento. Esto es aplicable en cualquier caso de uso, incluidos la migración, la recuperación ante desastres, bursting, prueba/desarrollo, y así sucesivamente.</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Otro caso de uso común para la solución VMware de Azure es la recuperación ante desastres (DR). La mayoría de las organizaciones no cuentan con una estrategia de recuperación ante desastres infalible o puede haber dificultades para justificar la ejecución de un centro de datos fantasma justo para la recuperación ante desastres. Los administradores podrían explorar opciones de recuperación ante desastres sin necesidad de espacio con un clúster sin piloto o un clúster bajo demanda. Entonces podrían escalar el almacenamiento sin añadir hosts adicionales, lo que podría ser una opción atractiva.</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">De este modo, en resumen, los casos de uso se pueden clasificar de dos formas:</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">Escalar la capacidad de almacenamiento con almacenes de datos ANF</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">Uso de almacenes de datos ANF como objetivo de recuperación ante desastres para un flujo de trabajo de recuperación optimizado en coste desde las instalaciones o en regiones de Azure entre los centros de datos definidos por software (SDDC). Esta guía proporciona información sobre el uso de Azure NetApp Files para proporcionar almacenamiento optimizado para almacenes de datos (actualmente en vista previa pública) Junto con las mejores funcionalidades de recuperación ante desastres y protección de datos de su clase en una solución Azure VMware, que le permite descargar la capacidad de almacenamiento del almacenamiento VSAN.</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">Opciones de VMware Cloud en Azure</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Solución Azure VMware</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">La solución VMware para Azure (AVS) es un servicio de cloud híbrido que proporciona centros de datos VMware completamente funcionales en un cloud público de Microsoft Azure. AVS es una solución de primera parte totalmente gestionada y compatible con Microsoft y verificada por VMware que utiliza infraestructura de Azure. Por lo tanto, los clientes obtienen VMware ESXi para virtualización informática, VSAN para almacenamiento hiperconvergente y NSX para redes y seguridad, todo ello al tiempo que aprovechan la presencia global de Microsoft Azure, instalaciones de centros de datos líderes en su clase y la proximidad al ecosistema enriquecido de servicios y soluciones nativos de Azure. Una combinación de un SDDC de la solución para Azure VMware y Azure NetApp Files proporciona el mejor rendimiento con una latencia de red mínima.</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">Independientemente del cloud utilizado, cuando se pone en marcha un SDDC de VMware, el clúster inicial incluye los siguientes componentes:</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">Hosts VMware ESXi para virtualización informática con un dispositivo vCenter Server para gestión.</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">Almacenamiento hiperconvergente VSAN de VMware que incorpora los activos de almacenamiento físico de cada host ESXi.</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">NSX de VMware para redes virtuales y seguridad con un clúster de NSX Manager para la gestión.</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">Tanto si su objetivo es adoptar un enfoque de todo el cloud como del cloud híbrido, Azure NetApp Files ofrece excelentes opciones para poner en marcha y gestionar las cargas de trabajo de las aplicaciones junto con servicios de archivos, a la vez que reduce el TCO permitiendo que los requisitos de datos se reduzcan a la capa de la aplicación. Independientemente del caso práctico, elija la solución VMware de Azure junto con Azure NetApp Files para comprender rápidamente las ventajas del cloud, una infraestructura consistente y operaciones en las instalaciones y varios clouds, portabilidad bidireccional de cargas de trabajo, y capacidad y rendimiento de nivel empresarial. Se trata del mismo proceso y procedimientos que ya conoce para conectar el almacenamiento. Recuerde que solo la posición de los datos ha cambiado con un nuevo nombre; las herramientas y los procesos siguen siendo los mismos y Azure NetApp Files ayuda a optimizar la implementación general.</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">Ahora puede usar Azure NetApp Files como almacén de datos en AVS SDDC.</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">Aumentar los tiempos de respuesta de las aplicaciones y ofrecer un mayor nivel de disponibilidad para proporcionar acceso a los datos de cargas de trabajo donde y cuando sea necesario.</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">Simplifique la complejidad general del almacenamiento VSAN con funciones de cambio de tamaño sencillas e instantáneas.</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">Rendimiento garantizado para cargas de trabajo críticas mediante una nueva formulación dinámica.</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Si el cloud de la solución para VMware Azure es el destino, Azure NetApp Files es la solución de almacenamiento adecuada para la puesta en marcha optimizada.</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Conectar almacenes de datos Azure NetApp Files a hosts de soluciones VMware Azure (avance)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS es un protocolo de sistema de archivos distribuido que es un estándar abierto IETF definido en solicitud de comentarios (RFC) que permite a cualquiera implementar el protocolo.</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">Anterior: Conceptos básicos de NAS protocols_overview.</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">Los volúmenes de Cloud Volumes Service se comparten a los clientes NFS exportando una ruta a la que pueden acceder un cliente o un conjunto de clientes. Los permisos para montar estas exportaciones se definen mediante políticas y reglas de exportación, que los administradores de Cloud Volumes Service pueden configurar.</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">La implantación de NFS de NetApp se considera un estándar oro para el protocolo y se utiliza en innumerables entornos NAS empresariales. En las siguientes secciones se tratan el NFS y las características de seguridad específicas disponibles en Cloud Volumes Service y cómo se implementan.</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">Usuarios y grupos UNIX locales predeterminados</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service contiene varios usuarios y grupos UNIX predeterminados para varias funcionalidades básicas. Estos usuarios y grupos no se pueden modificar ni eliminar actualmente. No es posible agregar nuevos usuarios y grupos locales a Cloud Volumes Service en este momento. Los usuarios y grupos de UNIX fuera de los usuarios y grupos predeterminados deben ser proporcionados por un servicio de nombres LDAP externo.</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">En la siguiente tabla se muestran los usuarios y grupos predeterminados y sus correspondientes ID numéricos. NetApp recomienda no crear nuevos usuarios o grupos en LDAP o en los clientes locales que vuelvan a usar estos ID numéricos.</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">Usuarios predeterminados: ID numéricos</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">Grupos predeterminados: ID numéricos</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">raíz:0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser:65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">nadie:65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">daemon:1</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">Cuando se utiliza NFSv4.1, el usuario raíz podría mostrarse como nadie cuando se ejecutan comandos de lista de directorios en clientes NFS. Esto se debe a la configuración de asignación de dominio de ID del cliente. Consulte la sección llamada <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> para obtener detalles sobre esta edición y cómo resolverla.</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">El usuario raíz</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">En Linux, la cuenta raíz tiene acceso a todos los comandos, archivos y carpetas de un sistema de archivos basado en Linux. Debido a la eficacia de esta cuenta, las prácticas recomendadas de seguridad a menudo requieren que el usuario raíz se desactive o se restrinja de alguna manera. En las exportaciones NFS, la potencia que tienen los usuarios raíz sobre los archivos y carpetas se puede controlar en Cloud Volumes Service mediante las normas y políticas de exportación, y un concepto denominado squash raíz.</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">comandos setuid/setgid (el bit de pegado)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">La función de ocupación de raíz garantiza que el usuario root que accede a un montaje NFS esté almacenado en la base del usuario numérico anónimo 65534 (consulte la sección “<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>”) y actualmente sólo está disponible cuando se utiliza CVS-Performance seleccionando Off para acceso raíz durante la creación de reglas de política de exportación. Si el usuario root está almacenado en el nombre del usuario anónimo, ya no tiene acceso a ejecutar chown o.<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> En los archivos o carpetas del montaje NFS, y los archivos o carpetas creados por el usuario raíz muestran el UID anon como el propietario/grupo. Además, el usuario raíz no puede modificar las ACL de NFSv4. Sin embargo, el usuario raíz todavía tiene acceso a chmod y archivos eliminados para los que no tiene permisos explícitos. Si desea limitar el acceso a los permisos de archivos y carpetas de un usuario raíz, considere la posibilidad de usar un volumen con ACL NTFS, creando un usuario de Windows con el nombre<block ref="63a9f0ea7bb98050796b649e85481845" prefix=" " category="inline-code"></block>y aplicar los permisos deseados a los archivos o carpetas.</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">El usuario anónimo</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">El ID de usuario anónimo (anon) especifica un ID de usuario o nombre de usuario de UNIX que se asigna a solicitudes de cliente que llegan sin credenciales de NFS válidas. Esto puede incluir al usuario root cuando se utiliza la función root squashing. El usuario anon en Cloud Volumes Service es 65534.</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">Este UID normalmente está asociado con el nombre de usuario<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> o.<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> En entornos Linux. Cloud Volumes Service utiliza también 65534 como usuario local de UNIX' pcuser» (véase la sección “<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>”), que también es el usuario de respaldo predeterminado para las asignaciones de nombres de Windows a UNIX cuando no se encuentra ningún usuario de UNIX válido coincidente en LDAP.</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">Debido a las diferencias en los nombres de usuario en Linux y Cloud Volumes Service para UID 65534, es posible que la cadena de nombre de los usuarios asignados a 65534 no coincida cuando se utiliza NFSv4.1. Como resultado, puede que vea<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> como usuario en algunos archivos y carpetas. Consulte la sección “<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>” para obtener información sobre este problema y cómo resolverlo.</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">Control de accesos/exportaciones</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">El acceso inicial a las exportaciones y recursos compartidos para montajes NFS se controla mediante reglas de la política de exportación basadas en host contenidas en una política de exportación. Se define una IP de host, nombre de host, subred, netgroup o dominio para permitir el acceso al montaje del recurso compartido de NFS y el nivel de acceso permitido al host. Las opciones de configuración de las reglas de política de exportación dependen del nivel de Cloud Volumes Service.</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">Para CVS-SW, hay disponibles las siguientes opciones para la configuración de la política de exportación:</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*Coincidencia de cliente.* Lista de direcciones IP separadas por comas, lista separada por comas de nombres de host, subredes, grupos de red, nombres de dominio.</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">*Reglas de acceso RO/RW.* Seleccione sólo lectura/escritura o lectura para controlar el nivel de acceso a la exportación.CVS-Performance ofrece las siguientes opciones:</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">*Reglas de acceso RO/RW.* Seleccione sólo lectura/escritura o lectura para controlar el nivel de acceso a la exportación.</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*Acceso raíz (on/OFF).* configura el squash raíz (consulte la sección “<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>" para obtener más información).</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*Tipo de protocolo.* esto limita el acceso al montaje NFS a una versión específica del protocolo. Cuando se especifican NFSv3 y NFSv4.1 para el volumen, deje las dos casillas en blanco o marque ambas.</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">*Nivel de seguridad de Kerberos (cuando se selecciona Enable Kerberos).* proporciona las opciones de krb5, krb5i y/o krb5p para acceso de solo lectura o de lectura/escritura.</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">Cambiar la propiedad (chown) y cambiar el grupo (chgrp)</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">NFS en Cloud Volumes Service sólo permite al usuario raíz ejecutar chown/chgrp en archivos y carpetas. Otros usuarios ven a.<block ref="7627e13d3e1910d7f604aa77914613da" prefix=" " category="inline-code"></block> error: incluso en los archivos que poseen. Si utiliza la raíz de squash (como se describe en la sección “<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>”), la raíz está ocupada para un usuario que no es raíz y no se permite el acceso a chown y chgrp. Actualmente no hay soluciones alternativas en Cloud Volumes Service para permitir chown y chgrp para usuarios no raíz. Si se requieren cambios de propiedad, considere usar volúmenes de protocolo dual y establezca el estilo de seguridad en NTFS para controlar los permisos del lado de Windows.</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">Gestión de permisos</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service admite ambos bits de modo (como 644, 777, etc. para rwx) y ACL de NFSv4.1 para controlar los permisos de los clientes NFS de los volúmenes que utilicen el estilo de seguridad UNIX. La gestión de permisos estándar se utiliza para estos (como chmod, chown o nfs4_setfacl) y funciona con cualquier cliente Linux que los admita.</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">Además, cuando se usan volúmenes de protocolo dual establecidos en NTFS, los clientes NFS pueden aprovechar la asignación de nombres Cloud Volumes Service a usuarios de Windows, que se utilizan para resolver los permisos NTFS. Esto requiere una conexión LDAP a Cloud Volumes Service para proporcionar traducciones de ID-a-nombre de usuario numérico porque Cloud Volumes Service requiere un nombre de usuario UNIX válido para asignar correctamente a un nombre de usuario de Windows.</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">Proporcionar ACL granulares para NFSv3</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">Los permisos de bit de modo solo cubren al propietario, al grupo y a todos los demás en la semántica, lo que significa que no hay controles de acceso de usuario granulares disponibles para NFSv3 básico. Cloud Volumes Service no admite ACL de POSIX, ni atributos extendidos (como chattr), de modo que las listas de control de acceso granulares solo son posibles en los siguientes escenarios con NFSv3:</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">Volúmenes de estilo de seguridad NTFS (servidor CIFS necesario) con asignaciones de usuarios de UNIX a Windows válidas.</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">Las ACL de NFSv4.1 se aplican mediante el montaje de NFSv4.1 en un cliente de administrador para aplicar ACL.</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">“LDAP”</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">Ambos métodos requieren una conexión LDAP para la administración de identidades de UNIX y una información de grupo y usuario de UNIX válida rellenada (consulte la sección <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>) Y sólo están disponibles con las instancias CVS-Performance. Para utilizar volúmenes de estilo de seguridad NTFS con NFS, debe utilizar el protocolo dual (SMB y NFSv3) o el protocolo doble (SMB y NFSv4.1), incluso si no se realiza ninguna conexión SMB. Para utilizar las ACL de NFSv4.1 con montajes NFSv3, debe seleccionar<block ref="3e8ec25076adc34554202fd2df86b9b4" prefix=" " category="inline-code"></block> como tipo de protocolo.</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">Nfs4_acl - Listas de control de acceso de NFSv4</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">Los bits del modo UNIX normal no proporcionan el mismo nivel de granularidad en permisos que proporcionan las ACL de NTFS o NFSv4.x. En la siguiente tabla, se compara la granularidad de permisos entre bits del modo NFSv3 y ACL de NFSv4.1. Para obtener más información sobre las ACL de NFSv4.1, consulte<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>.</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">Bits del modo NFSv3</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">ACL de NFSv4.1</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">Defina el ID de usuario en la ejecución</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">Establezca el ID de grupo en la ejecución</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">Guardar texto intercambiado (no definido en POSIX)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">Permiso de lectura para el propietario</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">Permiso de escritura para el propietario</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">Ejecutar permiso para el propietario en un archivo; o buscar (buscar) permiso para el propietario en el directorio</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">Permiso de lectura para grupo</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">Permiso de escritura para grupo</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">Ejecutar permiso para grupo en un archivo o buscar (buscar) permiso para grupo en el directorio</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">Permiso de lectura para otros</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">Permiso de escritura para otros</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">Ejecutar permiso para otros usuarios en un archivo; o buscar (buscar) permiso para otros en el directorio</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">Tipos de entrada de control de acceso (ACE) (permitir/Denegar/Auditoría) * indicadores de herencia * directorio-heredar * archivo-heredar * no-propagar-heredar * heredar-sólo</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">Permisos * datos de lectura (archivos) / directorio de lista (directorios) * escribir-datos (archivos) / crear-archivo (directorios) * anexar-datos (archivos) / subdirectorio de creación (directorios) * ejecutar (archivos) / cambiar-directorio (directorios) * eliminar * eliminar-hijo * atributos de lectura-escritura * escribir-atributos * atributos-ACL de lectura-escritura * Sincronizar-escritura-escritura-propietario * ACL</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">Por último, la pertenencia a grupos de NFS (tanto en NFSv3 COMO EN NFSV4.x) está limitada a un máximo predeterminado de 16 para AUTH_SYS según los límites de paquetes RPC. NFS Kerberos proporciona hasta 32 grupos y las ACL de NFSv4 eliminan la limitación a través de ACL granulares de usuarios y grupos (hasta 1024 entradas por ACE).</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">Crear y gestionar volúmenes de NFS</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">Además, Cloud Volumes Service ofrece compatibilidad ampliada con grupos para ampliar el número máximo de grupos admitidos hasta 32. Esto requiere una conexión LDAP a un servidor LDAP que contenga identidades de grupo y de usuario UNIX válidas. Para obtener más información acerca de cómo configurar esto, consulte<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> En la documentación de Google.</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">ID de usuario y grupo de NFSv3</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">Los ID de usuario y de grupo de NFSv3 se encuentran en el cable como identificadores numéricos en lugar de como nombres. Cloud Volumes Service no soluciona el nombre de usuario de estos ID numéricos con NFSv3, con los volúmenes de estilo de seguridad de UNIX que utilizan únicamente bits del modo. Cuando hay ACL de NFSv4.1, es necesario realizar una búsqueda de ID numéricos y/o una búsqueda de cadenas de nombre para resolver la ACL correctamente, incluso cuando se utiliza NFSv3. Con volúmenes de estilo de seguridad NTFS, Cloud Volumes Service debe resolver un ID numérico a un usuario UNIX válido y, a continuación, asignar a un usuario de Windows válido para negociar derechos de acceso.</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">Limitaciones de seguridad de los ID de usuario y de grupo de NFSv3</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">Con NFSv3, el cliente y el servidor nunca tienen que confirmar que el usuario que intenta leer o escribir con un ID numérico es un usuario válido; sólo es de confianza implícita. Esto abre el sistema de archivos hasta posibles infracciones simplemente falsificar cualquier ID numérico. Para evitar agujeros de seguridad como este, hay algunas opciones disponibles para Cloud Volumes Service.</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">La implementación de Kerberos para NFS obliga a los usuarios a autenticarse con un nombre de usuario y contraseña o un archivo keytab a obtener un vale Kerberos para permitir el acceso a un montaje. Kerberos solo está disponible con las instancias CVS-Performance y con NFSv4.1.</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">Limitar la lista de hosts de las reglas de la política de exportación los límites que los clientes NFSv3 tienen acceso al volumen de Cloud Volumes Service.</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">El uso de volúmenes de protocolo doble y la aplicación de ACL NTFS a los volúmenes obliga a los clientes NFSv3 a resolver los ID numéricos a nombres de usuario de UNIX válidos para autenticar correctamente el acceso a los montajes. Esto requiere habilitar LDAP y configurar las identidades de usuarios y grupos de UNIX.</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">Al SQUID el usuario raíz limita el daño que un usuario raíz puede hacer a un montaje NFS, pero no elimina por completo el riesgo. Para obtener más información, consulte la sección “<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>.”</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">En última instancia, la seguridad de NFS se limita a qué versión del protocolo utiliza que ofrece. NFSv3, aunque tiene un rendimiento general superior al de NFSv4.1, no proporciona el mismo nivel de seguridad.</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1 proporciona una mayor seguridad y fiabilidad en comparación con NFSv3, por los siguientes motivos:</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">Bloqueo integrado mediante un mecanismo basado en arrendamiento</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">Sesiones con estado</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">Todas las funciones de NFS en un único puerto (2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">Solo TCP</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">Asignación de dominio de ID</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Integración de Kerberos (NFSv3 puede utilizar Kerberos, pero solo para NFS, no para protocolos auxiliares como NLM)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">Dependencias de NFSv4.1</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">Debido a las funciones de seguridad adicionales de NFSv4.1, existen algunas dependencias externas implicadas que no fueron necesarias para utilizar NFSv3 (de forma similar a cómo requiere SMB dependencias como Active Directory).</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service ofrece compatibilidad con las ACL de NFSv4.x, las cuales proporcionan ventajas distintivas con respecto a los permisos de estilo POSIX normales, como las siguientes:</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">Control granular del acceso de los usuarios a los archivos y directorios</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">Mejor seguridad NFS</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">Interoperabilidad mejorada con CIFS/SMB</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">Eliminación de la limitación NFS de 16 grupos por usuario con seguridad AUTH_SYS</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">Los ACL omiten la necesidad de resolución del identificador de grupo (GID), que elimina en realidad las ACL de GID limititNFSv4.1 se controlan desde clientes NFS, no desde Cloud Volumes Service. Para utilizar las ACL de NFSv4.1, asegúrese de que la versión de software de su cliente las admite y de que están instaladas las utilidades NFS adecuadas.</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">Compatibilidad entre las ACL de NFSv4.1 y los clientes de SMB</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">Las ACL de NFSv4 son distintas de las de ACL de nivel de archivo de Windows (ACL de NTFS), pero llevan funciones similares. Sin embargo, en los entornos NAS multiprotocolo, si hay ACL de NFSv4.1 y utiliza acceso de doble protocolo (NFS y SMB en los mismos conjuntos de datos), los clientes que utilicen SMB2.0 y versiones posteriores no podrán ver ni gestionar ACL desde pestañas de seguridad de Windows.</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">Cómo funcionan las ACL de NFSv4.1</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">Como referencia, se definen los siguientes términos:</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*Lista de control de acceso (ACL).* una lista de entradas de permisos.</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*Entrada de control de acceso (ACE).* Entrada de permiso en la lista.</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">Cuando un cliente establece una ACL de NFSv4.1 en un archivo durante una operación SETATTR, Cloud Volumes Service establece esa ACL en el objeto, por lo que se sustituye cualquier ACL existente. Si no hay ACL en un archivo, los permisos de modo en el archivo se calculan a partir de OWNER@, GROUP@ y EVERYONE@. Si hay algún bit SUID/SGID/STICKY existente en el archivo, no se verán afectados.</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">Cuando un cliente obtiene una ACL de NFSv4.1 en un archivo durante UNA operación GETATTR, Cloud Volumes Service lee la ACL de NFSv4.1 asociada con el objeto, construye una lista de ACE y devuelve la lista al cliente. Si el archivo tiene una ACL de NT o bits de modo, se crea una ACL a partir de bits de modo y se devuelve al cliente.</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">Se deniega el acceso si EXISTE UNA ACE DENEGADA en la ACL; el acceso se concede si existe una ACE DE PERMISO. Sin embargo, también se deniega el acceso si ninguno de los ACE está presente en el ACL.</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">Un descriptor de seguridad consiste en una ACL de seguridad (SACL) y una ACL discrecional (DACL). Cuando NFSv4.1 interactúa con CIFS/SMB, el DACL se asigna de uno a uno con NFSv4 y CIFS. El DACL consta de LOS ACs PERMITIR Y DENEGAR.</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">Si es un básico<block ref="417e248f80c35ca0d471575a5fb951f5" prefix=" " category="inline-code"></block> Se ejecuta en un archivo o carpeta con conjuntos de ACL de NFSv4.1, se conservan las ACL de usuario y grupo existentes, pero se modifican las ACL de PROPIETARIO@, GRUPO@ y TODOS@ predeterminadas.</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">indicadores de herencia</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">Un cliente que utilice las ACL de NFSv4.1 puede definir y ver ACL de archivos y directorios en el sistema. Cuando se crea un archivo o subdirectorio nuevo en un directorio que tiene una ACL, ese objeto hereda todos los ACE de la ACL que se han etiquetado con el correspondiente<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>.</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">Si un archivo o directorio tiene una ACL de NFSv4.1, esa ACL se utiliza para controlar el acceso, independientemente de qué protocolo se utilice para acceder al archivo o directorio.</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">Los archivos y directorios heredan los ACE de las ACL de NFSv4 en directorios principales (posiblemente con las modificaciones adecuadas) siempre que se hayan etiquetado los ACE con las marcas de herencia correctas.</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">Cuando se crea un archivo o directorio como resultado de una solicitud de NFSv4, la ACL del archivo o directorio resultante depende de si la solicitud de creación de archivos incluye una ACL o solo permisos de acceso estándar a archivos UNIX. La ACL también depende de si el directorio primario tiene una ACL.</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">Si la solicitud incluye una ACL, se utiliza esa ACL.</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">Si la solicitud incluye sólo permisos de acceso estándar a archivos UNIX y el directorio principal no tiene una ACL, el modo de archivo de cliente se utiliza para establecer permisos de acceso estándar a archivos UNIX.</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">Si la solicitud incluye sólo permisos de acceso estándar a archivos UNIX y el directorio primario tiene una ACL no heredable, se establece una ACL predeterminada basada en los bits de modo pasados a la solicitud en el nuevo objeto.</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">Si la solicitud incluye sólo permisos de acceso estándar a archivos UNIX pero el directorio principal tiene una ACL, el archivo o directorio nuevos heredan los ACE de la ACL del directorio principal siempre que se hayan etiquetado los ACE con los indicadores de herencia correspondientes.</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">Permisos ACE</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">CÓMO: Utilizar NFSv4 ACL</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">Los permisos de ACL de NFSv4.1 utilizan una serie de valores de letras mayúsculas y minúsculas (como<block ref="a0331a73af55fd5fda99201f776e847c" prefix=" " category="inline-code"></block>) para controlar el acceso. Para obtener más información acerca de estos valores de letra, consulte<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>.</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">Comportamiento de ACL de NFSv4.1 con herencia umask y ACL</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">Las ACL de NFSv4 proporcionan la capacidad de ofrecer herencia de ACL</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">Indicador de herencia de ACL</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>. La herencia de ACL significa que los archivos o carpetas creados debajo de los objetos con conjuntos de ACL de NFSv4.1 pueden heredar las ACL según la configuración de<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>.</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">Umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> se utiliza para controlar el nivel de permisos en el que se crean archivos y carpetas en un directorio sin interacción del administrador. De forma predeterminada, Cloud Volumes Service permite a umask reemplazar las ACL heredadas, que es el comportamiento esperado según<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>.</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">Formato de ACL</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">Las ACL de NFSv4.1 tienen formato específico. El ejemplo siguiente es un conjunto ACE en un archivo:</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">El ejemplo anterior sigue las directrices de formato ACL de:</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">Tipo de<block ref="7fc56270e7a70fa81a5935b72eacbe29" prefix=" " category="inline-code"></block> significa “permitir”. Los indicadores heredar no se establecen en este caso, porque el principal no es un grupo y no incluye la herencia. Además, como ACE no es una entrada DE AUDITORÍA, no es necesario establecer los indicadores de auditoría. Para obtener más información sobre las ACL de NFSv4.1, consulte<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>.</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">Si la ACL de NFSv4.1 no se establece correctamente (o el cliente y el servidor no pueden resolver una cadena de nombre), es posible que la ACL no se comporte como se espera o que el cambio de ACL no se pueda aplicar y generar un error.</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">Los errores de muestra son los siguientes:</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">RECHAZO explícito</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">Los permisos de NFSv4.1 pueden incluir atributos DE DENEGACIÓN explícitos para EL PROPIETARIO, EL GRUPO Y TODOS. Esto se debe a que las ACL de NFSv4.1 son denegadas por defecto, lo que significa que si un ACE no concede explícitamente una ACL, se deniega. Los atributos DE DENEGACIÓN explícita anulan cualquier ACE de ACCESO, explícita o no.</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">DENEGAR ACE se establece con una etiqueta de atributo de<block ref="f623e75af30e62bbd73d6df5b50bb7b5" prefix=" " category="inline-code"></block>.</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">En el siguiente ejemplo, SE permite a GROUP@ todos los permisos de lectura y ejecución, pero se le deniega todo el acceso de escritura.</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">DENEGAR ACs debe evitarse siempre que sea posible porque pueden ser confusos y complicados; PERMITIR que las ACL que no están definidas explícitamente se deniegan implícitamente. Cuando SE establecen LAS ACE DENEGADAS, es posible que se deniegue el acceso a los usuarios cuando esperan que se les conceda el acceso.</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">El conjunto anterior de ACE es equivalente a 755 bits de modo, lo que significa:</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">El propietario tiene derechos completos.</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">Los grupos tienen sólo lectura.</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">Otros sólo han leído.</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">Sin embargo, incluso si los permisos se ajustan al equivalente de 775, se puede denegar el acceso debido a LA DENEGACIÓN explícita establecida en TODOS.</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">Dependencias de asignación de dominio de ID de NFSv4.1</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1 aprovecha la lógica de asignación de dominio de ID como capa de seguridad para ayudar a verificar que un usuario que intenta acceder a un montaje de NFSv4.1 es realmente lo que afirman que es. En estos casos, el nombre de usuario y el nombre del grupo que provienen del cliente NFSv4.1 anexa una cadena de nombres y la envía a la instancia de Cloud Volumes Service. Si esa combinación de nombre de usuario/grupo y cadena de ID no coincide, el usuario y/o grupo se utiliza en la función no se define ningún usuario por defecto en la<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block> archivo en el cliente.</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">Esta cadena de ID es un requisito para la observancia correcta de los permisos, especialmente cuando se utilizan las ACL de NFSv4.1 y/o Kerberos. Como resultado, las dependencias del servidor del servicio de nombres, como los servidores LDAP, son necesarias para garantizar la coherencia entre los clientes y la Cloud Volumes Service con el fin de resolver correctamente la identidad de nombres de usuario y grupo.</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service utiliza un valor de nombre de dominio de ID predeterminado estático de<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block>. Los clientes NFS utilizan de forma predeterminada el nombre de dominio DNS para la configuración de nombre de dominio ID, pero puede ajustar manualmente el nombre de dominio ID en<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block>.</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Si LDAP está habilitado en Cloud Volumes Service, Cloud Volumes Service automatiza el dominio de identificador de NFS para cambiar a lo que está configurado para el dominio de búsqueda en DNS y los clientes no tendrán que modificarse a menos que utilicen nombres de búsqueda de dominio DNS diferentes.</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Cuando Cloud Volumes Service puede resolver un nombre de usuario o de grupo en archivos locales o LDAP, se utiliza la cadena de dominio y los ID de dominio no coincidentes no se pueden squash a nadie. Si Cloud Volumes Service no puede encontrar un nombre de usuario o nombre de grupo en los archivos locales o LDAP, se utiliza el valor de ID numérico y el cliente NFS resuelve el nombre correctamente (esto es similar al comportamiento de NFSv3).</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">Sin cambiar el dominio de Id. De NFSv4.1 del cliente para que coincida con el uso del volumen de Cloud Volumes Service, verá el siguiente comportamiento:</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">Los usuarios y grupos UNIX con entradas locales en Cloud Volumes Service (como root, tal como se define en los usuarios y grupos locales de UNIX) se utilizan en el valor nobody.</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">Los usuarios y grupos de UNIX con entradas en LDAP (si Cloud Volumes Service está configurado para usar LDAP) no se conectan a nadie si los dominios DNS son diferentes entre los clientes NFS y Cloud Volumes Service.</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">Los usuarios y grupos de UNIX que no tienen entradas locales ni entradas LDAP utilizan el valor de ID numérico y resuelven el nombre especificado en el cliente NFS. Si no existe ningún nombre en el cliente, sólo se muestra el ID numérico.</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">A continuación se muestran los resultados de la situación anterior:</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">Cuando los dominios de ID de cliente y servidor coinciden, así es como el mismo aspecto del listado de archivos:</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">Para obtener más información acerca de este problema y cómo resolverlo, consulte la sección “<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>.”</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Dependencias de Kerberos</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">Si va a utilizar Kerberos con NFS, debe tener lo siguiente con Cloud Volumes Service:</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Dominio de Active Directory para servicios del centro de distribución Kerberos (KDC)</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">Dominio de Active Directory con atributos de usuario y grupo rellenados con información de UNIX para la funcionalidad LDAP (NFS Kerberos en Cloud Volumes Service requiere un SPN de usuario a la asignación de usuarios UNIX para una funcionalidad adecuada).</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">LDAP habilitado en la instancia de Cloud Volumes Service</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">Dominio de Active Directory para servicios DNS</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1 y el usuario/grupo nadie</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">Uno de los problemas más comunes que se ven con una configuración de NFSv4.1 es cuando se muestra un archivo o una carpeta en un listado mediante<block ref="44ba5ca65651b4f36f1927576dd35436" prefix=" " category="inline-code"></block> como propiedad de la<block ref="aa22bf558e0fe9237af37223aa4eecbb" prefix=" " category="inline-code"></block> combinación de<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Por ejemplo:</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">Y el ID numérico es<block ref="ac627ab1ccbdb62ec96e702f07f6425b" prefix=" " category="inline-code"></block>.</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">En algunos casos, es posible que el archivo muestre el propietario correcto pero<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> como grupo.</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">¿Quién no es nadie?</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">La<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> El usuario de NFSv4.1 es diferente del<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> usuario. Puede ver cómo un cliente NFS ve cada usuario ejecutando el<block ref="b80bb7740288fda1f201890375a60c8f" prefix=" " category="inline-code"></block> comando:</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">Con NFSv4.1, el<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> user es el usuario predeterminado definido por<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> file y puede definirse como cualquier usuario que desee utilizar.</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">¿Por qué sucede esto?</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">Puesto que la seguridad mediante la asignación de cadenas de nombres es un conjunto de claves de las operaciones de NFSv4.1, el comportamiento predeterminado cuando una cadena de nombres no coincide correctamente es squash a ese usuario con uno que normalmente no tendrá acceso a los archivos y carpetas que pertenecen a usuarios y grupos.</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">Cuando vea<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Para el usuario o el grupo de los listados de archivos, esto generalmente significa que hay algo configurado para NFSv4.1. Aquí puede entrar en juego la sensibilidad del caso.</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">Por ejemplo, si usuario1@CVSDEMO.LOLARL (uid 1234, gid 1234) está accediendo a una exportación, entonces Cloud Volumes Service debe ser capaz de encontrar usuario1@CVSDEMO.LOLARL (uid 1234, gid 1234). Si el usuario en Cloud Volumes Service es USER1@CVSDEMO.LLOLex, entonces no coincidiría (USUARIO1 en mayúscula frente al usuario en minúscula 1). En muchos casos, puede ver lo siguiente en el archivo de mensajes del cliente:</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">Tanto el cliente como el servidor deben estar de acuerdo en que un usuario es realmente quien afirma que es, por lo que debe comprobar lo siguiente para asegurarse de que el usuario que ve el cliente tiene la misma información que el usuario que ve Cloud Volumes Service.</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">*Dominio de ID NFSv4.x.* Cliente:<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> Archivo; utiliza Cloud Volumes Service<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block> y no se puede cambiar manualmente. Si se utiliza LDAP con NFSv4.1, Cloud Volumes Service cambia el dominio de ID por lo que utiliza el dominio de búsqueda DNS, que es el mismo que el dominio de AD.</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*Nombre de usuario e ID numéricos.* esto determina dónde busca el cliente los nombres de usuario y aprovecha la configuración del conmutador de servicio de nombres—cliente:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Y/o archivos locales passwd y group; Cloud Volumes Service no permite modificaciones a esto pero agrega automáticamente LDAP a la configuración cuando está habilitado.</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*Nombre del grupo e ID numéricos.* esto determina dónde está buscando el cliente los nombres de grupo y aprovecha la configuración del conmutador de servicio de nombres—cliente:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Y/o archivos locales passwd y group; Cloud Volumes Service no permite modificaciones a esto pero agrega automáticamente LDAP a la configuración cuando está habilitado.</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">En casi todos los casos, si ve<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> En las listas de usuarios y grupos de clientes, el problema es la traducción de ID de dominio de nombre de usuario o grupo entre Cloud Volumes Service y el cliente NFS. Para evitar esta situación, use LDAP para resolver la información de usuario y grupo entre los clientes y Cloud Volumes Service.</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">Ver cadenas de ID de nombres para NFSv4.1 en clientes</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">Si utiliza NFSv4.1, hay una asignación de cadena de nombre que se realiza durante las operaciones de NFS, como se ha descrito anteriormente.</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">Además de utilizar<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block> Para encontrar un problema con los ID de NFSv4, puede utilizar la<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> Comando en el cliente NFS para ver los nombres de usuario que se han asignado correctamente al dominio de NFSv4.</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">Por ejemplo, se trata del resultado del comando después de que un usuario que puede encontrar el cliente y Cloud Volumes Service accede a un montaje NFSv4.x:</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">Cuando un usuario que no se asigna correctamente al dominio de ID de NFSv4.1 (en este caso,<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>) intenta acceder al mismo montaje y toca un archivo, están asignados<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>, según lo esperado.</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">La<block ref="600a8e1223f644dfc8fc6d9eaf7c6585" prefix=" " category="inline-code"></block> salida muestra al usuario<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> en la pantalla pero no<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>; éste es el usuario anónimo en nuestra regla de política de exportación <block ref="f9df942af967185fc775031b3c286856" prefix="(" category="inline-code"></block>).</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">Siguiente: SMB.</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Todas las acciones de gestión a Cloud Volumes Service se realizan mediante API. La gestión de Cloud Volumes Service integrada en la consola cloud de GCP también utiliza la API de Cloud Volumes Service.</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">Arquitectura del plano de control</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">Anterior: Arquitectura Cloud Volumes Service.</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">Gestión de acceso e identidad</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">Gestión de acceso e identidad <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>) Es un servicio estándar que le permite controlar la autenticación (inicios de sesión) y la autorización (permisos) a las instancias de proyecto de Google Cloud. Google IAM proporciona un registro de auditoría completo de la autorización y eliminación de permisos. Actualmente, Cloud Volumes Service no proporciona auditoría del plano de control.</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">Información general sobre autorización/permisos</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">complete aquí la lista de permisos granulares</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM ofrece permisos granulares integrados para Cloud Volumes Service. Puede encontrar un<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>.</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM también ofrece dos roles predefinidos llamados<block ref="4a5395c87dd91b3242056f83b7cedb9b" prefix=" " category="inline-code"></block> y..<block ref="d8cd72eb52281636a72e12ef877b62f8" prefix=" " category="inline-code"></block>. Estos roles pueden asignarse a usuarios o cuentas de servicio específicos.</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">Asigne roles y permisos adecuados para permitir que los usuarios de IAM gestionen Cloud Volumes Service.</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">Algunos ejemplos para el uso de permisos granulares son los siguientes:</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">Cree una función personalizada con sólo permisos get/list/create/update para que los usuarios no puedan eliminar volúmenes.</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">Use un rol personalizado con solo<block ref="984f6a68d5cd59b0b62580124dedfd98" prefix=" " category="inline-code"></block> Permisos para crear una cuenta de servicio que se utilice para crear una integración de Snapshot coherente con las aplicaciones.</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">Cree un rol personalizado para delegar<block ref="49fb6de34b20a50950c47f0a75513736" prefix=" " category="inline-code"></block> para usuarios específicos.</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">Cuentas de servicio</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">Para realizar llamadas a la API de Cloud Volumes Service a través de scripts o.<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>, debe crear una cuenta de servicio con<block ref="5e467dce18f46b1803b06097fae60b82" prefix=" " category="inline-code"></block> función. Puede utilizar esta cuenta de servicio para generar los tokens JWT necesarios para autenticar las solicitudes de API de Cloud Volumes Service de dos maneras diferentes:</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">Genere una clave JSON y utilice las API de Google para obtener un token de JWT de él. Este es el método más sencillo, pero implica la gestión de secretos manuales (la clave JSON).</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">Suplantación de cuentas de servicio</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">Credenciales predeterminadas de la aplicación</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">Uso<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> con<block ref="4d4344aa5ad9d43d63ab2f068115cadb" prefix=" " category="inline-code"></block>. El código (script, Terraform, etc.) se ejecuta con<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> e representa a la cuenta de servicio para obtener sus permisos. Este enfoque refleja las mejores prácticas de seguridad de Google.</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">Creación de la cuenta de servicio y la clave privada</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">Consulte<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> Para obtener más información, consulte la documentación de cloud de Google.</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">API de Cloud Volumes Service</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">API de Cloud Volumes en la documentación de Google Cloud</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">La API de Cloud Volumes Service utiliza una API basada en REST usando HTTPS (TLSv1.2) como transporte de red subyacente. Puede encontrar la definición de API más reciente<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> E información acerca de cómo utilizar la API en<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>.</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">NetApp utiliza y protege el extremo de la API mediante la funcionalidad estándar HTTPS (TLSv1.2).</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">Fichas JWT</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">La autenticación a la API se realiza con tokens JWT portadores <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>). Se deben obtener tokens JWT válidos mediante la autenticación de Google Cloud IAM. Para ello, debe obtener un token del IAM mediante la obtención de una clave JSON de la cuenta de servicio.</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">Registro de auditoría</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">Actualmente, no hay registros de auditoría del plano de control a los que el usuario pueda acceder.</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">Siguiente: Arquitectura de plano de datos.</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">El primer paso para comprender cómo proteger los datos es identificar los riesgos y las posibles superficies de ataque.</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">Consideraciones de seguridad y superficies de ataque</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">Anterior: Cómo Cloud Volumes Service en Google Cloud protege sus datos.</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">El primer paso para comprender cómo proteger los datos es identificar los riesgos y las posibles superficies de ataque. Estos incluyen (pero no se limitan a) lo siguiente:</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">Administración y inicios de sesión</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">Datos en reposo</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">Datos en movimiento</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">Red y firewalls</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">Ransomware, malware y virus</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">Comprender las superficies de ataque puede ayudarle a proteger mejor sus entornos. Cloud Volumes Service en Google Cloud ya considera muchos de estos temas e implementa la funcionalidad de seguridad de forma predeterminada, sin ninguna interacción administrativa.</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">Garantizar inicios de sesión seguros</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">Al proteger los componentes esenciales de su infraestructura, es fundamental asegurarse de que solo los usuarios aprobados puedan iniciar sesión y gestionar sus entornos. Si los agentes erróneos infringen sus credenciales administrativas, tienen las claves para el castillo y pueden hacer lo que quieran: Cambiar configuraciones, eliminar volúmenes y backups, crear puertas traseras o deshabilitar las programaciones de Snapshot.</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service para Google Cloud proporciona protección contra accesos administrativos no autorizados a través de la confusión del almacenamiento como servicio (StaaS). Cloud Volumes Service está completamente mantenido por el proveedor de cloud sin disponibilidad para iniciar sesión externamente. Todas las operaciones de configuración y configuración se automatizan por completo, por lo que un administrador humano nunca tiene que interactuar con los sistemas excepto en circunstancias muy raras.</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">“Arquitectura de Cloud Volumes Service”.</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">Si se requiere inicio de sesión, Cloud Volumes Service en Google Cloud asegura los inicios de sesión manteniendo una lista muy corta de administradores de confianza que tienen acceso para iniciar sesión en los sistemas. Este método de gatekeeping ayuda a reducir el número de posibles malos actores con acceso. Además, la red de Google Cloud oculta los sistemas tras capas de seguridad de la red y sólo expone lo que se necesita al mundo exterior. Si quiere más información sobre la arquitectura de Google Cloud y Cloud Volumes Service, consulte la sección <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">Administración de clústeres y actualizaciones</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">Dos áreas con riesgos potenciales de seguridad incluyen la administración de clústeres (lo que ocurre si un actor defectuoso tiene acceso de administrador) y las actualizaciones (lo que ocurre si una imagen de software está comprometida).</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">Protección en la administración del almacenamiento</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">“Funcionamiento de servicio”.</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">El almacenamiento proporcionado como servicio elimina el riesgo añadido de exposición a los administradores al eliminar ese acceso a los usuarios finales fuera del centro de datos de cloud. En su lugar, la única configuración que se realiza es para el plano de acceso a los datos por parte de los clientes. Cada inquilino gestiona sus propios volúmenes y ningún inquilino puede llegar a otras instancias de Cloud Volumes Service. El servicio se gestiona mediante automatización, con una pequeña lista de administradores de confianza a los que se les da acceso a los sistemas a través de los procesos que se tratan en la sección <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">El tipo de servicio CVS-Performance ofrece replicación entre regiones como una opción para proporcionar protección de datos a otra región en caso de un fallo en una región. En esos casos, Cloud Volumes Service puede realizar una conmutación por error a la región no afectada para mantener el acceso a los datos.</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">Actualizaciones de servicios</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">Las actualizaciones ayudan a proteger los sistemas vulnerables. Cada actualización proporciona mejoras de seguridad y correcciones de errores que minimizan las superficies de ataque. Las actualizaciones de software se descargan desde repositorios centralizados y se validan antes de permitir que las actualizaciones verifiquen que las imágenes oficiales se utilizan y que las actualizaciones no se ven comprometidas por actores defectuosos.</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Con Cloud Volumes Service, los equipos del proveedor de cloud se encargan de gestionar las actualizaciones, lo que elimina la exposición al riesgo para los equipos de administrador, al proporcionar a los expertos conocedor de la configuración y las actualizaciones, que han automatizado y probado totalmente el proceso. Las actualizaciones no son disruptivas, y Cloud Volumes Service mantiene las últimas actualizaciones para obtener los mejores resultados generales.</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">Para obtener información acerca del equipo de administrador que realiza estas actualizaciones de servicio, consulte la sección <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">Protección de datos en reposo</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">El cifrado de datos en reposo es importante para proteger los datos confidenciales en caso de robo, devolución o reasignación de un disco. Los datos de Cloud Volumes Service se protegen en reposo mediante el cifrado basado en software.</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Las claves generadas por Google se utilizan para CVS-SW.</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2 certificado n.o 4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">Para CVS-Performance, las claves por volumen se almacenan en un gestor de claves incorporado en Cloud Volumes Service, que usa CryptoMod de ONTAP de NetApp para generar claves de cifrado AES-256. CryptoMod aparece en la lista CMVP de módulos validados FIPS 140-2-2. Consulte<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>.</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">A partir de noviembre de 2021, se empezó a disponer de la funcionalidad de cifrado gestionado por el cliente (CMEK) para CVS-Performance. Esta funcionalidad le permite cifrar las claves por volumen con claves maestras por proyecto y región alojadas en Google Key Management Service (KMS). KMS le permite asociar gestores de claves externos.</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Consulte la documentación de Cloud Volumes Service</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">Para obtener detalles sobre cómo configurar KMS para CVS-Performance,<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>.</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">Para obtener más información acerca de la arquitectura, consulte la sección <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">Protección de datos en tránsito</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">Además de proteger los datos en reposo, también debe ser capaz de proteger los datos cuando están en tránsito entre la instancia de Cloud Volumes Service y un destino de cliente o replicación. Cloud Volumes Service proporciona cifrado para los datos en tránsito en protocolos NAS mediante métodos de cifrado como el cifrado SMB mediante Kerberos, la firma/sellado de paquetes y NFS Kerberos 5p para el cifrado integral de transferencias de datos.</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">La replicación de volúmenes de Cloud Volumes Service utiliza TLS 1.2, que aprovecha los métodos de cifrado AES-GCM.</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">“Cifrado de datos en tránsito”</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">Los protocolos en vuelo más inseguros, como telnet, NDMP, etc., están desactivados de forma predeterminada. Sin embargo, DNS no está encriptado por Cloud Volumes Service (no admite segundos DNS) y debe ser encriptada usando cifrado de red externa cuando sea posible. Consulte la sección <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> para obtener más información sobre cómo proteger los datos en movimiento.</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">“Protocolos NAS”.</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">Para obtener información acerca del cifrado del protocolo NAS, consulte la sección <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">Usuarios y grupos para permisos NAS</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">Parte de la protección de datos en el cloud implica una autenticación de usuarios y grupos adecuada, en la que se comprueban los usuarios que acceden a los datos como usuarios reales del entorno y los grupos contienen usuarios válidos. Estos usuarios y grupos proporcionan acceso inicial al recurso compartido y a la exportación, así como validación de permisos para archivos y carpetas en el sistema de almacenamiento.</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service utiliza la autenticación estándar de grupos y usuarios de Windows basada en Active Directory para recursos compartidos de SMB y permisos de estilo Windows. El servicio también puede aprovechar proveedores de identidad UNIX, como LDAP para usuarios y grupos de UNIX para exportaciones NFS, validación de ID de NFSv4, autenticación Kerberos y ACL de NFSv4.</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">Actualmente sólo el LDAP de Active Directory es compatible con Cloud Volumes Service para la funcionalidad LDAP.</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">Detección, prevención y mitigación de ransomware, malware y virus</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">El ransomware, el malware y los virus representan una amenaza persistente para los administradores, y la detección, prevención y mitigación de esas amenazas son siempre una prioridad para las organizaciones empresariales. Un solo evento de ransomware en un conjunto de datos crucial puede costar potencialmente millones de dólares, por lo que es beneficioso hacer lo que puede minimizar el riesgo.</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">detección automática de ransomware</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Aunque Cloud Volumes Service no incluye actualmente medidas de detección o prevención nativas, como la protección antivirus o<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>, Hay formas de recuperarse rápidamente de un evento de ransomware mediante la habilitación de horarios habituales de copias Snapshot. Las copias Snapshot no modificables y de solo lectura hacen referencia a los bloques modificados del sistema de ficheros, son casi instantáneas, tienen un impacto mínimo en el rendimiento y solo utilizan espacio cuando se modifican o eliminan datos. Puede configurar programaciones para copias Snapshot de acuerdo con el objetivo de punto de recuperación (RPO)/objetivo de tiempo de recuperación (RTO) que desee y puede conservar hasta 1,024 copias Snapshot por volumen.</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link">La solución de NetApp para ransomware</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">El soporte de copias Snapshot se incluye sin coste adicional (además de los cargos en el almacenamiento de datos correspondientes a los bloques/datos modificados que conservan las copias Snapshot) con Cloud Volumes Service y, en el caso de un ataque de ransomware, se puede usar para revertir a una copia Snapshot antes de que se produjera el ataque. Las restauraciones Snapshot se realizan en cuestión de segundos y, a continuación, puede volver a servir datos de forma normal. Para obtener más información, consulte<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>.</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">Para evitar que el ransomware afecte a su negocio es necesario un enfoque multicapa que incluya una o varias de las siguientes opciones:</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">Protección de terminales</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">Protección contra amenazas externas a través de firewalls de red</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">Detección de anomalías de datos</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">Múltiples backups (in situ y fuera de ellas) de conjuntos de datos cruciales</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">Pruebas de restauración de backups periódicas</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">Copias Snapshot de NetApp de solo lectura inalterables</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">Autenticación multifactor para la infraestructura crucial</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">Auditorías de seguridad de inicios de sesión del sistema</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">Esta lista dista mucho de ser exhaustiva, pero es un buen proyecto a seguir cuando se trata del potencial de ataques de ransomware. Cloud Volumes Service en Google Cloud proporciona varias formas de protegerse contra eventos de ransomware y reducir sus efectos.</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">Copias Snapshot modificables</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">De forma nativa, Cloud Volumes Service proporciona copias Snapshot inmutables de solo lectura que se utilizan en una programación personalizable para una recuperación rápida de un momento específico en caso de eliminación de datos o si un volumen completo ha sido victimizado por un ataque de ransomware. Las restauraciones de Snapshot a copias Snapshot en buenas condiciones anteriores son rápidas y minimizan la pérdida de datos en función del período de retención de sus programaciones de Snapshot, y de objetivos de tiempo y de punto de recuperación. El efecto que tiene la tecnología Snapshot en el rendimiento es mínimo.</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Como las copias snapshot de Cloud Volumes Service son de solo lectura, no pueden infectarse con el ransomware a menos que el ransomware haya proliferado en el conjunto de datos inadvertido y las copias snapshot se han tomado de los datos infectados por el ransomware. Por este motivo, también debe considerar la detección de ransomware basada en anomalías de los datos. Cloud Volumes Service no ofrece actualmente una detección de forma nativa, pero puede utilizar un software de supervisión externo.</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">Backups y restauraciones</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service proporciona funcionalidades de backup de clientes NAS estándar (como backups a través de NFS o SMB).</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">replicación de volúmenes</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS-Performance ofrece replicación de volúmenes entre regiones a otros volúmenes CVS-Performance. Para obtener más información, consulte<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> En la documentación de Cloud Volumes Service.</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">backup en el cloud</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW ofrece funcionalidades de backup y restauración de volúmenes nativas del servicio. Para obtener más información, consulte<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> En la documentación de Cloud Volumes Service.</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">La replicación de volúmenes proporciona una copia exacta del volumen de origen para una conmutación por error rápida en caso de un desastre, incluidos los eventos de ransomware.</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">Replicación entre regiones</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS-Performance le permite replicar de forma segura volúmenes en las regiones de Google Cloud para la protección de datos y casos de uso de archivado mediante el cifrado TLS1.2 AES 256 GCM en una red de servicios de back-end controlada por NetApp mediante interfaces específicas que se utilizan para la replicación que se ejecuta en la red de Google. Un volumen primario (origen) contiene los datos de producción activos y se replica en un volumen secundario (destino) para proporcionar una réplica exacta del conjunto de datos primario.</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">La replicación inicial transfiere todos los bloques, pero las actualizaciones solo transmiten los bloques cambiados de un volumen primario. Por ejemplo, si una base de datos de 1 TB que reside en un volumen primario se replica en el volumen secundario, se transfiere 1 TB de espacio en la replicación inicial. Si esa base de datos tiene unos pocos cientos de filas (hipotéticamente, unos pocos MB) que cambian entre la inicialización y la siguiente actualización, sólo los bloques con las filas modificadas se replican al secundario (unos pocos MB). Esto ayuda a garantizar que los tiempos de transferencia siguen siendo bajos y que los costes de replicación siguen bajos.</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">Todos los permisos de los archivos y carpetas se replican en el volumen secundario, pero los permisos de acceso al recurso compartido (como políticas y reglas de exportación o recursos compartidos de SMB y ACL compartidos) se deben gestionar por separado. En el caso de una conmutación por error del sitio, el sitio de destino debe aprovechar los mismos servicios de nombre y las conexiones de dominio de Active Directory para proporcionar un manejo coherente de identidades y permisos de usuarios y grupos. Puede usar un volumen secundario como destino de conmutación por error en caso de un desastre si se rompe la relación de replicación, que convierte el volumen secundario en lectura/escritura.</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">Las réplicas de volúmenes son de solo lectura, lo que proporciona una copia inalterable de datos fuera de las instalaciones para una recuperación rápida de los datos en instancias donde un virus ha infectado los datos o ransomware ha cifrado el conjunto de datos principal. Los datos de solo lectura no se cifrarán, pero, si el volumen primario se ve afectado y se produce la replicación, los bloques infectados también se replican. Puede utilizar copias Snapshot antiguas no afectadas para la recuperación, pero es posible que los acuerdos de nivel de servicio no estén dentro del rango de objetivo de tiempo de recuperación/objetivo de punto de recuperación prometido en función de la rapidez con la que se detecte un ataque.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">Consideraciones de seguridad</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">Además, puede evitar acciones administrativas maliciosas, como eliminaciones de volúmenes, eliminaciones de copias Snapshot o cambios de programación de Snapshot, con gestión de replicación entre regiones (CRR) en Google Cloud. Para ello, se crean funciones personalizadas que separan a los administradores de volúmenes, que pueden eliminar volúmenes de origen, pero no interrumpir las operaciones y, por lo tanto, no se pueden eliminar los volúmenes de destino, de los administradores de CRR, que no pueden realizar ninguna operación de volumen. Consulte<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> En la documentación de Cloud Volumes Service para los permisos que permite cada grupo de administradores.</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="section-title">Backup de Cloud Volumes Service</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Aunque Cloud Volumes Service proporciona una gran durabilidad de los datos, los eventos externos pueden causar la pérdida de datos. En caso de producirse un evento de seguridad, como un virus o ransomware, los backups y las restauraciones se convierten en algo crucial para reanudar el acceso a los datos de forma puntual. Un administrador puede eliminar accidentalmente un volumen de Cloud Volumes Service. O los usuarios simplemente quieren conservar las versiones de backup de sus datos durante muchos meses y mantener el espacio adicional de copia Snapshot dentro del volumen supone un reto de costes. A pesar de que las copias Snapshot deberían ser la forma preferida de conservar las versiones de backup durante las últimas semanas para restaurar los datos perdidos de ellas, se encuentran dentro del volumen y se pierden si este desaparece.</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">Por todas estas razones, NetApp Cloud Volumes Service ofrece servicios de backup a través de<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>.</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">El backup de Cloud Volumes Service genera una copia del volumen en Google Cloud Storage (GCS). Solo realiza un backup de los datos reales almacenados en el volumen, no del espacio libre. Funciona como siempre incremental, lo que significa que transfiere el contenido del volumen una vez y desde allí sólo se realiza el backup de los datos modificados. En comparación con los conceptos clásicos de backup con varios backups completos, ahorrará una gran cantidad de almacenamiento de backup al reducir costes. Puesto que el precio mensual del espacio de backup es más bajo en comparación con un volumen, es el lugar ideal para mantener las versiones de backup por más tiempo.</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">Los usuarios pueden utilizar una copia de seguridad de Cloud Volumes Service para restaurar cualquier versión de copia de seguridad en el mismo volumen o en otro dentro de la misma región. Si el volumen de origen se elimina, se conservan los datos de backup y se debe gestionar (por ejemplo, se eliminan) de forma independiente.</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Documentación de backup de Cloud Volumes Service</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">número máximo de versiones de backup admitidas</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">precios</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service backup está integrado en Cloud Volumes Service as Option. Los usuarios pueden decidir qué volúmenes proteger activando el backup de Cloud Volumes Service por volumen. Consulte<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> para obtener información sobre los backups, el<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>, programación, y.<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>.</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">Todos los datos de backup de un proyecto se almacenan en un bloque de GCS que gestiona el servicio y que el usuario no puede ver. Cada proyecto utiliza un bloque diferente. Actualmente, los bloques se encuentran en la misma región que los volúmenes Cloud Volumes Service, pero se están debatiendo más opciones. Consulte la documentación para obtener la información más reciente.</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">El transporte de datos desde un bloque de Cloud Volumes Service a GCS utiliza redes de Google internas en servicio con HTTPS y TLS1.2. Los datos se cifran en reposo con claves gestionadas por Google.</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">roles/netappcloudvolumes.admin</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Para gestionar el backup de Cloud Volumes Service (crear, eliminar y restaurar backups), un usuario debe tener el<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> función.</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">Siguiente: Descripción de la arquitectura.</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB es un protocolo de uso compartido de archivos de red desarrollado por Microsoft que proporciona autenticación de usuarios/grupos centralizada, permisos, bloqueo y uso compartido de archivos a varios clientes de SMB a través de una red Ethernet.</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">SMB</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">Anterior: NFS.</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> Es un protocolo de uso compartido de archivos de red desarrollado por Microsoft que proporciona autenticación centralizada de usuarios/grupos, permisos, bloqueo y uso compartido de archivos a varios clientes SMB a través de una red Ethernet. Los archivos y carpetas se presentan a los clientes mediante recursos compartidos, que pueden configurarse con diversas propiedades de recursos compartidos y ofrecen control de acceso mediante permisos de nivel de recursos compartidos. SMB puede presentarse a cualquier cliente que ofrezca compatibilidad con el protocolo, incluidos clientes de Windows, Apple y Linux.</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service es compatible con las versiones SMB 2.1 y 3.x del protocolo.</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">Control de acceso/recursos compartidos de SMB</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Cuando un nombre de usuario de Windows solicita acceso al volumen Cloud Volumes Service, Cloud Volumes Service busca un nombre de usuario UNIX utilizando los métodos configurados por los administradores de Cloud Volumes Service.</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">Si se configura un proveedor de identidad UNIX externo (LDAP) y los nombres de usuario de Windows/UNIX son idénticos, entonces los nombres de usuario de Windows asignarán 1:1 a nombres de usuario de UNIX sin necesidad de ninguna configuración adicional. Cuando LDAP está habilitado, Active Directory se utiliza para alojar esos atributos UNIX para objetos de grupo y usuario.</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">“Utilizar LDAP para asignar nombres asimétricos”</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Si los nombres de Windows y UNIX no coinciden de la misma manera, se debe configurar LDAP para permitir que Cloud Volumes Service utilice la configuración de asignación de nombres LDAP (consulte la sección <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>).</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">Si LDAP no está en uso, los usuarios SMB de Windows se asignan a un usuario UNIX local predeterminado denominado<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> En Cloud Volumes Service. Esto significa que los usuarios que se asignan a los archivos escritos en Windows<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Mostrar propiedad de UNIX como<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> En entornos NAS multiprotocolo.<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> aquí está efectivamente la<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Usuario en entornos Linux (UID 65534).</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">En implementaciones con solo SMB, el<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> La asignación se sigue produciendo, pero no importa, porque la propiedad de usuarios y grupos de Windows se muestra correctamente y no se permite el acceso NFS al volumen sólo para SMB. Además, los volúmenes solo para SMB no admiten la conversión a volúmenes de protocolo doble o NFS después de crearse.</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows utiliza Kerberos para la autenticación de nombre de usuario con los controladores de dominio de Active Directory, que requiere un intercambio de nombre de usuario/contraseña con los DC de AD, que es externo a la instancia de Cloud Volumes Service. La autenticación Kerberos se utiliza cuando el<block ref="cd2eba6db07c5178e47368d41d7c8ecb" prefix=" " category="inline-code"></block> Los clientes SMB utilizan la ruta UNC que es la siguiente:</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">Existe una entrada DNS A/AAAA para SERVERNAME</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">Existe un SPN válido para el acceso SMB/CIFS para SERVERNAME</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">“Cómo aparece Cloud Volumes Service en Active Directory.”</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Cuando se crea un volumen SMB de Cloud Volumes Service, se crea el nombre de la cuenta de la máquina, tal como se define en la sección <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Ese nombre de cuenta de equipo también se convierte en la ruta de acceso a recursos compartidos SMB porque Cloud Volumes Service aprovecha DNS dinámico (DDNS) para crear las entradas A/AAAA y PTR necesarias en DNS y las entradas SPN necesarias en el principal de cuenta de máquina.</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">Para crear entradas PTR, la zona de búsqueda inversa para la dirección IP de la instancia Cloud Volumes Service debe existir en el servidor DNS.</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">Por ejemplo, este volumen Cloud Volumes Service utiliza la siguiente ruta de uso compartido UNC:<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>.</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">En Active Directory, estas son las entradas de SPN generadas por el servicio Cloud Volumes:</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">Este es el resultado de búsqueda directa/inversa de DNS:</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">De manera opcional, se puede aplicar un mayor control de acceso al habilitar o requerir el cifrado SMB para recursos compartidos SMB en Cloud Volumes Service. Si uno de los extremos no admite el cifrado SMB, no se permite el acceso.</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">Usar alias de nombre de SMB</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">En algunos casos, podría ser una preocupación de seguridad para los usuarios finales saber el nombre de la cuenta de equipo que se está utilizando para Cloud Volumes Service. En otros casos, es posible que simplemente desee proporcionar una ruta de acceso más sencilla a sus usuarios finales. En esos casos, puede crear alias SMB.</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">Si desea crear alias para la ruta de acceso compartida SMB, puede aprovechar lo que se conoce como registro CNAME en DNS. Por ejemplo, si desea usar el nombre<block ref="87154d57e8c4e5c93755c1e158cd3257" prefix=" " category="inline-code"></block> para acceder a los recursos compartidos en lugar de<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>, Pero todavía desea utilizar la autenticación Kerberos, un CNAME en DNS que señala al registro A/AAAA existente y un SPN adicional agregado a la cuenta de equipo existente proporciona acceso Kerberos.</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">Este es el resultado de búsqueda directa de DNS resultante después de agregar un CNAME:</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">Esta es la consulta SPN resultante tras agregar nuevos números de dominio:</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">En una captura de paquete, podemos ver la solicitud de configuración de sesión mediante el SPN vinculado al CNAME.</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">Dialectos de autenticación SMB</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">dialectos</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service admite lo siguiente<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> Para la autenticación SMB:</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">La autenticación Kerberos para acceso a recursos compartidos SMB es el nivel de autenticación más seguro que puede utilizar. Con el cifrado AES y SMB habilitado, el nivel de seguridad aumenta aún más.</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service también admite compatibilidad con versiones anteriores de la autenticación LM y NTLM. Cuando Kerberos está mal configurado (como al crear alias SMB), el acceso al recurso compartido vuelve a los métodos de autenticación más débiles (como NTLMv2). Debido a que estos mecanismos son menos seguros, se desactivan en algunos entornos de Active Directory. Si los métodos de autenticación más débiles están desactivados y Kerberos no está configurado correctamente, el acceso al recurso compartido falla porque no hay ningún método de autenticación válido al que recurrir.</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">Seguridad de red: Nivel de autenticación de LAN Manager</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Para obtener información acerca de cómo configurar o ver los niveles de autenticación compatibles en Active Directory, consulte<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>.</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">Modelos de permisos</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">Permisos NTFS/Archivo</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">Los permisos NTFS son los permisos aplicados a archivos y carpetas en sistemas de archivos que cumplen la lógica NTFS. Puede aplicar permisos NTFS en<block ref="972e73b7a882d0802a4e3a16946a2f94" prefix=" " category="inline-code"></block> o.<block ref="9b6545e4cea9b4ad4979d41bb9170e2b" prefix=" " category="inline-code"></block> y se puede establecer en<block ref="45f0fb72a0defdfdb01de4b5a5a6876b" prefix=" " category="inline-code"></block> o.<block ref="3682d1665cf331373000c20680732d3a" prefix=" " category="inline-code"></block> para control de acceso.</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">Los permisos básicos incluyen los siguientes:</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">Control total</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">Modificar</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">Lectura y ejecución</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">Lea</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">Escritura</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">Cuando establece permisos para un usuario o grupo, denominado ACE, reside en una ACL. Los permisos NTFS utilizan los mismos conceptos básicos de lectura/escritura/ejecución que los bits de modo UNIX, pero también pueden extenderse a controles de acceso más granulares y extendidos (también conocidos como permisos especiales), como tomar posesión, Crear carpetas/datos anexados, escribir atributos, etc.</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">Los bits de modo UNIX estándar no proporcionan el mismo nivel de granularidad que los permisos NTFS (como ser capaz de establecer permisos para objetos de usuario y grupo individuales en una ACL o establecer atributos extendidos). Sin embargo, las ACL de NFSv4.1 proporcionan la misma funcionalidad que las ACL de NTFS.</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">Los permisos NTFS son más específicos que los permisos de uso compartido y se pueden utilizar junto con los permisos de uso compartido. Con las estructuras de permisos NTFS, se aplica el más restrictivo. Como tal, las denegaciones explícitas a un usuario o grupo anulan incluso Control total al definir los derechos de acceso.</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">Los permisos NTFS se controlan desde clientes SMB de Windows.</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">Comparta los permisos</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">Los permisos de recursos compartidos son más generales que los permisos NTFS (sólo lectura/cambio/control total) y controlan la entrada inicial en un recurso compartido SMB, de forma similar a cómo funcionan las reglas de política de exportación NFS.</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">Si bien las reglas de política de exportación de NFS controlan el acceso mediante información basada en hosts, como direcciones IP o nombres de hosts, los permisos de uso compartido de SMB pueden controlar el acceso mediante ACE de usuario y de grupo en una ACL compartida. Puede configurar las ACL para compartir desde el cliente de Windows o desde la IU de gestión de Cloud Volumes Service.</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">De forma predeterminada, las ACL compartidas y las ACL de volumen inicial incluyen a todos los usuarios con control total. Las ACL de archivo se deben cambiar pero los permisos de uso compartido están anulados por los permisos de archivo de los objetos del recurso compartido.</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">Por ejemplo, si a un usuario solo se le permite acceso de lectura a la ACL del archivo de volumen Cloud Volumes Service, se les deniega el acceso para crear archivos y carpetas aunque la ACL de uso compartido esté establecida en todos los usuarios con control completo, como se muestra en la siguiente figura.</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">Para obtener los mejores resultados de seguridad, haga lo siguiente:</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">Elimine a todos los usuarios de las ACL de uso compartido y de archivo y, en su lugar, establezca el acceso compartido para usuarios o grupos.</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">Utilice grupos para controlar el acceso en lugar de usuarios individuales con el fin de facilitar la gestión y agilizar la incorporación/eliminación de usuarios para compartir ACL a través de la gestión de grupos.</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">Permita un acceso compartido menos restrictivo y más general a los ACE en los permisos de uso compartido y bloquee el acceso a los usuarios y grupos con permisos de archivos para obtener un control de acceso más granular.</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">Evite el uso general de ACL de denegación explícita, ya que anulan permitir ACL. Limitar el uso de ACL de denegación explícita para usuarios o grupos que deben restringirse rápidamente del acceso a un sistema de archivos.</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">Herencia de ACL</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">Asegúrese de prestar atención al<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> configuración al modificar los permisos; establecer el indicador de herencia en el nivel superior de un directorio o volumen con altos recuentos de archivos significa que cada archivo debajo de ese directorio o volumen ha heredado permisos que se le han agregado, que puede crear comportamientos no deseados como acceso no intencionado/denegación y pérdida prolongada de modificación de permisos a medida que se ajusta cada archivo.</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">Funciones de seguridad para recursos compartidos de SMB</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">Cuando se crea por primera vez un volumen con acceso de SMB en Cloud Volumes Service, se presenta una serie de opciones para proteger ese volumen.</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">Algunas de estas opciones dependen del nivel de Cloud Volumes Service (rendimiento o software) y las opciones disponibles son:</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*Hacer visible el directorio de la instantánea (disponible tanto para CVS-Performance como para CVS-SW).* esta opción controla si los clientes de SMB pueden acceder al directorio de la instantánea en un recurso compartido de SMB <block ref="f9f8c4c52f58b30f374525080a180c65" prefix="(" category="inline-code"></block> Y/o la ficha versiones anteriores). La configuración predeterminada no está activada, lo que significa que el volumen se oculta y se despermite el acceso a la<block ref="26bef40a7b3e14ad93e80f8f4be79090" prefix=" " category="inline-code"></block> y no aparecen copias Snapshot en la pestaña versiones anteriores del volumen.</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">Ocultar copias Snapshot de usuarios finales puede ser conveniente por motivos de seguridad, por motivos de rendimiento (ocultar estas carpetas de los análisis AV) o por preferencias. Las instantáneas Cloud Volumes Service son de sólo lectura, por lo que aunque estas Snapshots estén visibles, los usuarios finales no pueden eliminar ni modificar archivos en el directorio Snapshot. Se aplican permisos de archivo en los archivos o carpetas en el momento en que se realizó la copia snapshot. Si los permisos de un archivo o carpeta cambian entre copias Snapshot, los cambios también se aplican a los archivos o carpetas del directorio Snapshot. Los usuarios y grupos pueden obtener acceso a estos archivos o carpetas en función de los permisos. Aunque no es posible eliminar o modificar archivos del directorio Snapshot, es posible copiar archivos o carpetas fuera del directorio Snapshot.</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">*Activar cifrado SMB (disponible tanto para CVS-Performance como para CVS-SW).* el cifrado SMB está desactivado en el recurso compartido SMB de forma predeterminada (sin seleccionar). Al activar la casilla se habilita el cifrado SMB, lo que significa que el tráfico entre el cliente SMB y el servidor se cifra en tránsito con los niveles de cifrado más altos admitidos negociados. Cloud Volumes Service admite hasta el cifrado AES-256 para SMB. La habilitación del cifrado SMB supone un detrimento del rendimiento que puede o no ser perceptible para sus clientes de SMB, aproximadamente en el rango de 10-20 %. NetApp recomienda encarecidamente realizar pruebas para ver si esa penalización en el rendimiento es aceptable.</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">*Ocultar recurso compartido SMB (disponible tanto para CVS-Performance como para CVS-SW).* al establecer esta opción se oculta la ruta de acceso compartido SMB de la navegación normal. Esto significa que los clientes que no conocen la ruta de acceso al recurso compartido no pueden ver los recursos compartidos al acceder a la ruta UNC predeterminada (por ejemplo<block ref="eaf10dd9986e1d76c577b974d994e349" prefix=" " category="inline-code"></block>). Cuando se selecciona la casilla de verificación, solo los clientes que conozcan explícitamente la ruta de acceso compartido SMB o que tengan la ruta de acceso de recurso compartido definida por un objeto de directiva de grupo pueden tener acceso a ella (seguridad mediante ocultación).</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">¿Cómo funciona la enumeración basada en acceso (ABE)?</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*Activar enumeración basada en acceso (ABE) (sólo CVS-SW).* esto es similar a ocultar el recurso compartido SMB, excepto que los recursos compartidos o archivos sólo están ocultos de usuarios o grupos que no tienen permisos para acceder a los objetos. Por ejemplo, si el usuario de Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> No se permite al menos acceso de lectura a través de los permisos, entonces el usuario de Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> No se pueden ver los archivos o recursos compartidos de SMB en absoluto. Esta opción está deshabilitada de forma predeterminada y puede habilitarla mediante la selección de la casilla de verificación. Para obtener más información sobre ABE, consulte el artículo de la base de conocimientos de NetApp<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">Recursos compartidos de SMB disponibles de forma continua</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*Activar soporte compartido de disponibilidad continua (CA) (CVS-Performance solamente).*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Proporcionar una forma de minimizar las interrupciones de aplicaciones durante eventos de conmutación por error mediante la replicación de estados de bloqueo entre nodos del sistema de entorno de administración de Cloud Volumes Service. Esta no es una función de seguridad, pero sí ofrece una mejor resiliencia general. Actualmente, sólo se admiten las aplicaciones SQL Server y FSLogix para esta funcionalidad.</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">Recursos compartidos ocultos predeterminados</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">recursos compartidos administrativos ocultos</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">Cuando se crea un servidor SMB en Cloud Volumes Service, existen<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> (Usa la convención de nomenclatura de $) que se crean además del recurso compartido de SMB del volumen de datos. Entre ellas se incluyen C$ (acceso al espacio de nombres) e IPC$ (uso compartido de canalizaciones con nombre para la comunicación entre programas, como las llamadas a procedimiento remoto (RPC) utilizadas para el acceso a Microsoft Management Console (MMC)).</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Windows no permite el acceso anónimo a estos recursos compartidos de forma predeterminada</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">El recurso compartido IPC$ no contiene ACL compartidos y no se puede modificar; se utiliza estrictamente para las llamadas RPC y.<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>.</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">El recurso compartido C$ permite el acceso BUILTIN/Administrators de forma predeterminada, pero la automatización Cloud Volumes Service elimina la ACL compartida y no permite el acceso a nadie porque el acceso al recurso compartido C$ permite la visibilidad de todos los volúmenes montados en los sistemas de archivos Cloud Volumes Service. Como resultado, intenta navegar a.<block ref="33f61bb25149c01e06f9ef66d462e5a2" prefix=" " category="inline-code"></block> error.</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">Cuentas con derechos de administrador/copia de seguridad local/BUILTIN</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Los servidores SMB de Cloud Volumes Service mantienen una funcionalidad similar a los servidores SMB de Windows regulares en el sentido de que hay grupos locales (como BUILTIN\Administrators) que aplican derechos de acceso a determinados usuarios y grupos de dominio.</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege y SeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">Cuando se especifica un usuario que se va a agregar a los usuarios de copia de seguridad, el usuario se agrega al grupo BUILTIN\operadores de copia de seguridad en la instancia de Cloud Volumes Service que utiliza esa conexión de Active Directory, que a continuación obtiene la<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>.</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SQL Server en recursos compartidos de SMB</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">Cuando agrega un usuario a usuarios de privilegios de seguridad, se le da al usuario SeSecurityPrivilege, que es útil en algunos casos de uso de aplicaciones, como<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>.</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">Puede ver las pertenencias a grupos locales de Cloud Volumes Service a través de MMC con los privilegios adecuados. La siguiente figura muestra los usuarios que se han agregado mediante la consola de Cloud Volumes Service.</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">La siguiente tabla muestra la lista de grupos BUILTIN predeterminados y qué usuarios/grupos se agregan de forma predeterminada.</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">Grupo local/BUILTIN</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">Miembros predeterminados</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">BUILTIN\Administrators*</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">Dominio\Administradores de dominio</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">Operadores DE COPIAS DE seguridad/BUILTIN*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">EDIFICIO\huéspedes</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">Dominio\invitados de dominio</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">Usuarios AVANZADOS\BUILTIN</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">USUARIOS DE BUILTIN\Domain</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">USUARIOS de DOMINIO/dominio</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*Pertenencia a grupos controlada en la configuración de conexión de Cloud Volumes Service Active Directory.</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">Puede ver los usuarios y grupos locales (y los miembros del grupo) en la ventana MMC, pero no puede agregar ni eliminar objetos ni cambiar las pertenencias a grupos desde esta consola. De forma predeterminada, sólo el grupo Administradores de dominio y Administrador se agregan al grupo BUILTIN\Administradores de Cloud Volumes Service. Actualmente, no puede modificarlo.</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">Acceso a MMC/Computer Management</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">El acceso de SMB en Cloud Volumes Service proporciona conectividad a la MMC de gestión de equipos, que permite ver recursos compartidos, gestionar ACL de uso compartido, ver/gestionar sesiones de SMB y archivos abiertos.</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">Para utilizar MMC para ver los recursos compartidos y las sesiones de SMB en Cloud Volumes Service, el usuario que ha iniciado sesión debe ser un administrador de dominio. A otros usuarios se les permite el acceso para ver o administrar el servidor SMB desde MMC y recibir un cuadro de diálogo no tiene permisos al intentar ver recursos compartidos o sesiones en la instancia del SMB de Cloud Volumes Service.</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">Para conectarse al servidor SMB, abra Administración de equipos, haga clic con el botón derecho en Administración de equipos y, a continuación, seleccione conectar a otro equipo. Con esto se abre el cuadro de diálogo Seleccionar equipo, donde puede introducir el nombre del servidor SMB (que se encuentra en la información del volumen Cloud Volumes Service).</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">Cuando se ven los recursos compartidos de SMB con los permisos adecuados, se ven todos los recursos compartidos disponibles en la instancia de Cloud Volumes Service que comparten la conexión de Active Directory. Para controlar este comportamiento, configure la opción Ocultar recursos compartidos de SMB en la instancia de volumen de Cloud Volumes Service.</block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">Recuerde que sólo se permite una conexión de Active Directory por región.</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">En la siguiente tabla se muestra una lista de las funciones compatibles/no admitidas para MMC.</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">Funciones admitidas</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">Funciones no admitidas</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">Ver recursos compartidos</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">Ver sesiones SMB activas</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">Ver archivos abiertos</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">Ver usuarios y grupos locales</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">Ver las membresías de grupo local</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">Enumera la lista de sesiones, archivos y conexiones de árbol del sistema</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">Cierre los archivos abiertos en el sistema</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">Cierre las sesiones abiertas</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">Cree/gestione recursos compartidos</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">Creación de nuevos usuarios/grupos locales</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">Gestión/visualización de usuarios/grupos locales existentes</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">Ver eventos o registros de rendimiento</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">Gestionar el almacenamiento</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">Gestión de servicios y aplicaciones</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">Información de seguridad del servidor SMB</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">El servidor SMB en Cloud Volumes Service utiliza una serie de opciones que definen políticas de seguridad para las conexiones SMB, incluidos factores como la desviación del reloj de Kerberos, la antigüedad de los tickets, el cifrado, etc.</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">La siguiente tabla contiene una lista de esas opciones, qué hacen, las configuraciones predeterminadas y si se pueden modificar con Cloud Volumes Service. Algunas opciones no se aplican a Cloud Volumes Service.</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">Opción de seguridad</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">Qué hace</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">Valor predeterminado</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">¿Puede cambiar?</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">Sesgo de reloj Kerberos máximo (minutos)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Desfase de tiempo máximo entre Cloud Volumes Service y controladoras de dominio. Si la desviación de tiempo supera los 5 minutos, la autenticación de Kerberos fallará. Se establece en el valor predeterminado de Active Directory.</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Duración de la entrada de Kerberos (horas)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">Tiempo máximo que un ticket de Kerberos permanece válido antes de requerir una renovación. Si no se produce ninguna renovación antes de las 10 horas, debe obtener un boleto nuevo. Cloud Volumes Service realiza estas renovaciones automáticamente. 10 horas es el valor predeterminado de Active Directory.</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Renovación máxima de entradas Kerberos (días)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">Número máximo de días que se puede renovar un billete Kerberos antes de que se necesite una nueva solicitud de autorización. Cloud Volumes Service renueva automáticamente los boletos para las conexiones SMB. Seven Days es el valor predeterminado de Active Directory.</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Tiempo de espera de conexión Kerberos KDC (segundos)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">Número de segundos antes de que se agote el tiempo de espera de una conexión KDC.</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">Es necesario firmar para tráfico entrante del bloque de mensajes del servidor</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">Configuración para requerir la firma para el tráfico SMB. Si se establece en true, los clientes que no admiten la conectividad de firma fallan.</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">Requerir complejidad de contraseña para cuentas de usuario locales</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">Se usa para las contraseñas en usuarios SMB locales. Cloud Volumes Service no admite la creación de usuarios locales, por lo que esta opción no se aplica a Cloud Volumes Service.</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">Verdadero</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Utilice START_tls para conexiones LDAP de Active Directory</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Se utiliza para habilitar conexiones TLS de inicio para LDAP de Active Directory. Cloud Volumes Service no admite habilitar esto actualmente.</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">Es el cifrado AES-128 y AES-256 para Kerberos habilitado</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">Esto controla si el cifrado AES se utiliza para conexiones de Active Directory y se controla con la opción Activar cifrado AES para autenticación de Active Directory al crear o modificar la conexión de Active Directory.</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">Nivel de compatibilidad LM</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Nivel de dialectos de autenticación compatibles para conexiones de Active Directory. Consulte la sección “<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>” para más información.</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">ntlmv2-krb</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">Se requiere cifrado SMB para el tráfico CIFS entrante</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">Requiere cifrado SMB para todos los recursos compartidos. Cloud Volumes Service no lo utiliza; en su lugar, establezca el cifrado por volumen (consulte la sección “<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>”).</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">Seguridad de sesión de cliente</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">“Enlace del canal LDAP”.</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">Establece la firma y/o el sellado para la comunicación LDAP. Esto no está establecido actualmente en Cloud Volumes Service, pero podría ser necesario en futuras versiones para abordar . La solución de problemas de autenticación LDAP debidos a la revisión de Windows se trata en la sección <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>.</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">Activación de SMB2 para conexiones de CC</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">Utiliza SMB2 para conexiones de CC. Activado de forma predeterminada.</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">Valor predeterminado del sistema</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">Especificación de referencia LDAP</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">Al usar varios servidores LDAP, la búsqueda de referencias permite al cliente consultar otros servidores LDAP de la lista cuando no se encuentra una entrada en el primer servidor. Actualmente, Cloud Volumes Service no admite esta operación.</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">Utilice LDAPS para conexiones seguras de Active Directory</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">Permite el uso de LDAP sobre SSL. Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">Se requiere cifrado para la conexión de CC</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">Requiere cifrado para conexiones DC correctas. Deshabilitado de forma predeterminada en Cloud Volumes Service.</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">Siguiente: Protocolo dual/multiprotocolo.</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Cloud Volumes Service en Google Cloud ofrece múltiples formas de proteger sus datos de forma nativa.</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Cómo Cloud Volumes Service en Google Cloud protege sus datos</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">Arquitectura segura y modelo de multi-tenancy</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">“Arquitectura Cloud Volumes Service”</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">acceso a servicios privados</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service proporciona una arquitectura segura en Google Cloud al segmentar la gestión de servicios (plano de control) y el acceso a los datos (plano de datos) en diferentes extremos, de modo que ninguno de ellos puede afectar al otro (consulte la sección <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>). Utiliza Google's.<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA) marco para prestar el servicio. Este marco distingue entre el productor de servicios, que ofrece NetApp y está gestionado por este, y el consumidor de servicios, que es un cloud privado virtual (VPC) en un proyecto de cliente, alojando los clientes que deseen acceder a recursos compartidos de archivos de Cloud Volumes Service.</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">“Modelo de soporte”</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">“VPC compartidos”</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">En esta arquitectura, los clientes (consulte la sección <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>) Se definen como proyectos de Google Cloud que están completamente aislados entre sí a menos que el usuario lo conecte explícitamente. Los clientes permiten el aislamiento completo de volúmenes de datos, servicios de nombres externos y otras piezas esenciales de la solución de otros clientes con la plataforma de volúmenes de Cloud Volumes Service. Dado que la plataforma Cloud Volumes Service se conecta a través de la agrupación VPC, ese aislamiento también se aplica a ella. Para habilitar el uso compartido de volúmenes de Cloud Volumes Service entre varios proyectos, utilice un VPC compartido (consulte la sección <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>). Puede aplicar controles de acceso a recursos compartidos de SMB y exportaciones de NFS para limitar quién o qué puede ver o modificar conjuntos de datos.</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">Gestión de identidades sólida para el plano de control</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">Gestión de acceso a identidades (IAM)</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">En el plano de control en el que se lleva a cabo la configuración de Cloud Volumes Service, la gestión de identidades se gestiona mediante<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>. IAM es un servicio estándar que permite controlar la autenticación (inicios de sesión) y la autorización (permisos) de las instancias de proyectos de Google Cloud. Toda la configuración se realiza con las API de Cloud Volumes Service mediante un transporte HTTPS seguro con cifrado TLS 1.2 y la autenticación se realiza mediante tokens JWT para mayor seguridad. La interfaz de usuario de la consola de Google para Cloud Volumes Service convierte las entradas del usuario en llamadas a la API de Cloud Volumes Service.</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">Seguridad reforzada: Limitar las superficies de ataque</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">Parte de la seguridad efectiva está limitando el número de superficies de ataque disponibles en un servicio. Las superficies de ataque pueden incluir diversas cosas, como datos en reposo, transferencias en tránsito, inicios de sesión y los propios conjuntos de datos.</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">“Funcionamiento de servicio”,</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">Un servicio gestionado elimina algunas de las superficies de ataque de forma inherente en su diseño. Gestión de infraestructuras, como se describe en la sección <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> es manejado por un equipo específico y es automatizado para reducir el número de veces que un ser humano realmente toca configuraciones, lo que ayuda a reducir el número de errores intencionales y no intencionales. La conexión de red está cerrada de modo que solo los servicios necesarios puedan acceder los unos a los otros. El cifrado se lleva a cabo en el almacenamiento de datos, y solo el plano de datos necesita atención de seguridad de los administradores de Cloud Volumes Service. Al ocultar la mayor parte de la gestión de una interfaz API, la seguridad se logra limitando las superficies de ataque.</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">Modelo de confianza cero</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">Históricamente, la filosofía de seguridad DE TI ha sido confiar pero verificar, y se ha manifestado basándose únicamente en mecanismos externos (como firewalls y sistemas de detección de intrusiones) para mitigar las amenazas. Sin embargo, los ataques y las infracciones evolucionaron para evitar la verificación en entornos mediante el phishing, la ingeniería social, las amenazas internas y otros métodos que proporcionan la verificación para entrar en redes y causar estragos.</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">Zero Trust se ha convertido en una nueva metodología en seguridad, con el mantra actual “confiar en nada mientras sigue verificando todo”. Por lo tanto, no se permite el acceso predeterminado a nada. Este mantra se aplica de diversas maneras, incluidos los cortafuegos estándar y los sistemas de detección de intrusiones (IDS) y también con los siguientes métodos:</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">Métodos de autenticación sólidos (como Kerberos con cifrado AES o tokens JWT)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">Fuentes sólidas de identidades únicas (como Windows Active Directory, Lightweight Directory Access Protocol (LDAP) y Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">Segmentación de red y multi-tenancy seguro (solo se permite el acceso de forma predeterminada a los inquilinos)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">Controles de acceso granular con políticas de acceso con privilegios mínimos</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">Listas exclusivas pequeñas de administradores dedicados y de confianza con auditorías digitales y pistas en papel</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">La ejecución de Cloud Volumes Service en Google Cloud cumple con el modelo Zero Trust, al implementar la postura "no confiar en nada, verificar todo".</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">Cifrado</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">“Cifrado de datos en reposo”</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">“Cifrado SMB”</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">“Replicación entre regiones”</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">“Red de Google Cloud”</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">Cifrar datos en reposo (consulte la sección <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) Mediante el uso de cifrados XTS-AES-256 con el cifrado de volúmenes de NetApp (NVE) y en tránsito con <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> O soporte para NFS Kerberos 5p. Las transferencias de replicación entre regiones con REST sencilla están protegidas con cifrado TLS 1.2 (consulte la sección <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>). Además, Google Networking también proporciona comunicaciones cifradas (consulte la sección <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>) para una capa adicional de protección contra ataques. Para obtener más información sobre el cifrado de transporte, consulte la sección <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>.</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">Protección de datos y backups</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">La seguridad no se trata sólo de la prevención de ataques. También se trata de cómo recuperamos los ataques cuando se producen. Esta estrategia incluye protección de datos y backups. Cloud Volumes Service proporciona métodos para replicar en otras regiones en caso de interrupciones del servicio (consulte la sección <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>) o si un conjunto de datos se ve afectado por un ataque de ransomware. También puede realizar backups asíncronos de datos en ubicaciones externas a la instancia de Cloud Volumes Service mediante el uso de <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>. Con los backups periódicos, la mitigación de los eventos de seguridad puede llevar menos tiempo y ahorrar dinero y angustia para los administradores.</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">Mitigación de ransomware rápida con copias Snapshot líderes en el sector</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">“Copias Snapshot inmutables”</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">“Funcionamiento de servicio”</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Además de la protección de datos y los backups, Cloud Volumes Service ofrece compatibilidad con copias Snapshot inalterables (consulte la sección <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>) de volúmenes que permiten la recuperación de ataques de ransomware (consulte la sección <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>) en cuestión de segundos de descubrir el problema y con una interrupción mínima. El tiempo y los efectos de la recuperación dependen de la programación de la copia Snapshot, pero puede crear copias de SnapVault que proporcionen deltas de solo una hora en ataques de ransomware. Las copias Snapshot afectan al rendimiento y al uso de la capacidad y son un enfoque de bajo riesgo y gran recompensa para proteger sus conjuntos de datos.</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">Siguiente: Consideraciones de seguridad y superficies de ataque.</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">La seguridad, especialmente en el cloud, donde la infraestructura se encuentra fuera del control de los administradores de almacenamiento, es primordial para confiar en sus datos para ofrecer servicios ofrecidos por los proveedores de cloud. Este documento contiene una descripción general de las ofertas de seguridad que ofrece Cloud Volumes Service de NetApp en Google Cloud.</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918: Descripción general de la seguridad: Cloud Volumes Service de NetApp en Google Cloud</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">Oliver Krause, Justin Parisi, NetApp</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">Alcance del documento</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service proporciona en Google Cloud</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">La seguridad, especialmente en el cloud, donde la infraestructura se encuentra fuera del control de los administradores de almacenamiento, es primordial para confiar en sus datos para ofrecer servicios ofrecidos por los proveedores de cloud. Este documento ofrece una visión general de las ofertas de seguridad de NetApp<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>.</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Audiencia de destino</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">La audiencia de destino de este documento incluye, entre otros, los siguientes roles:</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">Proveedores de cloud</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">Administradores de almacenamiento</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">Arquitectos de almacenamiento</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">Recursos sobre el terreno</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">Responsables de la toma de decisiones empresariales</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">“Contacto”.</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">Si tiene alguna pregunta sobre el contenido de este informe técnico, consulte la sección <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">Abreviatura</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">Definición</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service, tipo de servicio CVS</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS-Performance</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud Volume Service, tipo de servicio CVS-Performance</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">SAL</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">Siguiente: Cómo Cloud Volumes Service en Google Cloud protege sus datos.</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">Los protocolos NAS incluyen NFS (v3 y v4.1) y SMB/CIFS (2.x y 3.x). Estos protocolos son cómo CVS permite el acceso compartido a los datos entre varios clientes NAS. Además, Cloud Volumes Service puede proporcionar acceso a clientes NFS y SMB/CIFS simultáneamente (doble protocolo) a la vez que se respetan toda la configuración de identidades y permisos de los archivos y carpetas de los recursos compartidos NAS.</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">Información general sobre los protocolos NAS</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">Anterior: Firewall.</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">Los protocolos NAS incluyen NFS (v3 y v4.1) y SMB/CIFS (2.x y 3.x). Estos protocolos son cómo CVS permite el acceso compartido a los datos entre varios clientes NAS. Además, Cloud Volumes Service puede proporcionar acceso a clientes NFS y SMB/CIFS simultáneamente (doble protocolo) a la vez que se respetan toda la configuración de identidades y permisos de los archivos y carpetas de los recursos compartidos NAS. Para mantener la seguridad de transferencia de datos más alta posible, Cloud Volumes Service admite el cifrado de protocolos en transferencia usando cifrado SMB y NFS Kerberos 5p.</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">El protocolo dual solo está disponible con CVS-Performance.</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">Siguiente: Conceptos básicos de los protocolos NAS.</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">El equipo de Cloud Volumes Service gestiona los servicios de back-end en Google Cloud y utiliza varias estrategias para proteger la plataforma y evitar el acceso no deseado.</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">Operación de servicio</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">Anterior: Otras dependencias de servicios de infraestructura NAS (KDC, LDAP, DNS).</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">Cada cliente obtiene su propia subred única, que tiene acceso acotado de forma predeterminada a otros clientes; cada cliente de Cloud Volumes Service obtiene su propio espacio de nombres y VLAN para aislar todos los datos. Una vez autenticado un usuario, el motor de entrega de servicios (SDE) sólo puede leer los datos de configuración específicos de ese arrendatario.</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">Seguridad física</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">Con la aprobación previa adecuada, solo los ingenieros in situ y los ingenieros de soporte de campo (FSE) con insignia de NetApp tienen acceso a la jaula y los racks para trabajar físicamente. La gestión de almacenamiento y redes no está permitida. Solo estos recursos in situ pueden realizar tareas de mantenimiento del hardware.</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">Para los ingenieros in situ, se crea un ticket para la descripción del trabajo (SOW, Stament ID) que incluye el identificador de rack y la ubicación del dispositivo (RU), y todos los demás detalles se incluyen en la incidencia. En el caso de los FSE de NetApp, es necesario elevar un ticket de visita a las instalaciones con LA COLOCACIÓN y el ticket incluye los detalles, la fecha y la hora del visitante a efectos de auditoría. La Descripción del Trabajo para el FSE se comunica internamente a NetApp.</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">Equipo de operaciones</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">El equipo de operaciones de Cloud Volumes Service consta de ingeniería de producción y un ingeniero de fiabilidad de sitio (SRE) para servicios de volumen de cloud, e ingenieros de soporte de campo y partners de NetApp para hardware. Todos los miembros del equipo de operaciones están acreditados por su trabajo en Google Cloud y se mantienen registros detallados del trabajo para cada ticket generado. Además, existe un estricto proceso de control y aprobación de cambios para garantizar que cada decisión sea examinada adecuadamente.</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">El equipo de SRE gestiona el plano de control y cómo se enrutan los datos desde las solicitudes de la interfaz de usuario al hardware y software de back-end en Cloud Volumes Service. El equipo de SRE también gestiona los recursos del sistema, como los máximos de volumen e inodo. Los SRE no pueden interactuar con los datos del cliente ni tener acceso a ellos. Los Sres también proporcionan coordinación con Autorizaciones de devolución de material (RMA), como solicitudes de sustitución de disco o memoria nuevas para el hardware de backend.</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">Responsabilidades del Cliente</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Los clientes de Cloud Volumes Service gestionan la administración de Active Directory y las funciones de usuario de su empresa, así como las operaciones de volumen y datos. Los clientes pueden tener roles administrativos y pueden delegar permisos en otros usuarios finales dentro del mismo proyecto de Google Cloud con las dos funciones predefinidas que proporcionan NetApp y Google Cloud (Administrador y Visor).</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">El administrador puede establecer la relación entre iguales de cualquier VPC del proyecto del cliente a Cloud Volumes Service que el cliente determine que es apropiado. Es responsabilidad del cliente gestionar el acceso a su suscripción a Google Cloud Marketplace y gestionar los ordenadores virtuales que tienen acceso al plano de datos.</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">Protección frente a SRE maliciosa</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">Una preocupación que podría surgir es cómo protege Cloud Volumes Service frente a situaciones en las que hay una SRE maliciosa o cuando se han comprometido las credenciales de SRE?</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">El acceso al entorno de producción es sólo con un número limitado de personas que reciben servicios de salud sexual y reproductiva. Los privilegios administrativos se limitan además a un puñado de administradores con experiencia. Todas las acciones realizadas por cualquier persona en el entorno de producción de Cloud Volumes Service se registran y cualquier anomalía en la línea de base o actividades sospechosas es detectada por nuestra plataforma de inteligencia de amenazas de gestión de eventos e información de seguridad (SIEM). Como resultado, se puede realizar un seguimiento y mitigar de acciones maliciosas antes de que se produzcan demasiados daños en el entorno de administración de Cloud Volumes Service.</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">Ciclo de vida de volumen</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service solo gestiona los objetos dentro del servicio, no los datos dentro de los volúmenes. Solo los clientes que acceden a los volúmenes pueden gestionar los datos, las ACL, los propietarios de archivos, etc. Los datos de estos volúmenes se cifran en reposo y el acceso se limita a los inquilinos de la instancia de Cloud Volumes Service.</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">El ciclo de vida del volumen para Cloud Volumes Service es create-update-delete. Los volúmenes conservan las copias Snapshot de los volúmenes hasta que se eliminan los volúmenes y solo los administradores de Cloud Volumes Service validados pueden eliminar volúmenes en Cloud Volumes Service. Cuando un administrador solicita la eliminación de un volumen, se necesita un paso adicional para introducir el nombre del volumen para verificar la eliminación. Una vez eliminado el volumen, este ya no se puede recuperar.</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">En los casos en que se termina un contrato de Cloud Volumes Service, NetApp Marca los volúmenes para su eliminación después de un período de tiempo específico. Antes de que caduque ese período de tiempo, puede recuperar volúmenes a petición del cliente.</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">Certificaciones</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">Cumplimiento de normativas: Seguridad y privacidad de los datos</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Cloud Volumes Services para Google Cloud está certificado actualmente para cumplir los estándares ISO/IEC 27001:2013 e ISO/IEC 27018:2019. El servicio también recibió recientemente su informe de certificación SOC2 de tipo I. Si desea obtener más información sobre el compromiso de NetApp con la privacidad y la seguridad de los datos, consulte<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>.</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">RGPD</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">contratos con clientes</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">Adición al procesamiento de datos del cliente</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">Cláusulas contractuales estándar</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">Nuestros compromisos con respecto a la privacidad y el cumplimiento del RGPD están disponibles en diversos de nuestros <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>, como nuestro<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>, que incluye la <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> Proporcionado por la Comisión Europea. También asumimos estos compromisos en nuestra Política de privacidad, respaldada por los valores fundamentales establecidos en nuestro Código de conducta corporativo.</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">Siguiente: Información adicional, historial de versiones e información de contacto.</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service ofrece la capacidad de compartir los mismos conjuntos de datos tanto a clientes SMB como NFS, a la vez que mantiene permisos de acceso adecuados de doble protocolo. Esto se realiza coordinando la asignación de identidades entre protocolos y utilizando un servidor LDAP de backend centralizado para proporcionar las identidades de UNIX a Cloud Volumes Service. Puede utilizar Windows Active Directory para proporcionar facilidad de uso a los usuarios de Windows y UNIX.</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">Protocolo doble/multiprotocolo</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">Anterior: SMB.</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">protocolo dual</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service permite compartir los mismos conjuntos de datos tanto con clientes SMB como NFS, a la vez que mantiene los permisos de acceso adecuados <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>). Esto se realiza coordinando la asignación de identidades entre protocolos y utilizando un servidor LDAP de backend centralizado para proporcionar las identidades de UNIX a Cloud Volumes Service. Puede utilizar Windows Active Directory para proporcionar facilidad de uso a los usuarios de Windows y UNIX.</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">Control de acceso</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">“Cuentas con derechos de administrador/copia de seguridad local/BUILTIN.”</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">Administración de MMC/Computer</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*Controles de acceso compartido.* determine qué clientes y/o usuarios y grupos pueden acceder a un recurso compartido NAS. Para NFS, las reglas y políticas de exportación controlan el acceso del cliente a las exportaciones. Las exportaciones NFS se gestionan desde la instancia de Cloud Volumes Service. SMB utiliza recursos compartidos de CIFS/SMB y ACL de uso compartido para proporcionar un control más granular a nivel de usuarios y grupos. Solo puede configurar las ACL a nivel de uso compartido desde clientes de SMB mediante<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Con una cuenta que tiene derechos de administrador en la instancia de Cloud Volumes Service (consulte la sección <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>).</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*Controles de acceso a archivos.* Controle los permisos a nivel de archivo o carpeta y siempre se administran desde el cliente NAS. Los clientes NFS pueden utilizar bits de modo tradicional (rwx) o ACL de NFSv4. Los clientes de SMB aprovechan los permisos NTFS.</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">El control de acceso de los volúmenes que sirven datos tanto a NFS como a SMB depende del protocolo en uso. Para obtener información sobre los permisos con protocolo dual, consulte la sección “<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>.”</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">Asignación de usuarios</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">Cuando un cliente accede a un volumen, Cloud Volumes Service intenta asignar el usuario entrante a un usuario válido en la dirección opuesta. Esto es necesario para que se determine el acceso adecuado a través de los protocolos y para garantizar que el usuario que solicita acceso sea realmente lo que afirma ser.</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">Por ejemplo, si un usuario de Windows llamado<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Intenta acceder a un volumen con permisos UNIX a través del bloque de mensajes del servidor y, a continuación, Cloud Volumes Service realiza una búsqueda para encontrar el usuario UNIX correspondiente llamado<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block>. Si existe, los archivos que se escriben en un recurso compartido SMB como usuario de Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Aparece como usuario UNIX<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> De clientes NFS.</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">Como alternativa, si un usuario de UNIX llamado<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Intenta acceder al volumen Cloud Volumes Service con permisos de Windows y el usuario UNIX debe poder asignarlo a un usuario de Windows válido. De lo contrario, se deniega el acceso al volumen.</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">Creación de una conexión AD</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">Actualmente, sólo se admite Active Directory para la gestión de identidades de UNIX externas con LDAP. Para obtener más información acerca de cómo configurar el acceso a este servicio, consulte<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>.</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">Modelo de permisos</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">Cuando se utilizan configuraciones de protocolo dual, Cloud Volumes Service utiliza estilos de seguridad para volúmenes para determinar el tipo de ACL. Estos estilos de seguridad se establecen en función de la especificación del protocolo NAS, o en el caso del protocolo dual, es la opción elegida en el momento de la creación del volumen de Cloud Volumes Service.</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">Si solo utiliza NFS, los volúmenes de Cloud Volumes Service utilizan permisos de UNIX.</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">Si solo utiliza SMB, los volúmenes de Cloud Volumes Service utilizan permisos NTFS.</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">Si se crea un volumen de protocolo doble, se puede elegir el estilo de ACL al crear un volumen. Esta decisión debe tomarse en función de la administración de permisos deseada. Si los usuarios gestionan permisos desde clientes de Windows/SMB, seleccione NTFS. Si sus usuarios prefieren usar clientes NFS y chmod/chown, utilice los estilos de seguridad de UNIX.</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">Siguiente: Consideraciones para crear conexiones de Active Directory.</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service para Google Cloud aprovecha el marco de acceso de servicios privados de Google Cloud. En este marco, los usuarios pueden conectarse a Cloud Volumes Service. Este marco usa construcciones de paridad de Service Networking y VPC, al igual que otros servicios de Google Cloud, para garantizar un aislamiento completo entre clientes.</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">Arquitectura de plano de datos</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">Anterior: Arquitectura del plano de control.</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service para Google Cloud aprovecha Google Cloud<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> marco. En este marco, los usuarios pueden conectarse a Cloud Volumes Service. Este marco usa construcciones de paridad de Service Networking y VPC, al igual que otros servicios de Google Cloud, para garantizar un aislamiento completo entre clientes.</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Para Cloud Volumes Service</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Para obtener información general sobre la arquitectura de Cloud Volumes Service para Google Cloud, consulte<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>.</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">Las VPC de usuario (independientes o compartidas) tienen una relación entre sí y las VPC dentro de los proyectos de arrendatarios administrados de Cloud Volumes Service, que alojan los volúmenes.</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">La figura anterior muestra un proyecto (el proyecto para consumidores CVS en el medio) con tres redes VPC conectadas a Cloud Volumes Service y a varios equipos virtuales de Compute Engine (GCE1-7) compartiendo volúmenes:</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1 permite a GCE1 acceder a los volúmenes A y B.</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2 permite a GCE2 y GCE4 acceder al volumen C.</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">La tercera red VPC es un VPC compartido, compartido con dos proyectos de servicio. Permite a GCE3, GCE4, GCE5 y GCE6 acceder a los volúmenes D y E. Las redes VPC compartidas solo se admiten para volúmenes del tipo de servicio CVS-Performance.</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7 no puede acceder a ningún volumen.</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">Los datos se pueden cifrar tanto en tránsito (mediante Kerberos y/o cifrado SMB) como en reposo en Cloud Volumes Service.</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">Siguiente: Cifrado de datos en tránsito.</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">Los protocolos NAS representan formas en las que varios clientes de una red pueden acceder a los mismos datos en un sistema de almacenamiento, como Cloud Volumes Service en GCP. NFS y SMB son los protocolos NAS definidos y funcionan cliente/servidor donde Cloud Volumes Service actúa como servidor.</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">Conceptos básicos de los protocolos NAS</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">Anterior: Descripción general de los protocolos NAS.</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">Los protocolos NAS representan formas en las que varios clientes de una red pueden acceder a los mismos datos en un sistema de almacenamiento, como Cloud Volumes Service en GCP. NFS y SMB son los protocolos NAS definidos y funcionan cliente/servidor donde Cloud Volumes Service actúa como servidor. Los clientes envían solicitudes de acceso, lectura y escritura al servidor y éste es responsable de coordinar los mecanismos de bloqueo de archivos, de almacenar permisos y de gestionar las solicitudes de identidad y autenticación.</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">Por ejemplo, se sigue el siguiente proceso general si un cliente NAS desea crear un nuevo archivo en una carpeta.</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">El cliente solicita al servidor información sobre el directorio (permisos, propietario, grupo, ID de archivo, espacio disponible, y así sucesivamente); el servidor responde con la información si el cliente y el usuario solicitante tienen los permisos necesarios en la carpeta principal.</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">Si los permisos del directorio permiten el acceso, el cliente le preguntará al servidor si el nombre de archivo que se está creando ya existe en el sistema de archivos. Si el nombre del archivo ya está en uso, se produce un error en la creación. Si el nombre del archivo no existe, el servidor hace saber al cliente que puede continuar.</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">El cliente realiza una llamada al servidor para crear el archivo con el identificador de directorio y el nombre de archivo y establece el acceso y las horas modificadas. El servidor emite un ID de archivo único al archivo para asegurarse de que no se crean otros archivos con el mismo ID de archivo.</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">El cliente envía una llamada para comprobar los atributos del archivo antes de la operación DE ESCRITURA. Si los permisos lo permiten, el cliente escribe el nuevo archivo. Si el protocolo/aplicación utiliza el bloqueo, el cliente solicita al servidor un bloqueo para evitar que otros clientes accedan al archivo mientras está bloqueado para evitar que se dañen los datos.</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">Siguiente: NFS.</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">Cuando se utiliza Cloud Volumes Service para recursos compartidos NAS, es posible que sea necesario tener dependencias externas para disponer de una funcionalidad adecuada. Estas dependencias están en juego en circunstancias específicas.</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">Otras dependencias de servicios de infraestructura NAS (KDC, LDAP y DNS)</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">Anterior: Consideraciones para crear conexiones de Active Directory.</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">Cuando se utiliza Cloud Volumes Service para recursos compartidos NAS, es posible que sea necesario tener dependencias externas para disponer de una funcionalidad adecuada. Estas dependencias están en juego en circunstancias específicas. En la siguiente tabla se muestran diversas opciones de configuración y qué dependencias, si las hay, son necesarias.</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">Dependencias necesarias</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">Solo NFSv3</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">Solo Kerberos para NFSv3</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Active Directory de Windows: * KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">Solo NFSv4.1</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">Configuración de asignación de ID de cliente (/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">Solo NFSv4.1 Kerberos</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Active Directory de Windows: LDAP de DNS de KDC</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">Solo SMB</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory: * KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">NAS multiprotocolo (NFS y SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">Configuración de asignación de ID de cliente (solo NFSv4.1; /etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">Kerberos keytab rotation/password restablecerse para objetos de cuenta de equipo</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">Con las cuentas de máquina SMB, Cloud Volumes Service programa reinicios periódicos de contraseñas para la cuenta de la máquina SMB. Estos restablecimientos de contraseña se producen utilizando el cifrado Kerberos y funcionan según una programación de cada cuarto domingo a una hora aleatoria entre LAS 11:00 y LAS 01:00. Estos restablecimientos de contraseña cambian las versiones de clave Kerberos, giran las pestañas clave almacenadas en el sistema Cloud Volumes Service y ayudan a mantener un mayor nivel de seguridad para los servidores SMB que se ejecutan en Cloud Volumes Service. Las contraseñas de las cuentas de equipo son aleatorias y no son conocidas por los administradores.</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">Para las cuentas de máquina NFS Kerberos, los restablecimientos de contraseña sólo tienen lugar cuando se crea o se intercambia una nueva keytab con el KDC. Actualmente, no es posible hacerlo en Cloud Volumes Service.</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">Puertos de red para su uso con LDAP y Kerberos</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">Documentación de Cloud Volumes Service sobre consideraciones de seguridad</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">Cuando se utilizan LDAP y Kerberos, debe determinar los puertos de red que utilizan estos servicios. En el, puede encontrar una lista completa de los puertos que utiliza Cloud Volumes Service<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>.</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service actúa como un cliente LDAP y utiliza consultas de búsqueda LDAP estándar para búsquedas de usuarios y grupos de identidades de UNIX. LDAP es necesario si tiene la intención de utilizar usuarios y grupos fuera de los usuarios predeterminados estándar proporcionados por Cloud Volumes Service. LDAP también es necesario si tiene previsto utilizar NFS Kerberos con directores de usuario (como user1@domain.com). Actualmente, sólo LDAP con Microsoft Active Directory es compatible.</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Para utilizar Active Directory como servidor LDAP de UNIX, debe rellenar los atributos UNIX necesarios en los usuarios y grupos que desee utilizar para las identidades de UNIX. Cloud Volumes Service utiliza una plantilla de esquema LDAP predeterminada en la que consulta atributos basados<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>. Como resultado, en la siguiente tabla se muestran los atributos de Active Directory mínimos necesarios que se deben rellenar para los usuarios y grupos y para qué se utiliza cada atributo.</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">Gestión del acceso de doble protocolo.</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Para obtener más información acerca de la configuración de atributos LDAP en Active Directory, consulte<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">Atributo</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">uid*</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">Especifica el nombre de usuario UNIX</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">UidNumber*</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">Especifica el ID numérico del usuario UNIX</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">GidNumber*</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">Especifica el identificador numérico del grupo principal del usuario UNIX</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">ObjectClass*</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">Especifica qué tipo de objeto se está utilizando; Cloud Volumes Service requiere que “user” se incluya en la lista de clases de objeto (se incluye de forma predeterminada en la mayoría de implementaciones de Active Directory).</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">Información general sobre la cuenta (nombre real, número de teléfono, etc., también conocido como gecos)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">UnixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">No es necesario configurar esto; no se utiliza en las búsquedas de identidad de UNIX para la autenticación NAS. Al establecer esta opción, el valor de unixUserPassword configurado se coloca en texto sin formato.</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">UnixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">Define la ruta a los directorios iniciales de UNIX cuando un usuario autentica con LDAP desde un cliente Linux. Establezca esta opción si desea utilizar la funcionalidad de directorio raíz de LDAP para UNIX.</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">LoginShell</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">Define la ruta al shell bash/profile para clientes Linux cuando un usuario autentica de acuerdo con LDAP.</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*Denota atributo es necesario para una funcionalidad adecuada con Cloud Volumes Service. Los atributos restantes son para uso exclusivo del cliente.</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">cn*</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">Especifica el nombre del grupo UNIX. Cuando se utiliza Active Directory para LDAP, se establece cuando se crea el objeto por primera vez, pero se puede cambiar más tarde. Este nombre no puede ser el mismo que el de otros objetos. Por ejemplo, si su usuario UNIX denominado user1 pertenece a un grupo denominado user1 en su cliente Linux, Windows no permite dos objetos con el mismo atributo cn. Para evitar esto, cambie el nombre del usuario de Windows por un nombre único (como user1-UNIX); LDAP en Cloud Volumes Service utiliza el atributo uid para los nombres de usuario de UNIX.</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">Especifica el identificador numérico del grupo UNIX.</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">Especifica qué tipo de objeto se está utilizando; Cloud Volumes Service requiere que se incluya un grupo en la lista de clases de objeto (este atributo se incluye de forma predeterminada en la mayoría de las implementaciones de Active Directory).</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">MemberUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">Especifica qué usuarios UNIX son miembros del grupo UNIX. Con LDAP de Active Directory en Cloud Volumes Service, este campo no es necesario. El esquema LDAP de Cloud Volumes Service utiliza el campo Miembro para las pertenencias a grupos.</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">Miembro*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">Necesario para grupos de miembros/grupos UNIX secundarios. Para rellenar este campo, agregue usuarios de Windows a grupos de Windows. Sin embargo, si los grupos de Windows no tienen atributos UNIX rellenados, no se incluyen en las listas de miembros de grupo del usuario UNIX. Todos los grupos que tengan que estar disponibles en NFS deben rellenar los atributos de grupo UNIX necesarios que aparecen en esta tabla.</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">Información de enlace LDAP</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">Para consultar a los usuarios en LDAP, Cloud Volumes Service debe enlazar (iniciar sesión) con el servicio LDAP. Este inicio de sesión tiene permisos de sólo lectura y se utiliza para consultar atributos UNIX LDAP para búsquedas de directorios. Actualmente, los vínculos LDAP sólo son posibles mediante una cuenta de máquina SMB.</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">Solo puede habilitar LDAP para<block ref="439d7969e09b4b31626fcf209b8fdcb7" prefix=" " category="inline-code"></block> Y utilícelo para NFSv3, NFSv4.1 o volúmenes de protocolo doble. Debe establecerse una conexión de Active Directory en la misma región que el volumen de Cloud Volumes Service para implementar correctamente el volumen habilitado para LDAP.</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">Cuando LDAP está habilitado, lo siguiente se produce en situaciones específicas.</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">"Recursos compartidos ocultos predeterminados"</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Si solo se utilizan NFSv3 o NFSv4.1 para el proyecto de Cloud Volumes Service, se crea una nueva cuenta de máquina en la controladora de dominio de Active Directory y el cliente LDAP de Cloud Volumes Service se enlaza a Active Directory mediante las credenciales de la cuenta del equipo. No se crean recursos compartidos de SMB para el volumen NFS ni los recursos compartidos administrativos ocultos predeterminados (consulte la sección <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Se han eliminado las ACL compartidas.</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Si se utilizan volúmenes de protocolo doble para el proyecto Cloud Volumes Service, solo se utiliza la cuenta de máquina única creada para el acceso SMB para vincular el cliente LDAP en Cloud Volumes Service a Active Directory. No se crean cuentas de equipo adicionales.</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">Si los volúmenes SMB dedicados se crean por separado (antes o después de que se habilitaron los volúmenes NFS con LDAP), la cuenta de máquina para los vínculos LDAP se comparte con la cuenta de la máquina SMB.</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">Si también está habilitado NFS Kerberos, se crean dos cuentas de máquina: Una para recursos compartidos SMB y/o enlaces LDAP y una para autenticación Kerberos NFS.</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="section-title">Consultas LDAP</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">Aunque los vínculos LDAP están cifrados, las consultas LDAP se pasan por el cable en texto sin formato utilizando el puerto LDAP 389 común. Este puerto conocido no se puede cambiar actualmente en Cloud Volumes Service. Como resultado, alguien con acceso al rastreo de paquetes en la red puede ver nombres de usuarios y grupos, identificadores numéricos y pertenencias a grupos.</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">“Consideraciones sobre rastreo y rastreo de paquetes”.</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">Sin embargo, las máquinas virtuales de Google Cloud no pueden snifar el tráfico unicast de otras máquinas virtuales. Solo las máquinas virtuales que participan activamente en el tráfico LDAP (es decir, que se pueden enlazar) pueden ver tráfico del servidor LDAP. Para obtener más información sobre el rastreo de paquetes en Cloud Volumes Service, consulte la sección <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">Valores predeterminados de la configuración del cliente LDAP</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Cuando se habilita LDAP en una instancia de Cloud Volumes Service, se crea una configuración de cliente LDAP con detalles de configuración específicos de forma predeterminada. En algunos casos, las opciones no se aplican a Cloud Volumes Service (no se admiten) o no son configurables.</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">Opción de cliente LDAP</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">Lista de servidores LDAP</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">Establece los nombres de servidor LDAP o las direcciones IP que se utilizarán para las consultas. Esto no se utiliza para Cloud Volumes Service. En su lugar, el dominio de Active Directory se utiliza para definir servidores LDAP.</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">No configurado</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Dominio de Active Directory</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">Establece el dominio de Active Directory que se utilizará para consultas LDAP. Cloud Volumes Service aprovecha los registros SRV para LDAP en DNS para buscar servidores LDAP en el dominio.</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Establezca el dominio de Active Directory especificado en la conexión de Active Directory.</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">Servidores de Active Directory preferidos</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">Establece los servidores de Active Directory preferidos que se utilizarán para LDAP. Que Cloud Volumes Service no admite. En su lugar, utilice los sitios de Active Directory para controlar la selección del servidor LDAP.</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">No configurado.</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">Enlazar mediante credenciales de SMB Server</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">Enlaza a LDAP mediante la cuenta de máquina SMB. Actualmente, el único método de enlace LDAP admitido en Cloud Volumes Service.</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">Plantilla de esquema</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">La plantilla de esquema utilizada para consultas LDAP.</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">Puerto del servidor LDAP</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">El número de puerto utilizado para consultas LDAP. Cloud Volumes Service utiliza actualmente sólo el puerto LDAP estándar 389. LDAPS/el puerto 636 actualmente no es compatible.</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">LDAPS habilitado</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">Controla si se utiliza LDAP sobre Secure Sockets Layer (SSL) para consultas y vínculos. Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">Tiempo de espera de consulta (s)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">Tiempo de espera para consultas. Si las consultas tardan más tiempo que el valor especificado, las consultas no se pueden realizar.</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">Nivel de autenticación de enlace mínimo</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">El nivel de enlace mínimo admitido. Dado que Cloud Volumes Service utiliza cuentas de equipo para los vínculos LDAP y Active Directory no admite enlaces anónimos de forma predeterminada, esta opción no entra en juego para la seguridad.</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">Anónimo</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">Enlazar DN</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">El nombre de usuario/distintivo (DN) utilizado para los vínculos cuando se utiliza el enlace simple. Cloud Volumes Service utiliza cuentas de equipo para enlaces LDAP y actualmente no admite autenticación de enlace simple.</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">DN base</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">El DN base que se utiliza para las búsquedas LDAP.</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">El dominio de Windows se utiliza para la conexión de Active Directory, en formato DN (es decir, DC=dominio, DC=local).</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">Ámbito de búsqueda base</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">El ámbito de búsqueda para las búsquedas de DN base. Los valores pueden incluir base, onelevel o subárbol. Cloud Volumes Service sólo admite búsquedas en subárboles.</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">Subárbol</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">DN de usuario</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">Define el DN en el que se inician las búsquedas del usuario para las consultas LDAP. Actualmente no es compatible con Cloud Volumes Service, por lo que todas las búsquedas de usuarios comienzan en el DN base.</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">Ámbito de búsqueda de usuarios</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">El ámbito de búsqueda para las búsquedas de DN de usuario. Los valores pueden incluir base, onelevel o subárbol. Cloud Volumes Service no admite la configuración del ámbito de búsqueda de usuarios.</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">DN de grupo</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">Define el DN donde comienzan las búsquedas de grupo para consultas LDAP. Actualmente no es compatible con Cloud Volumes Service, por lo que todas las búsquedas de grupo comienzan en el DN base.</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">Ámbito de búsqueda de grupos</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">El ámbito de búsqueda para las búsquedas de DN de grupo. Los valores pueden incluir base, onelevel o subárbol. Cloud Volumes Service no admite la configuración del ámbito de búsqueda de grupos.</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">DN de grupo de red</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">Define el DN donde comienzan las búsquedas de netgroup para las consultas LDAP. Actualmente no es compatible con Cloud Volumes Service, por lo que todas las búsquedas de netgroup comienzan en el DN base.</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">Ámbito de búsqueda de grupos de red</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">El ámbito de búsqueda para las búsquedas de DN de grupo de red. Los valores pueden incluir base, onelevel o subárbol. Cloud Volumes Service no admite la configuración del ámbito de búsqueda de netgroup.</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">Utilice start_tls sobre LDAP</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">Aprovecha Start TLS para conexiones LDAP basadas en certificados a través del puerto 389. Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">Habilite la búsqueda de netgroup-by-host</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">Habilita búsquedas de netgroup por nombre de host en lugar de expandir grupos de red para enumerar todos los miembros. Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">DN de netgroup por host</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">Define el DN donde comienzan las búsquedas netgroup-by-host para las consultas LDAP. Actualmente, netgroup-by-host no es compatible con Cloud Volumes Service.</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">Ámbito de búsqueda netgroup-by-host</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">El ámbito de búsqueda para las búsquedas DN de netgroup-by-host. Los valores pueden incluir base, onelevel o subárbol. Actualmente, netgroup-by-host no es compatible con Cloud Volumes Service.</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">Seguridad de sesión de cliente</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">Define qué nivel de seguridad de sesión utiliza LDAP (firma, sello o ninguno). La firma LDAP es compatible con CVS-Performance, si es solicitada por Active Directory. CVS-SW no admite la firma LDAP. En ambos tipos de servicio, el sellado no es compatible actualmente.</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">Búsqueda de referencias LDAP</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">Filtro de pertenencia a grupos</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">Proporciona un filtro de búsqueda LDAP personalizado que se utilizará al buscar miembros de grupo desde un servidor LDAP. Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">Se utiliza LDAP para la asignación de nombres asimétricos</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">Cloud Volumes Service, de forma predeterminada, asigna usuarios de Windows y usuarios UNIX con nombres de usuario idénticos de manera bidireccional sin configuración especial. Siempre que Cloud Volumes Service pueda encontrar un usuario UNIX válido (con LDAP), se producirá una asignación de nombre 1:1. Por ejemplo, si el usuario de Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Se utiliza, entonces, si Cloud Volumes Service puede encontrar un usuario UNIX llamado<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> En LDAP, la asignación de nombres se realiza correctamente para ese usuario, todos los archivos/carpetas creados por<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Mostrar la propiedad de usuario correcta y todas las ACL que afectan<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Sean honrados independientemente del protocolo NAS que se utilice. Esto se conoce como asignación simétrica de nombres.</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">La asignación de nombres asimétricos se produce cuando la identidad del usuario de Windows y de UNIX no coinciden. Por ejemplo, si el usuario de Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Tiene una identidad UNIX de<block ref="39ce7e2a8573b41ce73b5ba41617f8f7" prefix=" " category="inline-code"></block>, Cloud Volumes Service necesita una manera de ser contada acerca de la variación. Puesto que Cloud Volumes Service no admite actualmente la creación de reglas estáticas de asignación de nombres, se debe utilizar LDAP para buscar la identidad de los usuarios tanto para las identidades de Windows como UNIX para garantizar la propiedad correcta de los archivos y carpetas y los permisos esperados.</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">De forma predeterminada, Cloud Volumes Service incluye<block ref="2363dee608bcd9f6ce7f980bfdad5789" prefix=" " category="inline-code"></block> En el switch ns de la instancia de la base de datos de asignación de nombres, de modo que para proporcionar la funcionalidad de asignación de nombres mediante el uso de LDAP para nombres asimétricos, sólo es necesario modificar algunos de los atributos de usuario/grupo para reflejar lo que busca Cloud Volumes Service.</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">En la siguiente tabla se muestran los atributos que se deben rellenar en LDAP para la funcionalidad de asignación de nombres asimétrica. En la mayoría de los casos, Active Directory ya está configurado para hacerlo.</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Atributo Cloud Volumes Service</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Valor que utiliza Cloud Volumes Service para la asignación de nombres</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">Clase de objetos de Windows a UNIX</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">Especifica el tipo de objeto que se está utilizando. (Es decir, usuario, grupo, posixcuenta, etc.)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">Debe incluir al usuario (puede contener varios otros valores, si lo desea).</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Atributo de Windows a UNIX</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">Que define el nombre de usuario de Windows en el momento de su creación. Cloud Volumes Service lo utiliza para búsquedas de Windows a UNIX.</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">No se necesita ningún cambio aquí; sAMAccountName es igual que el nombre de inicio de sesión de Windows.</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">Define el nombre de usuario UNIX.</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">Nombre de usuario UNIX deseado.</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service actualmente no utiliza prefijos de dominio en las búsquedas LDAP, de modo que varios entornos LDAP de dominio no funcionan correctamente con las búsquedas del mapa de nombres LDAP.</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">En el ejemplo siguiente se muestra un usuario con el nombre de Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block>, El nombre UNIX<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Y el comportamiento que sigue al escribir archivos tanto de SMB como de NFS.</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">La figura siguiente muestra el aspecto de los atributos LDAP desde el servidor Windows.</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">Desde un cliente NFS, puede consultar el nombre de UNIX, pero no el nombre de Windows:</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">Cuando se escribe un archivo desde NFS AS<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, El siguiente es el resultado del cliente NFS:</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">Desde un cliente Windows, puede ver que el propietario del archivo está establecido en el usuario de Windows correcto:</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">Por el contrario, los archivos creados por el usuario de Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block> Desde un cliente SMB, se muestra el propietario UNIX correcto, tal y como se muestra en el texto siguiente.</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB:</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS:</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">Enlace de canal LDAP</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Aviso de seguridad de Microsoft ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">Debido a una vulnerabilidad en los controladores de dominio de Windows Active Directory,<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> Cambia la forma en que los DC permiten el enlace LDAP.</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">El impacto para Cloud Volumes Service es el mismo que para cualquier cliente LDAP. Cloud Volumes Service no admite actualmente el enlace de canal. Dado que Cloud Volumes Service admite la firma LDAP de forma predeterminada a través de la negociación, el enlace al canal LDAP no debe ser un problema. Si tiene problemas con la vinculación a LDAP con el enlace de canal activado, siga los pasos de corrección de ADV190023 para permitir que los enlaces LDAP de Cloud Volumes Service tengan éxito.</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="section-title">DNS</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">DNS dinámico</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory y Kerberos tienen dependencias en DNS para el nombre de host a IP/IP para la resolución de nombres de host. DNS requiere que el puerto 53 esté abierto. Cloud Volumes Service no realiza modificaciones en los registros DNS ni admite actualmente el uso de<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> en las interfaces de red.</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">Proteja el DNS de Windows</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">Puede configurar el DNS de Active Directory para restringir qué servidores pueden actualizar los registros DNS. Para obtener más información, consulte<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>.</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Tenga en cuenta que los recursos de un proyecto de Google utilizan de forma predeterminada Google Cloud DNS, que no está conectado con Active Directory DNS. Los clientes que utilizan DNS cloud no pueden resolver las rutas UNC que devuelve Cloud Volumes Service. Los clientes de Windows Unidos al dominio de Active Directory están configurados para usar DNS de Active Directory y pueden resolver dichas rutas UNC.</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">¿Por qué mi cliente no puede resolver el nombre NetBIOS de SMB?</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">Para unirse a un cliente a Active Directory, debe configurar su configuración DNS para utilizar el DNS de Active Directory. Opcionalmente, puede configurar Cloud DNS para reenviar solicitudes a Active Directory DNS. Consulte<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>si quiere más información.</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service no admite actualmente las consultas DNSSEC y las consultas DNS se realizan en texto sin formato.</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">Auditoría de acceso a los archivos</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">Actualmente no es compatible con Cloud Volumes Service.</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">Protección antivirus</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">Debe realizar análisis antivirus en Cloud Volumes Service en el cliente para un recurso compartido NAS. Actualmente no existe ninguna integración antivirus nativa con Cloud Volumes Service.</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">Siguiente: Operación de servicio.</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service expone varios puertos TCP para servir recursos compartidos NFS y SMB.</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">Servidor de seguridad</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">Anterior: Cifrado de datos en reposo.</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service expone varios puertos TCP para que sirvan a los recursos compartidos NFS y SMB:</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">Puertos necesarios para el acceso NFS</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">Puertos necesarios para el acceso a SMB</block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">configurado</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">Descubrimiento de DC basado en DNS</block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">Además, SMB, NFS con LDAP incluido Kerberos y configuraciones de protocolo dual requieren acceso a un dominio de Windows Active Directory. Deben estar las conexiones de Active Directory<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> por región. Los controladores de dominio de Active Directory (DC) se identifican mediante el uso<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> Utilizando los servidores DNS especificados. Se utiliza cualquiera de los DC devueltos. La lista de centros de datos elegibles se puede limitar especificando un sitio de Active Directory.</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">Integración de Cloud Volumes Service</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service se dirige a través de direcciones IP del rango CIDR asignado con el<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> command mientras<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>. Puede utilizar este CIDR como direcciones de origen para configurar firewalls entrantes en los controladores de dominio de Active Directory.</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">Exponer los puertos a los CIDR de Cloud Volumes Service como se menciona aquí</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Los controladores de dominio de Active Directory deben<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>.</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">Siguiente: Descripción general de los protocolos NAS.</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">Parte de confiar en una solución cloud es comprender la arquitectura y el modo en el que se protege. En esta sección se presentan distintos aspectos de la arquitectura de Cloud Volumes Service en Google para ayudar a solucionar los posibles problemas relacionados con la seguridad de los datos, así como llamadas a áreas en las que se puedan necesitar pasos de configuración adicionales para obtener la puesta en marcha más segura.</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">Anterior: Consideraciones de seguridad y superficies de ataque.</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">La arquitectura general de Cloud Volumes Service se puede dividir en dos componentes principales: El plano de control y el plano de datos.</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">Plano de control</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">El plano de control en Cloud Volumes Service es la infraestructura de back-end gestionada por los administradores de Cloud Volumes Service y el software de automatización nativo de NetApp. Este plano es completamente transparente para los usuarios finales e incluye redes, hardware de almacenamiento, actualizaciones de software, etc. para ayudar a ofrecer valor a una solución residente en cloud como Cloud Volumes Service.</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">Plano de datos</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">El plano de datos en Cloud Volumes Service incluye los volúmenes de datos reales y la configuración de Cloud Volumes Service general (como el control de acceso, la autenticación de Kerberos, etc.). El plano de datos está totalmente bajo el control de los usuarios finales y de los consumidores de la plataforma Cloud Volumes Service.</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">Existen diferencias distintas en cómo se asegura y gestiona cada plano. En las siguientes secciones se tratan estas diferencias, empezando por la descripción general de la arquitectura de Cloud Volumes Service.</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">Siguiente: Arquitectura de Cloud Volumes Service.</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">Háganos saber cómo podemos mejorar este informe técnico.</block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">Póngase en contacto con nosotros en correo electrónico: doccomments@netapp.com[doccomments@netapp.com]. Incluir EL INFORME TÉCNICO 4918 en el asunto.</block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">Información adicional, historial de versiones e información de contacto</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">Anterior: Operación de mantenimiento.</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Documentación de Google Cloud para Cloud Volumes Service</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Acceso a servicios privados de Google</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentación de productos de NetApp</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">Programa de módulos de validación criptográfico—NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616: Kerberos de NFS en ONTAP</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">Póngase en contacto con nosotros en correo electrónico: doccomments@netapp.com[doccomments@netapp.com]. Incluir EL INFORME TÉCNICO 4918 en el asunto.</block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">Los datos en tránsito pueden cifrarse en la capa de protocolo NAS, y la propia red de Google Cloud está cifrada, tal y como se describe en las siguientes secciones.</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">Cifrado de datos en tránsito</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">Anterior: Arquitectura de plano de datos.</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Red de Google Cloud</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">Cifrado en tránsito</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud cifra el tráfico en el nivel de la red, tal y como se describe en<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> En la documentación de Google. Como se mencionó en la sección "Arquitectura de Cloud Volumes Services", Cloud Volumes Service se ofrece desde un proyecto de productor de PSA controlado por NetApp.</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">En caso de CVS-SW, el inquilino productor ejecuta las VM de Google para ofrecer el servicio. Google cifra automáticamente el tráfico entre los equipos virtuales del usuario y los equipos virtuales de Cloud Volumes Service.</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">De cifrado IEEE 802.1AE (MACSec)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">encapsulación</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">Aunque la ruta de datos para CVS-Performance no está completamente cifrada en la capa de red, NetApp y Google usan una combinación de ambos<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>,<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (Cifrado de datos) y redes con limitaciones físicas para proteger los datos en tránsito entre el tipo de servicio CVS-Performance de Cloud Volumes Service y Google Cloud.</block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="section-title">Protocolos NAS</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">Los protocolos NFS y SMB NAS proporcionan un cifrado de transporte opcional en la capa del protocolo.</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="section-title">Cifrado SMB</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> Proporciona cifrado integral de datos SMB y protege los datos de espionaje en redes que no son de confianza. Puede habilitar el cifrado tanto para la conexión de datos de cliente/servidor (solo disponible para clientes compatibles con SMB3.x) como para la autenticación de la controladora de servidor/dominio.</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">Cuando el cifrado SMB está habilitado, los clientes que no admiten el cifrado no pueden acceder al recurso compartido.</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service admite cifrados de seguridad RC4-HMAC, AES-128-CTS-HMAC-SHA1 y AES-256-CTS-HMAC-SHA1 para el cifrado SMB. SMB negocia con el tipo de cifrado más alto admitido por el servidor.</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">NFSv4.1 Kerberos</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">Para NFSv4.1, CVS-Performance ofrece autenticación de Kerberos, tal como se describe en<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>. Puede activar Kerberos por volumen.</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">El tipo de cifrado disponible más actual para Kerberos es AES-256-CTS-HMAC-SHA1. Cloud Volumes Service de NetApp es compatible con AES-256-CTS-HMAC-SHA1, AES-128-CTS-HMAC-SHA1, DES3 y DES para NFS. También admite ARCFOUR-HMAC (RC4) para el tráfico CIFS/SMB, pero no para NFS.</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos proporciona tres niveles de seguridad distintos para montajes NFS que ofrecen opciones para la solidez de la seguridad de Kerberos.</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">Opciones de montaje comunes</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">Según RedHat’s<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> documentación:</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">Como regla general, cuanto mayor sea el nivel de seguridad de Kerberos, peor será el rendimiento, puesto que el cliente y el servidor pasan tiempo cifrando y descifrando las operaciones de NFS para cada paquete enviado. Muchos clientes y servidores NFS ofrecen soporte para la descarga de AES-ni a las CPU para una mejor experiencia general, pero el impacto en el rendimiento de Kerberos 5p (cifrado completo integral) es significativamente mayor que el impacto de Kerberos 5 (autenticación de usuario).</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">En la siguiente tabla se muestran las diferencias en el rendimiento y la seguridad de cada nivel.</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">Nivel de seguridad</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3: System</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">Menos seguro; texto sin formato con ID de usuario/ID de grupo numéricos</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">Capaz de ver UID, GID, direcciones IP de cliente, rutas de exportación, nombres de archivos, permisos en capturas de paquetes</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">Lo mejor para la mayoría de los casos</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x: Sys</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">Más seguro que NFSv3 (identificadores de cliente, coincidencia de cadena de nombre/cadena de dominio) pero texto sin formato</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">Se puede ver UID, GID, direcciones IP de cliente, cadenas de nombre, identificadores de dominio, rutas de exportación, nombres de archivo y permisos en capturas de paquetes</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">Bueno para cargas de trabajo secuenciales (como equipos virtuales, bases de datos, archivos de gran tamaño)</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">Malo con un número elevado de archivos/metadatos altos (un 30-50% peor)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS: Krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">El cifrado Kerberos para credenciales en cada paquete NFS envuelve UID/GID de usuarios/grupos en llamadas RPC en el contenedor GSS</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">El usuario que solicita el acceso al montaje necesita un ticket Kerberos válido (ya sea mediante el nombre de usuario/contraseña o el cambio de tabulación manual); el ticket caduca después de un período de tiempo especificado y el usuario debe volver a autenticarse para el acceso</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">No existe cifrado para operaciones de NFS ni para protocolos auxiliares como Mount/portmapper/nlm (puede ver rutas de exportación, direcciones IP, identificadores de archivos, permisos, nombres de archivos, atime/mtime en capturas de paquetes)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">Mejor en la mayoría de los casos para Kerberos; peor que AUTH_SYS</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS: Krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">El usuario que solicita el acceso al montaje necesita un ticket Kerberos válido (ya sea mediante el nombre de usuario/contraseña o el cambio de tabulación manual); el ticket caduca después de un período de tiempo especificado y el usuario debe volver a autenticarse para el acceso</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">La suma de comprobación de Kerberos GSS se agrega a cada paquete para garantizar que nada intercepta los paquetes. Si coinciden sumas de comprobación, se permite la conversación.</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">Mejor que krb5p porque la carga útil NFS no está cifrada; solo la sobrecarga añadida en comparación con krb5 es la suma de comprobación de integridad. El rendimiento del krb5i no será mucho peor que el krb5, pero sí que se verá algo de degradación.</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS: Krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">El usuario que solicita acceso al montaje necesita un ticket Kerberos válido (ya sea mediante nombre de usuario/contraseña o cambio manual de keytab); el ticket caduca después del período de tiempo especificado y el usuario debe volver a autenticarse para acceder</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">Todas las cargas de paquetes NFS se cifran con el contenedor GSS (no se pueden ver los identificadores de archivos, permisos, nombres de archivos, atime/mtime en capturas de paquetes).</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">Incluye comprobación de integridad.</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">El tipo de operación NFS es visible (FSINFO, ACCESS, GETATTR, etc.).</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">Los protocolos auxiliares (Mount, portmap, nlm, etc.) no están cifrados (puede ver rutas de exportación, direcciones IP)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">El peor rendimiento de los niveles de seguridad; krb5p debe cifrar/descifrar más.</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">Mejor rendimiento que krb5p con NFSv4.x para cargas de trabajo con un gran número de archivos.</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">En Cloud Volumes Service, un servidor de Active Directory configurado se utiliza como servidor Kerberos y servidor LDAP (para buscar identidades de usuario desde un esquema compatible con RFC2307). No se admiten otros servidores Kerberos o LDAP. NetApp recomienda encarecidamente utilizar LDAP para la gestión de identidades en Cloud Volumes Service. Para obtener más información acerca de cómo se muestra NFS Kerberos en capturas de paquetes, consulte la sección <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">Siguiente: Cifrado de datos en reposo.</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">De forma similar a otros servicios nativos de Google Cloud como CloudSQL, Google Cloud VMware Engine (GCVE) y filestore, Cloud Volumes Service utiliza Google PSA para prestar el servicio.</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Arquitectura Cloud Volumes Service</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">Agrupación de redes VPC</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">De forma similar a otros servicios nativos de Google Cloud como CloudSQL, Google Cloud VMware Engine (GCVE) y filestore, utiliza Cloud Volumes Service<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> para prestar el servicio. En PSA, los servicios se construyen dentro de un proyecto de productor de servicios, que utiliza<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> para conectarse con el consumidor de servicios. El productor de servicios lo proporciona y controla NetApp, y el consumidor de servicios es un VPC en un proyecto de cliente, que aloja a los clientes que desean acceder a recursos compartidos de archivos de Cloud Volumes Service.</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">sección de arquitectura</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">La siguiente figura, a la que se hace referencia desde<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> De la documentación de Cloud Volumes Service, muestra una vista de alto nivel.</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">La pieza situada encima de la línea de puntos muestra el plano de control del servicio, que controla el ciclo de vida del volumen. La pieza debajo de la línea de puntos muestra el plano de datos. El cuadro azul izquierdo muestra el VPC (consumidor de servicios) del usuario, el cuadro azul derecho es el productor de servicios que proporciona NetApp. Ambos se conectan mediante la agrupación de VPC.</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">Modelo de tenancy</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">En Cloud Volumes Service, los proyectos individuales se consideran inquilinos únicos. Esto significa que la manipulación de volúmenes, copias Snapshot, etc. se realiza por proyecto. En otras palabras, todos los volúmenes son propiedad del proyecto en el que se crearon y solo ese proyecto puede gestionar y acceder a los datos de su interior de forma predeterminada. Se considera la vista del plano de control del servicio.</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">VPC compartidos</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">En la vista del plano de datos, Cloud Volumes Service puede conectarse a un VPC compartido. Se pueden crear volúmenes en el proyecto de host o en uno de los proyectos de servicio conectados al VPC compartido. Todos los proyectos (host o servicio) conectados al VPC compartido pueden llegar a los volúmenes de la capa de red (TCP/IP). Debido a que todos los clientes con conectividad de red en el VPC compartido pueden acceder potencialmente a los datos mediante los protocolos NAS, se debe utilizar el control de acceso en el volumen individual (como las listas de control de acceso de usuarios/grupos (ACL) y los nombres de host/direcciones IP para las exportaciones de NFS para controlar quién puede acceder a los datos.</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">Puede conectar Cloud Volumes Service hasta a cinco VPC por proyecto de cliente. En el plano de control, el proyecto le permite gestionar todos los volúmenes creados, independientemente del VPC al que estén conectados. En el plano de datos, las PC están aisladas entre sí y cada volumen solo se puede conectar a un VPC.</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">El acceso a los volúmenes individuales está controlado por mecanismos de control de acceso específicos de los protocolos (NFS/SMB).</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">En otras palabras, en la capa de red, todos los proyectos conectados al VPC compartido pueden ver el volumen, mientras que, por el lado de la gestión, el plano de control solo permite que el proyecto del propietario vea el volumen.</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">Controles de servicio VPC</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">Los controles de servicio VPC establecen un perímetro de control de acceso alrededor de los servicios de Google Cloud que están conectados a Internet y son accesibles en todo el mundo. Estos servicios proporcionan control de acceso a través de identidades de usuario, pero no pueden restringir desde qué solicitudes de ubicación de red se originan. Los controles de servicio VPC cierran esa brecha introduciendo las funcionalidades para restringir el acceso a las redes definidas.</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">El plano de datos Cloud Volumes Service no está conectado a Internet externo sino a ordenadores virtuales privados con límites de red bien definidos (perímetros). Dentro de esa red, cada volumen utiliza un control de acceso específico del protocolo. Los administradores de proyectos de Google Cloud crean explícitamente cualquier conectividad de red externa. Sin embargo, el plano de control no proporciona las mismas protecciones que el plano de datos y puede ser accesible por cualquier persona desde cualquier lugar con credenciales válidas (<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>).</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">En resumen, el plano de datos Cloud Volumes Service proporciona la funcionalidad de control de acceso a la red, sin el requisito de admitir controles de servicio VPC y no utiliza de forma explícita los controles de servicio VPC.</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">Consideraciones sobre rastreo y rastreo de paquetes</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">Las capturas de paquetes pueden ser útiles para solucionar problemas de red u otros problemas (como permisos NAS, conectividad LDAP, etc.), pero también se pueden usar de forma malintencionada para obtener información sobre direcciones IP de red, direcciones MAC, nombres de usuarios y grupos, y sobre qué nivel de seguridad se está utilizando en los extremos. Debido a la forma en que se configuran las reglas de red, VPC y firewall de Google Cloud, el acceso no deseado a los paquetes de red debería ser difícil de obtener sin credenciales de inicio de sesión del usuario o <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> a las instancias de cloud. Las capturas de paquetes solo son posibles en extremos (como máquinas virtuales (VM)) y solo en extremos internos en el VPC, a menos que se utilice un VPC compartido o un reenvío de túnel/IP de red externo para permitir de forma explícita el tráfico externo a los extremos. No hay forma de sniff el tráfico fuera de los clientes.</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">Cuando se utilizan VPC compartidos, cifrado en tránsito con NFS Kerberos y/o. <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> puede enmascarar gran parte de la información obtenida de las trazas. Sin embargo, cierto tráfico se sigue enviando en texto sin texto, como <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> y.. <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>. En la siguiente figura se muestra una captura de paquetes de una consulta LDAP de texto sin formato originada en Cloud Volumes Service y la información de identificación potencial que se expone. Las consultas LDAP en Cloud Volumes Service actualmente no admiten cifrado ni LDAP sobre SSL. CVS-Performance admite la firma LDAP, si es solicitada por Active Directory. CVS-SW no admite la firma LDAP.</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">UnixUserPassword es consultada por LDAP y no se envía en texto sin formato sino en un hash salado. De forma predeterminada, LDAP de Windows no rellena los campos unixUserPassword. Este campo sólo es necesario si necesita aprovechar LDAP de Windows para inicios de sesión interactivos a través de LDAP a clientes. Cloud Volumes Service no admite inicios de sesión LDAP interactivos en las instancias.</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">En la siguiente figura se muestra una captura de paquetes desde una conversación Kerberos de NFS junto a una captura de NFS sobre AUTH_SYS. Tenga en cuenta que la información disponible en una traza difiere entre ambas y cómo habilitar el cifrado en tránsito ofrece una mayor seguridad general para el tráfico NAS.</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">Interfaces de red de equipos virtuales</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">modo promiscuo</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">Un truco que los atacantes podrían intentar es agregar una nueva tarjeta de interfaz de red (NIC) a una VM en<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> (Duplicación de puertos) o habilite el modo promiscuo en una NIC existente para sniff todo el tráfico. En Google Cloud, agregar una nueva NIC requiere que una máquina virtual se cierre por completo, lo que crea alertas, por lo que los atacantes no pueden pasar por alto.</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">Además, las NIC no se pueden establecer en modo promiscuo y activarán alertas en Google Cloud.</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">Siguiente: Arquitectura del plano de control.</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Todos los volúmenes de Cloud Volumes Service se cifran en reposo mediante el cifrado AES-256, lo que significa que todos los datos de usuario escritos en medios se cifran y solo se pueden descifrar con una clave por volumen.</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">Cifrado de datos en reposo</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">Anterior: Cifrado de datos en tránsito.</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">Para CVS-SW, se usan claves generadas por Google.</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">Para CVS-Performance, las claves por volumen se almacenan en un gestor de claves incorporado en Cloud Volumes Service.</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Servicio de administración de claves (KMS) de Google.</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">A partir de noviembre de 2021, ya estaba disponible la funcionalidad de obtener una vista previa de las claves de cifrado gestionadas por el cliente (CMEK). Esto permite cifrar las claves por volumen con una clave maestra por proyecto y por región alojada en<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> KMS le permite asociar gestores de claves externos.</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">Configurar las claves de cifrado gestionadas por el cliente</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">Para obtener información acerca de la configuración de KMS para CVS-Performance, consulte<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>.</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">Siguiente: Firewall.</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service permite conectar la instancia de Cloud Volumes Service a un servidor de Active Directory externo para la gestión de identidades tanto para usuarios de SMB como UNIX. Se requiere crear una conexión de Active Directory para utilizar SMB en Cloud Volumes Service.</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Consideraciones para crear conexiones de Active Directory</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">Anterior: Protocolo dual/multiprotocolo.</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">Acceso privado a Google</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Prácticas recomendadas con Active Directory en Google Cloud</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">La configuración para esto ofrece varias opciones que requieren cierta consideración para la seguridad. El servidor de Active Directory externo puede ser una instancia de las instalaciones o una nativa del cloud. Si utiliza un servidor de Active Directory en las instalaciones, no exponga el dominio a la red externa (como con una DMZ o una dirección IP externa). En su lugar, utilice túneles privados seguros o VPN, fideicomisos forestales de un solo sentido o conexiones de red dedicadas a las redes locales con<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>. Consulte la documentación de Google Cloud para obtener más información acerca de<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>.</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW requiere que los servidores de Active Directory se encuentren en la misma región. Si se intenta una conexión de CC en CVS-SW a otra región, el intento falla. Cuando utilice CVS-SW, asegúrese de crear sitios de Active Directory que incluyan los DC de Active Directory y, a continuación, especifique los sitios en Cloud Volumes Service para evitar intentos de conexión de DC entre regiones.</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Credenciales de Active Directory</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">Cuando se habilita SMB o LDAP para NFS, Cloud Volumes Service interactúa con los controladores de Active Directory para crear un objeto de cuenta de máquina que se usará para la autenticación. Esto no difiere del modo en que un cliente SMB de Windows se une a un dominio y requiere los mismos derechos de acceso a las unidades organizativas (OU) de Active Directory.</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">En muchos casos, los grupos de seguridad no permiten el uso de una cuenta de administrador de Windows en servidores externos como Cloud Volumes Service. En algunos casos, el usuario Administrador de Windows está completamente deshabilitado como una práctica recomendada de seguridad.</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">Permisos necesarios para crear cuentas de máquina SMB</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">permisos delegados para crear y modificar objetos de cuenta de equipo</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Para agregar objetos de máquina Cloud Volumes Service a un Active Directory, una cuenta que tenga derechos administrativos en el dominio o tiene<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> A una unidad organizativa especificada es necesaria. Puede hacerlo con el Asistente para delegación de control de Active Directory creando una tarea personalizada que proporcione a un usuario acceso a la creación o eliminación de objetos del equipo con los siguientes permisos de acceso proporcionados:</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">Lectura/Escritura</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">Crear/eliminar todos los objetos secundarios</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">Todas las propiedades de lectura y escritura</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">Cambiar/restablecer contraseña</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">Al hacerlo, se agrega automáticamente una ACL de seguridad para el usuario definido a la unidad organizativa de Active Directory y se minimiza el acceso al entorno de Active Directory. Una vez delegado un usuario, ese nombre de usuario y la contraseña se pueden proporcionar como credenciales de Active Directory en esta ventana.</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">El nombre de usuario y la contraseña que se pasan al dominio de Active Directory aprovechan el cifrado Kerberos durante la consulta del objeto de cuenta de equipo y la creación para mayor seguridad.</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Detalles de conexión de Active Directory</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Detalles de conexión de Active Directory</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">La<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> Proporcione campos para que los administradores proporcionen información específica del esquema de Active Directory para la colocación de la cuenta de la máquina, como los siguientes:</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">*Tipo de conexión de Active Directory.* se utiliza para especificar si la conexión de Active Directory en una región se utiliza para volúmenes de tipo de servicio Cloud Volumes Service o CVS-Performance. Si se establece de forma incorrecta en una conexión existente, es posible que no funcione correctamente cuando se utilice o edite.</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*Dominio.* el nombre de dominio de Active Directory.</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">consideraciones</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*Sitio.* limita los servidores de Active Directory a un sitio específico para seguridad y rendimiento<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>. Esto es necesario cuando varios servidores de Active Directory abarcan regiones porque Cloud Volumes Service no admite actualmente la activación de solicitudes de autenticación de Active Directory a servidores de Active Directory en una región diferente a la instancia de Cloud Volumes Service. (Por ejemplo, el controlador de dominio de Active Directory se encuentra en una región que sólo soporta CVS-Performance pero desea un recurso compartido SMB en una instancia CVS-SW.)</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">*Servidores DNS.* servidores DNS para utilizar en búsquedas de nombre.</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Cómo se muestra Cloud Volumes Service en Active Directory</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">*Nombre NetBIOS (opcional).* Si lo desea, el nombre NetBIOS del servidor. Esto se utiliza cuando se crean cuentas de equipo nuevas mediante la conexión de Active Directory. Por ejemplo, si el nombre NetBIOS se establece en CVS-EAST, los nombres de la cuenta de la máquina serán CVS-EAST-{1234}. Consulte la sección <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*Unidad organizativa (OU).* la unidad organizativa específica para crear la cuenta de equipo. Esto resulta útil si va a delegar el control a un usuario para las cuentas de equipo a una unidad organizativa específica.</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">*Cifrado AES.* también puede activar o desactivar la casilla de verificación Activar cifrado AES para autenticación AD. Habilitar el cifrado AES para la autenticación de Active Directory proporciona seguridad adicional para la comunicación de Cloud Volumes Service a Active Directory durante las búsquedas de usuarios y grupos. Antes de habilitar esta opción, consulte con el administrador de dominio para confirmar que los controladores de dominio de Active Directory admiten la autenticación AES.</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">De forma predeterminada, la mayoría de los servidores Windows no desactivan los cifrados más débiles (COMO DES o RC4-HMAC), pero si decide deshabilitar los cifrados más débiles, confirme que la conexión a Active Directory de Cloud Volumes Service se ha configurado para habilitar AES. De lo contrario, se producen fallos de autenticación. Al habilitar el cifrado AES, no se deshabilitan las cifrados, sino que se añade compatibilidad con AES a la cuenta de equipo SMB de Cloud Volumes Service.</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Detalles del dominio de Kerberos</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">Esta opción no se aplica a los servidores SMB. En su lugar, se utiliza al configurar NFS Kerberos para el sistema Cloud Volumes Service. Cuando se rellenan estos detalles, el Reino de Kerberos de NFS se configura (similar al archivo krb5.conf en Linux) y se utiliza cuando se especifica NFS Kerberos en la creación de volúmenes de Cloud Volumes Service, ya que la conexión de Active Directory actúa como el Centro de distribución de Kerberos de NFS (KDC).</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">Actualmente no se admiten los KDC que no son de Windows para su uso con Cloud Volumes Service.</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">Región</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">Una región le permite especificar la ubicación donde reside la conexión de Active Directory. Esta región debe ser la misma región que el volumen Cloud Volumes Service.</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*Usuarios NFS locales con LDAP.* en esta sección también hay una opción para permitir usuarios NFS locales con LDAP. Esta opción debe dejarse sin seleccionar si desea ampliar la compatibilidad con la pertenencia a grupos de usuarios UNIX más allá de la limitación de 16 grupos de NFS (grupos extendidos). Sin embargo, el uso de grupos extendidos requiere un servidor LDAP configurado para identidades UNIX. Si no tiene un servidor LDAP, deje esta opción sin seleccionar. Si tiene un servidor LDAP y desea utilizar usuarios UNIX locales (como root), seleccione esta opción.</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">Usuarios de backup</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">habilitar la auditoría del acceso de ese usuario</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">Esta opción permite especificar usuarios de Windows que tienen permisos de backup en el volumen de Cloud Volumes Service. Los privilegios de backup (SeBackupPrivilege) son necesarios para que algunas aplicaciones puedan realizar backups y restaurar correctamente los datos en los volúmenes NAS. Este usuario tiene un alto nivel de acceso a los datos del volumen, por lo que debe tenerse en cuenta<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>. Una vez habilitado, los eventos de auditoría aparecen en el Visor de sucesos &gt; registros de Windows &gt; Seguridad.</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">Usuarios con privilegios de seguridad</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">Como SQL Server</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">auditar el acceso de los usuarios</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">Esta opción permite especificar usuarios de Windows que tienen permisos de modificación de seguridad en el volumen de Cloud Volumes Service. Los privilegios de seguridad (SeSecurityPrivilege) son necesarios para algunas aplicaciones <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>) para establecer correctamente los permisos durante la instalación. Este privilegio se necesita para gestionar el registro de seguridad. Aunque este privilegio no es tan potente como SeBackupPrivilege, NetApp recomienda<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> con este nivel de privilegio, si es necesario.</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">Privilegios especiales asignados al nuevo inicio de sesión</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">Para obtener más información, consulte<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>.</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service aparece en Active Directory como un objeto de cuenta de equipo normal. Las convenciones de nomenclatura son las siguientes.</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB y NFS Kerberos crean objetos de cuentas de equipo independientes.</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">NFS con LDAP habilitado crea una cuenta de máquina en Active Directory para vínculos LDAP de Kerberos.</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">Los volúmenes dobles de protocolo con LDAP comparten la cuenta de máquina CIFS/SMB para LDAP y SMB.</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">Las cuentas de máquina de CIFS/SMB utilizan una convención de nomenclatura del NOMBRE-1234 (ID de cuatro dígitos aleatorio con un guión anexado al nombre de &lt;10 caracteres) para la cuenta de la máquina. Puede definir EL NOMBRE mediante el valor de nombre NetBIOS en la conexión de Active Directory (consulte la sección “<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>”).</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos utiliza NFS-NAME-1234 como convención de nomenclatura (hasta 15 caracteres). Si se utilizan más de 15 caracteres, el nombre es NFS-TRUNCADO-NAME-1234.</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">Las instancias de CVS-Performance de NFS solo con LDAP habilitado crean una cuenta de máquina SMB para enlazar al servidor LDAP con la misma convención de nomenclatura que las instancias de CIFS/SMB.</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">Cuando se crea una cuenta de máquina SMB, los recursos compartidos admin ocultos predeterminados (consulte la sección <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) También se crean (c$, admin$, ipc$), pero esos recursos compartidos no tienen ACL asignados y son inaccesibles.</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">Los objetos de cuenta de equipo se colocan de forma predeterminada en CN=Computers, pero a puede especificar una unidad organizativa diferente cuando sea necesario. Consulte la sección “<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>” Para obtener información sobre los derechos de acceso necesarios para agregar/eliminar objetos de cuenta de máquina para Cloud Volumes Service.</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Cuando Cloud Volumes Service agrega la cuenta de la máquina SMB a Active Directory, se rellenan los siguientes campos:</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">cn (con el nombre del servidor SMB especificado)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">DNSHostName (con SMBserver.domain.com)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">MSDS-SupportedEncryptionTypes (permite DES_CBC_MD5, RC4_HMAC_MD5 si el cifrado AES no está habilitado; si el cifrado AES está habilitado, SE permite EL intercambio DE la cuenta DES_CBC_MD5, RC4_HMAC_MD5, AES128_CTS_HMAC_SHA1_96, AES256_CTS_HMAC_HMAC_96 con la cuenta SMB)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">Nombre (con el nombre del servidor SMB)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">SAMAccountName (con smbServer$)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">ServicePrincipalName (con host/smbserver.domain.com y host/smbServer SPN para Kerberos)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">Si desea deshabilitar los tipos de cifrado Kerberos más débiles (enctype) en la cuenta de la máquina, puede cambiar el valor MSDS-SupportedEncryptionTypes de la cuenta de la máquina a uno de los valores de la tabla siguiente para permitir sólo AES.</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">MSDS-SupportedEncryptionTypes de valor</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">Enctype activado</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">SÓLO AES128_CTS_HMAC_SHA1_96</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">SÓLO AES256_CTS_HMAC_SHA1_96</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96 Y AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5, RC4_HMAC, AES128_CTS_HMAC_SHA1_96 Y AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">Para habilitar el cifrado AES para cuentas de equipo SMB, haga clic en Activar cifrado AES para autenticación AD al crear la conexión de Active Directory.</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">Para habilitar el cifrado AES para Kerberos de NFS,<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>.</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">Siguiente: Otras dependencias de servicios de infraestructura NAS (KDC, LDAP, DNS).</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">Resumen y conclusión: Por qué elegir el multicloud híbrido de NetApp con VMware</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">NetApp Cloud Volumes junto con las soluciones de VMware para los principales proveedores a hiperescala ofrecen un gran potencial para las organizaciones que desean aprovechar el cloud híbrido. El resto de esta sección proporciona los casos de uso que muestran la integración de NetApp Cloud Volumes para ofrecer auténticas funcionalidades de multicloud híbrido.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">Caso de uso n.o 1: Optimización del almacenamiento</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">Cuando se realiza un ejercicio de configuración con salida RVtools, siempre es evidente que la escala de la potencia (vCPU/vmem) es paralela al almacenamiento. Muchas veces, las organizaciones se encuentran en una situación en la que el espacio de almacenamiento requiere el tamaño del clúster mucho más allá de lo que se necesita para la potencia.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">Al integrar Cloud Volumes de NetApp, las organizaciones pueden desarrollar una solución cloud basada en vSphere con un método de migración simple, sin necesidad de volver a plataformas, sin cambios de IP ni cambios de arquitectura. Asimismo, esta optimización le permite escalar el espacio de almacenamiento a la vez que mantiene el número de hosts al menor tiempo necesario en vSphere, pero sin cambios en la jerarquía de almacenamiento, la seguridad ni los archivos que se han puesto a disposición. Esto permite optimizar la puesta en marcha y reducir el TCO general entre un 35 y un 45 %. Esta integración también le permite ampliar el almacenamiento del almacenamiento de datos templados al rendimiento de producción en segundos.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">Caso de uso n.o 2: Migración al cloud</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">Las organizaciones sufren la presión de migrar aplicaciones desde los centros de datos en las instalaciones al cloud público por varios motivos: Un vencimiento del arrendamiento inminente; una directiva financiera para pasar de gastos de capital a gastos operativos (gastos operativos) o, simplemente, una obligación descendente para trasladarlo todo al cloud.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">Cuando la velocidad es crucial, solo es posible utilizar un método de migración optimizado, ya que volver a crear plataformas y refactorizar aplicaciones para adaptarse a la plataforma IaaS en particular del cloud es lenta y cara y, a menudo, lleva meses. Al combinar Cloud Volumes de NetApp con la replicación de SnapMirror con gestión eficiente del ancho de banda para el almacenamiento conectado al «guest» (incluidos RDM en combinación con las copias Snapshot coherentes con las aplicaciones y HCX, la migración específica del cloud (como Azure Migrate) o productos de terceros para replicar máquinas virtuales), esta transición es incluso más fácil que depender de mecanismos de filtros de I/o que requieren tiempo.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">Caso de uso n.o 3: Expansión del centro de datos</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">Cuando un centro de datos alcanza límites de capacidad debido a los picos de demanda estacionales o simplemente a un crecimiento orgánico constante, cambiar a VMware alojado en cloud junto con Cloud Volumes de NetApp es una solución sencilla. El aprovechamiento de Cloud Volumes de NetApp permite la creación, replicación y expansión del almacenamiento de forma muy sencilla, al proporcionar alta disponibilidad en las zonas de disponibilidad y funcionalidades de escalado dinámico. El aprovechamiento de Cloud Volumes de NetApp ayuda a minimizar la capacidad de clústeres de hosts, ya que permite superar la necesidad de ampliar clústeres.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">Caso de uso n.o 4: Recuperación ante desastres en el cloud</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">En un enfoque tradicional, si se produce un desastre, las máquinas virtuales replicadas al cloud requerirían la conversión a la propia plataforma de hipervisor de la nube antes de poder restaurarlas, no una tarea que se debe manejar durante una crisis.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">Mediante el uso de Cloud Volumes de NetApp para almacenamiento conectado al invitado con la replicación de SnapCenter y SnapMirror desde las instalaciones junto con soluciones de virtualización de cloud público, es posible diseñar un mejor método para la recuperación ante desastres que permita la recuperación de réplicas de equipos virtuales en una infraestructura VMware SDDC totalmente coherente junto con herramientas de recuperación específicas para cloud (Por ejemplo, Azure Site Recovery) o herramientas de terceros equivalentes, como Veeam. Este enfoque también le permite realizar simulacros de recuperación ante desastres y recuperar rápidamente desde el ransomware. Esto también permite escalar a producción completa para pruebas o durante un desastre añadiendo hosts bajo demanda.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">Caso de uso n.o 5: Modernización de aplicaciones</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">Una vez que las aplicaciones se encuentran en el cloud público, las organizaciones querrán aprovechar los cientos de potentes servicios de cloud para modernizarlas y ampliarlas. Con el uso de Cloud Volumes de NetApp, la modernización es un proceso sencillo, ya que los datos de aplicaciones no están bloqueados en VSAN y permite la movilidad de datos en una amplia variedad de casos de uso, incluido Kubernetes.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">Tanto si su objetivo es llegar a un cloud híbrido como en un cloud all-cloud, NetApp Cloud Volumes ofrece opciones excelentes para poner en marcha y gestionar las cargas de trabajo de las aplicaciones, junto con los servicios de archivos y protocolos de bloques, a la vez que reduce el TCO, pues permite que los requisitos de datos se cumplan sin problemas en la capa de la aplicación.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">Sea cual sea el caso de uso, elija su cloud preferido/proveedor a hiperescala junto con Cloud Volumes de NetApp para la realización rápida de las ventajas del cloud, una infraestructura consistente y operaciones en las instalaciones y en varios clouds, la portabilidad bidireccional de las cargas de trabajo, y la capacidad y el rendimiento de nivel empresarial.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">Es el mismo proceso y procedimientos que ya conocen y que se utilizan para conectar el almacenamiento. Recuerde que solo la posición de los datos ha cambiado con nuevos nombres; las herramientas y los procesos siguen siendo los mismos y Cloud Volumes de NetApp ayuda a optimizar la puesta en marcha general.</block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">Disponibilidad de región – almacén de datos NFS complementario para Google Cloud Platform (GCP)</block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por datos como ransomware. Con SnapMirror de NetApp, las cargas de trabajo de VMware en las instalaciones que utilizan el almacenamiento conectado a invitado se pueden replicar a Cloud Volumes ONTAP de NetApp que se ejecuta en Google Cloud.</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="doc">Recuperación ante desastres de aplicaciones con replicación de SnapCenter, Cloud Volumes ONTAP y Veeam</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">Autores: Suresh Thoppay, NetApp</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">La recuperación ante desastres en el cloud es un método resiliente y rentable de proteger las cargas de trabajo contra interrupciones del sitio y eventos dañados por datos como ransomware. Con SnapMirror de NetApp, las cargas de trabajo de VMware en las instalaciones que utilizan el almacenamiento conectado a invitado se pueden replicar a Cloud Volumes ONTAP de NetApp que se ejecuta en Google Cloud. Así se tratan los datos de aplicaciones; sin embargo, ¿qué ocurre con los equipos virtuales mismos? La recuperación ante desastres debería cubrir todos los componentes dependientes, incluidos equipos virtuales, VMDK, datos de aplicaciones, etc. Para ello, se puede utilizar SnapMirror y Veeam para recuperar sin problemas cargas de trabajo replicadas de las instalaciones a Cloud Volumes ONTAP a la vez que se utiliza almacenamiento VSAN para VMDK de máquinas virtuales.</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">Este documento proporciona un enfoque paso a paso para configurar y realizar la recuperación ante desastres que utiliza SnapMirror, Veeam y Google Cloud VMware Engine (GCVE) de NetApp.</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">Para la conectividad entre el entorno local y la red de Google Cloud, utilice las opciones de conectividad como interconexión dedicada o VPN en la nube. Los segmentos se deben crear en función del diseño VLAN en las instalaciones.</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">Existen múltiples opciones para conectar los centros de datos en las instalaciones a Google Cloud, lo que nos impide esbozar un flujo de trabajo específico en este documento. Consulte la documentación de Google Cloud para conocer el método de conectividad apropiado de las instalaciones a Google.</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Instale el software Veeam y empiece a replicar máquinas virtuales a la instancia de Google Cloud VMware Engine.</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">Durante un evento de desastre, rompa la relación de SnapMirror mediante Cloud Manager y active la conmutación al nodo de respaldo de máquinas virtuales con Veeam.</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">Ponga en marcha aplicaciones en línea.</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Configurar CVO en Google Cloud y replicar volúmenes a CVO</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">cvo</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">El primer paso consiste en configurar Cloud Volumes ONTAP en Google Cloud <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>) Y replicar los volúmenes deseados en Cloud Volumes ONTAP con las frecuencias y retentions de instantánea deseadas.</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">Configurar la replicación con SnapCenter</block>
  <block id="8064e6b40ef12da2c44763dcfe735ae8" category="paragraph">Para obtener una muestra de instrucciones paso a paso acerca de la configuración de SnapCenter y la replicación de los datos, consulte<block ref="68793c30d3c5e8a024de6c79bc478fe1" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">Configurar los hosts GCVE y el acceso a datos CVO</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">Dos factores importantes que se deben tener en cuenta al implementar un SDDC son el tamaño del clúster SDDC en la solución GCVE y durante cuánto tiempo mantener el SDDC en servicio. Estas dos consideraciones clave para una solución de recuperación ante desastres ayudan a reducir los costes operativos generales. SDDC puede ser de tan solo tres hosts, hasta un clúster de varios hosts en una puesta en marcha a escala completa.</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">Cloud Volumes ONTAP se puede implementar en cualquier VPC y GCVE debe tener una conexión privada a ese VPC para que la máquina virtual se conecte a los LUN de iSCSI.</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="inline-link">Poner en marcha y configurar el entorno de virtualización en Google Cloud Platform (GCP)</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">Para configurar GCVE SDDC, consulte<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>. Como requisito previo, compruebe que los equipos virtuales invitados que residen en los hosts GCVE pueden consumir datos de Cloud Volumes ONTAP una vez establecida la conectividad.</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Una vez que Cloud Volumes ONTAP y GCVE se hayan configurado correctamente, comience a configurar Veeam para automatizar la recuperación de las cargas de trabajo en las instalaciones en GCVE (máquinas virtuales con VMDK de aplicación y máquinas virtuales con almacenamiento en invitado) mediante la función Veeam Replication y aprovechando SnapMirror para las copias de los volúmenes de aplicación en Cloud Volumes ONTAP.</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Instale Veeam Components</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">Consulte la documentación de Veeam para conocer el procedimiento de instalación</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">Según el escenario de implementación, se debe poner en marcha el servidor de backup de Veeam, el repositorio de backup y el proxy de backup. En este caso de uso, no es necesario poner en marcha el almacén de objetos para Veeam y tampoco se requiere ningún repositorio de escalado horizontal.<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">Configure la replicación de VM con Veeam</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">Configure el trabajo de replicación de máquina virtual de vSphere</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">Tanto el vCenter en las instalaciones como el vCenter de GCVE deben registrarse con Veeam.<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> En el asistente Guest Processing, seleccione Desactivar el procesamiento de aplicaciones, ya que utilizará SnapCenter para los procesos de backup y recuperación con reconocimiento de aplicaciones.</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Conmutación al nodo de respaldo de Microsoft SQL Server VM</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">La replicación de Veeam permite cambiar las direcciones IP de las máquinas virtuales en el sitio de recuperación ante desastres.</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Soluciones de NetApp para Google Cloud Virtualization Engine (GCVE)</block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">Más información sobre las soluciones que NetApp ofrece a GCP.</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">Al igual que en las instalaciones, la planificación de Google Cloud VMware Engine (GCVE) es crucial para un entorno listo para la producción con éxito para la creación de equipos virtuales y la migración.</block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">Implementar y configurar GCVE</block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">Para configurar un entorno GCVE en GCP, inicie sesión en la consola de GCP y acceda al portal VMware Engine.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">Haga clic en el botón “New Private Cloud” e introduzca la configuración deseada para GCVE Private Cloud. En “ubicación”, asegúrese de poner en marcha el cloud privado en la misma región/zona donde se pone en marcha CVS/CVO, para garantizar el mejor rendimiento y la menor latencia.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">Requisitos previos:</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">Configurar el rol del IAM de administración de servicio del motor VMware</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">Habilite el acceso a la API de VMware Engine y la cuota de nodo</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">Asegúrese de que la gama CIDR no se superpone con ninguna de las subredes en las instalaciones o en la nube. El rango CIDR debe ser /27 o superior.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">Nota: La creación de clouds privados puede tardar entre 30 minutos y 2 horas.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">Una vez aprovisionado el cloud privado, configure el acceso privado al cloud privado para obtener una conexión de ruta de datos de alto rendimiento y baja latencia.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">Documentación para GCP</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">De este modo, se asegurará de que la red VPC en la que se ejecutan las instancias de Cloud Volumes ONTAP pueda comunicarse con la nube privada de GCVE. Para ello, siga la <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. Para Cloud Volume Service, establezca una conexión entre VMware Engine y Cloud Volumes Service mediante la ejecución de un par de tiempo único entre los proyectos de host de inquilinos. Siga estos pasos para obtener más información <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">Inicie sesión en vcenter con el usuario CloudOwner@gve.loc/. Para acceder a las credenciales, vaya al portal VMware Engine, vaya a Resources y seleccione la nube privada adecuada. En la sección Basic info, haga clic en el enlace View para la información de inicio de sesión de vCenter (vCenter Server, HCX Manager) o la información de inicio de sesión de NSX-T (NSX Manager).</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">En una máquina virtual Windows, abra un explorador y desplácese hasta la URL del cliente web de vCenter <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> Y utilice el nombre de usuario admin como CloudOwner@gve.locloc l y pegue la contraseña copiada. De igual modo, también es posible acceder al administrador de NSX-T mediante la URL del cliente web <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> utilice el nombre de usuario admin y pegue la contraseña copiada para crear segmentos nuevos o modificar las puertas de enlace del nivel existente.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">Para conectar desde una red local a un cloud privado con motor de VMware, aproveche la VPN de cloud o la interconexión de cloud para obtener la conectividad adecuada y asegúrese de que los puertos necesarios estén abiertos. Siga estos pasos para obtener más información <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Funcionalidades de NetApp para Google Cloud Platform GCVE</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">Descubra más información sobre las funcionalidades que NetApp aporta a Google Cloud Platform (GCP) Google Cloud Virtualization Engine (GCVE): Desde NetApp como dispositivo de almacenamiento conectado como invitado o un almacén de datos NFS complementario a la migración de flujos de trabajo, ampliando o repasando al cloud, backup/restauración y recuperación ante desastres.</block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="inline-link-macro">Configuración de GCVE en GCP</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="inline-link-macro">Opciones de almacenamiento de NetApp para GCVE</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">El almacenamiento de NetApp se puede utilizar de varias maneras, ya sea como adivinar conectado o como un almacén de datos NFS complementario, en GCP GCVE.</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">Consulte las soluciones de NetApp para Google Cloud GCVE</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">Soluciones de multicloud híbrido de NetApp para GCP/GCVE</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">Opciones de almacén de datos NFS suplementario de NetApp para GCP</block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="doc">Opciones de almacenamiento de NetApp para GCP</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCP admite almacenamiento NetApp conectado como invitado con Cloud Volumes ONTAP (CVO) o Cloud Volumes Service (CVS).</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="example-title">Implemente Cloud Volumes ONTAP en Google Cloud (hágalo usted mismo)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Los recursos compartidos y LUN de Cloud Volumes ONTAP se pueden montar a partir de equipos virtuales creados en el entorno de cloud privado GCVE. Los volúmenes también pueden montarse en el cliente Linux y en el cliente Windows y se puede acceder A LUN y LUN en clientes Linux o Windows como dispositivos de bloque cuando se monta a través de iSCSI, porque Cloud Volumes ONTAP admite los protocolos iSCSI, SMB y NFS. Los volúmenes de Cloud Volumes ONTAP se pueden configurar en unos pocos pasos sencillos.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">Para replicar volúmenes de un entorno local al cloud por motivos de recuperación ante desastres o migración, establezca la conectividad de red con Google Cloud, ya sea mediante una VPN de sitio a sitio o Cloud Interconnect. La replicación de datos de las instalaciones a Cloud Volumes ONTAP no se encuentra fuera del alcance de este documento. Para replicar datos entre sistemas Cloud Volumes ONTAP y locales, consulte <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">En la ficha lienzo de Cloud Manager, haga clic en Agregar un entorno de trabajo y, a continuación, seleccione Google Cloud Platform como la nube y el tipo de configuración del sistema. A continuación, haga clic en Siguiente.</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">Proporcione los detalles del entorno que se va a crear, incluidos el nombre del entorno y las credenciales de administración. Una vez que haya terminado, haga clic en continuar.</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">Seleccione o anule la selección de los servicios complementarios para la implementación de Cloud Volumes ONTAP, como detección de datos y cumplimiento de normativas o backup en el cloud. A continuación, haga clic en continuar.</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">SUGERENCIA: Se mostrará un mensaje emergente de verificación al desactivar los servicios de complemento. Los servicios complementarios se pueden agregar o eliminar después de la implementación de CVO, considere deseleccionarlos si no son necesarios desde el principio para evitar costes.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">Seleccione una ubicación, elija una política de firewall y seleccione la casilla de comprobación para confirmar la conectividad de red con el almacenamiento de Google Cloud.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">Seleccione la opción de licencia: Pago por uso o BYOL para usar la licencia existente. En este ejemplo, se utiliza la opción Freemium. A continuación, haga clic en continuar.</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">Seleccione entre varios paquetes preconfigurados disponibles en función del tipo de carga de trabajo que se pondrá en marcha en máquinas virtuales que se ejecuten en VMware Cloud en AWS SDDC.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">SUGERENCIA: Coloque el ratón sobre los mosaicos para obtener más información o personalice los componentes de CVO y la versión de ONTAP haciendo clic en Cambiar configuración.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">En la página Review &amp; Approve, revise y confirme las selecciones.para crear la instancia de Cloud Volumes ONTAP, haga clic en Go.</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">SUGERENCIA: Haga clic en el icono Menú (º), seleccione Avanzado para ver más opciones y seleccione Configuración CIFS.</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">La creación del volumen SMB es un proceso sencillo. En lienzo, haga doble clic en el entorno de trabajo Cloud Volumes ONTAP para crear y gestionar volúmenes y haga clic en la opción Crear volumen. Elija el tamaño adecuado y el gestor de cloud elija el agregado que lo contiene o utilice un mecanismo de asignación avanzado para colocarlo en un agregado concreto. Para esta demostración, se selecciona CIFS/SMB como protocolo.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">SUGERENCIA: Haga clic en el menú de volumen (º) para mostrar sus opciones.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">Una vez creado el volumen, utilice el comando de montaje para mostrar las instrucciones de conexión de volúmenes y, a continuación, conéctese al recurso compartido desde las máquinas virtuales en Google Cloud VMware Engine.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">Copie la siguiente ruta y utilice la opción Map Network Drive para montar el volumen en la máquina virtual que se ejecuta en el motor de VMware de Google Cloud.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">Una vez asignado, se puede acceder fácilmente y los permisos NTFS se pueden establecer en consecuencia.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="example-title">Conectar el LUN en Cloud Volumes ONTAP a un host</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Para conectar el LUN de Cloud Volumes ONTAP a un host, complete los pasos siguientes:</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">Una vez que se ha aprovisionado el volumen, seleccione el menú volumen (º) y, a continuación, haga clic en Target IQN. Para copiar el nombre completo de iSCSI (IQN), haga clic en Copy. Configurar una conexión iSCSI desde el host al LUN.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Para lograr lo mismo para el host que reside en Google Cloud VMware Engine:</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">RDP a la máquina virtual alojada en Google Cloud VMware Engine.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">El host de Windows debe tener una conexión iSCSI con cada nodo del clúster. El DSM nativo selecciona las mejores rutas que se van a utilizar.</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">Siga las instrucciones del asistente. En este ejemplo, la unidad F: Está montada.</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">En los clientes Linux, compruebe que el daemon iSCSI se esté ejecutando. Una vez aprovisionados las LUN, consulte la guía detallada sobre la configuración de iSCSI con Ubuntu como ejemplo aquí. Para verificar, ejecute lsblk cmd desde el shell.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="example-title">Montar el volumen NFS de Cloud Volumes ONTAP en el cliente Linux</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Para montar el sistema de archivos Cloud Volumes ONTAP (DIY) desde máquinas virtuales en Google Cloud VMware Engine, siga los siguientes pasos:</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">Aprovisione el volumen siguiendo los pasos que se indican a continuación</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">En la pestaña Volumes, haga clic en Create New Volume.</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">En la página Create New Volume, seleccione un tipo de volumen:</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">En la ficha volúmenes, coloque el cursor del ratón sobre el volumen, seleccione el icono de menú (º) y, a continuación, haga clic en Mount Command.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">Haga clic en Copiar.</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">Conéctese a la instancia de Linux designada.</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Abra un terminal en la instancia mediante el shell seguro (SSH) e inicie sesión con las credenciales adecuadas.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">Cree un directorio para el punto de montaje del volumen con el comando siguiente.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">Monte el volumen NFS Cloud Volumes ONTAP en el directorio que se creó en el paso anterior.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service (CVS)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud Volumes Services (CVS) es una cartera completa de servicios de datos que ofrece soluciones avanzadas de cloud. Cloud Volumes Services admite varios protocolos de acceso a archivos para los principales proveedores de cloud (compatibilidad con NFS y SMB).</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">Otras ventajas y funciones incluyen: Protección de datos y restauración con Snapshot; funciones especiales para replicar, sincronizar y migrar destinos de datos en las instalaciones o en el cloud; y alto rendimiento constante en el nivel de un sistema de almacenamiento flash dedicado.</block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="example-title">Configuración de Cloud Volumes Service con el motor de VMware</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Los recursos compartidos de Cloud Volumes Service se pueden montar a partir de máquinas virtuales que se crean en el entorno de motor de VMware. Los volúmenes también pueden montarse en el cliente Linux y asignarse en el cliente Windows, ya que Cloud Volumes Service admite los protocolos SMB y NFS. Los volúmenes de Cloud Volumes Service se pueden configurar en pasos sencillos.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service y el cloud privado Google Cloud VMware Engine deben encontrarse en la misma región.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">guía</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Para comprar, habilitar y configurar Cloud Volumes Service de NetApp para Google Cloud desde Google Cloud Marketplace, siga este detallado <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="example-title">Cree un volumen CVS NFS en el cloud privado de GCVE</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">Para crear y montar volúmenes NFS, complete los siguientes pasos:</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Acceda a Cloud Volumes desde Soluciones de partners dentro de la consola cloud de Google.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">En la consola Cloud Volumes, vaya a la página Volumes y haga clic en Create.</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">En la página Create File System, especifique el nombre del volumen y las etiquetas de facturación según sea necesario para los mecanismos de pago por uso.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">Seleccione el servicio adecuado. Para GCVE, seleccione CVS-Performance y el nivel de servicio deseado para la mejora de la latencia y el rendimiento superior en función de los requisitos de la carga de trabajo de la aplicación.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">Especifique la región de Google Cloud para el volumen y la ruta del volumen (la ruta del volumen debe ser única en todos los volúmenes de cloud del proyecto)</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">Seleccione el nivel de rendimiento del volumen.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">Especifique el tamaño del volumen y el tipo de protocolo. En esta prueba, se utiliza NFSv3.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">En este paso, seleccione la red VPC desde la que se podrá acceder al volumen. Compruebe que la agrupación de VPC esté en su lugar.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">SUGERENCIA: Si VPC peering no se ha hecho, aparecerá un botón emergente que le guiará a través de los comandos peering. Abra una sesión de Cloud Shell y ejecute los comandos adecuados para conectar el VPC con el productor de Cloud Volumes Service. Si decide previamente preparar la agrupación en VPC, consulte estas instrucciones.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">Gestione las reglas de política de exportación agregando las reglas adecuadas y seleccione la casilla de verificación para la versión NFS correspondiente.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">Nota: El acceso a los volúmenes NFS no será posible a menos que se agregue una política de exportación.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Haga clic en Guardar para crear el volumen.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="example-title">Montar exportaciones de NFS a máquinas virtuales que se ejecutan en el motor de VMware</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">Antes de preparar el montaje del volumen NFS, asegúrese de que el estado de la conexión entre iguales de la conexión privada aparezca como activo. Una vez el estado es activo, utilice el comando Mount.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">Para montar un volumen NFS, haga lo siguiente:</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">En Cloud Console, vaya a Cloud Volumes &gt; Volumes.</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Vaya a la página Volumes</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">Haga clic en el volumen NFS para el que desea montar las exportaciones NFS.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">Desplácese a la derecha, en Mostrar más, haga clic en Mount Instructions.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">Para realizar el proceso de montaje desde el SO invitado del equipo virtual de VMware, siga estos pasos:</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">Use SSH Client y SSH en la máquina virtual.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">Instale el cliente nfs en la instancia.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">En la instancia de Red Hat Enterprise Linux o SuSE Linux:</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">En una instancia de Ubuntu o Debian:</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">Cree un nuevo directorio en la instancia, como "/nimCVSNFSol01":</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">Monte el volumen con el comando correspondiente. A continuación se muestra el comando de ejemplo del laboratorio:</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="example-title">Crear y montar SMB comparte con máquinas virtuales que se ejecutan en VMware Engine</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">En el caso de los volúmenes SMB, asegúrese de que las conexiones de Active Directory estén configuradas antes de crear el volumen de SMB.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">Una vez que la conexión AD esté en su lugar, cree el volumen con el nivel de servicio deseado. Los pasos son similares a crear un volumen NFS, excepto seleccionar el protocolo adecuado.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">Seleccione el servicio adecuado. Para GCVE, seleccione CVS-Performance y el nivel de servicio deseado para la mejora de la latencia y el rendimiento superior en función de los requisitos de la carga de trabajo.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">Especifique el tamaño del volumen y el tipo de protocolo. En esta prueba, se utiliza SMB.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">instrucciones</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">SUGERENCIA: Si VPC peering no se ha hecho, aparecerá un botón emergente que le guiará a través de los comandos peering. Abra una sesión de Cloud Shell y ejecute los comandos adecuados para conectar el VPC con el productor de Cloud Volumes Service. Si decide previamente preparar la agrupación VPC, consulte las mismas <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">Para montar el volumen SMB, haga lo siguiente:</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">Haga clic en el volumen de SMB para el que desea asignar un recurso compartido de SMB.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">Para realizar el proceso de montaje desde el SO invitado Windows del equipo virtual VMware, siga los pasos que se indican a continuación:</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">Haga clic en el botón Inicio y, a continuación, haga clic en Equipo.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">Haga clic en asignar unidad de red.</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">En la lista Unidad, haga clic en cualquier letra de unidad disponible.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">En el cuadro carpeta, escriba:</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">Para conectarse cada vez que inicie sesión en el equipo, active la casilla de verificación Reconectar al iniciar sesión.</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">Haga clic en Finalizar.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">Soluciones de NetApp para VMware en proveedores a hiperescala</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">Obtenga más información acerca de las funcionalidades que NetApp aporta a los tres (3) proveedores a hiperescala principales, desde NetApp como dispositivo de almacenamiento conectado a invitado o un almacén de datos NFS complementario, para la migración de flujos de trabajo, para ampliar o bursting al cloud, backup/restauración y recuperación ante desastres.</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">Elija su cloud y deje que NetApp haga el resto.</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">Para ver las funcionalidades de un proveedor a hiperescala específico, haga clic en la pestaña adecuada para ese proveedor a hiperescala.</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">VMware en la configuración de proveedores a hiperescala</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">Opciones de almacenamiento de NetApp</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="ccb4d111a650d51ca9a8feb2542610be" category="paragraph">El almacenamiento de NetApp se puede utilizar de varias maneras, ya sea como almacenamiento de datos NFS supongo conectado o como un almacén de datos NFS complementario, en cada uno de los 3 principales proveedores a hiperescala.</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">Con las soluciones de cloud de NetApp y VMware, muchos casos de uso son fáciles de poner en marcha en el proveedor a hiperescala que elija. VMware define los casos de uso de cargas de trabajo en el cloud principal como:</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">Examine las soluciones de NetApp para AWS/VMC</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">Examine las soluciones de NetApp para Azure / AVS</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Examine las soluciones de NetApp para Google Cloud Platform (GCP)/GCVE</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Soluciones de NetApp para Amazon VMware Managed Cloud (VMC)</block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">Más información acerca de las soluciones que NetApp aporta a AWS.</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">Recuperación ante desastres con VMC en AWS (invitado conectado)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="d923ff878d26dac68fc7ac0c94a428f0" category="inline-link-macro">Recuperación ante desastres (DRO) con FSX para ONTAP y VMC</block>
  <block id="1ecab9e830a635b196a9f6c159eefe2c" category="list-text"><block ref="1ecab9e830a635b196a9f6c159eefe2c" category="inline-link-macro-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">Migrar cargas de trabajo al almacén de datos FSxN mediante VMware HCX</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938: Monte Amazon FSX para ONTAP como almacén de datos NFS con VMware Cloud en AWS</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">Todas las organizaciones exitosas se encuentran en el camino de la transformación y la modernización. Como parte de este proceso, las empresas suelen usar sus inversiones existentes en VMware para aprovechar las ventajas de la nube y explorar cómo migrar, aumentar, ampliar y ofrecer recuperación tras desastres a los procesos de la manera más fluida posible. Los clientes que migran al cloud deben evaluar los casos de uso de elasticidad y ráfaga, salida del centro de datos, consolidación del centro de datos, escenarios de fin de la vida útil, fusiones, adquisiciones, etc.</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">integración reciente</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">Aunque VMware Cloud en AWS es la opción preferida para la mayoría de los clientes, ya que ofrece funcionalidades híbridas únicas a los clientes, las opciones de almacenamiento nativo limitadas han restringido su utilidad para organizaciones con cargas de trabajo con un gran volumen de almacenamiento. Debido a que el almacenamiento está directamente ligado a los hosts, la única forma de escalar el almacenamiento es añadir más hosts, lo cual puede aumentar los costes entre un 35 % y un 40 % o más para cargas de trabajo con un uso intensivo del almacenamiento. Estas cargas de trabajo necesitan almacenamiento adicional y rendimiento segregado, no una potencia adicional, pero esto implica pagar por hosts adicionales. Aquí es donde el<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> El de FSX para ONTAP resulta muy útil para cargas de trabajo con un uso intensivo del almacenamiento y el rendimiento con VMware Cloud en AWS.</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">Consideremos el siguiente caso: Un cliente requiere ocho hosts para la potencia (vCPU/vmem), pero también tienen un requisito fundamental para el almacenamiento. Tras su evaluación, necesitan 16 hosts para satisfacer los requisitos de almacenamiento. Esto aumenta el TCO general porque deben comprar toda la capacidad adicional cuando todo lo que realmente necesitan es más almacenamiento. Esto es aplicable en cualquier caso de uso, incluidos la migración, la recuperación ante desastres, bursting, prueba/desarrollo, y así sucesivamente.</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">Este documento le guía por los pasos necesarios para aprovisionar y conectar FSX para ONTAP como almacén de datos NFS para VMware Cloud en AWS.</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">Cloud Tech Zone de VMware</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">Esta solución también está disponible en VMware. Visite la <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">Opciones de conectividad</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">En esta sección se describe la arquitectura de conectividad de alto nivel junto con los pasos necesarios para implementar la solución para ampliar el almacenamiento en un clúster SDDC sin la necesidad de añadir hosts adicionales.</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">Los pasos de puesta en marcha de alto nivel son los siguientes:</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">Cree Amazon FSX para ONTAP en un VPC designado nuevo.</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">Cree un grupo SDDC.</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">Cree VMware Transit Connect y un accesorio TGW.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">Configurar enrutamiento (AWS VPC y SDDC) y grupos de seguridad.</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">Conecte un volumen NFS como almacén de datos al clúster SDDC.</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">Introducción a VMware Cloud en AWS</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">Antes de aprovisionar y conectar FSX para ONTAP como almacén de datos NFS, primero debe configurar un entorno VMware en Cloud SDDC o obtener un SDDC existente actualizado a v1.20 o superior. Para obtener más información, consulte <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>.</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">FSX para ONTAP no es compatible actualmente con clústeres extendidos.</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">Este documento abarca los pasos necesarios para configurar Amazon FSX para ONTAP con el cloud de VMware en AWS. Amazon FSX para ONTAP proporciona opciones excelentes para poner en marcha y gestionar las cargas de trabajo de aplicaciones junto con servicios de archivos y reducir el TCO, ya que hace que los requisitos de datos sean fluido en la capa de la aplicación. Sea cual sea el caso práctico, elija VMware Cloud en AWS junto con Amazon FSX para ONTAP para obtener la rápida comprensión de las ventajas del cloud, una infraestructura consistente y operaciones desde las instalaciones a AWS, la portabilidad bidireccional de cargas de trabajo, y la capacidad y el rendimiento de clase empresarial. Es el mismo proceso y procedimientos que ya conoce y que se utilizan para conectar el almacenamiento. Recuerde que solo la posición de los datos ha cambiado con nuevos nombres, las herramientas y los procesos siguen siendo los mismos y Amazon FSX para ONTAP ayuda a optimizar la implementación general.</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">Para obtener más información sobre este proceso, puede seguir el vídeo detallado del tutorial.</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">Region Availability – almacén de datos NFS suplementario para VMC</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">Funcionalidades de NetApp para VMC de AWS</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">Obtenga más información acerca de las funcionalidades que NetApp aporta al cloud VMware Cloud (VMC) de AWS: Desde NetApp como dispositivo de almacenamiento conectado como invitado o un almacén de datos NFS complementario a la migración de flujos de trabajo, extensión o repartición al cloud, backup/restauración y recuperación ante desastres.</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="inline-link-macro">Configuración de VMC en AWS</block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="inline-link-macro">Opciones de almacenamiento de NetApp para VMC</block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">El almacenamiento de NetApp se puede utilizar de varias maneras, ya sea como almacenes de datos NFS conectados o como almacenes de datos NFS complementarios, en VMC de AWS.</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">Con las soluciones de cloud de NetApp y VMware, la puesta en marcha de muchos casos de uso es sencilla en su AWS VMC. Los casos de uso se definen para cada una de las áreas cloud definidas por VMware:</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">Consulte las soluciones de NetApp para AWS VMC</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">Opción de almacén de datos NFS complementario en AWS</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">Después de que VMware Cloud esté listo y conectado a AWS VPC, debe implementar Amazon FSX para ONTAP de NetApp en un VPC recién designado en lugar de al VPC original conectado o existente.</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">Configuración de un grupo SDDC en VMware Cloud</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">Para empezar, implemente un VPC adicional en la misma región y zona de disponibilidad donde reside SDDC y, a continuación, implemente Amazon FSX para ONTAP de NetApp en el nuevo VPC.<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> La consola permite las opciones de configuración de redes necesarias para conectarse al VPC recién designado, donde se pondrá en marcha FSX para ONTAP.</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">Implemente FSX para ONTAP en la misma zona de disponibilidad que VMware Cloud en AWS SDDC.</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">No se puede implementar FSX para ONTAP en el VPC conectado. En su lugar, debe ponerla en marcha en un VPC nuevo y luego conectar el VPC a una puerta de enlace de tránsito gestionada por VMware (vTGW) a través de grupos de SDDC.</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">Paso 1: Crear FSX de Amazon para ONTAP en un VPC nuevo y designado</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">Para crear y montar el sistema de archivos Amazon FSX para ONTAP de NetApp, lleve a cabo los siguientes pasos:</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">Abra la consola de Amazon FSX en<block ref="3cac88c5e8406527329e138d581346fe" prefix=" " category="inline-code"></block> Y seleccione *Crear sistema de archivos* para iniciar el asistente *creación de sistemas de archivos*.</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">En la página Select File System Type, seleccione *Amazon FSX para NetApp ONTAP* y, a continuación, haga clic en *Siguiente*. Aparece la página *Crear sistema de archivos*.</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">Para el método de creación, elija *creación estándar*.</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">El tamaño de los almacenes de datos puede variar bastante de un cliente a otro. Si bien la cantidad recomendada de máquinas virtuales por almacén de datos NFS es subjetiva, hay muchos factores que determinan la cantidad óptima de máquinas virtuales que pueden colocarse en cada almacén de datos. Aunque la mayoría de los administradores solo consideran la capacidad, la cantidad de I/o simultáneas que se envían a los VMDK es uno de los factores más importantes para el rendimiento general. Utilice las estadísticas de rendimiento de las instalaciones para ajustar el tamaño de los volúmenes de almacenes de datos según corresponda.</block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">En la sección *Networking* para la nube privada virtual (VPC), elija el VPC y las subredes preferidas adecuados junto con la tabla de rutas. En este caso, se selecciona Demo- FSxforONTAP-VPC en el menú desplegable.</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">Asegúrese de que se trata de un VPC nuevo y no conectado.</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">De forma predeterminada, FSX para ONTAP utiliza 198.19.0.0/16 como el intervalo de direcciones IP de punto final predeterminado para el sistema de archivos. Asegúrese de que el rango de direcciones IP del extremo no entra en conflicto con el VMC en el SDDC de AWS, las subredes VPC asociadas y la infraestructura en las instalaciones. Si no está seguro, utilice un rango que no se superpone sin conflictos.</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">En la sección *Seguridad y cifrado* de la clave de cifrado, elija la clave de cifrado del Servicio de administración de claves de AWS (AWS KMS) que protege los datos del sistema de archivos en reposo. Para la *Contraseña administrativa del sistema de archivos*, introduzca una contraseña segura para el usuario fsxadmin.</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">En la sección *Configuración de máquina virtual de almacenamiento predeterminada*, especifique el nombre de la SVM.</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">A partir de GA, se admiten cuatro almacenes de datos NFS.</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">En la sección *Configuración de volumen predeterminada*, especifique el nombre del volumen y el tamaño necesarios para el almacén de datos y haga clic en *Siguiente*. Este debe ser un volumen NFSv3. En *eficiencia del almacenamiento*, elija *activada* para activar las funciones de eficiencia del almacenamiento de ONTAP (compresión, deduplicación y compactación). Después de la creación, utilice el shell para modificar los parámetros de volumen utilizando *_volume modify_* de la siguiente manera:</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">Garantía de volumen (estilo de garantía de espacio)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">None (thin provisioning): Se establece de forma predeterminada</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">reserva_fraccionaria (reserva fraccionaria)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0% – establecido de forma predeterminada</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve (porcentaje de espacio de instantánea)</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">AutoSize (modo de ajuste automático)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Enabled: Se establece de forma predeterminada</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">Política de organización en niveles del volumen</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Solo Snapshot: Se configura de forma predeterminada</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">Use el siguiente comando SSH para crear y modificar volúmenes:</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*Comando para crear un nuevo volumen de almacén de datos desde el shell:*</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*Nota:* los volúmenes creados a través de shell tardarán unos minutos en aparecer en la consola de AWS.</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*Comando para modificar parámetros de volumen que no están establecidos por defecto:*</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">En un supuesto de migración inicial, la política de Snapshot predeterminada puede causar problemas de capacidad completa del almacén de datos. Para superarla, modifique la política de Snapshot para adaptarla a las necesidades.</block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">Revise la configuración del sistema de archivos que se muestra en la página *Crear sistema de archivos*.</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">Haga clic en *Crear sistema de archivos*.</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">Repita los pasos anteriores para crear más máquinas virtuales de almacenamiento o sistemas de archivos y volúmenes de almacenes de datos según los requisitos de capacidad y rendimiento.</block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">Para obtener más información sobre el rendimiento de Amazon FSX para ONTAP, consulte<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>.</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">Paso 2: Creación de un grupo SDDC</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">Una vez creados los sistemas de archivos y las SVM, utilice VMware Console para crear un grupo SDDC y configurar VMware Transit Connect. Para ello, complete los siguientes pasos y recuerde que debe desplazarse entre VMware Cloud Console y la consola AWS.</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">Inicie sesión en la consola VMC en<block ref="80524a1862c565bfe10233035e45c5b3" prefix=" " category="inline-code"></block>.</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">En la página *Inventario*, haga clic en *grupos SDDC*.</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">En la ficha *grupos SDDC*, haga clic en *ACCIONES* y seleccione *Crear grupo SDDC*. Para realizar demostraciones, se llama al grupo SDDC<block ref="a34cf36b08316aadda6e1c15679a89f8" prefix=" " category="inline-code"></block>.</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">En la cuadrícula Membresía, seleccione los SDDC que desea incluir como miembros del grupo.</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">Compruebe que “Configuración de VMware Transit Connect para su grupo incurrirá en cargos por archivo adjunto y transferencia de datos” y, a continuación, seleccione *Crear grupo*. El proceso puede tardar unos minutos en completarse.</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">Paso 3: Configurar VMware Transit Connect</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">Instrucciones para asociar un VPC externo al grupo</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">Conecte el VPC designado recientemente creado al grupo de SDDC. Seleccione la ficha *VPC externo* y siga la<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>. El proceso puede tardar 10-15 minutos en completarse.</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">Haga clic en *Agregar cuenta*.</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">Proporcione la cuenta de AWS que se utilizó para aprovisionar el FSX para el sistema de archivos ONTAP.</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">Haga clic en *Agregar*.</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">De nuevo en la consola de AWS, inicie sesión en la misma cuenta de AWS y desplácese a la página de servicio *Resource Access Manager*. Hay un botón para que acepte el recurso compartido.</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">Como parte del proceso VPC externo, se le pedirá a través de la consola de AWS un nuevo recurso compartido a través de Resource Access Manager. El recurso compartido es la puerta de enlace de tránsito de AWS gestionada por VMware Transit Connect.</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">Haga clic en *Aceptar recurso compartido*.</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">De nuevo en la consola de VMC, ahora ve que el VPC externo está en un estado asociado. Esto puede tardar varios minutos en aparecer.</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">Paso 4: Crear un archivo adjunto de puerta de enlace de tránsito</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">En la consola de AWS, vaya a la página de servicio VPC y desplácese hasta el VPC que se utilizó para aprovisionar el sistema de archivos FSX. Aquí puede crear un archivo adjunto de puerta de enlace de tránsito haciendo clic en *accesorio de puerta de enlace de tránsito* en el panel de navegación de la derecha.</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">En *VPC Attachment*, asegúrese de que la compatibilidad con DNS está activada y seleccione el VPC en el que se implementó FSX para ONTAP.</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">Haga clic en *Crear* *archivo adjunto de puerta de enlace de tránsito*.</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">De nuevo en VMware Cloud Console, desplácese de nuevo a SDDC Group &gt; pestaña External VPC. Seleccione el ID de cuenta de AWS utilizado para FSX, haga clic en VPC y haga clic en *Aceptar*.</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">Esta opción puede tardar varios minutos en aparecer.</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">A continuación, en la ficha *VPC externo* de la columna *rutas*, haga clic en la opción *Agregar rutas* y agregue las rutas necesarias:</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">Una ruta para el rango de IP flotante para las IP flotantes de Amazon FSX para ONTAP de NetApp.</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">Una ruta para el espacio de direcciones VPC externo recién creado.</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">Paso 5: Configurar el enrutamiento (AWS VPC y SDDC) y grupos de seguridad</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">En la consola de AWS, cree la ruta de vuelta al SDDC ubicando el VPC en la página de servicio VPC y seleccionando la tabla de rutas *main* para el VPC.</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">Vaya a la tabla de rutas en el panel inferior y haga clic en *Editar rutas*.</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">En el panel *Editar rutas*, haga clic en *Agregar ruta* e introduzca CIDR para la infraestructura SDDC seleccionando *Puerta de enlace de tránsito* y la identificación de TGL asociada. Haga clic en *Guardar cambios*.</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">El siguiente paso es verificar que el grupo de seguridad del VPC asociado se actualice con las reglas de entrada correctas para la CIDR de un grupo SDDC.</block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="list-text">Actualice la regla de entrada con el bloque CIDR de la infraestructura SDDC.</block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">Compruebe que la tabla de rutas VPC (donde reside FSX para ONTAP) se actualiza para evitar problemas de conectividad.</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">Actualice el grupo de seguridad para aceptar el tráfico NFS.</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">Este es el paso final en la preparación de la conectividad con el SDDC adecuado. Con el sistema de archivos configurado, las rutas agregadas y los grupos de seguridad actualizados, es hora de montar los almacenes de datos.</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">Paso 6: Conectar volumen NFS como almacén de datos al clúster SDDC</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">Una vez que se ha aprovisionado el sistema de archivos y se ha establecido la conectividad, acceda a VMware Cloud Console para montar el almacén de datos NFS.</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">En la consola VMC, abra la pestaña *almacenamiento* del SDDC.</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">Haga clic en *ASOCIAR ALMACÉN de DATOS* y rellene los valores necesarios.</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">La dirección del servidor NFS es la dirección IP de NFS que se puede encontrar en la pestaña FSX &gt; Storage virtual Machines &gt; Endpoints en la consola de AWS.</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">Haga clic en *ASOCIAR ALMACÉN de DATOS* para asociar el almacén de datos al clúster.</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">Valide el almacén de datos de NFS accediendo a vCenter como se muestra a continuación:</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">Opciones de almacenamiento conectado invitado de NetApp para AWS</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS admite almacenamiento de NetApp conectado como invitado con el servicio FSX nativo (FSX ONTAP) o Cloud Volumes ONTAP (CVO).</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">FSX ONTAP</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX para ONTAP de NetApp es un servicio completamente gestionado que ofrece un almacenamiento de archivos muy fiable, escalable, de alto rendimiento y con numerosas funciones integrado en el popular sistema de archivos ONTAP de NetApp. FSX para ONTAP combina las funciones, el rendimiento, las funcionalidades y las operaciones API de los sistemas de archivos de NetApp con la agilidad, la escalabilidad y la simplicidad de un servicio AWS totalmente gestionado.</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX para ONTAP proporciona un almacenamiento de archivos compartido con gran diversidad de funciones, rápido y flexible, al que se puede acceder ampliamente desde instancias informáticas de Linux, Windows y MacOS que se ejecutan en AWS o en las instalaciones. FSX para ONTAP ofrece un almacenamiento en unidades de estado sólido (SSD) de alto rendimiento con latencias inferiores a milisegundos. Con FSX para ONTAP, puede obtener niveles de SSD de rendimiento de su carga de trabajo a la vez que paga el almacenamiento SSD por una pequeña fracción de sus datos.</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">La gestión de los datos con FSX para ONTAP es más sencilla porque puede crear copias Snapshot, clonar y replicar los archivos con solo hacer clic en un botón. Además, FSX para ONTAP ordena automáticamente los datos en niveles para un almacenamiento elástico de menor coste, reduciendo así la necesidad de aprovisionar o gestionar capacidad.</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">FSX para ONTAP también proporciona un almacenamiento duradero y de alta disponibilidad con backups totalmente gestionados y soporte para la recuperación ante desastres en toda la región. Para facilitar la protección y seguridad de sus datos, FSX para ONTAP admite la seguridad de datos y aplicaciones antivirus más conocidas.</block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="example-title">Configure Amazon FSX para ONTAP de NetApp con VMware Cloud en AWS</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Se pueden montar LUN y recursos compartidos de archivos de Amazon FSX para ONTAP de NetApp a partir de máquinas virtuales creadas dentro del entorno VMware SDDC en VMware Cloud en AWS. Los volúmenes también pueden montarse en el cliente Linux y asignarse en el cliente Windows mediante el protocolo NFS o SMB, y se puede acceder A LAS LUN en clientes Linux o Windows como dispositivos de bloque cuando se montan mediante iSCSI. Amazon FSX para el sistema de archivos ONTAP de NetApp puede configurarse rápidamente con los siguientes pasos.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">Amazon FSX para ONTAP de NetApp y VMware Cloud en AWS debe estar en la misma zona de disponibilidad para conseguir un mejor rendimiento y evitar cargos por transferencia de datos entre zonas de disponibilidad.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="example-title">Cree y monte Amazon FSX para volúmenes de ONTAP</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">Para crear y montar el sistema de archivos Amazon FSX para ONTAP de NetApp, lleve a cabo los siguientes pasos:</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Consola de Amazon FSX</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">Abra el <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> Y elija Crear sistema de archivos para iniciar el asistente de creación del sistema de archivos.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">En la página Select File System Type, seleccione Amazon FSX para ONTAP de NetApp y, a continuación, seleccione Next. Aparece la página Crear sistema de archivos.</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">En la sección Networking, para la nube privada virtual (VPC), elija el VPC adecuado y las subredes preferidas junto con la tabla de rutas. En este caso, se selecciona vmcfsx2.vpc en la lista desplegable.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">Para el método de creación, seleccione creación estándar. También puede seleccionar creación rápida, pero este documento utiliza la opción creación estándar.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">En la sección Security &amp; Encryption, en la clave de cifrado, elija la clave de cifrado del servicio de gestión de claves de AWS (AWS KMS) que protege los datos del sistema de archivos en reposo. Para la contraseña administrativa del sistema de archivos, introduzca una contraseña segura para el usuario fsxadmin.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">En la máquina virtual y especifique la contraseña para su uso con vsadmin para administrar ONTAP mediante las API DE REST o la CLI. Si no se especifica ninguna contraseña, se puede utilizar un usuario fsxadmin para administrar la SVM. En la sección Active Directory, asegúrese de unirse a Active Directory a la SVM para aprovisionar los recursos compartidos de SMB. En la sección Default Storage Virtual Machine Configuration, proporcione un nombre para el almacenamiento en esta validación, los recursos compartidos de SMB se aprovisionan mediante un dominio de Active Directory autogestionado.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">En la sección Default Volume Configuration, especifique el nombre y el tamaño del volumen. Este es un volumen NFS. Para la eficiencia del almacenamiento, elija Activado para activar las funciones de eficiencia del almacenamiento de ONTAP (compresión, deduplicación y compactación) o Desactivado para desactivarlas.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Revise la configuración del sistema de archivos que se muestra en la página Crear sistema de archivos.</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">Haga clic en Crear sistema de archivos.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Introducción a Amazon FSX para ONTAP de NetApp</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">Para obtener información detallada, consulte <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">Después de crear el sistema de archivos como se ha mencionado anteriormente, cree el volumen con el tamaño y el protocolo necesarios.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">Abra el <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">En el panel de navegación de la izquierda, elija sistemas de archivos y, a continuación, elija el sistema de archivos ONTAP para el que desea crear un volumen.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Seleccione la pestaña volúmenes.</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Seleccione la pestaña Crear volumen.</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">Se muestra el cuadro de diálogo Crear volumen.</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">Por motivos de demostración, se crea un volumen NFS en esta sección que se puede montar fácilmente en máquinas virtuales que se ejecuten en el cloud de VMware en AWS. nfsdemovol01 se crea como se muestra a continuación:</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="example-title">Montaje del volumen ONTAP FSX en el cliente Linux</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">Para montar el volumen ONTAP FSX creado en el paso anterior. A partir de los equipos virtuales de Linux dentro de VMC en AWS SDDC, complete los pasos siguientes:</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Abra un terminal en la instancia mediante Secure Shell (SSH) e inicie sesión con las credenciales adecuadas.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">Cree un directorio para el punto de montaje del volumen con el comando siguiente:</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">Monte el volumen NFS de Amazon FSX para ONTAP de NetApp en el directorio creado en el paso anterior.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">Una vez ejecutado, ejecute el comando df para validar el montaje.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="example-title">Conecte volúmenes ONTAP FSX a clientes de Microsoft Windows</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Para administrar y asignar recursos compartidos de archivos en un sistema de archivos Amazon FSX, se debe utilizar la GUI de carpetas compartidas.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">Abra el menú Inicio y ejecute fsgmt.msc mediante Ejecutar como administrador. Al hacerlo, se abre la herramienta GUI de carpetas compartidas.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">Haga clic en Acción &gt; todas las tareas y elija conectar a otro equipo.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">En otro equipo, introduzca el nombre de DNS de la máquina virtual de almacenamiento (SVM). Por ejemplo, se utiliza FSXSMBTESTING01.FSXTESTING.LOCAL en este ejemplo.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP encuentra el nombre de DNS de la SVM en la consola de Amazon FSX, elige Storage Virtual Machines, selecciona SVM y, a continuación, desplácese hacia abajo hasta extremos para encontrar el nombre DNS del SMB. Haga clic en Aceptar. El sistema de archivos Amazon FSX aparece en la lista de carpetas compartidas.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">En la herramienta carpetas compartidas, seleccione recursos compartidos en el panel izquierdo para ver los recursos compartidos activos del sistema de archivos Amazon FSX.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">Ahora elija un nuevo recurso compartido y complete el asistente Crear una carpeta compartida.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">Creación de recursos compartidos de SMB</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Para obtener más información sobre la creación y gestión de recursos compartidos SMB en un sistema de archivos Amazon FSX, consulte <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">Una vez que se ha establecido la conectividad, el recurso compartido de SMB se puede conectar y utilizar para los datos de las aplicaciones. Para ello, copie la ruta de uso compartido y utilice la opción Map Network Drive para montar el volumen en el equipo virtual que se ejecuta en VMware Cloud en el centro de datos definido por software de AWS.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="example-title">Conecte un FSX para la LUN de ONTAP de NetApp a un host mediante iSCSI</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">El tráfico iSCSI para FSX atraviesa VMware Transit Connect/AWS Transit Gateway a través de las rutas proporcionadas en la sección anterior. Para configurar un LUN en Amazon FSX para ONTAP de NetApp, siga la documentación encontrada <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">En los clientes Linux, asegúrese de que el daemon iSCSI esté en ejecución. Una vez aprovisionados las LUN, consulte la guía detallada sobre la configuración de iSCSI con Ubuntu (como ejemplo) <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">En este documento, se muestra la conexión del LUN iSCSI a un host Windows:</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="example-title">Aprovisionar un LUN en FSX para ONTAP de NetApp:</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">Acceda a la CLI de ONTAP de NetApp mediante el puerto de gestión de FSX para el sistema de archivos ONTAP.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">Cree las LUN con el tamaño necesario tal y como se indica en la salida de ajuste de tamaño.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">En este ejemplo, creamos una LUN de tamaño 5g (5368709120).</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">Cree los iGroups necesarios para controlar qué hosts tienen acceso a una LUN específica.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">Se mostraron dos entradas.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">Asigne las LUN a iGroups mediante el siguiente comando:</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">Conectar la LUN recién aprovisionada a una máquina virtual Windows:</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">Para conectar el nuevo LUN tor un host de Windows que reside en el cloud de VMware en el centro de datos definido por software de AWS, complete los siguientes pasos:</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">RDP a la máquina virtual de Windows alojada en VMware Cloud en el SDDC de AWS.</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Vaya a Administrador de servidores &gt; Panel &gt; Herramientas &gt; iniciador iSCSI para abrir el cuadro de diálogo Propiedades del iniciador iSCSI.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">En la pestaña Destinos, seleccione el objetivo detectado y haga clic en Iniciar sesión o conectar.</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">Seleccione Activar acceso múltiple y, a continuación, seleccione “Restaurar automáticamente esta conexión cuando se inicie el equipo” o “Agregar esta conexión a la lista de destinos favoritos”. Haga clic en Avanzado.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Los LUN de la máquina virtual de almacenamiento (SVM) aparecen como discos en el host Windows. El host no detecta automáticamente los nuevos discos que se añaden. Active una detección repetida manual para detectar los discos realizando los pasos siguientes:</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Cuando el host Windows accede por primera vez a una nueva LUN, no tiene sistema de archivos o partición. Inicialice la LUN y, de manera opcional, formatee la LUN con un sistema de archivos realizando los pasos siguientes:</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="example-title">Implemente una nueva instancia de Cloud Volumes ONTAP en AWS (hágalo usted mismo)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Los recursos compartidos y las LUN de Cloud Volumes ONTAP se pueden montar a partir de máquinas virtuales que se crean en VMware Cloud en un entorno SDDC de AWS. Los volúmenes también se pueden montar en clientes Windows nativos de VM de AWS, y se puede acceder A LUN en clientes Linux o Windows como dispositivos de bloque cuando se monta a través de iSCSI, porque Cloud Volumes ONTAP admite los protocolos iSCSI, SMB y NFS. Los volúmenes de Cloud Volumes ONTAP se pueden configurar en unos pocos pasos sencillos.</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">Para replicar volúmenes de un entorno local al cloud por motivos de recuperación ante desastres o migración, establezca la conectividad de red a AWS mediante una VPN de sitio a sitio o DirectConnect. La replicación de datos de las instalaciones a Cloud Volumes ONTAP no se encuentra fuera del alcance de este documento. Para replicar datos entre sistemas Cloud Volumes ONTAP y locales, consulte <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">Utilice la <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Para ajustar el tamaño de las instancias de Cloud Volumes ONTAP de forma precisa. Además, supervise el rendimiento local para utilizarlo como entradas en el dimensionador de Cloud Volumes ONTAP.</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">Inicie sesión en NetApp Cloud Central; aparecerá la pantalla Fabric View. Localice la pestaña Cloud Volumes ONTAP y seleccione Go to Cloud Manager. Una vez que haya iniciado sesión, aparecerá la pantalla Canvas.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">En la página de inicio de Cloud Manager, haga clic en Add a Working Environment y, a continuación, seleccione AWS como cloud y el tipo de configuración del sistema.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">Proporcione los detalles del entorno que se va a crear, incluidos el nombre del entorno y las credenciales de administración. Haga clic en Continue.</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">Seleccione los servicios complementarios para la puesta en marcha de Cloud Volumes ONTAP, incluidos Cloud Data Sense, Cloud Backup y Cloud Insights. Haga clic en Continue.</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">En la página ha Deployment Models, elija la configuración de varias zonas de disponibilidad.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">En la página Region &amp; VPC, introduzca la información de red y, a continuación, haga clic en Continue.</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">En la página conectividad y autenticación SSH, elija los métodos de conexión para el par de alta disponibilidad y el mediador.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">Especifique las direcciones IP flotantes y, a continuación, haga clic en continuar.</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">Seleccione las tablas de rutas adecuadas para incluir rutas a las direcciones IP flotantes y, a continuación, haga clic en continuar.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">En la página Data Encryption, elija el cifrado gestionado por AWS.</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">Seleccione la opción de licencia: Pago por uso o BYOL para usar una licencia existente. En este ejemplo, se utiliza la opción de pago por uso.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">Seleccione entre varios paquetes preconfigurados disponibles en función del tipo de carga de trabajo que se va a poner en marcha en equipos virtuales que se ejecuten en el cloud de VMware en AWS SDDC.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">Seleccione la instancia de CVO para crear el volumen y haga clic en la opción Create Volume. Elija el tamaño adecuado y el gestor de cloud elija el agregado que lo contiene o utilice un mecanismo de asignación avanzado para colocarlo en un agregado concreto. En esta demostración, se ha seleccionado SMB como protocolo.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">Una vez que el volumen se ha aprovisionado, está disponible en el panel Volumes. Debido a que se aprovisiona un recurso compartido de CIFS, debe otorgar a sus usuarios o grupos permiso a los archivos y carpetas y comprobar que esos usuarios pueden acceder al recurso compartido y crear un archivo.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">Una vez creado el volumen, utilice el comando de montaje para conectarse al recurso compartido desde la máquina virtual que se ejecuta en VMware Cloud en hosts SDDC de AWS.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">Copie la siguiente ruta y utilice la opción Map Network Drive para montar el volumen en el equipo virtual que se ejecuta en VMware Cloud en el centro de datos definido por software de AWS.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Para conectar el LUN de Cloud Volumes ONTAP a un host, complete los pasos siguientes:</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">En la página lienzo de Cloud Manager, haga doble clic en el entorno de trabajo de Cloud Volumes ONTAP para crear y gestionar volúmenes.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Haga clic en Add Volume &gt; New Volume, seleccione iSCSI y haga clic en Create Initiator Group. Haga clic en Continue.</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">Para realizar lo mismo con el host que reside en VMware Cloud en SDDC de AWS, complete los pasos siguientes:</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP a la máquina virtual alojada en el cloud de VMware en AWS.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">Seleccione Activar acceso múltiple y, a continuación, seleccione Restaurar automáticamente esta conexión cuando se inicie el equipo o Agregar esta conexión a la lista de destinos favoritos. Haga clic en Avanzado.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">+<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">Los LUN de la SVM se muestran como discos al host Windows. El host no detecta automáticamente los nuevos discos que se añaden. Active una detección repetida manual para detectar los discos realizando los pasos siguientes:</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">En los clientes Linux, compruebe que el daemon iSCSI se esté ejecutando. Una vez aprovisionados los LUN, consulte una guía detallada sobre la configuración de iSCSI para su distribución de Linux. Por ejemplo, se puede encontrar la configuración de Ubuntu iSCSI <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. Para verificar, ejecute lsblk cmd desde el shell.</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">Para montar el sistema de archivos Cloud Volumes ONTAP (DIY) desde equipos virtuales en VMC en AWS SDDC, complete los siguientes pasos:</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">Soluciones de multicloud híbrido de NetApp para AWS/VMC</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">En esta solución, SnapCenter ofrece copias Snapshot coherentes con las aplicaciones para los datos de aplicaciones de SQL Server y Oracle. Esta configuración, junto con la tecnología SnapMirror, proporciona replicación de datos de alta velocidad entre nuestro AFF local y el clúster ONTAP FSX. Además, Veeam Backup &amp; Replication proporciona funcionalidades de backup y restauración para nuestras máquinas virtuales.</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="doc">Requisitos de la solución DR, requisitos previos y planificación</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">Esta solución incluye tecnologías innovadoras de NetApp, VMware, Amazon Web Services (AWS) y Veeam.</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="example-title">Base de cloud de VMware</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">La plataforma VMware Cloud Foundation integra múltiples ofertas de productos que permiten a los administradores aprovisionar infraestructuras lógicas en un entorno heterogéneo. Estas infraestructuras (conocidas como dominios) ofrecen operaciones coherentes entre clouds públicos y privados. El software Cloud Foundation incluye una lista de materiales que identifica componentes validados y validados previamente para reducir el riesgo para los clientes y facilitar la puesta en marcha.</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Entre los componentes de la lista de materiales de Cloud Foundation se incluyen los siguientes:</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Generador de cloud</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">Administrador de SDDC</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">Dispositivo VMware vCenter Server</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="list-text">NSX de VMware</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">Automatización de vRealize</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">VRealize Suite Lifecycle Manager</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">Información del registro de vRealize</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">Documentación de VMware Cloud Foundation</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">Para obtener más información acerca de VMware Cloud Foundation, consulte<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>.</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere es una plataforma de virtualización que transforma los recursos físicos en pools de recursos informáticos, de red y de almacenamiento que pueden utilizarse para satisfacer los requisitos de carga de trabajo y aplicación del cliente. Los componentes principales de VMware vSphere son los siguientes:</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">*ESXi.* este hipervisor VMware permite la abstracción de procesadores de computación, memoria, red y otros recursos y los pone a disposición de las máquinas virtuales y cargas de trabajo de contenedor.</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">* VCenter.* VMware vCenter crea una experiencia de administración central para interactuar con recursos informáticos, redes y almacenamiento como parte de la infraestructura virtual.</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">Los clientes obtienen todo el potencial de su entorno vSphere usando ONTAP de NetApp con una integración de producto profunda, un soporte robusto y potentes funciones y eficiencias del almacenamiento para crear un multicloud híbrido sólido.</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">Si quiere más información sobre VMware vSphere, siga<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>.</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">Si quiere más información sobre las soluciones de NetApp con VMware, siga<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>.</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">NSX de VMware, que normalmente se conoce como un hipervisor de red, emplea un modelo definido por software para conectar cargas de trabajo virtualizadas. VMware NSX está omnipresente en las instalaciones y en VMware Cloud en AWS, donde impulsa la virtualización y la seguridad de redes para las aplicaciones y cargas de trabajo de los clientes.</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">Si desea obtener más información sobre VMware NSX, siga<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>.</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">El software ONTAP de NetApp lleva casi dos décadas siendo una solución de almacenamiento líder para entornos VMware vSphere y sigue agregando funcionalidades innovadoras que simplifican la gestión y reducen los costes. El uso de ONTAP junto con vSphere es una excelente combinación que le permite reducir los gastos en hardware del host y software de VMware. También puede proteger sus datos con un coste menor y un alto rendimiento uniforme, al tiempo que aprovecha las eficiencias del almacenamiento nativo.</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">Si desea obtener más información sobre ONTAP de NetApp, siga estos pasos<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="example-title">Herramientas de NetApp ONTAP para VMware</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">Las herramientas de ONTAP para VMware combinan varios complementos en un único dispositivo virtual que proporciona gestión del ciclo de vida integral para máquinas virtuales en entornos VMware que usan sistemas de almacenamiento de NetApp. Las herramientas de ONTAP para VMware incluyen lo siguiente:</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">*Virtual Storage Console (VSC).* lleva a cabo tareas administrativas completas para equipos virtuales y almacenes de datos con el almacenamiento de NetApp.</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">*Proveedor VASA para ONTAP.* habilita la gestión basada en políticas de almacenamiento (SPBM) con VMware Virtual Volumes (vVols) y almacenamiento NetApp.</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">*Adaptador de replicación de almacenamiento (SRA)*. Recupera los almacenes de datos de vCenter y las máquinas virtuales en caso de fallo cuando se combinan con VMware Site Recovery Manager (SRM).</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">Las herramientas de ONTAP para VMware permiten a los usuarios gestionar no solo almacenamiento externo, sino también integrarse con vVols y Site Recovery Manager de VMware. De este modo, resulta mucho más fácil poner en marcha y utilizar el almacenamiento de NetApp desde su entorno vCenter.</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">Si quiere más información sobre las herramientas de ONTAP de NetApp para VMware, siga este<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>.</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="example-title">SnapCenter de NetApp</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">El software SnapCenter de NetApp es una plataforma empresarial fácil de usar para coordinar y administrar de un modo seguro la protección de datos en todas las aplicaciones, bases de datos y sistemas de archivos. SnapCenter simplifica las tareas de backup y restauración y la gestión del ciclo de vida de los clones al descargar estas tareas a los propietarios de las aplicaciones sin sacrificar la capacidad de supervisar y regular la actividad de los sistemas de almacenamiento. Al aprovechar la gestión de datos basada en el almacenamiento, SnapCenter aumenta el rendimiento y la disponibilidad, y reduce los tiempos de pruebas y desarrollo.</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">El plugin de SnapCenter para VMware vSphere es compatible con operaciones de backup y restauración consistentes con los fallos y las máquinas virtuales para máquinas virtuales (VM), almacenes de datos y discos de máquinas virtuales (VMDK). También es compatible con los plugins específicos de la aplicación SnapCenter a fin de proteger las operaciones de backup y restauración consistentes con las aplicaciones para bases de datos y sistemas de archivos virtualizados.</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">Si desea obtener más información sobre SnapCenter de NetApp, siga estos pasos<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>.</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">Protección de datos de terceros</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Replicación de &amp;amp; Veeam</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replication es una solución de backup, recuperación y gestión de datos para cargas de trabajo físicas, virtuales y de cloud. Veeam Backup &amp; Replication cuenta con integraciones especializadas con la tecnología Snapshot de NetApp que protegen aún más los entornos vSphere.</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Si desea obtener más información sobre Veeam Backup &amp; Replication, consulte<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>.</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="example-title">Gestión de acceso e identidad de AWS</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">Los entornos de AWS contienen una amplia variedad de productos, entre los que se incluyen los de computación, almacenamiento, bases de datos, redes y análisis. y mucho más para ayudar a resolver los retos empresariales. Las empresas deben ser capaces de definir quién está autorizado para acceder a estos productos, servicios y recursos. Es igualmente importante determinar en qué condiciones se permite a los usuarios manipular, cambiar o agregar configuraciones.</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">La gestión de acceso e identidad de AWS (AIM) proporciona un plano de control seguro para gestionar el acceso a servicios y productos de AWS. Los usuarios, claves de acceso y permisos configurados correctamente permiten la puesta en marcha de VMware Cloud en AWS y Amazon FSX.</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">Para obtener más información sobre AIM, siga<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>.</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud en AWS aporta el software SDDC empresarial de VMware al cloud de AWS con acceso optimizado a los servicios nativos de AWS. Con la tecnología de VMware Cloud Foundation, VMware Cloud en AWS integra los productos informáticos, de almacenamiento y de virtualización de redes de VMware (vSphere de VMware, VSAN de VMware y NSX de VMware) junto con la gestión de VMware vCenter Server optimizada para ejecutarse en una infraestructura de AWS dedicada, elástica y con configuración básica.</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">Si quiere más información sobre VMware Cloud en AWS, siga<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">Amazon FSX para ONTAP de NetApp es un sistema ONTAP completamente gestionado y con funciones disponibles como servicio AWS nativo. Basado en ONTAP de NetApp, ofrece funciones familiares a la vez que ofrece la simplicidad de un servicio cloud totalmente gestionado.</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">Amazon FSX para ONTAP ofrece compatibilidad multiprotocolo con varios tipos de computación, incluidos VMware en el cloud público o en las instalaciones. Disponible para casos de uso conectados a los invitados actualmente y para almacenes de datos NFS en la previsualización tecnológica, Amazon FSX para ONTAP permite a las empresas aprovechar las funciones conocidas de sus entornos locales y en el cloud.</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">Si quiere más información sobre Amazon FSX para ONTAP de NetApp, siga este<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>.</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="section-title">Descripción general: Recuperación ante desastres en el almacenamiento conectado a invitados de AWS</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">En esta sección se proporcionan instrucciones para ayudar a los usuarios a verificar, configurar y validar sus entornos cloud y en las instalaciones para usarlos con NetApp y VMware. Concretamente, esta solución se centra en el caso de uso conectado a invitados de VMware con ONTAP AFF en las instalaciones y VMware Cloud y AWS FSX ONTAP para el cloud. Esta solución se demuestra con dos aplicaciones: Oracle y MS SQL en una situación de recuperación ante desastres.</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="example-title">Habilidades y conocimientos</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Para acceder a Cloud Volumes Service para AWS se necesitan las siguientes habilidades e información:</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">El acceso a su entorno local de VMware y ONTAP y sus conocimientos.</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">Acceda a VMware Cloud y AWS y conozca.</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">Acceso a AWS y Amazon FSX ONTAP y su conocimiento.</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">Conocimiento de sus recursos SDDC y AWS.</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">Conocimiento de la conectividad de red entre sus recursos locales y en el cloud.</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">Conocimientos prácticos sobre escenarios de recuperación ante desastres.</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">Conocimientos prácticos de aplicaciones implementadas en VMware.</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="example-title">Administrativa</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">Tanto si interactuamos con los recursos en las instalaciones como en el cloud, los usuarios y los administradores deben tener la capacidad y los derechos necesarios para aprovisionar dichos recursos cuando los necesiten en función de sus derechos. La interacción de sus roles y permisos para sus sistemas locales, como ONTAP y VMware, y sus recursos cloud, incluidos VMware Cloud y AWS, es primordial para una correcta puesta en marcha de cloud híbrido.</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">Deben llevarse a cabo las siguientes tareas administrativas para crear una solución de recuperación ante desastres con VMware y ONTAP in situ y VMware Cloud en AWS y FSX ONTAP.</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">Funciones y cuentas que permiten aprovisionar los siguientes elementos:</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">Recursos de almacenamiento de ONTAP</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">Máquinas virtuales de VMware, almacenes de datos, etc.</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPC y grupos de seguridad</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">Aprovisionamiento de entornos VMware locales y ONTAP</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">Entorno de cloud de VMware</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">Un Amazon para FSX para el sistema de archivos ONTAP</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">Conectividad entre su entorno local y AWS</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">Conectividad para el VPC de AWS</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">El entorno virtual de VMware incluye las licencias de hosts ESXi, VMware vCenter Server, las redes NSX y otros componentes, como se puede ver en la siguiente figura. Todas las licencias se conceden de forma diferente, y es importante comprender cómo los componentes subyacentes consumen la capacidad disponible con licencia.</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="example-title">Hosts ESXi</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">Los hosts de computación en un entorno de VMware se ponen en marcha con ESXi. Cuando se dispone de licencia con vSphere en distintos niveles de capacidad, los equipos virtuales pueden aprovechar las CPU físicas de cada host y las funciones adecuadas.</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="example-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">La gestión del almacenamiento y los hosts ESXi es una de las muchas funcionalidades que el administrador de VMware tiene a su disposición con vCenter Server. Desde VMware vCenter 7.0, hay tres ediciones de VMware vCenter disponibles, según la licencia:</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">Aspectos básicos de vCenter Server</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">Base de vCenter Server</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">VCenter Server Standard</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">NSX de VMware proporciona a los administradores la flexibilidad necesaria para habilitar funciones avanzadas. Las funciones están habilitadas en función de la versión de NSX-T Edition con licencia:</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">Profesional</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">Avanzada</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">Oficina/Sucursal remota</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">Las licencias con ONTAP de NetApp se refieren a cómo los administradores obtienen acceso a diversas funciones y funcionalidades del almacenamiento de NetApp. Una licencia es un registro de uno o más derechos de software. La instalación de claves de licencia, también conocidas como códigos de licencia, permite utilizar ciertas funciones o servicios en el sistema de almacenamiento. Por ejemplo, ONTAP es compatible con los principales protocolos de cliente estándar del sector (NFS, SMB, FC, FCoE, iSCSI, Y NVMe/FC) mediante licencias.</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Las licencias de funciones de Data ONTAP se emiten en paquetes, cada una de las cuales contiene varias funciones o una sola función. Un paquete requiere una clave de licencia y la instalación de la clave permite acceder a todas las funciones del paquete.</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">Los tipos de licencia son los siguientes:</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*Licencia bloqueada en nodo.* al instalar una licencia bloqueada en nodo se da derecho a un nodo a la funcionalidad con licencia. Para que el clúster utilice la funcionalidad con licencia, debe tener licencia al menos un nodo para la funcionalidad.</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*Licencia principal/sitio.* Una licencia principal o de sitio no está vinculada a un número de serie específico del sistema. Cuando instala una licencia de sitio, todos los nodos del clúster podrán disfrutar de la funcionalidad con licencia.</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*Demo/licencia temporal.* una demostración o licencia temporal expira después de un cierto tiempo. Esta licencia le permite probar ciertas funcionalidades de software sin tener que adquirir derechos.</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*Licencia de capacidad (sólo ONTAP Select y FabricPool).* una instancia de ONTAP Select está autorizada según la cantidad de datos que el usuario desea administrar. A partir de ONTAP 9.4, FabricPool requiere una licencia de capacidad para usar con un nivel de almacenamiento de terceros (por ejemplo, AWS).</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter requiere varias licencias para permitir operaciones de protección de datos. El tipo de licencia de SnapCenter que instale dependerá del entorno de almacenamiento y de las funciones que desee utilizar. La licencia estándar de SnapCenter protege aplicaciones, bases de datos, sistemas de archivos y máquinas virtuales. Antes de añadir un sistema de almacenamiento a SnapCenter, debe instalar una o más licencias de SnapCenter.</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">Para habilitar la protección de aplicaciones, bases de datos, sistemas de archivos y máquinas virtuales, debe tener una licencia estándar basada en controladora en los sistemas de almacenamiento FAS o AFF, o una licencia estándar basada en capacidad instalada en las plataformas ONTAP Select y Cloud Volumes ONTAP.</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">Consulte los siguientes requisitos previos de backup de SnapCenter para esta solución:</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">Se creó un volumen y un recurso compartido de SMB en el sistema ONTAP en las instalaciones para localizar los archivos de configuración y base de datos con backup.</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">Una relación de SnapMirror entre el sistema ONTAP en las instalaciones y FSX o CVO en la cuenta de AWS. Se utiliza para transportar la instantánea que contiene la base de datos SnapCenter con backup y los archivos de configuración.</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">Windows Server instalado en la cuenta del cloud, ya sea en una instancia de EC2 o en una máquina virtual del centro de datos definido por software de VMware Cloud.</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter instalado en la instancia o máquina virtual de EC2 de Windows en VMware Cloud.</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="example-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">Como parte de la validación de esta solución, utilizamos MS SQL para demostrar la recuperación ante desastres.</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">Si quiere más información sobre prácticas recomendadas con MS SQL y ONTAP de NetApp, siga estos pasos<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>.</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="example-title">Oracle</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">Como parte de la validación de esta solución, utilizamos ORACLE para demostrar la recuperación ante desastres. Si quiere más información sobre prácticas recomendadas con ORACLE y ONTAP de NetApp, siga estos pasos<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>.</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="example-title">Veeam</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">Como parte de la validación de esta solución, utilizamos Veeam para demostrar la recuperación ante desastres. Si quiere más información sobre prácticas recomendadas con Veeam y ONTAP de NetApp, siga estos pasos<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>.</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">Debe poder realizar las siguientes tareas:</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">Poner en marcha y configurar servicios de dominio.</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">Poner en marcha ONTAP FSX por requisitos de aplicación en un VPC dado.</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">Configure VMware Cloud en la puerta de enlace de computación de AWS para permitir el tráfico de FSX ONTAP.</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">Configure un grupo de seguridad de AWS para permitir la comunicación entre VMware Cloud en subredes AWS con las subredes AWS VPC donde se pone en marcha el servicio ONTAP FSX.</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="example-title">Cloud de VMware</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">Configure VMware Cloud en SDDC de AWS.</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="example-title">Verificación de cuenta de Cloud Manager</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">Debe poder poner en marcha recursos con NetApp Cloud Manager. Para verificar que puede, lleve a cabo las siguientes tareas:</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Regístrese en Cloud Central</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> si todavía no lo ha hecho.</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Inicie sesión en Cloud Manager</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>.</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">Configure entornos de trabajo y usuarios</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>.</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">Cree un conector</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>.</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">Debe ser capaz de realizar la siguiente tarea después de tener una cuenta de AWS:</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">Crear un usuario administrativo IAM capaz de aprovisionar Amazon FSX para el sistema de archivos ONTAP de NetApp.</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="example-title">Requisitos previos de configuración</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">Dada la diversidad de topologías que tienen clientes, esta sección se centra en los puertos necesarios para permitir la comunicación de los recursos locales a los recursos cloud.</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="example-title">Consideraciones sobre el firewall y los puertos necesarios</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">En las tablas siguientes se describen los puertos que se deben habilitar en toda la infraestructura.</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Si quiere ver una lista más completa de los puertos necesarios para el software Veeam Backup &amp; Replication, siga<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>.</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">Siga esta página para obtener una lista más completa de los requisitos de los puertos para SnapCenter<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>.</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">En la siguiente tabla se enumeran los requisitos de puerto de Veeam para Microsoft Windows Server.</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">De</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">Para</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">Puerto</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">Notas</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">Servidor de backup</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Servidor Microsoft Windows</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Puerto necesario para poner en marcha los componentes de Veeam Backup &amp; Replication.</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">Proxy de backup</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">El puerto predeterminado que utiliza el servicio de instalación de Veeam.</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">Repositorio de backup</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500 a 3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">El intervalo predeterminado de puertos que se utiliza como canales de transmisión de datos y para recoger archivos de registro.</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">Monte el servidor</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Puerto predeterminado utilizado por Veeam Data mover.</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">Para cada conexión TCP que utiliza un trabajo, se asigna un puerto de este intervalo.</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">En la siguiente tabla se enumeran los requisitos de puerto de Veeam para Linux Server.</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Servidor Linux</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">Puerto que se utiliza como canal de control desde la consola al host Linux de destino.</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">En la siguiente tabla se enumeran los requisitos de puerto de Veeam Backup Server.</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS, TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">El puerto predeterminado que se utiliza para las conexiones a vCenter Server. Puerto que se utiliza como canal de control desde la consola al host Linux de destino.</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Microsoft SQL Server aloja la base de datos de configuración de Veeam Backup &amp; Replication</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Puerto utilizado para la comunicación con Microsoft SQL Server en el que se implementa la base de datos de configuración de Veeam Backup &amp; Replication (si se utiliza una instancia predeterminada de Microsoft SQL Server).</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">Servidor DNS con resolución de nombres de todos los servidores de backup</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">Puerto que se utiliza para la comunicación con el servidor DNS</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">Si utiliza vCloud Director, asegúrese de abrir el puerto 443 en instancias subyacentes de vCenter Server.</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">En la siguiente tabla, se enumeran los requisitos de puerto de Veeam Backup Proxy.</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">El puerto predeterminado que utiliza Veeam Backup VSS Integration Service para tomar una snapshot VSS durante el backup de recurso compartido de archivos SMB.</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">El puerto web de VMware predeterminado que se puede personalizar en la configuración de vCenter.</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">En la siguiente tabla se enumeran los requisitos de puerto SnapCenter.</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">Tipo de puerto</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">Puerto de gestión SnapCenter</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">Este puerto se utiliza para establecer la comunicación entre el cliente SnapCenter (el usuario de SnapCenter) y el servidor SnapCenter. También se utiliza para establecer la comunicación de los hosts del plugin con SnapCenter Server.</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">Puerto de comunicación SMCore de SnapCenter</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">Este puerto se utiliza para establecer la comunicación entre SnapCenter Server y los hosts en los que se han instalado los plugins de SnapCenter.</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Hosts de plugins de Windows, instalación</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135, 445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">Estos puertos se utilizan para establecer la comunicación entre SnapCenter Server y el host en el que se está instalando el plugin. Los puertos se pueden cerrar después de la instalación. Además, Windows Instrumentation Services busca de los puertos 49152 a 65535, los cuales deben estar abiertos.</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Hosts de plugin de Linux, instalación</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">Estos puertos se utilizan para establecer la comunicación entre SnapCenter Server y el host en el que se está instalando el plugin. Los puertos los utiliza SnapCenter para copiar archivos binarios de paquetes de plugin en los hosts de plugin de Linux.</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">Paquete de plugins de SnapCenter para Windows/Linux</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">Este puerto se utiliza para establecer la comunicación entre SMCore y los hosts en los que se han instalado los plugins de SnapCenter.</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">Puerto de VMware vSphere vCenter Server</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">Este puerto se usa para establecer la comunicación entre el plugin de SnapCenter para VMware vSphere y vCenter Server.</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">Puerto del plugin de SnapCenter para VMware vSphere</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">Este puerto se usa para establecer la comunicación entre el cliente web de vCenter vSphere y el servidor SnapCenter.</block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="paragraph">Esta solución requiere una comunicación correcta del clúster ONTAP en las instalaciones a las direcciones de red de clústeres de interconexión de ONTAP de AWS para llevar a cabo las operaciones de SyncMirror de NetApp. Además, un servidor de backup de Veeam debe tener acceso a un bloque de AWS S3. En lugar de utilizar el transporte por Internet, se puede utilizar un enlace VPN o Direct Connect existente como enlace privado a un bloque de S3.</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP admite los principales protocolos de almacenamiento utilizados para la virtualización, incluidos iSCSI, Fibre Channel (FC), Fibre Channel sobre Ethernet (FCoE) o memoria no volátil exprés sobre Fibre Channel (NVMe/FC) para entornos SAN. ONTAP también admite NFS (v3 y v4.1) y SMB o S3 para conexiones como invitado. Usted puede elegir libremente qué funciona mejor para su entorno y puede combinar los protocolos que necesite en un solo sistema. Por ejemplo, puede aumentar el uso general de almacenes de datos NFS con unos pocos LUN iSCSI o recursos compartidos invitados.</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">Esta solución utiliza almacenes de datos NFS para almacenes de datos en las instalaciones para VMDK «guest» y tanto iSCSI como NFS para los datos de aplicaciones «guest».</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="example-title">Redes cliente</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">Los puertos de red de VMkernel y las redes definidas por software proporcionan conectividad a los hosts ESXi, lo que les permite comunicarse con elementos fuera del entorno de VMware. La conectividad depende del tipo de interfaces de VMkernel utilizadas.</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">Para esta solución, se configuraron las siguientes interfaces de VMkernel:</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">Gestión</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="example-title">Redes de almacenamiento provistas</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">Una LIF (interfaz lógica) representa un punto de acceso de red a un nodo del clúster. De este modo, se permite la comunicación con las máquinas virtuales de almacenamiento que alojan los datos a los que acceden los clientes. Puede configurar las LIF en los puertos a través de los que el clúster envía y recibe comunicaciones a través de la red.</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">Para esta solución, los LIF están configurados para los siguientes protocolos de almacenamiento:</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="example-title">Opciones de conectividad de cloud</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">Los clientes tienen muchas opciones al conectar su entorno local a recursos cloud, como la puesta en marcha de topologías VPN o Direct Connect.</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="example-title">Red privada virtual (VPN)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">Las VPN (redes privadas virtuales) se utilizan a menudo para crear un túnel IPSec seguro con redes MPLS privadas o basadas en Internet. Una VPN es fácil de configurar, pero carece de fiabilidad (si está basada en Internet) y velocidad. El punto final se puede terminar en el VPC de AWS o en el SDDC de VMware Cloud. Para esta solución de recuperación ante desastres creamos una conectividad con FSX de AWS para ONTAP de NetApp desde la red local. De modo que puede terminarse en AWS VPC (Virtual Private Gateway o puerta de enlace de tránsito), en la que esté conectado FSX para ONTAP de NetApp.</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">La configuración de VPN se puede basar en rutas o en directivas. Con una configuración basada en rutas, los extremos intercambian las rutas automáticamente y la instalación aprende la ruta a las subredes recién creadas. Con una configuración basada en directivas, debe definir las subredes locales y remotas y, cuando se agregan nuevas subredes y se les permite comunicarse en el túnel IPSec, debe actualizar las rutas.</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">Si el túnel VPN IPSec no se crea en la puerta de enlace predeterminada, se deben definir las rutas de red remotas en las tablas de rutas a través del punto final del túnel VPN local.</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">En la siguiente figura se muestran las opciones de conexión VPN típicas.</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="example-title">Conexión directa</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect proporciona un enlace dedicado a la red de AWS. Las conexiones dedicadas crean enlaces a AWS mediante un puerto Ethernet de 1 Gbps, 10 Gbps o 100 Gbps. Los partners de AWS Direct Connect proporcionan conexiones alojadas mediante enlaces de red preconfigurados entre sí y AWS y están disponibles desde 50 Mbps hasta 10 Gbps. De forma predeterminada, el tráfico no está cifrado. Sin embargo, hay opciones disponibles para proteger el tráfico con MACsec o IPsec. MACsec proporciona cifrado de capa-2 mientras IPsec proporciona cifrado de capa-3. MACsec proporciona una mayor seguridad ocultando los dispositivos que se están comunicando.</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">Los clientes deben tener su equipo de enrutador en una ubicación de AWS Direct Connect. Para configurar esto, puede trabajar con la red de partners de AWS (APN). Se realiza una conexión física entre ese enrutador y el enrutador de AWS. Para habilitar el acceso a FSX para ONTAP de NetApp en VPC, debe tener una interfaz virtual privada o una interfaz virtual de tránsito de Direct Connect a un VPC. Con una interfaz virtual privada, la escalabilidad de conexión Direct Connect to VPC es limitada.</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">En la siguiente figura se muestran las opciones de la interfaz de Direct Connect.</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="example-title">Puerta de enlace de tránsito</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">Documentación de AWS Direct Connect</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">La puerta de enlace de tránsito es una estructura a nivel de región que permite una mayor escalabilidad de una conexión directa Connect-to-VPC dentro de una región. Si se requiere una conexión entre regiones, las puertas de enlace de tránsito deben tener una relación entre iguales. Si quiere más información, consulte<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>.</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="example-title">Consideraciones sobre la red de cloud</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">En el cloud, la infraestructura de red subyacente la gestiona el proveedor de servicios cloud, mientras que los clientes deben gestionar las redes VPC, subredes, tablas de rutas, etc. en AWS. También deben gestionar los segmentos de red de NSX en el perímetro de computación. SDDC agrupa las rutas para VPC externo y Transit Connect.</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">Cuando se implementa FSX para ONTAP de NetApp con disponibilidad Multi-AZ en un VPC conectado a VMware Cloud, el tráfico iSCSI recibe las actualizaciones necesarias de la tabla de rutas para permitir la comunicación. De forma predeterminada, no hay ninguna ruta disponible desde VMware Cloud a la subred FSX ONTAP NFS/SMB en el VPC conectado para la puesta en marcha de Multi-AZ. Para definir esa ruta, utilizamos el grupo VMware Cloud SDDC, que es una puerta de enlace de tránsito gestionada por VMware, para permitir la comunicación entre los SDDC de cloud de VMware en la misma región, así como con VPs externos y otras puertas de enlace de tránsito.</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">Existen costes de transferencia de datos asociados al uso de una puerta de enlace de tránsito. Para obtener información sobre los costes específicos de una región, consulte<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>.</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDC se puede poner en marcha en una única zona de disponibilidad, es decir, tener un único centro de datos. También hay disponible una opción de cluster ampliado, que es como una solución MetroCluster de NetApp, que puede proporcionar una mayor disponibilidad y menores tiempos de inactividad en caso de fallo en zonas de disponibilidad.</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">Para minimizar los costes de transferencia de datos, mantenga el centro de datos definido por software de VMware Cloud y los servicios o las instancias de AWS en la misma zona de disponibilidad. Es mejor coincidir con un ID de zona de disponibilidad en lugar de con un nombre, ya que AWS proporciona la lista de pedidos de AZ específica para la cuenta a fin de distribuir la carga entre zonas de disponibilidad. Por ejemplo, una cuenta (US-East-1a) podría indicar el ID 1 de AZ, mientras que otra cuenta (US-East-1c) podría indicar el ID 1 de AZ. El ID de zona de disponibilidad se puede recuperar de varias maneras. En el siguiente ejemplo, recuperamos el ID de AZ de la subred VPC.</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">Documentación de VMware</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">En VMware Cloud SDDC, la red se gestiona con NSX, y la puerta de enlace perimetral (enrutador de nivel 0) que gestiona el puerto de enlace ascendente de tráfico norte-sur está conectada al VPC de AWS. La puerta de enlace informática y las puertas de enlace de gestión (routers de nivel 1) gestionan el tráfico de este a oeste. Si los puertos de enlace ascendente del perímetro se utilizan mucho, puede crear grupos de tráfico para asociarlos con subredes o IP de host específicas. La creación de un grupo de tráfico crea nodos de borde adicionales para separar el tráfico. Compruebe la<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> En el número mínimo de hosts de vSphere necesarios para usar una configuración perimetral.</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">Al aprovisionar el SDDC de VMware Cloud, los puertos de VMkernel ya están configurados y listos para el consumo. VMware gestiona esos puertos y no es necesario realizar ninguna actualización.</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">En la figura siguiente se muestra un ejemplo de información de VMkernel del host.</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="example-title">Redes de almacenamiento aprovisionadas (iSCSI, NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">Para las redes de almacenamiento invitado de máquinas virtuales, normalmente se crean grupos de puertos. Con NSX, creamos segmentos que se consumen en vCenter como grupos de puertos. Dado que las redes de almacenamiento se encuentran en una subred enrutable, puede acceder a las LUN o montar las exportaciones NFS mediante el NIC predeterminado incluso sin crear segmentos de red independientes. Para separar el tráfico de almacenamiento, se pueden crear segmentos adicionales, definir reglas y controlar el tamaño de MTU en esos segmentos. Para proporcionar tolerancia a fallos, es mejor tener al menos dos segmentos dedicados a la red de almacenamiento. Como hemos mencionado anteriormente, si el ancho de banda ascendente se convierte en un problema, puede crear grupos de tráfico y asignar prefijos IP y puertas de enlace para realizar el enrutamiento basado en el origen.</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">Se recomienda emparejar los segmentos del centro de datos definido por el centro de recuperación ante desastres con el entorno de origen para evitar que se produzcan conjeturas en la asignación de segmentos de red durante la recuperación tras fallos.</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="example-title">Grupos de seguridad</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">Muchas opciones de seguridad proporcionan una comunicación segura en AWS VPC y en la red de VMware Cloud SDDC. Dentro de la red VMware Cloud SDDC, puede utilizar el flujo de seguimiento de NSX para identificar la ruta, incluidas las reglas utilizadas. A continuación, puede utilizar un analizador de red en la red VPC para identificar la ruta, incluidas las tablas de rutas, los grupos de seguridad y las listas de control de acceso a la red, que se consumen durante el flujo.</block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="paragraph">Los sistemas AFF a-Series de NetApp ofrecen una infraestructura de almacenamiento de alto rendimiento con opciones flexibles de gestión de datos habilitadas para el cloud para cumplir con un gran número de escenarios empresariales. En esta solución, utilizamos un sistema de almacenamiento A300 de ONTAP AFF como principal en las instalaciones.</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">ONTAP de NetApp y las herramientas de ONTAP para VMware y SnapCenter se han utilizado en la solución para proporcionar funcionalidades completas de gestión y backup de aplicaciones que se integran a la perfección con VMware vSphere.</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">Utilizamos almacenamiento de ONTAP para los almacenes de datos VMware que alojaban los equipos virtuales y sus archivos VMDK. VMware admite varios protocolos de almacenamiento para almacenes de datos conectados y, en esta solución, utilizamos volúmenes NFS para almacenes de datos en los hosts ESXi. Sin embargo, los sistemas de almacenamiento ONTAP son compatibles con todos los protocolos compatibles con VMware.</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">La siguiente figura muestra las opciones de almacenamiento de VMware.</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">Los volúmenes ONTAP se utilizaron para el almacenamiento conectado a invitados iSCSI y NFS para nuestros equipos virtuales de aplicaciones. Utilizamos los siguientes protocolos de almacenamiento para los datos de aplicaciones:</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">Volúmenes NFS para archivos de base de datos de Oracle conectados invitados.</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">LUN iSCSI para bases de datos y registros de transacciones de Microsoft SQL Server invitados conectados.</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">Tipo de base de datos</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">Protocolo de almacenamiento</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">Descripción del volumen</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">Archivos de base de datos</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">Archivos de registro</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Binario de Oracle</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Datos de Oracle</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Ficheros de recuperación de Oracle</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">También utilizamos almacenamiento ONTAP para el repositorio de backup de Veeam principal, así como para un objetivo de backup para los backups de la base de datos SnapCenter.</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Recurso compartido de SMB para el repositorio de backup de Veeam.</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">Recurso compartido de SMB como objetivo para los backups de la base de datos de SnapCenter.</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="example-title">Almacenamiento en cloud</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">Esta solución incluye VMware Cloud en AWS para alojar máquinas virtuales que se restauran como parte del proceso de conmutación al nodo de respaldo. A medida que se escribe esto, VMware admite almacenamiento VSAN para los almacenes de datos que alojan las máquinas virtuales y VMDK.</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">FSX para ONTAP se utiliza como almacenamiento secundario para los datos de aplicaciones duplicados mediante SnapCenter y SyncMirror. Como parte del proceso de conmutación al respaldo, el cluster FSX para ONTAP se convierte en almacenamiento principal y las aplicaciones de base de datos pueden reanudar el funcionamiento normal que se ejecuta en el cluster de almacenamiento FSX.</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="example-title">Configuración de Amazon FSX para ONTAP de NetApp</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Para poner en marcha AWS FSX para NetApp ONTAP mediante Cloud Manager, siga las instrucciones en<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>.</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">Después de poner en marcha FSX ONTAP, arrastre y suelte las instancias de ONTAP en las instalaciones en FSX ONTAP para iniciar la configuración de replicación de los volúmenes.</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">La siguiente figura muestra nuestro entorno ONTAP FSX.</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="example-title">Se han creado interfaces de red</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">FSX para ONTAP de NetApp cuenta con interfaces de red preconfiguradas y listas para su uso para redes iSCSI, NFS, SMB y entre clústeres.</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="example-title">Almacenamiento en almacenes de datos de equipos virtuales</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">VMware Cloud SDDC incluye dos almacenes de datos VSAN llamados<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> y..<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>. Nosotros usamos<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> Al equipo virtual de gestión de host con acceso restringido a las credenciales de cloudadmin. Para las cargas de trabajo, lo utilizamos<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>.</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="paragraph">VMware vSphere ofrece una infraestructura virtualizada en el centro de datos y en los principales proveedores de cloud. Este ecosistema es ideal para escenarios de recuperación ante desastres en los que los recursos informáticos virtualizados permanecen consistentes independientemente de la ubicación. Esta solución utiliza recursos informáticos virtualizados de VMware tanto en la ubicación del centro de datos como en VMware Cloud en AWS.</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">Esta solución utiliza servidores HPE ProLiant DL360 Gen 10 con VMware vSphere v7.0U3. Implementamos seis instancias informáticas para proporcionar recursos adecuados para nuestros servidores SQL y Oracle.</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">Implementamos 10 equipos virtuales Windows Server 2019 ejecutando SQL Server 2019 con diferentes tamaños de base de datos y 10 equipos virtuales Oracle Linux 8.5 que ejecutaban Oracle 19c, de nuevo, con diferentes tamaños de base de datos.</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">Implementamos un SDDC en VMware Cloud en AWS con dos hosts para proporcionar recursos adecuados para ejecutar las máquinas virtuales restauradas desde nuestro sitio principal.</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="section-title">Herramientas de backup en cloud</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="paragraph">Para llevar a cabo una conmutación al nodo de respaldo de nuestros equipos virtuales de aplicación y volúmenes de base de datos en los servicios de VMware Cloud Volume que se ejecutan en AWS, fue necesario instalar y configurar una instancia en ejecución tanto de SnapCenter Server como de Veeam Backup and Replication Server. Una vez finalizada la conmutación por error, estas herramientas también deben configurarse para reanudar las operaciones de backup normales hasta que se haya planificado y ejecutado una conmutación tras recuperación al centro de datos en las instalaciones.</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="example-title">Implementación de herramientas de backup</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">El servidor SnapCenter y el servidor Veeam Backup &amp; Replication se pueden instalar en el VMware Cloud SDDC, o se pueden instalar en instancias de EC2 que residen en un VPC con conectividad de red al entorno de VMware Cloud.</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="example-title">Servidor SnapCenter</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">Centro de documentación de NetApp</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">El software SnapCenter está disponible en el sitio de soporte de NetApp y se puede instalar en sistemas Microsoft Windows que residan en un dominio o un grupo de trabajo. Encontrará una guía de planificación detallada e instrucciones de instalación en la <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>.</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">Puede encontrar el software SnapCenter en<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Servidor de replicación de &amp;amp; Veeam Backup</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Documentación técnica del centro de ayuda de Veeam</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">Puede instalar el servidor Veeam Backup &amp; Replication en un servidor de Windows en VMware Cloud en AWS o en una instancia de EC2. Para obtener instrucciones detalladas sobre la implementación, consulte<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="example-title">Herramientas de copia de seguridad y configuración</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">Una vez instalados, SnapCenter y Veeam Backup &amp; Replication deben configurarse de modo que puedan realizar las tareas necesarias para restaurar los datos en VMware Cloud en AWS.</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="list-text">Configuración de SnapCenter</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">Para restaurar los datos de la aplicación que se han replicado en FSX ONTAP, primero debe realizar una restauración completa de la base de datos de SnapCenter local. Una vez completado este proceso, se restablece la comunicación con las máquinas virtuales y los backups de aplicaciones pueden reanudarse usando FSX ONTAP como almacenamiento primario.</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">Implemente un servidor SnapCenter secundario de Windows</block>
  <block id="520d23cd5df8582645ee42124b69ccae" category="paragraph">Para obtener una lista de los pasos que se deben completar en el servidor de SnapCenter que reside en AWS, consulte la sección <block ref="a29fcfa081b59708af69951be417dc25" category="inline-link-macro-rx"></block>.</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Configuración de replicación de &amp;amp; Veeam Backup</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Para restaurar máquinas virtuales que se han realizado backups en el almacenamiento de Amazon S3, Veeam Server debe instalarse en un servidor Windows y configurarse para comunicarse con VMware Cloud, FSX ONTAP y el bloque de S3 que contiene el repositorio de backup original. También debe tener un nuevo repositorio de backup configurado en FSX ONTAP para realizar nuevos backups de las máquinas virtuales una vez restauradas.</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">Ponga en marcha el servidor de replicación de &amp;amp; Veeam secundario</block>
  <block id="82a8a7d9b8f053ce73af1c1b5b8694ff" category="paragraph">Si quiere ver una lista completa de los pasos necesarios para completar la conmutación por error de los equipos virtuales de aplicaciones, consulte la sección <block ref="83d03cb08c05a76f36dedd6b85344746" category="inline-link-macro-rx"></block>.</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">Un entorno y un plan de recuperación ante desastres contrastados es críticos para que las organizaciones puedan garantizar que las aplicaciones críticas se restauren rápidamente en caso de interrupción grave del servicio. Esta solución se centra en la demostración de casos prácticos de recuperación ante desastres centrándose en las tecnologías de VMware y NetApp, tanto en las instalaciones como con VMware Cloud en AWS.</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931: Recuperación ante desastres con VMware Cloud en Amazon Web Services y Guest Connect</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">Autores: Chris Reno, Josh Powell y Suresh Toppay - Ingeniería de soluciones de NetApp</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp tiene un largo historial de integración con VMware, tal y como muestran las decenas de miles de clientes que han elegido a NetApp como partner de almacenamiento para su entorno virtualizado. Esta integración continúa con las opciones conectadas a invitados en el cloud y las integraciones recientes también con almacenes de datos NFS. Esta solución se centra en el caso práctico conocido como almacenamiento conectado a invitados.</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">En el almacenamiento de conexión «guest», el VMDK invitado se pone en marcha en un almacén de datos con aprovisionamiento de VMware, y los datos de aplicaciones se alojan en iSCSI o NFS y se asignan directamente al equipo virtual. Las aplicaciones Oracle y MS SQL se utilizan para demostrar una situación de recuperación ante desastres, como se muestra en la siguiente figura.</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">Supuestos, requisitos previos y descripción general de los componentes</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">Antes de poner en marcha esta solución, revise la descripción general de los componentes, los requisitos previos necesarios para poner en marcha la solución y los supuestos que se realizan al documentar esta solución.</block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">Realizar una recuperación ante desastres con SnapCenter</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">En esta sección trataremos la configuración de SnapCenter, SnapMirror y Veeam tanto para backup como para restaurar.</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">Las siguientes secciones tratan la configuración y los pasos necesarios para completar una conmutación por error en el sitio secundario:</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="section-title">Configurar las relaciones de SnapMirror y los programas de retención</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="paragraph">SnapCenter puede actualizar las relaciones de SnapMirror en el sistema de almacenamiento primario (primario &gt; reflejo) y en los sistemas de almacenamiento secundario (primario &gt; almacén) con la finalidad de archivarlas y retenerlos a largo plazo. Para ello, debe establecer e inicializar una relación de replicación de datos entre un volumen de destino y un volumen de origen mediante SnapMirror.</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">Los sistemas ONTAP de origen y de destino deben estar en redes con una relación entre iguales mediante Amazon VPC, una puerta de enlace de tránsito, AWS Direct Connect o una VPN de AWS.</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">Se requieren los siguientes pasos para configurar las relaciones de SnapMirror entre un sistema ONTAP en las instalaciones y FSX ONTAP:</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">Guía del usuario de FSX para ONTAP – ONTAP</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="admonition">Consulte la<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> Para obtener más información sobre la creación de relaciones de SnapMirror con FSX.</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="example-title">Registre las interfaces lógicas de interconexión de clústeres de origen y destino</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">Para el sistema ONTAP de origen que reside en las instalaciones, puede recuperar la información de LIF entre clústeres desde System Manager o desde la CLI.</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">En ONTAP System Manager, desplácese a la página Network Overview y recupere las direcciones IP de Type: Interclúster configurado para comunicarse con el VPC donde se instaló FSX.</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">Para recuperar las direcciones IP de interconexión de clústeres para FSX, inicie sesión en la CLI y ejecute el siguiente comando:</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="example-title">Establecer una relación entre clústeres y FSX y ONTAP</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">Para establecer una relación entre iguales de clústeres entre clústeres ONTAP, se debe confirmar una clave de acceso única introducida en el clúster de ONTAP de inicio en el otro clúster de paridad.</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">Configure peering en el clúster FSX de destino mediante el<block ref="9b5825a8b104756a9fc62c8432005be0" prefix=" " category="inline-code"></block> comando. Cuando se le solicite, introduzca una clave de acceso única que se usará más adelante en el clúster de origen para finalizar el proceso de creación.</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">En el clúster de origen, puede establecer la relación de paridad de clústeres mediante ONTAP System Manager o CLI. En ONTAP System Manager, desplácese hasta Protection &gt; Overview y seleccione Peer Cluster.</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">En el cuadro de diálogo Peer Cluster, rellene la información que corresponda:</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">Introduzca la clave de acceso que se utilizó para establecer la relación de clúster entre iguales en el clúster FSX de destino.</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">Seleccione<block ref="93cba07454f06a4a960172bbd6e2a435" prefix=" " category="inline-code"></block> para establecer una relación cifrada.</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">Introduzca las direcciones IP de la LIF entre clústeres del clúster FSX de destino.</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">Haga clic en Iniciar Cluster peering para finalizar el proceso.</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">Compruebe el estado de la relación de paridad del clúster desde el clúster FSX con el siguiente comando:</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="example-title">Establecer la relación de paridad de SVM</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">El siguiente paso consiste en configurar una relación de SVM entre las máquinas virtuales de almacenamiento de destino y origen que contengan los volúmenes que se incluirán en las relaciones de SnapMirror.</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">En el clúster FSX de origen, use el siguiente comando de la CLI para crear la relación entre iguales de SVM:</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">En el clúster de ONTAP de origen, acepte la relación de paridad con ONTAP System Manager o CLI.</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">En ONTAP System Manager, vaya a Protection &gt; Overview y seleccione Peer Storage VMs, en Storage VM peers.</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">En el cuadro de diálogo de la VM de almacenamiento del mismo nivel, rellene los campos necesarios:</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">La máquina virtual de almacenamiento de origen</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">El clúster de destino</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">La máquina virtual de almacenamiento de destino</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">Haga clic en Peer Storage VMs para completar el proceso de paridad de SVM.</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="example-title">Crear una política de retención de snapshots</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter gestiona los programas de retención para los backups que existen como copias Snapshot en el sistema de almacenamiento principal. Esto se establece al crear una política en SnapCenter. SnapCenter no gestiona las políticas de retención para backups que se conservan en sistemas de almacenamiento secundario. Estas políticas se gestionan por separado mediante una política de SnapMirror creada en el clúster FSX secundario y asociada con los volúmenes de destino que se encuentran en una relación de SnapMirror con el volumen de origen.</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">Al crear una política de SnapCenter, tiene la opción de especificar una etiqueta de política secundaria que se añada a la etiqueta de SnapMirror de cada snapshot generada al realizar un backup de SnapCenter.</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">En el almacenamiento secundario, estas etiquetas se adaptan a las reglas de normativas asociadas con el volumen de destino con el fin de aplicar la retención de copias Snapshot.</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">El siguiente ejemplo muestra una etiqueta de SnapMirror presente en todas las copias de Snapshot generadas como parte de una política utilizada para los backups diarios de nuestros volúmenes de registros y base de datos de SQL Server.</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">Documentación de SnapCenter</block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">Para obtener más información sobre la creación de políticas de SnapCenter para una base de datos de SQL Server, consulte<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">Primero debe crear una política de SnapMirror con reglas que exijan el número de copias de snapshot que se retendrán.</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">Cree la política SnapMirror en el clúster FSX.</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">Añada reglas a la política con etiquetas de SnapMirror que coincidan con las etiquetas de política secundaria especificadas en las políticas de SnapCenter.</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">El siguiente script ofrece un ejemplo de una regla que se puede agregar a una directiva:</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">Crear reglas adicionales para cada etiqueta de SnapMirror y el número de copias de Snapshot que se retendrán (período de retención).</block>
  <block id="2f061612da9689d76bf56673168e2297" category="example-title">Crear volúmenes de destino</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">Para crear un volumen de destino en FSX que será el destinatario de copias Snapshot de nuestros volúmenes de origen, ejecute el siguiente comando en FSX ONTAP:</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="example-title">Crear las relaciones de SnapMirror entre los volúmenes de origen y de destino</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">Para crear una relación de SnapMirror entre un volumen de origen y de destino, ejecute el siguiente comando en la ONTAP de FSX:</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="example-title">Inicializar las relaciones de SnapMirror</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">Inicialice la relación de SnapMirror. Este proceso inicia una snapshot nueva generada del volumen de origen y la copia al volumen de destino.</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">Para crear un volumen, ejecute el siguiente comando en FSX ONTAP:</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="section-title">Implemente y configure servidores de Windows SnapCenter localmente.</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="example-title">Ponga en marcha Windows SnapCenter Server en las instalaciones</block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="paragraph">Esta solución utiliza SnapCenter de NetApp para realizar backups coherentes con las aplicaciones de bases de datos de SQL Server y Oracle. Junto con Veeam Backup &amp; Replication para realizar backups de VMDK de máquinas virtuales, esto ofrece una completa solución de recuperación ante desastres para centros de datos en las instalaciones y basados en cloud.</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">Centro de documentación de NetApp</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">El software SnapCenter está disponible en el sitio de soporte de NetApp y se puede instalar en sistemas Microsoft Windows que residan en un dominio o un grupo de trabajo. Encontrará una guía de planificación detallada e instrucciones de instalación en la<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>.</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">El software SnapCenter puede obtenerse en<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">Una vez instalado, puede acceder a la consola SnapCenter desde un explorador Web utilizando _\https://Virtual_Cluster_IP_or_FQDN:8146_.</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">Después de iniciar sesión en la consola, debe configurar SnapCenter para las bases de datos de SQL Server y Oracle.</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="example-title">Añada controladoras de almacenamiento a SnapCenter</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">Para añadir controladoras de almacenamiento a SnapCenter, complete los siguientes pasos:</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">En el menú de la izquierda, seleccione Storage Systems y haga clic en New para comenzar el proceso de adición de controladoras de almacenamiento a SnapCenter.</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">En el cuadro de diálogo Add Storage System, añada la dirección IP de gestión para el clúster de ONTAP en las instalaciones locales, y el nombre de usuario y la contraseña. A continuación, haga clic en Submit para iniciar la detección del sistema de almacenamiento.</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">Repita este proceso para agregar el sistema FSX ONTAP a SnapCenter. En este caso, seleccione más opciones en la parte inferior de la ventana Add Storage System y haga clic en la casilla de comprobación for Secondary para designar el sistema FSX como sistema de almacenamiento secundario actualizado con copias SnapMirror o nuestras copias Snapshot de backup principales.</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">Para obtener más información relacionada con la adición de sistemas de almacenamiento a SnapCenter, consulte la documentación en<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>.</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="example-title">Añada hosts a SnapCenter</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">El siguiente paso es agregar servidores de aplicaciones host a SnapCenter. El proceso es similar tanto para SQL Server como para Oracle.</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">En el menú de la izquierda, seleccione hosts y haga clic en Añadir para comenzar el proceso de añadir controladoras de almacenamiento a SnapCenter.</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">En la ventana Add hosts, añada el tipo de host, el nombre de host y las credenciales del sistema host. Seleccione el tipo de plugin. Para SQL Server, seleccione el plugin para Microsoft Windows y Microsoft SQL Server.</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Para Oracle, rellene los campos obligatorios en el cuadro de diálogo Add Host y seleccione la casilla de comprobación del plugin de base de datos de Oracle. A continuación, haga clic en Enviar para iniciar el proceso de detección y añadir el host a SnapCenter.</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="example-title">Crear políticas de SnapCenter</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">Las políticas establecen las reglas específicas que se deben seguir para una tarea de backup. Incluyen, entre otros, la programación de backup, el tipo de replicación y cómo SnapCenter realiza el backup y los truncamiento de transacciones.</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">Puede acceder a las políticas en la sección Configuración del cliente web de SnapCenter.</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">Para obtener información completa sobre la creación de políticas para backups de SQL Server, consulte<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Para obtener toda la información sobre la creación de políticas para backups de Oracle, consulte<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>.</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">A medida que avanza por el asistente de creación de políticas, tenga una nota especial de la sección Replication. En esta sección, usted establece los tipos de copias secundarias de SnapMirror que desea realizar durante el proceso de backup.</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">La configuración "Actualizar SnapMirror después de crear una copia Snapshot local" hace referencia a la actualización de una relación de SnapMirror cuando esa relación existe entre dos máquinas virtuales de almacenamiento que residen en el mismo clúster.</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">La opción “Actualizar SnapVault después de crear una copia snapshot local” se utiliza para actualizar una relación de SnapMirror que existe entre dos clústeres independientes y entre un sistema ONTAP local y Cloud Volumes ONTAP o FSxN.</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">En la siguiente imagen, se muestran las opciones anteriores y su aspecto en el asistente de política de backup.</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="example-title">Crear grupos de recursos de SnapCenter</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">Los grupos de recursos permiten seleccionar los recursos de la base de datos que desea incluir en los backups y las políticas aplicadas a esos recursos.</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">Vaya a la sección Recursos del menú de la izquierda.</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">En la parte superior de la ventana, seleccione el tipo de recurso con el que trabajar (en este caso Microsoft SQL Server) y, a continuación, haga clic en Nuevo grupo de recursos.</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">La documentación de SnapCenter recoge detalles paso a paso para crear grupos de recursos para bases de datos de SQL Server y Oracle.</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">Para realizar backups de recursos de SQL, siga<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>.</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Para realizar backups de recursos de Oracle, siga<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>.</block>
  <block id="498fdd311192093265ba745435fc1476" category="section-title">Ponga en marcha y configure Veeam Backup Server</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Documentación técnica del centro de ayuda de Veeam</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">La solución utiliza el software Veeam Backup &amp; Replication para realizar backups de nuestros equipos virtuales de aplicaciones y archivar una copia de los backups en un bloque de Amazon S3 mediante un repositorio de backup de escalado horizontal (SOBR) de Veeam. Veeam se pone en marcha en servidores Windows como parte de esta solución. Para obtener directrices específicas sobre la puesta en marcha de Veeam, consulte<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>.</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="example-title">Configurar el repositorio de backup de escalado horizontal de Veeam</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">Después de implementar y obtener licencias del software, puede crear un repositorio de backup de escalado horizontal (SOBR) como almacenamiento de destino para tareas de backup. También debería incluir un bloque de S3 como backup de datos de máquinas virtuales fuera de sus instalaciones para la recuperación ante desastres.</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">Consulte los siguientes requisitos previos antes de comenzar.</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">Cree un recurso compartido de archivos SMB en su sistema ONTAP local como almacenamiento objetivo para backups.</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">Cree un bloque de Amazon S3 para incluirlo en el SBR. Este es un repositorio para los backups fuera de las instalaciones.</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="example-title">Añada el almacenamiento de ONTAP a Veeam</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">En primer lugar, añada el clúster de almacenamiento de ONTAP y el sistema de archivos SMB/NFS asociado como infraestructura de almacenamiento en Veeam.</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Abra la consola de Veeam e inicie sesión. Vaya a Storage Infrastructure y seleccione Add Storage.</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">En el asistente Add Storage, seleccione NetApp como proveedor de almacenamiento y, a continuación, seleccione Data ONTAP.</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">Introduzca la dirección IP de administración y active la casilla de verificación servidor dedicado a almacenamiento NAS. Haga clic en Siguiente.</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">Añada sus credenciales para acceder al clúster de ONTAP.</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">En la página NAS Filer, elija los protocolos que desea analizar y seleccione Next.</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">Complete las páginas Apply y Summary del asistente y haga clic en Finish para iniciar el proceso de detección de almacenamiento. Una vez finalizada la exploración, se añade el clúster ONTAP junto con los servidores dedicados a almacenamiento NAS como recursos disponibles.</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">Cree un repositorio de backup con los recursos compartidos NAS recién detectados. En Infraestructura de copia de seguridad, seleccione repositorios de copia de seguridad y haga clic en el elemento de menú Agregar repositorio.</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Documentación de Veeam</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">Siga todos los pasos del Asistente para crear un repositorio de copia de seguridad nuevo para crear el repositorio. Para obtener información detallada sobre la creación de repositorios de Veeam Backup, consulte<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>.</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="example-title">Añada el bloque de Amazon S3 como repositorio de backup</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">El paso siguiente es añadir el almacenamiento Amazon S3 como repositorio de backup.</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">Vaya a Backup Infrastructure &gt; repositorios de backup. Haga clic en Add Repository.</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">En el asistente Add Backup Repository, seleccione Object Storage y, a continuación, Amazon S3. Esto inicia el asistente Nuevo repositorio de almacenamiento de objetos.</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">Proporcione un nombre para el repositorio de almacenamiento de objetos y haga clic en Next.</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">En la siguiente sección, introduzca sus credenciales. Necesita una clave de acceso de AWS y una clave secreta.</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Una vez que se haya cargado la configuración de Amazon, seleccione su centro de datos, bloque y carpeta y haga clic en Apply. Por último, haga clic en Finalizar para cerrar el asistente.</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="example-title">Cree un repositorio de backup de escalado horizontal</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">Ahora que hemos añadido nuestros repositorios de almacenamiento a Veeam, podemos crear el SOBR para organizar automáticamente en niveles las copias de backup en nuestro almacenamiento de objetos Amazon S3 externo para la recuperación ante desastres.</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">En Backup Infrastructure, seleccione repositorios de escalado horizontal y, a continuación, haga clic en el elemento de menú Add Scale-Out Repository.</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">En el nuevo repositorio de copia de seguridad de escalado horizontal, proporcione un nombre para SOBR y haga clic en Siguiente.</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">Para el nivel de rendimiento, elija el repositorio de backup que contiene el recurso compartido de SMB que reside en el clúster de ONTAP local.</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">Para la Política de colocación, elija la ubicación de los datos o el rendimiento en función de sus requisitos. Seleccione Siguiente.</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">Para el nivel de capacidad, hemos ampliado el SOBR con el almacenamiento de objetos Amazon S3. Para la recuperación ante desastres, seleccione Copy backups to Object Storage tan pronto como se creen para garantizar una entrega puntual de nuestros backups secundarios.</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">Por último, seleccione aplicar y Finalizar para finalizar la creación del SORR.</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="example-title">Crear las tareas del repositorio de backup de escalado horizontal</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">El paso final para configurar Veeam es crear tareas de backup utilizando el SOBR recién creado como destino del backup. La creación de empleos de respaldo es una parte normal del repertorio de cualquier administrador de almacenamiento y no cubrimos los pasos detallados aquí. Si desea obtener más información acerca de la creación de trabajos de backup en Veeam, consulte<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="section-title">Configuración y herramientas de backup en el cloud</block>
  <block id="f201deaeba7cc565253f52d974008543" category="paragraph">Para llevar a cabo una conmutación al nodo de respaldo de los equipos virtuales de aplicación y los volúmenes de base de datos en los servicios de VMware Cloud Volume que se ejecutan en AWS, debe instalar y configurar una instancia en ejecución tanto de SnapCenter Server como de Veeam Backup and Replication Server. Una vez finalizada la conmutación al respaldo, también debe configurar estas herramientas para reanudar las operaciones de backup normales hasta que se haya planificado y ejecutado una conmutación tras recuperación al centro de datos en las instalaciones.</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="example-title">Implemente un servidor SnapCenter secundario de Windows</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">El servidor SnapCenter se pone en marcha en VMware Cloud SDDC o se instala en una instancia EC2 que reside en un VPC con conectividad de red al entorno cloud de VMware.</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">El software SnapCenter está disponible en el sitio de soporte de NetApp y se puede instalar en sistemas Microsoft Windows que residan en un dominio o un grupo de trabajo. Encontrará una guía de planificación detallada e instrucciones de instalación en la<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>.</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">Puede encontrar el software de SnapCenter en<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="example-title">Configurar servidor SnapCenter secundario de Windows</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">Para realizar una restauración de datos de aplicación reflejados en FSX ONTAP, primero debe realizar una restauración completa de la base de datos de SnapCenter local. Una vez completado este proceso, se restablece la comunicación con los equipos virtuales y los backups de aplicaciones pueden reanudarse usando FSX ONTAP como almacenamiento principal.</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">Para ello, debe completar los siguientes elementos en el servidor SnapCenter:</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">Configure el nombre del equipo para que sea idéntico al servidor SnapCenter local original.</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">Configure las redes para comunicarse con VMware Cloud y la instancia de FSX ONTAP.</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">Complete el procedimiento para restaurar la base de datos de SnapCenter.</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">Confirmar que SnapCenter se encuentra en el modo de recuperación ante desastres para garantizar que FSX es ahora el almacenamiento principal de los backups.</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">Confirmar que se restablece la comunicación con las máquinas virtuales restauradas.</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">Proceso de restauración de bases de datos de SnapCenter</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">Para obtener más información sobre cómo completar estos pasos, consulte la sección <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>.</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">Ponga en marcha el servidor de replicación de &amp;amp; de Veeam secundario</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">Puede instalar el servidor de Veeam Backup &amp; Replication en un servidor de Windows en el cloud de VMware en AWS o en una instancia de EC2. Para obtener instrucciones detalladas sobre la implementación, consulte<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">Configurar el servidor de replicación secundario de Veeam Backup &amp;amp;</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Para realizar una restauración de máquinas virtuales cuyo backup se ha realizado en el almacenamiento de Amazon S3, debe instalar Veeam Server en un servidor Windows y configurarlo para comunicarse con VMware Cloud, FSX ONTAP y el bloque de S3 que contiene el repositorio de backup original. También debe tener un nuevo repositorio de backup configurado en FSX ONTAP para realizar nuevos backups de las máquinas virtuales después de restaurarlas.</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">Para realizar este proceso, deben completarse los siguientes elementos:</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">Configurar las redes para que se comuniquen con VMware Cloud, FSX ONTAP y el bloque de S3 que contiene el repositorio de backup original.</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">Configure un recurso compartido de SMB en FSX ONTAP y así sea un nuevo repositorio de backup.</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">Monte el bloque original de S3 que se utilizó como parte del repositorio de backup de escalado horizontal en las instalaciones.</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">Después de restaurar la máquina virtual, establezca nuevas tareas de backup para proteger las máquinas virtuales de SQL y Oracle.</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">Restaure equipos virtuales de aplicación con Veeam Full Restore</block>
  <block id="5ad23c05d5054f7daf749b3a328903be" category="paragraph">Si desea obtener más información sobre la restauración de máquinas virtuales mediante Veeam, consulte la sección <block ref="145e19bb138e7c87e2d24d78a1c11e93" category="inline-link-macro-rx"></block>.</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="section-title">Backup de la base de datos de SnapCenter para recuperación ante desastres</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter permite realizar las tareas de backup y recuperación de sus datos de configuración y base de datos MySQL subyacentes con el fin de recuperar el servidor SnapCenter en caso de desastre. Para nuestra solución, recuperamos la base de datos y la configuración de SnapCenter en una instancia de EC2 de AWS que reside en nuestro VPC. Para obtener más información sobre este paso, consulte<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>.</block>
  <block id="46137d274838eaef40c110eac160dabc" category="example-title">Requisitos previos de backup de SnapCenter</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">Se requieren los siguientes requisitos previos para el backup de SnapCenter:</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">Se creó un volumen y un recurso compartido de SMB en el sistema ONTAP en las instalaciones para localizar los archivos de configuración y base de datos con backup.</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">Una relación de SnapMirror entre el sistema ONTAP en las instalaciones y FSX o CVO en la cuenta de AWS. Esta relación se utiliza para transportar la snapshot que contiene la base de datos y los archivos de configuración de SnapCenter con backup.</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="example-title">Resumen del proceso de backup y restauración de SnapCenter</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">Cree un volumen en el sistema ONTAP local para alojar la base de datos de copia de seguridad y los archivos de configuración.</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">Configuración de una relación de SnapMirror entre on-premises y FSX/CVO.</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">Monte el recurso compartido de SMB.</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">Recupere el token de autorización de Swagger para realizar tareas de API.</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">Inicie el proceso de restauración de la base de datos.</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">Utilice la utilidad xcopy para copiar el directorio local de la base de datos y el archivo de configuración en el recurso compartido SMB.</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">En FSX, cree un clon del volumen ONTAP (copiado mediante SnapMirror desde las instalaciones).</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">Monte el recurso compartido de SMB de FSX a EC2/VMware Cloud.</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">Copie el directorio de restauración del recurso compartido SMB en un directorio local.</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">Ejecute el proceso de restauración de SQL Server desde Swagger.</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="example-title">Realice un backup de la base de datos de SnapCenter y la configuración</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter proporciona una interfaz de cliente web para ejecutar comandos de la API DE REST. Para obtener información sobre cómo acceder a las API DE REST a través de Swagger, consulte la documentación de SnapCenter en<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>.</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="example-title">Inicie sesión en Swagger y obtenga el token de autorización</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Después de navegar por la página de Swagger, debe recuperar un token de autorización para iniciar el proceso de restauración de base de datos.</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">Acceda a la página web de API de SnapCenter Swagger en _\https://&lt;SnapCenter Server IP&gt;:8146/swagger/_.</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">Expanda la sección Auth y haga clic en Inténtelo.</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">En el área UserOperationContext, rellene las credenciales y la función de SnapCenter y haga clic en Ejecutar.</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">En el cuerpo de respuesta que aparece a continuación, puede ver el token. Copie el texto del token para la autenticación al ejecutar el proceso de backup.</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="example-title">Realizar un backup de base de datos de SnapCenter</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">A continuación, vaya al área de recuperación ante desastres de la página Swagger para iniciar el proceso de backup de SnapCenter.</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">Expanda el área de recuperación ante desastres haciendo clic en ella.</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">Expanda el<block ref="ff68c70c197c21bcd2eda286f1ff14b6" prefix=" " category="inline-code"></block> Y haga clic en probar.</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">En la sección SmDRBackupRequest, añada la ruta de acceso correcta al destino local y seleccione Execute para iniciar el backup de la base de datos y la configuración de SnapCenter.</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">El proceso de backup no permite realizar el backup directamente en un recurso compartido de archivos NFS o CIFS.</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="example-title">Supervise el trabajo de backup desde SnapCenter</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">Inicie sesión en SnapCenter para revisar los archivos de registro al iniciar el proceso de restauración de la base de datos. En la sección Supervisión, puede ver los detalles del backup de recuperación ante desastres del servidor SnapCenter.</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="example-title">Utilice la utilidad XCOPY para copiar el archivo de copia de seguridad de la base de datos en el recurso compartido SMB</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">A continuación, debe mover el backup de la unidad local del servidor SnapCenter al recurso compartido CIFS que se utiliza para copiar los datos en la ubicación secundaria ubicada en la instancia de FSX en AWS. Utilice xcopy con opciones específicas que conserven los permisos de los archivos.</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">Abra un símbolo del sistema como Administrador. Desde el símbolo del sistema, introduzca los siguientes comandos:</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Conmutación al respaldo</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="example-title">Desastre ocurre en el sitio principal</block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="paragraph">Para un desastre que se produzca en el centro de datos principal en las instalaciones, nuestro escenario incluye la conmutación al respaldo en un sitio secundario que reside en la infraestructura de Amazon Web Services mediante VMware Cloud en AWS. Asumimos que ya no se puede acceder a las máquinas virtuales y al clúster ONTAP que ofrecemos en las instalaciones. Además, ya no se puede acceder a las máquinas virtuales SnapCenter y Veeam y deben reconstruirse en nuestro sitio secundario.</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">En esta sección se aborda la conmutación por error de nuestra infraestructura al cloud y se tratan los siguientes temas:</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">Restauración de la base de datos de SnapCenter. Una vez establecido un nuevo servidor SnapCenter, restaure los archivos de configuración y de base de datos de MySQL y coloque la base de datos en modo de recuperación ante desastres para permitir que el almacenamiento FSX secundario se convierta en el dispositivo de almacenamiento primario.</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Restaure los equipos virtuales de aplicaciones mediante Veeam Backup &amp; Replication. Conecte el almacenamiento S3 que contiene los backups de la máquina virtual, importe los backups y restáutelos en VMware Cloud en AWS.</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">Restaure los datos de aplicaciones de SQL Server mediante SnapCenter.</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">Restaure los datos de la aplicación Oracle mediante SnapCenter.</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="example-title">Proceso de restauración de bases de datos de SnapCenter</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter admite escenarios de recuperación ante desastres, ya que permite el backup y la restauración de sus archivos de configuración y base de datos de MySQL. Esto permite a un administrador mantener backups periódicos de la base de datos de SnapCenter en el centro de datos local y restaurar posteriormente esa base de datos a una base de datos de SnapCenter secundaria.</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">Para acceder a los archivos de copia de seguridad de SnapCenter en el servidor SnapCenter remoto, siga estos pasos:</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">Rompa la relación de SnapMirror del clúster FSX y haga que el volumen sea de lectura/escritura.</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">Cree un servidor CIFS (si es necesario) y cree un recurso compartido CIFS que señale la ruta de unión del volumen clonado.</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">Utilice xcopy para copiar los archivos de copia de seguridad en un directorio local del sistema SnapCenter secundario.</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">Instale SnapCenter v4.6.</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">Asegúrese de que el servidor SnapCenter tiene el mismo FQDN que el servidor original. Esto es necesario para que la restauración de la base de datos se realice correctamente.</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">Para iniciar el proceso de restauración, lleve a cabo los siguientes pasos:</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">Acceda a la página web de API de Swagger para el servidor SnapCenter secundario y siga las instrucciones anteriores para obtener un token de autorización.</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Desplácese hasta la sección Disaster Recovery de la página Swagger, seleccione<block ref="533e3565b4ab97ee497d4500afcfa0ca" prefix=" " category="inline-code"></block>Y haga clic en probar.</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">Pegue el token de autorización y, en la sección SmDRResterRequest, pegue el nombre del backup y el directorio local del servidor SnapCenter secundario.</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">Seleccione el botón Ejecutar para iniciar el proceso de restauración.</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">En SnapCenter, desplácese hasta la sección Supervisión para ver el progreso del trabajo de restauración.</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">Para habilitar las restauraciones de SQL Server a partir de almacenamiento secundario, es necesario cambiar la base de datos de SnapCenter al modo de recuperación ante desastres. Esto se realiza como una operación independiente y se inicia en la página web de la API de Swagger.</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">Desplácese hasta la sección Disaster Recovery y haga clic en<block ref="6f4ce9a3fde10d5d540991396641c75c" prefix=" " category="inline-code"></block>.</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">Pegar en el token de autorización de usuario.</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">En la sección SmSetDisasterRecoverySettingsRequest, cambie<block ref="b7332a241d968e08b968a292c8d519aa" prefix=" " category="inline-code"></block> para<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>.</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">Haga clic en Execute para habilitar el modo de recuperación ante desastres para SQL Server.</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">Consulte los comentarios sobre procedimientos adicionales.</block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="section-title">Restaure equipos virtuales de aplicación con la restauración completa de Veeam</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="example-title">Cree un repositorio de backup e importe los backups desde S3</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">Desde el servidor de Veeam secundario, importe los backups desde el almacenamiento S3 y restaure las máquinas virtuales de SQL Server y Oracle al clúster de VMware Cloud.</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">Para importar los backups del objeto S3 que formaba parte del repositorio de backup de escalado horizontal en las instalaciones, complete los siguientes pasos:</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">Vaya a repositorios de copia de seguridad y haga clic en Añadir repositorio en el menú superior para abrir el asistente Añadir repositorio de copia de seguridad. En la primera página del asistente, seleccione Object Storage como el tipo de repositorio de backup.</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">Seleccione Amazon S3 como tipo de almacenamiento de objetos.</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">En la lista de Amazon Cloud Storage Services, seleccione Amazon S3.</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">Seleccione las credenciales introducidas previamente en la lista desplegable o añada una nueva credencial para acceder al recurso de almacenamiento en cloud. Haga clic en Siguiente para continuar.</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">En la página Bucket, introduzca el centro de datos, el bloque, la carpeta y las opciones que desee. Haga clic en Apply.</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">Finalmente, seleccione Finalizar para completar el proceso y agregar el repositorio.</block>
  <block id="076951b7756435f95654310ef960f866" category="example-title">Importe los backups desde el almacenamiento de objetos S3</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">Para importar los backups desde el repositorio de S3 que se agregó en la sección anterior, complete los siguientes pasos.</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">En el repositorio de backup de S3, seleccione Import backups para abrir el asistente Import backups.</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">Una vez creados los registros de la base de datos para la importación, seleccione Siguiente y, a continuación, Finalizar en la pantalla de resumen para iniciar el proceso de importación.</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">Una vez finalizada la importación, puede restaurar máquinas virtuales en el clúster de cloud de VMware.</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="example-title">Restaure equipos virtuales de aplicación con la funcionalidad de restauración completa de Veeam en VMware Cloud</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">Para restaurar las máquinas virtuales de SQL y Oracle en VMware Cloud en el dominio/clúster de carga de trabajo de AWS, realice los siguientes pasos.</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">En la página Veeam Home, seleccione el almacenamiento de objetos que contiene los backups importados, seleccione las máquinas virtuales que desea restaurar y, a continuación, haga clic con el botón derecho en Restore entire VM.</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">En la primera página del asistente Full VM Restore, modifique las máquinas virtuales para realizar el backup si lo desea y seleccione Next.</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">En la página Restore Mode, seleccione Restore to a New Location o with Disfruta de una configuración diferente.</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">En la página host, seleccione el host o el clúster de destino ESXi al que desea restaurar la máquina virtual.</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">En la página datastores, seleccione la ubicación del almacén de datos de destino para los archivos de configuración y el disco duro.</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">En la página Network, asigne las redes originales en el equipo virtual a las redes en la nueva ubicación de destino.</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">Seleccione si desea analizar el malware en el equipo virtual restaurado, revise la página de resumen y haga clic en Finish para iniciar la restauración.</block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="section-title">Restauración de datos de aplicaciones de SQL Server</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">El siguiente proceso proporciona instrucciones sobre cómo recuperar un servidor SQL Server en VMware Cloud Services en AWS en caso de un desastre que haga que el sitio local deje de funcionar.</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">Se asume que los siguientes requisitos previos están completos para continuar con los pasos de recuperación:</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">La máquina virtual de Windows Server se ha restaurado en el cloud SDDC de VMware mediante Veeam Full Restore.</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">Resumen del proceso de backup y restauración de SnapCenter.</block>
  <block id="fe51b70218e2191f0338d4bcb01eb4a7" category="list-text">Se ha establecido un servidor SnapCenter secundario y se ha completado la restauración y configuración de bases de datos SnapCenter siguiendo los pasos descritos en la sección <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="example-title">VM: Configuración posterior a la restauración para máquina virtual de SQL Server</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">Una vez finalizada la restauración de la máquina virtual, debe configurar la red y otros elementos durante la preparación para volver a detectar la máquina virtual host en SnapCenter.</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">Asigne nuevas direcciones IP para Management e iSCSI o NFS.</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">Una el host al dominio de Windows.</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">Añada los nombres de host a DNS o al archivo hosts del servidor SnapCenter.</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">Si el plugin de SnapCenter se implementó mediante credenciales de dominio diferentes al dominio actual, es necesario cambiar la cuenta de inicio de sesión del plugin para el servicio de Windows en la máquina virtual de SQL Server. Después de cambiar la cuenta de inicio de sesión, reinicie los servicios de SnapCenter SMCore, del plugin para Windows y del plugin para SQL Server.</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">Para volver a detectar automáticamente las máquinas virtuales restauradas en SnapCenter, el FQDN debe ser idéntico a la máquina virtual que se añadió originalmente a SnapCenter en las instalaciones.</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="example-title">Configurar almacenamiento FSX para la restauración de SQL Server</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">Para realizar el proceso de restauración de recuperación ante desastres de una máquina virtual de SQL Server, debe interrumpir la relación de SnapMirror existente del clúster FSX y otorgar acceso al volumen. Para ello, lleve a cabo los siguientes pasos.</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">Para romper la relación de SnapMirror existente de la base de datos de SQL Server y los volúmenes de registro, ejecute el siguiente comando desde la CLI de FSX:</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">Conceda acceso a la LUN mediante la creación de un grupo de iniciadores que contenga el IQN de iSCSI de la máquina virtual de SQL Server Windows:</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">Finalmente, asigne las LUN al iGroup que acaba de crear:</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">Para encontrar el nombre de ruta, ejecute el<block ref="b8fdaa53ba08988f3b422c1226f85a2a" prefix=" " category="inline-code"></block> comando.</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="example-title">Configure la máquina virtual de Windows para acceder a iSCSI y detectar los sistemas de archivos</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">Desde la máquina virtual de SQL Server, configure el adaptador de red iSCSI para que se comunique en el grupo de puertos de VMware que se ha establecido con conectividad a las interfaces de destino iSCSI de la instancia de FSX.</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">Abra la utilidad iSCSI Initiator Properties y borre la configuración de conectividad antigua de las fichas Discovery, Favorite Targets y Targets.</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">Busque las direcciones IP para acceder a la interfaz lógica iSCSI en la instancia/clúster de FSX. Encontrará información en la consola de AWS en Amazon FSX &gt; ONTAP &gt; Storage Virtual Machines.</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">En la pestaña Discovery, haga clic en Discover Portal e introduzca las direcciones IP para los destinos iSCSI de FSX.</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">En la ficha destino, haga clic en conectar, seleccione Activar Multi-Path si es apropiado para su configuración y, a continuación, haga clic en Aceptar para conectarse al destino.</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">Abra la utilidad Administración de equipos y ponga los discos en línea. Compruebe que conservan las mismas letras de unidad que tenían anteriormente.</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="example-title">Conecte las bases de datos de SQL Server</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">En la máquina virtual de SQL Server, abra Microsoft SQL Server Management Studio y seleccione Attach para iniciar el proceso de conexión a la base de datos.</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">Haga clic en Agregar y desplácese a la carpeta que contiene el archivo de base de datos principal de SQL Server, selecciónelo y haga clic en Aceptar.</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">Si los registros de transacciones se encuentran en una unidad independiente, elija la carpeta que contiene el registro de transacciones.</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">Cuando haya terminado, haga clic en Aceptar para adjuntar la base de datos.</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="example-title">Confirme la comunicación de SnapCenter con el plugin de SQL Server</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">Cuando la base de datos SnapCenter se restaura a su estado anterior, se vuelven a detectar automáticamente los hosts de SQL Server. Para que esto funcione correctamente, tenga en cuenta los siguientes requisitos previos:</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter debe ponerse en modo de recuperación ante desastres. Esto se puede realizar a través de la API de Swagger o con la configuración global en recuperación ante desastres.</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">El FQDN de SQL Server debe ser idéntico a la instancia que se ejecutaba en el centro de datos local.</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">Debe romperse la relación de SnapMirror original.</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">Las LUN que contienen la base de datos deben montarse en la instancia de SQL Server y la base de datos adjunta.</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">Para confirmar que SnapCenter está en modo de recuperación ante desastres, vaya a Configuración desde el cliente web SnapCenter. Vaya a la ficha Configuración global y, a continuación, haga clic en recuperación ante desastres. Asegúrese de que la casilla Habilitar recuperación ante desastres esté habilitada.</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="section-title">Restaure los datos de la aplicación Oracle</block>
  <block id="38631d978812c49b6f395a78becd9750" category="paragraph">El siguiente proceso proporciona instrucciones sobre cómo recuperar los datos de aplicaciones de Oracle en VMware Cloud Services en AWS en caso de un desastre que haga que el sitio local deje de funcionar.</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">Complete los siguientes requisitos previos para continuar con los pasos de recuperación:</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">La máquina virtual del servidor Oracle Linux se ha restaurado en el VMware Cloud SDDC con Veeam Full Restore.</block>
  <block id="66d808fa42d45f6883d1a223ee26eb0c" category="list-text">Se ha establecido un servidor SnapCenter secundario y se han restaurado los archivos de base de datos y configuración de SnapCenter siguiendo los pasos descritos en esta sección <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="example-title">Configurar FSX para la restauración de Oracle – rompa la relación de SnapMirror</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">Para que los servidores Oracle puedan acceder a los volúmenes de almacenamiento secundario alojados en la instancia de FSxN, primero debe romper la relación de SnapMirror existente.</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">Después de iniciar sesión en la CLI de FSX, ejecute el siguiente comando para ver los volúmenes filtrados por el nombre correcto.</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">Ejecute el siguiente comando para interrumpir las relaciones de SnapMirror existentes.</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Actualice la ruta de unión en el cliente web de Amazon FSX:</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">Añada el nombre de la ruta de unión y haga clic en Update. Especifique esta ruta de unión cuando monte el volumen NFS desde el servidor de Oracle.</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="example-title">Montar volúmenes de NFS en Oracle Server</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">En Cloud Manager, puede obtener el comando de montaje con la dirección IP de LIF NFS correcta para montar los volúmenes NFS que contienen los registros y archivos de la base de datos de Oracle.</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">En Cloud Manager, acceda a la lista de volúmenes para el clúster FSX.</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">En el menú Action, seleccione Mount Command para ver y copiar el comando Mount que se va a utilizar en nuestro servidor Oracle Linux.</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">Monte el sistema de archivos NFS en el servidor Oracle Linux. Los directorios para montar el recurso compartido de NFS ya existen en el host Oracle Linux.</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">Desde el servidor Oracle Linux, utilice el comando Mount para montar los volúmenes NFS.</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Repita este paso con cada volumen asociado con las bases de datos de Oracle.</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">Para que el montaje NFS sea coherente tras reiniciar, edite el<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archivo para incluir los comandos de montaje.</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Reinicie el servidor Oracle. Las bases de datos Oracle deben iniciarse normalmente y estar disponibles para su uso.</block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">Una vez completado correctamente el proceso de conmutación al nodo de respaldo descrito en esta solución, SnapCenter y Veeam reanudan sus funciones de backup que se ejecutan en AWS. Además, FSX para ONTAP ahora se designa como almacenamiento principal sin relaciones de SnapMirror existentes con el centro de datos local original. Tras la reanudación de la función normal en las instalaciones, puede utilizar un proceso idéntico al descrito en esta documentación para reflejar los datos de nuevo en el sistema de almacenamiento ONTAP local.</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">Como también se describe en esta documentación, puede configurar SnapCenter para que refleje los volúmenes de datos de aplicaciones del FSX para ONTAP a un sistema de almacenamiento ONTAP que reside en las instalaciones. Asimismo, Veeam se puede configurar para que replique copias de backup en Amazon S3 utilizando un repositorio de backup de escalado horizontal para que estos backups estén accesibles a través de un servidor de backup de Veeam que se encuentra en el centro de datos local.</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">La conmutación por recuperación no está dentro del ámbito de esta documentación, pero la conmutación por recuperación difiere poco del proceso detallado que se describe aquí.</block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="paragraph">El caso de uso que se presenta en esta documentación se centra en tecnologías probadas de recuperación ante desastres que destacan la integración entre NetApp y VMware. Los sistemas de almacenamiento ONTAP de NetApp proporcionan tecnologías contrastadas de mirroring de datos que permiten a las organizaciones diseñar soluciones de recuperación ante desastres que abarcan las tecnologías ONTAP y en las instalaciones que residen con los proveedores de cloud líderes.</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">FSX para ONTAP en AWS es una solución de este tipo que permite una integración fluida con SnapCenter y SyncMirror para replicar datos de aplicaciones en el cloud. Veeam Backup &amp; Replication es otra tecnología muy conocida que se integra bien con los sistemas de almacenamiento ONTAP de NetApp y puede proporcionar conmutación al nodo de respaldo al almacenamiento nativo de vSphere.</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">Esta solución presentó una solución de recuperación ante desastres utilizando el almacenamiento «guest connect» en un sistema ONTAP que aloja datos de aplicaciones de SQL Server y Oracle. SnapCenter con SnapMirror proporciona una solución fácil de gestionar para proteger volúmenes de aplicaciones en sistemas ONTAP y replicarlos en FSX o CVO que residen en el cloud. SnapCenter es una solución preparada para recuperación ante desastres que permite conmutar por error todos los datos de aplicaciones al cloud de VMware en AWS.</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">Enlaces a la documentación de la solución</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="inline-link">Multicloud híbrido de NetApp con soluciones de VMware</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="inline-link">Soluciones NetApp</block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">Implemente y configure el entorno de virtualización en AWS</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">Al igual que en las instalaciones, la planificación de VMware Cloud en AWS es crucial para tener un entorno preparado para la producción con éxito a la hora de crear máquinas virtuales y migración.</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">El almacenamiento invitado es actualmente el único método compatible para conectar Cloud Volumes ONTAP (CVO) a AWS VMC.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="example-title">Ponga en marcha y configure VMware Cloud para AWS</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> Ofrece una experiencia nativa del cloud para cargas de trabajo basadas en VMware en el ecosistema de AWS. Cada centro de datos definido por software (SDDC) de VMware se ejecuta en un cloud privado virtual de Amazon (VPC) y proporciona una pila completa de VMware (incluido vCenter Server), las redes definidas por software NSX-T, el almacenamiento definido por software VSAN y uno o más hosts ESXi que proporcionan recursos informáticos y de almacenamiento a sus cargas de trabajo.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">En esta sección se describe cómo configurar y gestionar VMware Cloud en AWS y cómo utilizarlo en combinación con Amazon FSX para ONTAP de NetApp y/o Cloud Volumes ONTAP en AWS con el almacenamiento invitado.</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">Regístrese para obtener una cuenta de AWS</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Cuenta de Amazon Web Services</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="paragraph">Regístrese en para ver un <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">Se necesita una cuenta de AWS para empezar, suponiendo que no se haya creado ya. Nuevo o existente, necesita privilegios administrativos en la cuenta para muchos pasos de este procedimiento. Vea esto <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> Para obtener más información acerca de las credenciales de AWS.</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">Regístrese para obtener una cuenta de My VMware</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">Mi VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="paragraph">Regístrese en <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> cuenta.</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">Para acceder a la cartera de cloud de VMware (incluido VMware Cloud en AWS), necesita una cuenta de cliente de VMware o una cuenta de My VMware. Si todavía no lo ha hecho, cree una cuenta de VMware <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="example-title">Aprovisione SDDC en VMware Cloud</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">Una vez que se ha configurado la cuenta de VMware y se ha realizado el ajuste de tamaño adecuado, la puesta en marcha de un centro de datos definido por software es el siguiente paso obvio para usar el servicio VMware Cloud en AWS. Para crear un SDDC, elija una región AWS para alojarlo, proporcione un nombre al SDDC y especifique cuántos hosts ESXi desea que contenga el SDDC. Si todavía no tiene una cuenta de AWS, puede crear un SDDC de configuración de inicio que contenga un único host ESXi.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">Inicie sesión en VMware Cloud Console con sus credenciales de VMware existentes o creadas recientemente.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">Configure la región, la puesta en marcha y el tipo de host de AWS y el nombre del SDDC:</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">Conéctese a la cuenta de AWS deseada y ejecute la pila AWS Cloud Formation.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">En esta validación se utiliza la configuración de un solo host.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">Seleccione el VPC de AWS que desee para conectar el entorno de VMC con.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">Configure la subred de gestión de VMC; esta subred contiene servicios gestionados por VMC como vCenter, NSX, etc. No elija un espacio de direcciones superpuesto con ninguna otra red que necesite conectividad con el entorno SDDC. Por último, siga las recomendaciones para el tamaño CIDR anotado a continuación.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">Revise y reconozca la configuración del SDDC y, a continuación, haga clic en Deploy the SDDC.</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">Normalmente, el proceso de puesta en marcha tarda aproximadamente dos horas en completarse.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">Tras la finalización, el SDDC está listo para su uso.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">Implemente un SDDC a partir de la consola VMC</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">Para obtener una guía paso a paso sobre la puesta en marcha de SDDC, consulte <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">Para conectar VMware Cloud a FSX ONTAP, lleve a cabo los siguientes pasos:</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">Con la puesta en marcha de VMware Cloud completada y conectada a AWS VPC, debe poner en marcha Amazon FSX para ONTAP de NetApp en un nuevo VPC, en lugar de hacerlo en el VPC conectado original (consulte la captura de pantalla de abajo). No se puede acceder a FSX (IP flotantes de NFS y SMB) si se ha implementado en el VPC conectado. Tenga en cuenta que los extremos DE ISCSI como Cloud Volumes ONTAP funcionan muy bien con el VPC conectado.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">Ponga en marcha un VPC adicional en la misma región y, a continuación, ponga en marcha Amazon FSX para ONTAP de NetApp en el nuevo VPC.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">La configuración de un grupo SDDC en la consola VMware Cloud permite las opciones de configuración de red necesarias para conectarse al nuevo VPC, en el que se pone en marcha FSX. En el paso 3, compruebe que “Configuración de VMware Transit Connect para su grupo incurrirá en cargos por archivo adjunto y transferencia de datos” y, a continuación, seleccione Crear grupo. El proceso puede tardar unos minutos en completarse.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">Instrucciones para añadir un VPC externo</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">Conecte el VPC recién creado al grupo de SDDC recién creado. Seleccione la pestaña External VPC y siga el <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> al grupo. Este proceso puede tardar entre 10 y 15 minutos en completarse.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">Puerta de enlace de tránsito de AWS</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">Como parte del proceso VPC externo, se le pedirá a través de la consola de AWS que un nuevo recurso compartido a través de Resource Access Manager. El recurso compartido es el <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> Gestionado por VMware Transit Connect.</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Cree el adjunto de puerta de enlace de tránsito.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">De nuevo en la consola VMC, acepte el archivo adjunto VPC. Este proceso puede tardar aproximadamente 10 minutos en completarse.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">En la ficha VPC externo, haga clic en el icono de edición de la columna rutas y añádase las siguientes rutas requeridas:</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">IP flotantes</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">Una ruta para el intervalo IP flotante para Amazon FSX para ONTAP de NetApp <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Ruta para el intervalo IP flotante para Cloud Volumes ONTAP (si procede).</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">reglas del firewall</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">pasos detallados</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">Por último, permita el tráfico bidireccional <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> Para acceder a FSX/CVO. Siga estas <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> Para reglas de firewall de puerta de enlace de computación para conectividad de carga de trabajo SDDC.</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">Una vez configurados los grupos de firewall para la puerta de enlace de gestión y computación, es posible acceder al para vCenter de la siguiente manera:</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">El siguiente paso es verificar que Amazon FSX ONTAP o Cloud Volumes ONTAP está configurado en función de sus requisitos y que los volúmenes se aprovisionan para descargar componentes de almacenamiento de VSAN para optimizar la implementación.</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR 4942: Migre cargas de trabajo al almacén de datos FSX ONTAP mediante VMware HCX</block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">Descripción general: Migración de máquinas virtuales con VMware HCX, almacenes de datos complementarios de FSX ONTAP y VMware Cloud</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">Un caso práctico común para VMware Cloud (VMC) en Amazon Web Services (AWS), con su almacén de datos NFS complementario en Amazon FSX para ONTAP de NetApp, es la migración de cargas de trabajo de VMware. VMware HCX es la opción preferida y proporciona diversos métodos de migración para mover máquinas virtuales (VM) locales y sus datos, ejecutándose en cualquier almacén de datos compatibles con VMware, a almacenes de datos VMC, lo que incluye almacenes de datos NFS complementarios en FSX para ONTAP.</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX es principalmente una plataforma de movilidad que está diseñada para simplificar la migración de cargas de trabajo, el reequilibrado de las cargas de trabajo y la continuidad empresarial entre clouds. Se incluye como parte de VMware Cloud en AWS y ofrece muchas formas de migrar cargas de trabajo y se puede usar para operaciones de recuperación ante desastres.</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">Este documento proporciona una guía paso a paso para la puesta en marcha y configuración de VMware HCX, incluidos todos sus componentes principales, tanto en las instalaciones como en el centro de datos de cloud, lo cual permite disponer de diversos mecanismos de migración de equipos virtuales.</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">Introducción a las implementaciones de HCX</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">Lista de comprobación de instalación B - HCX con VMware Cloud en el entorno de destino AWS SDDC</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">Para obtener más información, consulte<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> y..<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>.</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">Esta lista proporciona los pasos de alto nivel para instalar y configurar VMware HCX:</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">Active HCX para el centro de datos definido por software (SDDC) de VMC a través de VMware Cloud Services Console.</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">Descargue e implemente el instalador de OVA del conector HCX en la instancia local de vCenter Server.</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">Active HCX con una clave de licencia.</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">Emparejar el conector VMware HCX en las instalaciones con VMC HCX Cloud Manager.</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(Opcional) realice la extensión de red para ampliar la red y evitar la reIP.</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">Preparación para la instalación del HCX</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">Antes de empezar, asegúrese de que se cumplan los siguientes requisitos previos. Para obtener más información, consulte<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>. Una vez que se hayan establecido los requisitos previos, incluida la conectividad, configure y active HCX generando una clave de licencia desde la consola VMware HCX en VMC. Después de activar HCX, se implementa el plugin de vCenter y es posible acceder a él mediante la consola de vCenter para la gestión.</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">Antes de continuar con la activación e implementación de HCX, deben completarse los siguientes pasos de instalación:</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">Enlace de VMware</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">Utilice un VMware SDDC existente o cree un nuevo SDDC a continuación<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> o esto<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>.</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">La ruta de red desde el entorno vCenter en las instalaciones al centro de datos definido por software de VMC debe admitir la migración de máquinas virtuales mediante vMotion.</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">Asegúrese de que es necesario<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Se permiten para el tráfico de vMotion entre la instancia local de vCenter Server y SDDC vCenter.</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">El volumen NFS de FSX para ONTAP debe montarse como un almacén de datos complementario en el centro de datos VMC SDDC. Para conectar los almacenes de datos NFS al clúster adecuado, siga los pasos que se describen en este<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> o esto<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>.</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">Para realizar las pruebas, el entorno de laboratorio local utilizado para esta validación se conectó mediante una VPN sitio a sitio a AWS VPC, que permitía la conectividad local con AWS y al centro de datos definido por software de cloud de VMware mediante una puerta de enlace de tránsito externa. La migración HCX y la extensión del tráfico de red fluyen por Internet entre el SDDC de destino en las instalaciones y el de cloud de VMware. Esta arquitectura se puede modificar para utilizar interfaces virtuales privadas de Direct Connect.</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">La siguiente imagen muestra la arquitectura de alto nivel.</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">Paso 1: Active HCX mediante VMC SDDC mediante la opción Add-ons</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">Inicie sesión en la consola VMC en<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> Y acceder al inventario.</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">Para seleccionar el SDDC adecuado y acceder a los Add- ons, haga clic en Ver detalles en SDDC y seleccione la pestaña Add Ons.</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">Haga clic en Activate for VMware HCX.</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">Este paso tarda hasta 25 minutos en completarse.</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">Una vez completada la implementación, valide la implementación confirmando que HCX Manager y sus plugins asociados están disponibles en vCenter Console.</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">Cree los firewalls de Management Gateway adecuados para abrir los puertos necesarios para acceder a HCX Cloud Manager.HCX Cloud Manager ahora está listo para operaciones HCX.</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">Para que el conector local se comunique con HCX Manager en VMC, asegúrese de que los puertos de firewall adecuados están abiertos en el entorno local.</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">Desde la consola VMC, vaya al panel HCX, vaya a Administración y seleccione la ficha actualización de sistemas. Haga clic en solicitar un enlace de descarga para la imagen OVA del conector HCX.</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">Con el conector HCX descargado, implemente el OVA en el vCenter Server local. Haga clic con el botón derecho en vSphere Cluster y seleccione la opción Deploy OVF Template.</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Introduzca la información necesaria en el asistente implementar plantilla OVF, haga clic en Siguiente y, a continuación, en Finalizar para implementar el OVA del conector HCX de VMware.</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">Encienda el dispositivo virtual manualmente.para obtener instrucciones paso a paso, vaya a.<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">Después de implementar el OVA del conector HCX de VMware en las instalaciones e iniciar el dispositivo, lleve a cabo los siguientes pasos para activar el conector HCX. Genere la clave de licencia desde la consola VMware HCX en VMC e introduzca la licencia durante la configuración del conector VMware HCX.</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">En VMware Cloud Console, vaya a Inventory, seleccione el centro de datos definido por software y haga clic en View Details. En la pestaña Add Ons, en el icono VMware HCX, haga clic en Open HCX.</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">En la ficha claves de activación, haga clic en Crear clave de activación. Seleccione el Tipo de sistema como conector HCX y haga clic en Confirmar para generar la clave. Copie la clave de activación.</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">Se necesita una llave independiente para cada conector HCX desplegado en las instalaciones.</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">Inicie sesión en el conector VMware HCX local en<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> uso de las credenciales de administrador.</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">En la sección licencias, introduzca la clave de activación copiada en el paso 2 y haga clic en Activar.</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">El conector HCX local debe tener acceso a Internet para que la activación se complete correctamente.</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">En Datacenter Location, proporcione la ubicación deseada para instalar VMware HCX Manager en las instalaciones. Haga clic en Continue.</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">En Nombre del sistema, actualice el nombre y haga clic en continuar.</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">Seleccione Sí y, a continuación, continúe.</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">En Connect your vCenter, proporcione la dirección IP o el nombre de dominio completo (FQDN) y las credenciales de vCenter Server y haga clic en Continue.</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">Utilice el FQDN para evitar problemas de comunicación más adelante.</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">En Configure SSO/PSC, proporcione el FQDN o la dirección IP de Platform Services Controller y haga clic en Continue.</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">Introduzca la dirección IP o el FQDN de vCenter Server.</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">Compruebe que la información se haya introducido correctamente y haga clic en Restart.</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">Una vez completado, la instancia de vCenter Server se muestra como verde. Tanto la instancia de vCenter Server como el de SSO deben tener los parámetros de configuración correctos, que deben ser los mismos que la página anterior.</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">Este proceso debe tardar aproximadamente de 10 a 20 minutos y el plugin se debe añadir a vCenter Server.</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">Paso 4: Emparejar el conector VMware HCX en las instalaciones con VMC HCX Cloud Manager</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">Para crear un par de sitios entre la instancia local de vCenter Server y el SDDC de VMC, inicie sesión en la instancia local de vCenter Server y acceda al plugin HCX vSphere Web Client.</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">En Infraestructura, haga clic en Agregar un emparejamiento de sitios. Para autenticar el sitio remoto, introduzca la dirección IP o la URL de HCX Cloud Manager de VMC y las credenciales del rol CloudAdmin.</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">La información HCX se puede recuperar desde la página SDDC Settings.</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">Para iniciar el emparejamiento de sitios, haga clic en conectar.</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">El conector HCX de VMware debe poder comunicarse con HCX Cloud Manager IP a través del puerto 443.</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">El dispositivo VMware HCX Interconnect (HCX-IX) proporciona capacidades de túnel seguro a través de Internet y conexiones privadas al sitio de destino que permiten la replicación y las capacidades basadas en vMotion. La interconexión proporciona cifrado, ingeniería de tráfico y una SD-WAN. Para crear el dispositivo de interconexión HCI-IX, lleve a cabo los siguientes pasos:</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">En Infrastructure, seleccione Interconnect &gt; malla de servicio multisitio &gt; Compute Profiles &gt; Create Compute Profile.</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">Los perfiles de computación contienen los parámetros de puesta en marcha de computación, almacenamiento y red necesarios para poner en marcha un dispositivo virtual de interconexión. También especifican qué parte del centro de datos de VMware será accesible al servicio HCX.</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">Crear un perfil de computación</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">Para obtener instrucciones detalladas, consulte<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>.</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">Una vez creado el perfil de computación, cree el perfil de red seleccionando malla de servicio multisitio &gt; Perfiles de red &gt; Crear perfil de red.</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">El perfil de red define un rango de direcciones IP y redes que utilizará HCX para sus dispositivos virtuales.</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">Esto requerirá dos o más direcciones IP. Estas direcciones IP se asignarán desde la red de gestión a los dispositivos virtuales.</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">Creación de un perfil de red</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">Para obtener instrucciones detalladas, consulte<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>.</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">Si está conectando con una SD-WAN a través de Internet, tiene que reservar IP públicas en la sección redes y seguridad.</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">Para crear una malla de servicio, seleccione la pestaña malla de servicio dentro de la opción Interconnect (interconexión) y seleccione sites in situ y VMC SDDC.</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">La malla de servicio establece un par de perfiles de red y de computación local y remota.</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">Parte de este proceso implica la implementación de dispositivos HCX que se configurarán automáticamente tanto en los sitios de origen como en los de destino, con lo que se creará una estructura de transporte segura.</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">Seleccione los perfiles de computación de origen y remoto y haga clic en Continue.</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">Seleccione el servicio que desea activar y haga clic en continuar.</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Se requiere una licencia HCX Enterprise para la migración de vMotion asistida con replicación, la integración de SRM y la migración asistida por SO.</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">Cree un nombre para la malla de servicio y haga clic en Finalizar para comenzar el proceso de creación. La puesta en marcha tardará aproximadamente 30 minutos en completarse. Una vez configurada la malla de servicio, se crean las máquinas virtuales y las redes necesarias para migrar las máquinas virtuales de carga de trabajo.</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">Paso 6: Migrar cargas de trabajo</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX proporciona servicios de migración bidireccionales entre dos o más entornos diferentes, como los centros de datos SDDC en las instalaciones y los VMC. Las cargas de trabajo de aplicaciones se pueden migrar a y desde sitios activados por HCX mediante diversas tecnologías de migración como la migración masiva de HCX, HCX vMotion, migración en frío de HCX, vMotion asistido con replicación de HCX (disponible con la edición de HCX Enterprise) y la migración asistida por HCX OS (disponible con la edición de HCX Enterprise).</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">Para obtener más información sobre las tecnologías de migración HCX disponibles, consulte<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">El dispositivo HCX-IX utiliza el servicio de agente de movilidad para realizar migraciones vMotion, de frío y de replicación asistida (RAV).</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">El dispositivo HCX-IX agrega el servicio Mobility Agent como un objeto host en vCenter Server. El procesador, la memoria, los recursos de almacenamiento y redes que se muestran en este objeto no representan el consumo real en el hipervisor físico que aloja el dispositivo IX.</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">HCX vMotion de VMware</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">En esta sección se describe el mecanismo HCX vMotion. Esta tecnología de migración utiliza el protocolo VMware vMotion para migrar una máquina virtual a VMC SDDC. La opción de migración de vMotion se utiliza para migrar el estado de las máquinas virtuales de una única máquina virtual a la vez. No se produce ninguna interrupción del servicio durante este método de migración.</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">La extensión de red debe estar en su lugar (para el grupo de puertos en el que está conectada la máquina virtual) para migrar la máquina virtual sin necesidad de modificar la dirección IP.</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">Desde el cliente vSphere local, vaya a Inventory, haga clic con el botón derecho en la máquina virtual que se va a migrar y seleccione HCX Actions &gt; Migrate to HCX Target Site.</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">En el asistente Migrate Virtual Machine, seleccione Remote Site Connection (VMC SDDC de destino).</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">Agregue un nombre de grupo y, en transferencia y colocación, actualice los campos obligatorios (clúster, almacenamiento y red de destino) y haga clic en Validar.</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">Una vez finalizadas las comprobaciones de validación, haga clic en Ir para iniciar la migración.</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">Comprender vMotion y la migración de datos fríos de VMware HCX</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">La transferencia de vMotion captura la memoria activa de la máquina virtual, su estado de ejecución, su dirección IP y su dirección MAC. Para obtener más información sobre los requisitos y las limitaciones de HCX vMotion, consulte<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>.</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">Es posible supervisar el progreso y la finalización de vMotion desde el panel HCX &gt; Migration.</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMotion asistido con replicación de VMware</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">Como ya se ha visto en la documentación de VMware, VMware HCX Replication Assisted vMotion (RAV) combina las ventajas de la migración masiva y vMotion. La migración masiva usa replicación de vSphere para migrar varias máquinas virtuales en paralelo: El equipo virtual se reinicia durante la conmutación de sitios. HCX vMotion migra sin tiempo de inactividad, pero se ejecuta en serie una máquina virtual a la vez en un grupo de replicación. RAV replica el equipo virtual en paralelo y lo mantiene sincronizado hasta la ventana de cambio. Durante el proceso de conmutación de sitios, migra un equipo virtual a la vez sin tiempo de inactividad de dicho equipo.</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">La siguiente captura de pantalla muestra el perfil de migración como Replication Assisted vMotion.</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">La duración de la replicación puede ser más larga en comparación con vMotion de un pequeño número de máquinas virtuales. Con RAV, sólo sincronice los deltas e incluya el contenido de la memoria. A continuación se muestra una captura de pantalla del estado de la migración; muestra cómo la hora de inicio de la migración es la misma y la hora de finalización es diferente para cada equipo virtual.</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">Si quiere más información acerca de las opciones de migración a HCX y sobre cómo migrar cargas de trabajo de las instalaciones a VMware Cloud en AWS mediante HCX, consulte la<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion requiere 100 Mbps o más capacidad de rendimiento.</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">La VMC FSX de destino para el almacén de datos ONTAP debe tener espacio suficiente para acomodar la migración.</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">Tanto si su objetivo es llegar a un cloud híbrido o un cloud, como si los datos residen en almacenamiento de cualquier tipo o proveedor en las instalaciones, Amazon FSX para ONTAP de NetApp y HCX proporcionan opciones excelentes para poner en marcha y migrar las cargas de trabajo, a la vez que reduce el TCO y permite que los requisitos de datos se adaptan perfectamente a la capa de la aplicación. Sea cual sea el caso de uso, elija VMC junto con FSX para el almacén de datos ONTAP para comprender rápidamente las ventajas del cloud, una infraestructura consistente y operaciones en las instalaciones y varios clouds, la portabilidad bidireccional de las cargas de trabajo, y la capacidad y el rendimiento de clase empresarial. Es el mismo proceso y procedimientos que ya conoce que se utiliza para conectar el almacenamiento y migrar máquinas virtuales mediante la replicación de VMware vSphere, VMware vMotion o incluso una copia NFC.</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">Ahora puede usar Amazon FSX ONTAP como almacén de datos con VMC SDDC.</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">Puede migrar datos fácilmente desde cualquier centro de datos local a una instancia de VMC que se ejecute con FSX para almacén de datos ONTAP</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">Puede aumentar y reducir fácilmente el almacén de datos ONTAP de FSX para satisfacer los requisitos de capacidad y rendimiento durante la actividad de migración.</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">Documentación de VMware Cloud</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Documentación de Amazon FSX para ONTAP de NetApp</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">Obtenga más información acerca de las soluciones que NetApp ofrece el entorno de VMware en cada uno de los proveedores a hiperescala, desde la migración de flujos de trabajo, la ampliación o la descarga al cloud, backup/restauración y recuperación ante desastres.</block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">Soluciones NetApp para entornos VMware</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">Tanto si opera en un modelo de cloud híbrido como si es un modelo de "primero el cloud", NetApp ofrece una amplia variedad de soluciones destinadas a abordar los casos prácticos más comunes para gestionar cargas de trabajo en un modelo de cloud o de cloud híbrido.</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">NetApp también ofrece soluciones para el almacenamiento aprovisionado como almacenamiento "invitado" (conectado) o como almacén de datos NFS complementario en cada uno de los proveedores a hiperescala. Todas las soluciones se categorizan al unísono con la clasificación de VMware de las cargas de trabajo del cloud. Estas clasificaciones incluyen:</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">Para obtener más detalles sobre las soluciones disponibles para cada proveedor a hiperescala, visite:</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">De NetApp para AWS / VMC</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">De NetApp para Azure / AVS</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">Soluciones para GCP/GCVE</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">Casos de uso del multicloud híbrido de NetApp con VMware</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">Una descripción de los casos de uso que son importantes para la organización TECNOLÓGICA al planificar una puesta en marcha de cloud híbrido o cloud-first.</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">Casos de uso populares</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">Sus casos de uso son:</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">Recuperación tras desastres,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">Alojar cargas de trabajo durante el mantenimiento del centro de datos; * explosión rápida en la que se necesitan recursos adicionales más allá de lo aprovisionado en el centro de datos local,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">Ampliación de sitios de VMware,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">Migración rápida al cloud,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">Desarrollo/pruebas, y.</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">Modernización de aplicaciones aprovechando tecnologías complementarias de cloud.</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">A lo largo de esta documentación, las referencias de cargas de trabajo del cloud se detaltarán por medio de casos de uso de VMware. Estos casos de uso son:</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">En el camino hacia la TECNOLOGÍA</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">La mayoría de las organizaciones se encuentran en un camino hacia la transformación y la modernización. Como parte de este proceso, las empresas intentan aprovechar sus inversiones existentes en VMware al mismo tiempo que aprovechan las ventajas de la nube y exploran las formas de hacer el proceso de migración de la forma más fluida posible. Este enfoque facilita enormemente sus esfuerzos de modernización, ya que los datos ya están en el cloud.</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">La respuesta más sencilla a este escenario son las ofertas de VMware en cada proveedor a hiperescala. Al igual que Cloud Volumes de NetApp®, VMware proporciona una forma de mover o ampliar los entornos VMware locales a cualquier cloud, lo que le permite conservar activos, habilidades y herramientas existentes en las instalaciones al tiempo que ejecuta cargas de trabajo de forma nativa en el cloud. De este modo se reduce el riesgo, ya que no se producirán interrupciones del servicio ni se necesitarán cambios en la IP, y el equipo DE TECNOLOGÍA podrá utilizar las habilidades y herramientas existentes de la manera en que lo hacen en las instalaciones. Esto puede llevar a migraciones de cloud aceleradas y a una transición mucho más fluida a una arquitectura multicloud híbrida.</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">Descripción de la importancia de las opciones de almacenamiento de NFS suplementario</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">Mientras que VMware en cualquier cloud ofrece funcionalidades híbridas únicas a todos los clientes, las opciones de almacenamiento NFS suplementario limitadas han restringido su utilidad para las organizaciones con cargas de trabajo que requieren un gran nivel de almacenamiento. Debido a que el almacenamiento está directamente ligado a los hosts, la única forma de escalar el almacenamiento es añadir más hosts, lo cual puede aumentar los costes entre un 35 y un 40 % o más para cargas de trabajo con un uso intensivo del almacenamiento. Estas cargas de trabajo solo necesitan almacenamiento adicional, no una potencia adicional. Pero eso significa pagar por los anfitriones adicionales.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">Consideremos este caso:</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">Un cliente solo necesita cinco hosts para CPU y memoria, pero tiene muchas necesidades de almacenamiento y necesita 12 hosts para satisfacer sus requisitos de almacenamiento. Este requisito acaba realmente a la altura del escalado financiero al tener que comprar la potencia adicional cuando solo necesitan aumentar el almacenamiento.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">Cuando planifica la adopción y las migraciones de la nube, siempre es importante evaluar el mejor enfoque y tomar el camino más sencillo que reduzca las inversiones totales. El método más habitual y sencillo para la migración de cualquier aplicación es el realojamiento (también conocido como lift and shift), en el que no hay ningún equipo virtual (VM) ni conversión de datos. Al utilizar Cloud Volumes de NetApp con el centro de datos definido por software (SDDC) de VMware, al tiempo que complementa VSAN, proporciona una opción de elevación y cambio sencilla.</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">Opciones de almacenamiento de NetApp para proveedores de cloud público</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">Explore las opciones para NetApp como almacenamiento en los tres principales proveedores a hiperescala.</block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">Configuración del entorno de virtualización en el proveedor de cloud</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">Aquí se ofrece información sobre cómo configurar el entorno de virtualización en cada uno de los proveedores a hiperescala compatibles.</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">Información general del multicloud híbrido de NetApp con VMware</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">La mayoría de las organizaciones DE TECNOLOGÍA siguen el enfoque de «cloud híbrido primero». Estas organizaciones se encuentran en una fase de transformación, y los clientes evalúan su entorno TECNOLÓGICO actual y, posteriormente, migran sus cargas de trabajo al cloud según el proceso de evaluación y detección.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">Los factores para que los clientes migren a la nube pueden ser la elasticidad y la ráfaga, la salida del centro de datos, la consolidación del centro de datos, escenarios de fin de la vida útil, las fusiones, adquisiciones, etc. El motivo de esta migración puede variar en función de cada organización y sus respectivas prioridades empresariales. A la hora de trasladarse al cloud híbrido, elegir el almacenamiento adecuado en el cloud es muy importante para aprovechar el poder de la implementación y la elasticidad del cloud.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">Opciones de cloud de VMware en el cloud público</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">avs</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">La solución de VMware para Azure es un servicio de cloud híbrido que permite centros de datos SDDC de VMware completamente funcionales dentro del cloud público de Microsoft Azure. Azure VMware Solution es una solución de primera parte totalmente gestionada y con soporte de Microsoft, verificada por VMware aprovechando la infraestructura de Azure. Esto significa que, cuando se pone en marcha la solución VMware para Azure, el cliente obtiene ESXi de VMware para virtualización informática, VSAN para almacenamiento hiperconvergente NSX y NSX para redes y seguridad, todo ello al tiempo que aprovecha la presencia global de Microsoft Azure, las mejores instalaciones de los centros de datos de su clase y la proximidad al amplio ecosistema de servicios y soluciones de Azure nativos.</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">vmc</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud en AWS aporta el software SDDC empresarial de VMware al cloud de AWS con acceso optimizado a los servicios nativos de AWS. Con la tecnología de VMware Cloud Foundation, VMware Cloud en AWS integra los productos de virtualización de redes, almacenamiento e informática de VMware (vSphere de VMware, VSAN de VMware y NSX de VMware) junto con la gestión de VMware vCenter Server, optimizada para ejecutarse en una infraestructura de AWS dedicada, elástica y con configuración básica.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Motor de Google Cloud VMware</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">cve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine es una oferta de infraestructura como servicio (IaaS) basada en la infraestructura escalable de alto rendimiento de Google Cloud y la pila de VMware Cloud Foundation: VMware vSphere, vCenter, VSAN y NSX-T. Este servicio posibilita una ruta rápida al cloud, que migra o amplía sin problemas las cargas de trabajo de VMware existentes de entornos en las instalaciones a Google Cloud Platform sin los costes, el esfuerzo o el riesgo de volver a crear la arquitectura de aplicaciones o cambiar las herramientas. Se trata de un servicio que vende y recibe soporte de Google, en estrecha colaboración con VMware.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">El cloud privado SDDC y la colocación de Cloud Volumes de NetApp proporcionan el mejor rendimiento con una latencia de red mínima.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">¿Sabía esto?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">Independientemente del cloud utilizado, cuando se pone en marcha un SDDC de VMware, el clúster inicial incluye los siguientes productos:</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">Hosts VMware ESXi para virtualización de recursos informáticos con un dispositivo vCenter Server para gestión</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">Almacenamiento hiperconvergente VSAN de VMware que incorpora los activos de almacenamiento físico de cada host ESXi</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">NSX de VMware para redes virtuales y seguridad con un clúster de NSX Manager para la gestión</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">Para los clientes que planean alojar cargas de trabajo intensivas del almacenamiento y escalar horizontalmente en cualquier solución VMware alojada en el cloud, la infraestructura hiperconvergente predeterminada dicta que la expansión se haga en los recursos de computación y almacenamiento.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Al integrarse con NetApp Cloud Volumes, como Azure NetApp Files, Amazon FSX para NetApp ONTAP, Cloud Volumes ONTAP (disponible en los tres principales proveedores a hiperescala) y Cloud Volumes Service para Google Cloud, los clientes ahora tienen opciones para escalar su almacenamiento de forma independiente, Y solo añada nodos de computación al clúster SDDC según sea necesario.</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware no recomienda configuraciones de clúster desequilibradas, por lo que ampliar el almacenamiento significa añadir más hosts, lo que implica más TCO.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">Solo es posible un entorno VSAN. Por lo tanto, todo el tráfico de almacenamiento competirá directamente con las cargas de trabajo de producción.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">No existe una opción para proporcionar varios niveles de rendimiento con el fin de alinear los requisitos de las aplicaciones, el rendimiento y el coste.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">Es muy fácil llegar a los límites de la capacidad de almacenamiento de VSAN creada sobre los hosts del clúster. Utilice Cloud Volumes de NetApp para escalar el almacenamiento para alojar conjuntos de datos activos o organizar los datos en niveles en el almacenamiento persistente.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSX para NetApp ONTAP, Cloud Volumes ONTAP (disponible en los tres principales proveedores a hiperescala) y Cloud Volumes Service para Google Cloud se pueden utilizar en combinación con las máquinas virtuales invitadas. Esta arquitectura de almacenamiento híbrido consta de un almacén de datos VSAN que contiene el sistema operativo invitado y datos binarios de aplicaciones. Los datos de la aplicación se conectan a la máquina virtual a través de un iniciador iSCSI basado en invitados o los montajes NFS/SMB que se comunican directamente con Amazon FSX para ONTAP de NetApp, Cloud Volume ONTAP, Azure NetApp Files y Cloud Volumes Service para Google Cloud respectivamente. Esta configuración le permite superar con facilidad los retos que plantea la capacidad de almacenamiento, al igual que VSAN, el espacio libre disponible depende de las políticas de almacenamiento y espacio de Slack utilizadas.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">Consideremos un clúster SDDC de tres nodos en VMware Cloud en AWS:</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">La capacidad bruta total para un SDDC de tres nodos = 31,1 TB (aproximadamente 10 TB para cada nodo).</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">El espacio de demora que se debe mantener antes de que se añadan hosts adicionales = 25% = (.25 x 31,1 TB) = 7,7 TB.</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">La capacidad bruta utilizable tras la deducción de espacio libre = 23,4 TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">El espacio libre efectivo disponible depende de la normativa de almacenamiento aplicada.</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = espacio libre efectivo = 23,4 TB (capacidad bruta utilizable/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = espacio libre efectivo = 11,7 TB (capacidad bruta útil/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = espacio libre efectivo = 17,5 TB (capacidad bruta utilizable/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">Por este motivo, el uso de Cloud Volumes de NetApp como almacenamiento conectado al invitado ayudaría a ampliar el almacenamiento y optimizar el TCO cumpliendo con los requisitos de rendimiento y protección de datos.</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">El almacenamiento en invitado era la única opción disponible en el momento de escribir este documento. A medida que esté disponible la compatibilidad complementaria con almacenes de datos NFS, estará disponible la documentación adicional <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>.</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">En los modelos de almacenamiento híbrido, coloque cargas de trabajo de nivel 1 o de alta prioridad en un almacén de datos VSAN para satisfacer cualquier requisito de latencia específica, ya que forman parte del host en sí y cerca de él. Utilice mecanismos «guest» para cualquier equipo virtual de carga de trabajo para el que se pueda aceptar latencias transaccionales.</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">Utilice la tecnología SnapMirror® de NetApp para replicar los datos de la carga de trabajo del sistema ONTAP local en Cloud Volumes ONTAP o Amazon FSX para ONTAP de NetApp con el fin de facilitar la migración mediante mecanismos de nivel de bloque. Esto no se aplica a Azure NetApp Files y Cloud Volumes Services. Para la migración de datos a Azure NetApp Files o Cloud Volumes Services, utilice XCP, Cloud Sync, rysnc o robocopy de NetApp en función del protocolo de archivo utilizado.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">Las pruebas demuestran una latencia adicional de entre 2 y 4 ms al acceder al almacenamiento desde los respectivos centros de datos de dominio completo. Tenga en cuenta esta latencia adicional en los requisitos de las aplicaciones al asignar el almacenamiento.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">En el caso del montaje de almacenamiento conectado «guest» durante la conmutación por error de prueba y la conmutación en caso de recuperación en caso de fallo real, asegúrese de que los iniciadores iSCSI se vuelven a configurar, DNS se actualiza para los recursos compartidos SMB y los puntos de montaje NFS se actualizan en fstab.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">Asegúrese de que la configuración del registro de E/S multivía (MPIO), firewall y tiempo de espera de disco de Microsoft en invitado esté configurada correctamente dentro de la máquina virtual.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">Esto solo se aplica al almacenamiento conectado como invitado.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">Ventajas del almacenamiento en cloud de NetApp</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">El almacenamiento en cloud de NetApp ofrece las siguientes ventajas:</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">Mejora la densidad de computación a almacenamiento escalando el almacenamiento con independencia de la capacidad de computación.</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">Permite reducir el número de hosts, con lo que se reduce el TCO general.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">El fallo del nodo de computación no afecta al rendimiento de almacenamiento.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">La reformulación del volumen y la funcionalidad de nivel de servicio dinámica de Azure NetApp Files le permiten optimizar los costes ajustando el tamaño de las cargas de trabajo de estado constante y evitando, por tanto, el sobreaprovisionamiento.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Las eficiencias del almacenamiento, la organización en niveles del cloud y las funcionalidades de modificación del tipo de instancia de Cloud Volumes ONTAP permiten formas óptimas de añadir y escalar almacenamiento.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">Evita el sobreaprovisionamiento de recursos de almacenamiento solo se añaden cuando es necesario.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">Le permiten crear copias y clones Snapshot eficientes sin que el rendimiento se vea afectado.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Ayuda a gestionar los ataques de ransomware mediante una recuperación rápida de copias Snapshot.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">Proporciona una recuperación ante desastres regional, basada en la transferencia de bloques incremental y el nivel de bloque de backup integrado en las regiones proporciona un mejor RPO y RTO.</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">Se habilita la tecnología SnapMirror u otros mecanismos de migración de datos relevantes. Hay muchas opciones de conectividad, desde las instalaciones hasta cualquier cloud a hiperescala. Utilice la ruta adecuada y trabaje con los equipos de redes pertinentes.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">Involucre a los arquitectos de soluciones de NetApp y a los respectivos arquitectos de cloud a hiperescala para planificar y ajustar el tamaño del almacenamiento y al número necesario de hosts. NetApp recomienda identificar los requisitos de rendimiento del almacenamiento antes de utilizar el dimensionador Cloud Volumes ONTAP para finalizar el tipo de instancia de almacenamiento o el nivel de servicio adecuado con el rendimiento adecuado.</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">Desde el punto de vista más alto, esta arquitectura (que se muestra en la siguiente figura) aborda cómo lograr una conectividad multicloud híbrida y portabilidad de aplicaciones en múltiples proveedores de cloud utilizando Cloud Volumes ONTAP de NetApp, Cloud Volumes Service para Google Cloud y Azure NetApp Files como opción de almacenamiento en invitado adicional.</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">Arquitectura de cloud híbrido empresarial</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">Disponibilidad de región para almacenes de datos NFS suplementarios en AWS, Azure y GCP</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">Obtenga más información sobre la compatibilidad de región global para almacenes de datos NFS complementarios en AWS, Azure y Google Cloud Platform (GCP).</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">Disponibilidad de regiones de AWS</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Disponibilidad de regiones de Azure</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">Disponibilidad de región de GCP</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">La disponibilidad de la región de GCP se publicará cuando GCP entre en una disponibilidad pública.</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">Las soluciones de NetApp son un conjunto de capacidades estratégicas y tecnológicas que hacen hincapié en la cartera de productos y servicios de NetApp para satisfacer las necesidades empresariales más importantes de nuestros clientes.</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">Los últimos incorporaciones al material complementario de las soluciones de cloud híbrido, virtualización de puestos de trabajo y contenedores</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">Novedades en soluciones de cloud híbrido, virtualización de escritorios y contenedores</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">Descripción general del material complementario de las soluciones y soluciones de cloud híbrido, virtualización de escritorio y contenedores más reciente.</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">*Cloud híbrido/privado*</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">*Virtualización*</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere para ONTAP</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">*Virtualización de escritorio*</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">Infraestructura de puestos de trabajo virtuales de cloud híbrido con Virtual Desktop Service (VDS) de NetApp</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">*Contenedores*</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">DevOps con NetApp Astra</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Instalación automatizada del centro de control de Astra a través de Ansible</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">Astra Control Center de NetApp en Red Hat OpenShift</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">Multi-tenancy en Red Hat OpenShift con ONTAP de NetApp</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160: Red Hat OpenShift con NetApp</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">Anthos en Bare Metal con NetApp</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">Muestras de codificación y salida AsciiDoc</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">En este documento se incluyen algunos ejemplos de origen de asciidoc y el resultado resultante.</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">Niveles de rumbo</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[Subrayado azul]*Fuente AsciiDoc:*</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[Subrayado azul]*HTML generado:*</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">Nivel de título 1 (título de la sección)</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">Nivel de título 2 (título de la sección)</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">Nivel de título 3 (título de la sección)</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">Nivel de título 4 (título de la sección)</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">Nivel de título 5 (título de la sección)</block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">Solo debe haber un título de documento (nivel 0) por documento y no se pueden omitir los títulos de las secciones (los subtítulos de las secciones deben ser el siguiente nivel de encabezado debajo de esta sección). Por este motivo, la muestra no se muestra en la salida para eliminar los errores de generación durante el procesamiento.</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">Listas</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">Lista no ordenada:</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">esta es una lista sin ordenar</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">sigue siendo una lista sin ordenar</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">se trata de un subelemento de una lista sin ordenar</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">Lista de pedidos:</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">esta es una lista ordenada</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">sigue siendo una lista ordenada</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">este es un subelemento de una lista ordenada</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">Imágenes</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">Puede enlazar a imágenes del repositorio o a cualquier parte de la Web. Para las imágenes dentro del repositorio, se colocan en la carpeta de medios, por lo que debe asegurarse de que el ":imagesdir: ./media/" está establecido correctamente.</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">Imagen dentro del repositorio</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">Imagen fuera del repositorio</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">Vínculos</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">Al igual que las imágenes, los enlaces pueden hacer referencia a documentos dentro del repositorio o en cualquier parte de la web. Para las referencias internas, es importante asegurarse de que la ruta al origen del vínculo se especifica en la instrucción "link:".</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">Registro de cambios de soluciones de NetApp (interno)</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">Registro de cambios de soluciones de NetApp (externo)</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">Contenido plegable (también conocido como Dos corbatas)</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">Título</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">El texto que se contrairá aquí.</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">Haga clic en "Título" para ver el contenido ampliado</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">Creación de una tabla</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">Columna A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">Columna B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">Columna C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">Texto de la columna A</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">Texto en la columna B</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">Texto en la columna C</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">Este es otro ejemplo en el que una fila abarca toda la tabla y otras tienen datos que abarcan varias columnas:</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">Encabezado columna 1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">Encabezado columna 2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">Encabezado columna 3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">Encabezado columna 4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">Esta es una fila muy larga que se extiende por las 4 columnas de la tabla. Es la única celda de esta fila y no deja celdas vacías.</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">Esta es una fila larga que se extiende por 3 de las columnas de la tabla dejando una celda vacía.</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">Esta fila abarca 2 de las columnas y deja 2 celdas vacías.</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">Este</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">fila</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">es</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">normal</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">Documentación de AsciiDoc</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">Hay muchas opciones que puede especificar para cambiar el diseño de una tabla. Para obtener más información, busque un ejemplo en el repositorio (versión HTML) que desee obtener y vaya a VScode para ver el origen o visite <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">Bloques tabulados</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">Primera ficha</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">Aquí va el contenido de la primera ficha</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">Segunda ficha</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">Aquí va el contenido de la segunda ficha</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">Haga clic en "Segunda ficha" para ver el contenido de esa sección.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Hemos obtenido la certificación con Confluent Platform con Kafka para almacenar por niveles en StorageGRID de NetApp.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Verificación confluente</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Hemos realizado la verificación con el almacenamiento en niveles de 6.2 de la plataforma Confluent en StorageGRID de NetApp. Los equipos de NetApp y Confluent trabajaron juntos en esta verificación y ejecutaron los casos de prueba necesarios para la verificación.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configuración de la plataforma Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Utilizamos la siguiente configuración para la verificación.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Para la verificación, utilizamos tres zoeepers, cinco brokers, cinco servidores de ejecución de script de prueba, servidores de herramientas con nombres con 256 GB de RAM y 16 CPU. En el caso del almacenamiento de NetApp, utilizamos StorageGRID con un equilibrador de carga SG1000 con cuatro SGF6024s. El almacenamiento y los agentes se conectaron a través de conexiones de 100 GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">En la siguiente figura, se muestra la topología de red de la configuración utilizada para la verificación fluida.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Los servidores de herramientas actúan como clientes de aplicación que envían solicitudes a nodos Confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configuración de almacenamiento por niveles confluente</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configuración de almacenamiento por niveles requiere los siguientes parámetros en Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Para la verificación, utilizamos StorageGRID con el protocolo HTTP, pero HTTPS también funciona. La clave de acceso y la clave secreta se almacenan en el nombre de archivo que se proporciona en el<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parámetro.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Almacenamiento de objetos de NetApp: StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Hemos configurado la configuración de un único sitio en StorageGRID para la verificación.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Pruebas de verificación</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Completamos los cinco casos de prueba siguientes para la verificación. Estas pruebas se ejecutan en el marco de Trogdor. Las dos primeras fueron pruebas de funcionalidad y las tres restantes fueron pruebas de rendimiento.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Prueba de corrección del almacén de objetos</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Esta prueba determina si todas las operaciones básicas (por ejemplo, Get/put/delete) en la API de almacén de objetos funcionan bien de acuerdo con las necesidades de almacenamiento por niveles. Es una prueba básica que cada servicio de almacén de objetos debe esperar pasar por delante de las siguientes pruebas. Es una prueba asertiva que pasa o falla.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Prueba de corrección de la funcionalidad de organización en niveles</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Esta prueba determina si la funcionalidad de almacenamiento por niveles completo funciona bien con una prueba asertiva que pasa o falla. La prueba crea un tema de prueba que, de forma predeterminada, se configura con la clasificación por niveles habilitada y un tamaño de conjunto de datos activo muy reducido. Produce una secuencia de eventos para el tema de prueba recién creado, espera a que los agentes archiven los segmentos en el almacén de objetos y luego consume la secuencia de eventos y valida que la secuencia consumida coincide con la secuencia producida. El número de mensajes producidos en el flujo de eventos es configurable, lo que permite al usuario generar una carga de trabajo lo suficientemente grande en función de las necesidades de las pruebas. El tamaño reducido del hotset garantiza que las búsquedas del consumidor fuera del segmento activo se sirvan sólo desde el almacén de objetos; esto ayuda a probar la corrección del almacén de objetos para las lecturas. Hemos realizado este test con y sin inyección de fallo del almacén de objetos. Simulamos el fallo del nodo deteniendo el servicio de gestor de servicios en uno de los nodos en StorageGRID y validando que la funcionalidad integral funciona con almacenamiento de objetos.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Punto de referencia de obtención de nivel</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">En esta prueba se validó el rendimiento de lectura del almacenamiento de objetos por niveles y se comprueban las solicitudes de lectura de recuperación de rango bajo carga pesada de los segmentos generados por la prueba de rendimiento. En esta prueba, Confluent desarrolló clientes personalizados para atender las solicitudes de obtención de nivel.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Producir-consumir prueba de rendimiento de cargas de trabajo</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Esta prueba generó indirectamente la carga de trabajo de escritura en el almacén de objetos mediante el archivado de segmentos. La carga de trabajo de lectura (segmentos leídos) se generó desde el almacenamiento de objetos cuando los grupos de consumidores obtuvieron los segmentos. Esta carga de trabajo fue generada por el script de prueba. En esta prueba se verificó el rendimiento de lectura y escritura en el almacenamiento de objetos en subprocesos paralelos. Hemos probado con y sin inyección de fallo en el almacén de objetos como lo hicimos con la prueba de corrección de la funcionalidad de organización en niveles.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Prueba de rendimiento de cargas de trabajo de retención</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">En esta prueba se comprobó el rendimiento de eliminación de un almacén de objetos en una gran carga de trabajo de retención de temas. La carga de trabajo de retención se generó mediante un script de prueba que produce muchos mensajes en paralelo a un tema de prueba. El tema de prueba se configuraba con una configuración de retención agresiva basada en tamaño y en tiempo que provocaba que la secuencia de eventos se purgaran continuamente del almacén de objetos. A continuación, se archivaron los segmentos. Esto llevó a un gran número de eliminaciones en el almacenamiento de objetos por parte del agente y la colección del rendimiento de las operaciones de eliminación del almacén de objetos.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">Siguiente: Pruebas de rendimiento con escalabilidad.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID cuenta con una amplia variedad de funciones que los usuarios pueden aprovechar y personalizar para su entorno en constante cambio. Desde la puesta en marcha al escalado de SmartStore de Splunk, su entorno exige una rápida adopción de los cambios y debe no ser disruptivo para Splunk. Las políticas de gestión de datos (ILM) y los clasificadores de tráfico (QoS) flexibles de StorageGRID le permiten planificar y adaptarse a su entorno.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Funciones flexibles de StorageGRID para Splunk SmartStore</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Anterior: Descripción general de la solución.</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestión sencilla con Grid Manager</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager es una interfaz gráfica basada en navegador que permite configurar, gestionar y supervisar el sistema StorageGRID en ubicaciones distribuidas globalmente en un único panel, como se muestra en la siguiente imagen.</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Realice las siguientes tareas con la interfaz de Grid Manager:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gestione repositorios de objetos distribuidos de varios petabytes como imágenes, vídeo y registros.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Supervise nodos de grid y servicios para garantizar la disponibilidad de los objetos.</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Gestione la ubicación de datos de objetos a lo largo del tiempo mediante las reglas de gestión de ciclo de vida de la información (ILM). Estas reglas rigen lo que ocurre con los datos de un objeto después de ingerirlo, cómo se protege de la pérdida, dónde se almacenan los datos de objetos y durante cuánto tiempo.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Supervisar las transacciones, el rendimiento y las operaciones dentro del sistema.</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Aplicación StorageGRID de NetApp para Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">La aplicación StorageGRID de NetApp para Splunk es una aplicación específica para Splunk Enterprise. Esta aplicación funciona en combinación con el complemento StorageGRID de NetApp para Splunk. Proporciona visibilidad sobre el estado de StorageGRID, la información de uso de cuentas, detalles de auditoría de seguridad, uso de recursos y supervisión, etc.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">En la siguiente imagen, se muestra la aplicación StorageGRID para Splunk.</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Políticas de ILM</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID cuenta con políticas de gestión de datos flexibles que incluyen mantener varias copias de los objetos y utilizar esquemas de EC (codificación de borrado) como 2+1 y 4+2 (y muchos otros) para almacenar los objetos en función de requisitos específicos de rendimiento y protección de datos. A medida que las cargas de trabajo y los requisitos cambian con el tiempo, es común que las políticas de ILM también cambien con el tiempo. La modificación de las políticas de ILM es una función fundamental, por lo que permite a los clientes de StorageGRID adaptarse a su entorno en constante cambio de forma rápida y sencilla.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID escala el rendimiento añadiendo más nodos, que pueden ser máquinas virtuales o dispositivos de configuración básica o de diseño específico como SG5712, SG5760, SGF6024 o SGF6024. En nuestras pruebas, superamos los requisitos de rendimiento clave de SmartStore con un grid de tres nodos de tamaño mínimo mediante el dispositivo SG6060. A medida que los clientes escalan sus infraestructuras de Splunk con indizadores adicionales, pueden añadir más nodos de almacenamiento para aumentar el rendimiento y la capacidad.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configuración de equilibrador de carga y extremo</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Los nodos de administración en StorageGRID proporcionan la interfaz de usuario (interfaz de usuario) de Grid Manager y el extremo de la API DE REST para ver, configurar y gestionar el sistema StorageGRID, así como registros de auditoría para realizar un seguimiento de la actividad del sistema. Para proporcionar un extremo de S3 de alta disponibilidad para el almacenamiento remoto SmartStore de Splunk, se implementó el equilibrador de carga de StorageGRID, que se ejecuta como servicio en nodos de administración y nodos de puerta de enlace. Además, el equilibrador de carga también gestiona el tráfico local y habla con el GSLB (equilibrio de carga de servidor global) para ayudar en la recuperación ante desastres.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Para mejorar aún más la configuración de los extremos, StorageGRID proporciona políticas de clasificación del tráfico integradas en el nodo de administración, le permite supervisar el tráfico de la carga de trabajo y aplicar diversos límites de calidad de servicio a sus cargas de trabajo. Las políticas de clasificación del tráfico se aplican a los extremos en el servicio StorageGRID Load Balancer para los nodos de puerta de enlace y los nodos de administración. Estas políticas pueden ayudar a limitar y supervisar el tráfico.</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">Siguiente: Arquitectura de Splunk.</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Este caso de uso se basa en un cliente de retransmisión que necesita realizar un backup de los datos de análisis basados en cloud en su centro de datos en las instalaciones.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Caso de uso 2: Backup y recuperación ante desastres del cloud a las instalaciones</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">Anterior: Caso de uso 1: Backup de datos de Hadoop.</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Este caso de uso se basa en un cliente de retransmisión que necesita realizar backups de los datos de análisis basados en cloud en su centro de datos en las instalaciones, como se muestra en la siguiente figura.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Situación</block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">En este escenario, los datos del sensor del IoT se ingieren en el cloud y se analizan mediante un clúster de código abierto Apache Spark dentro de AWS. El requisito es realizar backups de los datos procesados desde el cloud a las instalaciones.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">Requisitos y retos</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Los principales requisitos y retos de este caso de uso son:</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">La habilitación de la protección de datos no debe provocar ningún efecto sobre el rendimiento en el clúster de producción de Spark/Hadoop en el cloud.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Los datos de los sensores del cloud necesitan moverse y protegerse a las instalaciones de una forma eficiente y segura.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilidad para transferir datos del cloud a las instalaciones en distintas condiciones, como bajo demanda, instantáneas y durante tiempos de carga en un clúster bajo.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Solución</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">El cliente utiliza Elastic Block Store (EBS) de AWS para su almacenamiento HDFS con clúster Spark y recibir datos de sensores remotos a través de Kafka. Por lo tanto, el almacenamiento HDFS actúa como el origen de los datos de backup.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Para cumplir estos requisitos, ONTAP Cloud de NetApp se pone en marcha en AWS y se crea un recurso compartido de NFS para que actúe como objetivo de backup para el clúster de Spark/Hadoop.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">Una vez creado el recurso compartido de NFS, se utiliza el módulo de análisis in situ para copiar los datos del almacenamiento EBS de HDFS a la unidad NFS de ONTAP. Después de que los datos residen en NFS en ONTAP Cloud, la tecnología SnapMirror puede utilizarse para reflejar los datos del cloud en un almacenamiento en las instalaciones según sea necesario de una forma segura y eficiente.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Esta imagen muestra el backup y la recuperación ante desastres del cloud a la solución en las instalaciones.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">Siguiente: Caso de uso 3 - activación de DevTest en datos de Hadoop existentes.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">En este apartado se describe la tecnología utilizada en esta solución.</block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">Anterior: Detalles de la arquitectura de la solución.</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">StorageGRID de NetApp es una plataforma de almacenamiento de objetos rentable y de alto rendimiento. Mediante el almacenamiento por niveles, la mayoría de los datos de Confluent Kafka, que se almacenan en el almacenamiento local o el almacenamiento SAN del intermediario, se descargan al almacén de objetos remoto. Esta configuración da lugar a importantes mejoras operativas al reducir el tiempo y el coste necesarios para reequilibrar, ampliar o reducir clústeres, o sustituir un intermediario fallido. El almacenamiento de objetos desempeña un papel importante en la gestión de datos que residen en el nivel de almacén de objetos; por este motivo, es importante elegir el almacenamiento de objetos adecuado.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID ofrece gestión de datos inteligente y global condicionada por políticas mediante una arquitectura de grid distribuida basada en nodos. Simplifica la gestión de petabytes de datos no estructurados y de miles de millones de objetos mediante su espacio de nombre de objetos global omnipresente combinado con funciones sofisticadas de gestión de datos. El acceso en una sola llamada a objetos abarca varios sitios y simplifica las arquitecturas de alta disponibilidad al tiempo que garantiza un acceso continuo a los objetos, independientemente de las interrupciones del servicio del sitio o de la infraestructura.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">El multi-tenancy permite que varias aplicaciones de datos empresariales y cloud no estructurados se puedan mantener de forma segura dentro del mismo grid, lo que aumenta el retorno de la inversión y los casos de uso de StorageGRID de NetApp. Puede crear múltiples niveles de servicio con políticas de ciclo de vida de objetos condicionados por metadatos, y así optimizar la durabilidad, la protección, el rendimiento y la localidad en múltiples geografías. Los usuarios pueden ajustar las políticas de gestión de datos y supervisar y aplicar los límites de tráfico para realinear el entorno de datos sin interrupciones a medida que cambien sus requisitos en los entornos TECNOLÓGICOS en constante cambio.</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">Grid Manager de StorageGRID es una interfaz gráfica basada en navegador que permite configurar, gestionar y supervisar el sistema StorageGRID en ubicaciones distribuidas por todo el mundo en una misma consola.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Puede realizar las siguientes tareas con la interfaz de Grid Manager de StorageGRID:</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Políticas de gestión del ciclo de vida de la información</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">Política de ILM</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">Reglas de ILM</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID cuenta con políticas de gestión de datos flexibles, que incluyen mantener copias de réplicas de los objetos y usar esquemas de EC (codificación de borrado) como 2+1 y 4+2 (entre otros) para almacenar los objetos, en función de requisitos específicos de rendimiento y protección de datos. A medida que las cargas de trabajo y los requisitos cambian con el tiempo, es común que las políticas de ILM también cambien con el tiempo. La modificación de las políticas de ILM es una función fundamental, por lo que permite a los clientes de StorageGRID adaptarse a su entorno en constante cambio de forma rápida y sencilla. Compruebe la <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> y.. <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> configure en StorageGRID.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 O SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID escala el rendimiento añadiendo más nodos de almacenamiento, que pueden ser máquinas virtuales, dispositivos físicos o específicos como el <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. En nuestras pruebas, superamos los requisitos de rendimiento clave de Apache Kafka con un grid de tres nodos de tamaño mínimo con el dispositivo SGF6024. A medida que los clientes escalan su clúster Kafka con agentes adicionales, pueden añadir más nodos de almacenamiento para aumentar el rendimiento y la capacidad.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Equilibrador de carga y configuración de punto final</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Los nodos de administración en StorageGRID proporcionan la interfaz de usuario (interfaz de usuario) de Grid Manager y el extremo de la API DE REST para ver, configurar y gestionar el sistema StorageGRID, así como registros de auditoría para realizar un seguimiento de la actividad del sistema. Para proporcionar un extremo de S3 de alta disponibilidad para el almacenamiento por niveles de Confluent Kafka, implementamos el equilibrador de carga StorageGRID, que se ejecuta como servicio en nodos de administración y nodos de puerta de enlace. Además, el equilibrador de carga también gestiona el tráfico local y habla con el GSLB (equilibrio de carga de servidor global) para ayudar en la recuperación ante desastres.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Para mejorar aún más la configuración de los extremos, StorageGRID proporciona políticas de clasificación del tráfico integradas en el nodo de administración, le permite supervisar el tráfico de la carga de trabajo y aplica diversos límites de calidad de servicio a sus cargas de trabajo. Las políticas de clasificación del tráfico se aplican a los extremos en el servicio StorageGRID Load Balancer para los nodos de puerta de enlace y los nodos de administración. Estas políticas pueden ayudar a configurar y supervisar el tráfico.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Clasificación del tráfico en StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID cuenta con la funcionalidad de calidad de servicio incorporada. Las políticas de clasificación del tráfico pueden ayudar a supervisar diferentes tipos de tráfico S3 que provienen de una aplicación cliente. A continuación, puede crear y aplicar políticas para limitar este tráfico en función del ancho de banda de entrada/salida, el número de solicitudes simultáneas de lectura/escritura o la tasa de solicitud de lectura/escritura.</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">Apache Kafka</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka es una implementación de marco de un bus de software que utiliza procesamiento de secuencias escrito en Java y Scala. Su objetivo es proporcionar una plataforma unificada, de alto rendimiento y baja latencia para manejar fuentes de datos en tiempo real. Kafka se puede conectar a un sistema externo para exportar e importar datos a través de Kafka Connect y proporciona flujos Kafka, una biblioteca de procesamiento de secuencias Java. Kafka utiliza un protocolo binario basado en TCP optimizado para la eficiencia y se basa en una abstracción de «conjunto de mensajes» que agrupa naturalmente los mensajes juntos para reducir la sobrecarga de la red ida y vuelta. De este modo, permite realizar operaciones de disco secuenciales de mayor tamaño, paquetes de red de mayor tamaño y bloques de memoria contiguos, con lo que Kafka puede convertir un flujo de ráfagas de escrituras de mensajes aleatorios en escrituras lineales. La figura siguiente muestra el flujo de datos básicos de Apache Kafka.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka almacena mensajes de valor clave que provienen de un número arbitrario de procesos llamados productores. Los datos pueden particionarse en diferentes particiones dentro de diferentes temas. Dentro de una partición, los mensajes se ordenan estrictamente por sus desplazamientos (la posición de un mensaje dentro de una partición) y se indexan y almacenan junto con una Marca de hora. Otros procesos llamados consumidores pueden leer mensajes de las particiones. Para el procesamiento en streaming, Kafka ofrece la API Streams, que permite escribir aplicaciones Java que consumen datos de Kafka y escribir resultados de nuevo en Kafka. Apache Kafka también funciona con sistemas de procesamiento de secuencias externas como Apache Apex, Apache Flink, Apache Spark, Apache Storm y Apache NIFI.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka se ejecuta en un clúster de uno o más servidores (denominados intermediarios), y las particiones de todos los temas se distribuyen entre los nodos del clúster. Además, las particiones se replican en varios agentes. Esta arquitectura permite a Kafka distribuir flujos masivos de mensajes de forma tolerante a fallos y le ha permitido reemplazar algunos de los sistemas de mensajería convencionales como Java Message Service (JMS), Advanced Message Queue Server Protocol (AMQP), etc. Desde la versión 0.11.0.0, Kafka ofrece escrituras transaccionales, que proporcionan un procesamiento de secuencias exactamente una vez con la API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka apoya dos tipos de temas: Regular y compactado. Los temas regulares se pueden configurar con un tiempo de retención o con un enlace al espacio. Si hay registros antiguos que superan el tiempo de retención especificado o si se supera el límite de espacio para una partición, se permite a Kafka eliminar los datos antiguos para liberar espacio de almacenamiento. Los temas se configuran por defecto con un tiempo de retención de 7 días, pero también es posible almacenar los datos de forma indefinida. Para temas compactados, los registros no caducan en función de los límites de tiempo o espacio. En su lugar, Kafka trata los mensajes posteriores como actualizaciones del mensaje más antiguo con la misma clave y garantiza que nunca se elimine el mensaje más reciente por clave. Los usuarios pueden eliminar mensajes por completo escribiendo un mensaje de desecho llamado con el valor nulo para una clave específica.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Hay cinco API principales en Kafka:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*API de productores.* permite que una aplicación publique flujos de registros.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer API.* permite a una aplicación suscribirse a temas y procesos flujos de registros.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API de conector.* ejecuta las API reutilizables de productores y consumidores que pueden vincular los temas a las aplicaciones existentes.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams API.* esta API convierte los flujos de entrada a salida y produce el resultado.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*Admin API.* se utiliza para administrar temas de Kafka, corredores y otros objetos de Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Las API de consumidores y productores se basan en el protocolo de mensajería Kafka y ofrecen una implementación de referencia para clientes consumidores y productores de Kafka en Java. El protocolo de mensajería subyacente es un protocolo binario que los desarrolladores pueden utilizar para escribir sus propios clientes consumidores o productores en cualquier lenguaje de programación. Esto libera a Kafka del ecosistema Java Virtual Machine (JVM). En el wiki de Apache Kafka se mantiene una lista de clientes no Java disponibles.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Casos de uso de Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka es más popular en mensajería, seguimiento de la actividad de sitios web, métricas, agregación de registros, procesamiento de flujos, origen de eventos y registro de confirmación.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka ha mejorado el rendimiento, las particiones integradas, la replicación y la tolerancia a fallos, lo que lo convierte en una buena solución para aplicaciones de procesamiento de mensajes a gran escala.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka puede reconstruir las actividades de un usuario (vistas de página, búsquedas) en una canalización de seguimiento como un conjunto de fuentes de suscripción-publicación en tiempo real.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka se utiliza a menudo para datos de supervisión operativa. Esto implica agregar estadísticas de aplicaciones distribuidas para producir fuentes centralizadas de datos operativos.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Muchas personas usan Kafka como reemplazo de una solución de agregación de registros. La agregación de registros normalmente recopila archivos de registro físicos fuera de los servidores y los coloca en un lugar central (por ejemplo, un servidor de archivos o HDFS) para su procesamiento. Kafka abstrae los detalles de los archivos y proporciona una abstracción más limpia de los datos de registro o evento como una secuencia de mensajes. De este modo, se consigue un procesamiento de menor latencia y una compatibilidad más sencilla con múltiples fuentes de datos y consumo de datos distribuido.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Muchos usuarios de los datos de procesos de Kafka en las canalizaciones de procesamiento, que consisten en múltiples etapas, en las que los datos de entrada sin procesar se consumen a partir de temas de Kafka y luego se agregan, enriquecen o transforman de otro modo en nuevos temas para un mayor consumo o procesamiento de seguimiento. Por ejemplo, una canalización de procesamiento para recomendar artículos de noticias podría rastrear el contenido del artículo de fuentes RSS y publicarlo en un tema de "artículos". Un procesamiento posterior puede normalizar o deduplicar este contenido, publicar el contenido del artículo limpio en un nuevo tema, y una fase final de procesamiento puede intentar recomendar este contenido a los usuarios. Estas canalizaciones de procesamiento crean gráficos de flujos de datos en tiempo real basados en temas individuales.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">La externalización de eventos es un estilo de diseño de aplicación para el que los cambios de estado se registran como una secuencia de registros ordenada por tiempo. La compatibilidad de Kafka con datos de registro almacenados muy grandes lo convierte en un entorno de administración excelente para una aplicación integrada en este estilo.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka puede servir como una especie de registro de confirmación externo para un sistema distribuido. El registro ayuda a replicar datos entre nodos y actúa como mecanismo de repetición de la sincronización de los nodos con errores para restaurar sus datos. La función de compactación de registros de Kafka ayuda a dar soporte a este caso de uso.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">Confluente</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform es una plataforma lista para las empresas que completa Kafka con funcionalidades avanzadas diseñadas para ayudar a acelerar el desarrollo y la conectividad de las aplicaciones, permitir transformaciones a través del procesamiento de secuencias, simplificar las operaciones empresariales a escala y cumplir los estrictos requisitos de arquitectura. Diseñado por los creadores originales de Apache Kafka, Confluent amplía las ventajas de Kafka con funciones de nivel empresarial al tiempo que elimina la carga de la gestión o supervisión de Kafka. Hoy en día, más del 80 % de las empresas Fortune 100 cuentan con tecnología de transmisión de datos; la mayoría de ellas utilizan Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">¿Por qué confluente?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Mediante la integración de datos históricos y en tiempo real en una única fuente central de verdad, Confluent facilita la creación de una categoría completamente nueva de aplicaciones modernas condicionadas por eventos, obtener una canalización de datos universal y desbloquear nuevos casos de uso potentes con total escalabilidad, rendimiento y fiabilidad.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">¿Para qué se utiliza Confluent?</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Gracias a la plataforma Confluent podrá centrarse en cómo obtener valor empresarial de sus datos en lugar de preocuparse por los mecanismos subyacentes, como por ejemplo, cómo se transportan datos o se integran entre sistemas dispares. En concreto, Confluent Platform simplifica la conexión de fuentes de datos a Kafka, la creación de aplicaciones de streaming y la protección, supervisión y gestión de la infraestructura de Kafka. En la actualidad, Confluent Platform se utiliza para una amplia variedad de casos de uso en numerosos sectores, desde servicios financieros, ventas al por menor de canal integral y coches autónomos, hasta detección de fraude, Microservicios y el Internet de las cosas.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">En la siguiente figura, se muestran los componentes de la plataforma Confluent Kafka.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Descripción general de la tecnología de transmisión de eventos de Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">En el centro de la plataforma Confluente lo es<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>, la plataforma de transmisión distribuida de código abierto más popular. Las capacidades clave de Kafka son las siguientes:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Publicar y suscribirse a flujos de registros.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Almacene flujos de registros de forma tolerante a fallos.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Procesar flujos de registros.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Lista para usar, Confluent Platform también incluye registro de esquemas, proxy REST, un total de más de 100 conectores Kafka predefinidos y ksqlDB.</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Descripción general de las características empresariales de la plataforma Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* Confluent Control Center.* un sistema basado en GUI para la gestión y monitorización de Kafka. Le permite gestionar fácilmente Kafka Connect y crear, editar y gestionar conexiones a otros sistemas.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">* Confluent for Kubernetes.* Confluent for Kubernetes es un operador de Kubernetes. Los operadores de Kubernetes amplían las funcionalidades de orquestación de Kubernetes, al proporcionar las funciones y requisitos únicos para una aplicación de plataforma específica. En el caso de la plataforma con fluidez, esto incluye simplificar en gran medida el proceso de puesta en marcha de Kafka en Kubernetes y automatizar las tareas habituales del ciclo de vida de la infraestructura.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* Conectores Confluent a Kafka.* los conectores usan la API Kafka Connect para conectar Kafka a otros sistemas como bases de datos, almacenes de clave-valor, índices de búsqueda y sistemas de archivos. Confluent Hub tiene conectores descargables para las fuentes de datos y los sumideros más populares, incluidas versiones totalmente probadas y compatibles de estos conectores con Confluent Platform. Encontrará más información<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Clústeres de equilibrio automático.* proporciona equilibrio de carga automatizado, detección de fallos y autorreparación. Proporciona soporte para agregar o decomisionar intermediarios según sea necesario, sin realizar ajustes manuales.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Confluent cluster linkando.* conecta directamente los clusters y refleja temas de un cluster a otro a través de un puente de enlace. La vinculación de clústeres simplifica la configuración de implementaciones en varios centros de datos, varios clústeres y nube híbrida.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* Confluent auto data equilibrador.* supervisa su clúster para el número de corredores, el tamaño de particiones, el número de particiones y el número de líderes dentro del clúster. Permite mover datos para crear una carga de trabajo uniforme en su clúster, a la vez que se desregula el tráfico del reequilibrio para minimizar el efecto en las cargas de trabajo de producción al mismo tiempo que se reequilibran.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* Confluent replicator.* hace más fácil que nunca mantener múltiples clústeres de Kafka en varios centros de datos.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Almacenamiento Tiered.* ofrece opciones para el almacenamiento de grandes volúmenes de datos Kafka con su proveedor de cloud preferido, reduciendo así la carga y los costes operativos. Con un almacenamiento por niveles, puede mantener los datos en un almacenamiento de objetos rentable y a los agentes de escalado solo cuando necesite más recursos informáticos.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Confluent JMS Client.* Confluent Platform incluye un cliente compatible con JMS para Kafka. Este cliente Kafka implementa la API estándar JMS 1.1, utilizando los agentes Kafka como back-end. Esto resulta útil si tiene aplicaciones heredadas con JMS y desea reemplazar el agente de mensajes JMS existente con Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* Proxy de Confluent MQTT.* proporciona una forma de publicar datos directamente a Kafka desde dispositivos MQTT y puertas de enlace sin necesidad de un intermediario de MQTT en el medio.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* Plugins de seguridad Confluent.* los plugins de seguridad Confluent se utilizan para agregar capacidades de seguridad a varias herramientas y productos de Confluent Platform. Actualmente, hay un plugin disponible para el proxy de REST de Confluent que ayuda a autenticar las solicitudes entrantes y propagar el principal autenticado a solicitudes a Kafka. Esto permite a los clientes proxy DE Confluent REST utilizar las funciones de seguridad multitenant del agente Kafka.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">Siguiente: Verificación confluente.</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Este documento describe las directrices de prácticas recomendadas para usar Kafka en una controladora de almacenamiento de NetApp.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912: Directrices de mejores prácticas para el almacenamiento por niveles de Confluent Kafka con NetApp</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatillparambil, NetApp Rankesh Kumar, Confluente</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka es una plataforma de transmisión de eventos distribuida por la comunidad capaz de gestionar billones de eventos al día. Inicialmente concebido como una cola de mensajería, Kafka se basa en la abstracción de un registro de confirmación distribuido. Desde que LinkedIn creó y obtuvo el código abierto en 2011, Kafka ha pasado de ser una cola de mensajes a una plataforma de transmisión de eventos completa. Con fluidez, entrega la distribución de Apache Kafka con la plataforma Confluent. La plataforma Confluent complementa a Kafka con otras funciones comerciales y comunitarias diseñadas para mejorar la experiencia en streaming de operadores y desarrolladores en producción a gran escala.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">Este documento describe las directrices de mejores prácticas sobre el uso de Confluent Tiered Storage en una oferta de almacenamiento de objetos de NetApp mediante el siguiente contenido:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Verificación fluida con el almacenamiento de objetos de NetApp – StorageGRID de NetApp</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Pruebas de rendimiento del almacenamiento por niveles</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Directrices de prácticas recomendadas para hablar con fluidez de los sistemas de almacenamiento de NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">¿Por qué Confluent Tiered Storage?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Este artículo de Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent se ha convertido en la plataforma de streaming en tiempo real predeterminada para muchas aplicaciones, especialmente para cargas de trabajo de Big Data, análisis y streaming. El almacenamiento por niveles permite a los usuarios separar el procesamiento del almacenamiento en la plataforma Confluent. Hace que el almacenamiento de datos sea más rentable, le permite almacenar cantidades de datos virtualmente infinitas y escalar las cargas de trabajo cuanto antes (o incluso reduciendo) bajo demanda, además facilita las tareas administrativas como los datos y el reequilibrio de inquilinos. Los sistemas de almacenamiento compatibles con S3 pueden aprovechar todas estas funcionalidades para democratizar los datos con todos los eventos en un mismo lugar, eliminando la necesidad de realizar una ingeniería de datos compleja. Para obtener más información sobre por qué se debe usar el almacenamiento por niveles para Kafka, consulte <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">¿Por qué utilizar StorageGRID de NetApp para el almacenamiento por niveles?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID es una plataforma de almacenamiento de objetos líder en el sector por parte de NetApp. StorageGRID es una solución de almacenamiento basada en cloud definida por software compatible con las API de objetos estándares del sector, incluida la API de Amazon simple Storage Service (S3). StorageGRID almacena y gestiona datos no estructurados a escala para proporcionar un almacenamiento de objetos seguro y duradero. El contenido se sitúa en el lugar, en el momento y el nivel de almacenamiento adecuados, optimizando los flujos de trabajo y reduciendo los costes de la distribución global de medios enriquecidos.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">El mayor diferenciador de StorageGRID es su motor de políticas de gestión del ciclo de vida de la información (ILM) que posibilita la gestión del ciclo de vida de los datos condicionada por políticas. El motor de políticas puede utilizar metadatos para gestionar cómo se almacenan los datos a lo largo de su vida útil para optimizar inicialmente el rendimiento y optimizar automáticamente los costes y la durabilidad a medida que los datos envejecen.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Habilitar el almacenamiento multinivel fluido</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">La idea básica del almacenamiento por niveles es separar las tareas del almacenamiento de datos del procesamiento de los datos. Con esta separación, resulta mucho más fácil que el nivel de almacenamiento de datos y el nivel de procesamiento de datos se escalen de forma independiente.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Una solución de almacenamiento por niveles para Confluent debe enfrentarse a dos factores. En primer lugar, debe trabajar o evitar las propiedades comunes de consistencia y disponibilidad de los almacenes de objetos, como incoherencias en las operaciones de LISTA y falta de disponibilidad de objetos ocasionales. En segundo lugar, debe manejar correctamente la interacción entre el almacenamiento organizado por niveles y el modelo de tolerancia a fallos y replicación de Kafka, incluida la posibilidad de que los líderes zombis sigan manteniendo rangos de desviación de nivel. El almacenamiento de objetos de NetApp proporciona tanto la disponibilidad de objetos consistente como el modelo de alta disponibilidad hacen que el almacenamiento cansado esté disponible para gamas de compensación por nivel. El almacenamiento de objetos de NetApp proporciona disponibilidad de objetos coherente y un modelo de alta disponibilidad para que el almacenamiento cansado esté disponible para equidistancias de nivel.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Con el almacenamiento por niveles, puede utilizar plataformas de alto rendimiento para lecturas y escrituras de baja latencia cerca del final de los datos en streaming. Además, puede utilizar almacenes de objetos más económicos y escalables como StorageGRID de NetApp para lecturas históricas de alto rendimiento. También disponemos de una solución técnica para Spark con la controladora de almacenamiento de netapp y nuestros detalles están aquí. La siguiente figura muestra cómo Kafka se adapta a una canalización de análisis en tiempo real.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">La figura siguiente muestra cómo StorageGRID de NetApp se integra como nivel de almacenamiento de objetos de Confluent Kafka.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">Siguiente: Detalles de la arquitectura de la solución.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp es una herramienta nativa que se usa para copiar dentro de los clústeres y crear clústeres de gran tamaño. El proceso básico de Hadoop DistCp es un flujo de trabajo de backup típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde un origen de HDFS en un destino correspondiente.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protección de datos para Hadoop y NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">Anterior: Estructura de datos proporcionada por NetApp para la arquitectura de Big Data.</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DistCp es una herramienta nativa que se usa para copiar dentro de los clústeres y crear clústeres de gran tamaño. El proceso básico de Hadoop DistCp que se muestra en la siguiente figura es un flujo de trabajo de backup típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde un origen de HDFS a un destino correspondiente. El acceso directo NFS de NetApp permite a los clientes establecer NFS como destino para la herramienta Hadoop DistCp para copiar los datos desde el origen HDFS en un recurso compartido de NFS a través de MapReduce. El acceso directo para NFS de NetApp actúa como controlador NFS de la herramienta DistCp.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">Siguiente: Descripción general de los casos prácticos de protección de datos de Hadoop.</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp cuenta con tres carteras de almacenamiento: FAS/AFF, E-Series y Cloud Volumes ONTAP. Hemos validado AFF y E-Series con el sistema de almacenamiento ONTAP para soluciones Hadoop con Apache Spark. El Data Fabric con tecnología de NetApp integra servicios y aplicaciones de gestión de datos (elementos básicos) para el acceso, control, protección y seguridad de los datos.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Información general de las soluciones Spark de NetApp</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">Anterior: Tecnología de soluciones.</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">NetApp cuenta con tres carteras de almacenamiento: FAS/AFF, E-Series y Cloud Volumes ONTAP. Hemos validado AFF y E-Series con el sistema de almacenamiento ONTAP para soluciones Hadoop con Apache Spark. El Data Fabric con tecnología de NetApp integra servicios y aplicaciones de gestión de datos (elementos básicos) para el acceso, control, protección y seguridad de los datos, como se muestra en la siguiente figura.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">El Data Fabric proporciona servicios y aplicaciones de gestión de datos.</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Los elementos básicos de la figura anterior incluyen:</block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">*Acceso directo NFS de NetApp.* proporciona los últimos clústeres Hadoop y Spark con acceso directo a volúmenes NFS de NetApp sin requisitos adicionales de software o controlador.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">*Servicios de volúmenes de cloud y Cloud Volumes ONTAP de NetApp.* almacenamiento conectado definido por software basado en ONTAP que se ejecuta en Amazon Web Services (AWS) o Azure NetApp Files (ANF) en servicios de cloud de Microsoft Azure.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">*La tecnología SnapMirror de NetApp.* ofrece funcionalidades de protección de datos entre instancias locales y de cloud de ONTAP o NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Proveedores de servicios en la nube.* estos proveedores incluyen AWS, Microsoft Azure, Google Cloud e IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.* Servicios de análisis basados en cloud como Amazon Elastic MapReduce (EMR) y Databricks en AWS, así como Microsoft Azure HDInsight y Azure Databricks.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">En la siguiente figura se muestra la solución Spark con el almacenamiento de NetApp.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Fomente la solución con almacenamiento de NetApp.</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">La solución ONTAP Spark utiliza el protocolo de acceso directo NFS de NetApp para análisis in situ y flujos de trabajo de IA, ML y DL mediante el acceso a los datos de producción existentes. Los datos de producción disponibles en los nodos de Hadoop se exportan para realizar trabajos de análisis e IA sin movimiento, ML y DL. Puede acceder a los datos para procesar en nodos Hadoop con el acceso directo NFS de NetApp o sin ellos. En Spark con el independiente o.<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Gestor de clústeres, puede configurar un volumen NFS mediante<block ref="9e2ac298651bd7b0cfb93c36f03ec623" prefix=" " category="inline-code"></block>. Validamos tres casos de uso con conjuntos de datos diferentes. Los detalles de estas validaciones se presentan en la sección “resultados de la prueba”. (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La siguiente figura muestra el posicionamiento del almacenamiento de Apache Spark/Hadoop de NetApp.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Posicionamiento del almacenamiento de Apache Spark/Hadoop de NetApp.</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Hemos identificado las características únicas de la solución Spark E-Series, la solución AFF/FAS ONTAP Spark y la solución StorageGRID Spark, y se ha realizado una validación y pruebas detalladas. Basándose en nuestras observaciones, NetApp recomienda la solución E-Series para instalaciones vírgenes y puestas en marcha escalables nuevas y la solución AFF/FAS para cargas de trabajo de análisis in situ, IA, ML y DL que utilizan datos NFS existentes, y StorageGRID para IA, APRENDIZAJE AUTOMÁTICO y análisis de datos modernos cuando se requiere almacenamiento de objetos.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Soluciones de NetApp recomendadas para Spark.</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un lago de datos es un repositorio de almacenamiento para grandes conjuntos de datos de forma nativa que se puede usar para trabajos de análisis, IA, ML y DL. Creamos un repositorio de lago de datos para las soluciones E-Series, AFF/FAS y SG6060 de StorageGRID. El sistema E-Series proporciona acceso HDFS al clúster de Hadoop Spark, mientras que se accede a los datos de producción existentes a través del protocolo de acceso directo NFS al clúster de Hadoop. Para los conjuntos de datos que residen en el almacenamiento de objetos, StorageGRID de NetApp proporciona acceso seguro S3 y S3A.</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">Siguiente: Resumen de casos de uso.</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="881214767967db331c99550277ceb793" category="summary">En esta página se describe la arquitectura de Splunk, que incluye definiciones de claves, puestas en marcha distribuidas de Splunk, SmartStore de Splunk, flujo de datos, requisitos de hardware y software, requisitos de uno y varios sitios, etc.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Arquitectura de Splunk</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">Anterior: Funciones flexibles de StorageGRID para Splunk SmartStore.</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Definiciones de claves</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">En las dos tablas siguientes se enumeran los componentes de Splunk y NetApp que se utilizan en la puesta en marcha distribuida de Splunk.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Esta tabla enumera los componentes de hardware de Splunk para la configuración distribuida de Splunk Enterprise.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Componente de Splunk</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexador</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repositorio para datos de Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Transportista universal</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsable de la incorporación de datos y el reenvío de datos a los indizadores</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Jefe de búsqueda</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">Interfaz de usuario utilizada para buscar datos en indizadores</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Maestro de clústeres</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gestiona la instalación de indizadores y cabezales de búsqueda de Splunk</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Consola de supervisión</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Herramienta de supervisión centralizada utilizada en toda la puesta en marcha</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Maestro de licencias</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">El maestro de licencias se ocupa de las licencias de Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Servidor de instalación</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Actualiza las configuraciones y distribuye las aplicaciones al componente de procesamiento</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Componente de almacenamiento</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Almacenamiento all-flash utilizado para gestionar datos de niveles activos. También se conoce como almacenamiento local.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Almacenamiento de objetos S3 utilizado para gestionar datos de nivel cálido. Utilizado por SmartStore para mover datos entre el nivel caliente y el nivel cálido. También se conoce como almacenamiento remoto.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">En esta tabla, se enumeran los componentes de la arquitectura de almacenamiento de Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Componente responsable</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Proporciona a los indizadores la posibilidad de organizar los datos en niveles desde el almacenamiento local hasta el almacenamiento de objetos.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Caliente</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">El lugar de aterrizaje donde los reenviadores universales colocan los datos recién escritos. El almacenamiento es editable y se pueden realizar búsquedas de datos. Este nivel de datos suele estar compuesto por SSD o HDD rápidos.</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Cache Manager</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gestiona la caché local de datos indexados, recupera datos en caliente del almacenamiento remoto cuando se produce una búsqueda y desaloja los datos que se utilizan con menor frecuencia de la caché.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Cálido</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Los datos se rolan lógicamente al bloque, cuyo nombre se cambia por el nivel cálido primero desde el nivel activo. Los datos dentro de este nivel están protegidos y, como el nivel activo, pueden estar compuestos por SSD o HDD de mayor capacidad. Tanto los backups incrementales como los completos son compatibles con las soluciones de protección de datos comunes.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Puestas en marcha distribuidas de Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Para admitir entornos de mayor tamaño, en los que los datos se originan en muchas máquinas, se necesita procesar grandes volúmenes de datos. Si muchos usuarios necesitan buscar los datos, puede escalar la implementación distribuyendo instancias de Splunk Enterprise entre varias máquinas. Esto se conoce como una puesta en marcha distribuida.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">En una puesta en marcha distribuida típica, cada instancia de Splunk Enterprise realiza una tarea especializada y reside en uno de los tres niveles de procesamiento correspondientes a las funciones de procesamiento principales.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">En la tabla siguiente se enumeran los niveles de procesamiento de Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Nivel</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Entrada de datos</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Transportista</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Un transportista consume datos y, a continuación, reenvía los datos a un grupo de indizadores.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indización</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indizador indexa los datos entrantes que suele recibir de un grupo de reenviadores. El indexador transforma los datos en eventos y almacena los eventos en un índice. El indizador también busca los datos indexados en respuesta a las solicitudes de búsqueda desde un cabezal de búsqueda.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestión de búsqueda</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Un jefe de búsqueda sirve como recurso central para la búsqueda. Los encabezados de búsqueda de un clúster son intercambiables y tienen acceso a las mismas búsquedas, paneles de control, objetos de conocimiento, etc., desde cualquier miembro del clúster de cabezales de búsqueda.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">En la siguiente tabla, se enumeran los componentes importantes utilizados en un entorno distribuido de Splunk Enterprise.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilidad</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Maestro de clústeres de índices</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordina las actividades y actualizaciones de un clúster de indizadores</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestión de índices</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Clúster de índices</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Grupo de indizadores de Splunk Enterprise que están configurados para replicar datos entre sí</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Despliegue del jefe de búsqueda</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Gestiona la implementación y las actualizaciones del maestro de clústeres</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestión de jefes de búsqueda</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Clúster de cabezales de búsqueda</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Grupo de jefes de búsqueda que sirve como recurso central para la búsqueda</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Equilibradores de carga</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Los componentes en clúster los utilizan para gestionar el aumento de la demanda mediante cabezales de búsqueda, indizadores y objetivos S3 para distribuir la carga entre componentes en clúster.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Load Management para componentes agrupados</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Conozca las siguientes ventajas de las puestas en marcha distribuidas de Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Acceda a fuentes de datos diversas o dispersas</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Proporcione funcionalidades para abordar las necesidades de los datos de empresas de cualquier tamaño y complejidad</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Logre una alta disponibilidad y garantice la recuperación ante desastres con replicación de datos y puesta en marcha multisitio</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">SmartStore de Splunk</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore es una funcionalidad de indexación que permite almacenar datos indexados en almacenes de objetos remotos, como Amazon S3. A medida que aumenta el volumen de datos de una instalación, la demanda de almacenamiento suele ser superior a la demanda de recursos informáticos. SmartStore permite gestionar el almacenamiento de indizadores y los recursos informáticos de forma rentable escalando dichos recursos por separado.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore introduce un nivel de almacenamiento remoto y un gestor de caché. Estas funciones permiten que los datos residan de forma local en los indizadores o en el nivel de almacenamiento remoto. El gestor de caché gestiona el movimiento de datos entre el indexador y el nivel de almacenamiento remoto, que se configura en el indexador.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Con SmartStore puede reducir al mínimo el espacio de almacenamiento de los indizadores y elegir los recursos informáticos optimizados para I/O. La mayoría de los datos residen en el almacenamiento remoto. El indizador mantiene una memoria caché local que contiene una cantidad mínima de datos: Bloques activos, copias de bloques calientes que participan en búsquedas activas o recientes y metadatos de bloques.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flujo de datos de Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Cuando los datos procedentes de diversas fuentes llegan a los indizadores, los datos se indexan y se guardan localmente en un bloque activo. El indexador también replica los datos del contenedor caliente a los indizadores de destino. Hasta ahora, el flujo de datos es idéntico al flujo de datos para los índices no SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Cuando el cucharón caliente se desplaza para calentarse, el flujo de datos diverge. El indexador de origen copia el bloque caliente en el almacén de objetos remoto (nivel de almacenamiento remoto) y deja la copia existente en su caché, ya que las búsquedas tienden a ejecutarse en datos indexados recientemente. Sin embargo, los indizadores objetivo eliminan sus copias porque el almacén remoto proporciona alta disponibilidad sin tener que conservar varias copias locales. La copia maestra del bloque reside ahora en el almacén remoto.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">La siguiente imagen muestra el flujo de datos de SmartStore de Splunk.</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">El gestor de caché del indexador es central para el flujo de datos de SmartStore. Recupera copias de cubos del almacén remoto según sea necesario para gestionar solicitudes de búsqueda. También expulsa de la caché copias de bloques antiguas o con menos búsquedas, ya que la probabilidad de que participen en las búsquedas disminuye con el tiempo.</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">El trabajo del administrador de caché consiste en optimizar el uso de la caché disponible a la vez que garantiza que las búsquedas tengan acceso inmediato a los bloques que necesitan.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">En la siguiente tabla se enumeran los componentes de software necesarios para implementar la solución. Los componentes de software que se usan en cualquier implementación de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Familia de productos</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nombre del producto</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Versión del producto</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Almacenamiento de objetos de StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise con SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Requisitos de uno y varios sitios</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">En un entorno empresarial Splunk (puestas en marcha medianas y grandes), en el que los datos se originan en muchas máquinas y donde muchos usuarios necesitan buscar los datos, puede escalar la puesta en marcha mediante la distribución de instancias de Splunk Enterprise entre uno y varios sitios.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">En la siguiente tabla, se enumeran los componentes utilizados en un entorno distribuido de Splunk Enterprise.</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">Grupo de indizadores de Splunk Enterprise configurados para replicar los datos de los demás</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Equilibradores de carga</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestión de cargas para componentes en clúster</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">En esta figura, se muestra un ejemplo de una instalación distribuida de un solo sitio.</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">En esta figura se muestra un ejemplo de una puesta en marcha distribuida multisitio.</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">En las siguientes tablas se indica el número mínimo de componentes de hardware necesarios para implementar la solución. Los componentes de hardware que se usan en implementaciones específicas de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">Independientemente de si ha puesto en marcha Splunk SmartStore y StorageGRID en un único sitio o en varios sitios, todos los sistemas se gestionan desde el GESTOR DE GRID de StorageGRID en un único panel. Consulte la sección “simple Management with Grid Manager” para obtener más información.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Esta tabla enumera el hardware utilizado para un único sitio.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disco</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacidad utilizable</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Nota</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">SG1000 de StorageGRID</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nodo de administración y equilibrador de carga</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">SG6060 de StorageGRID</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48, 8 TB (HDD NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1 PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Almacenamiento remoto</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Esta tabla enumera el hardware utilizado para una configuración multisitio (por sitio).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nodo de administración y equilibrador de carga</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Equilibrador de carga de StorageGRID de NetApp: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">El almacenamiento de objetos requiere el uso de un equilibrador de carga para presentar el espacio de nombres del almacenamiento en cloud. StorageGRID ofrece soporte para balanceadores de carga de terceros de proveedores líderes como F5 y Citrix, pero muchos clientes eligen el equilibrador StorageGRID de clase empresarial para conseguir simplicidad, resiliencia y alto rendimiento. El equilibrador de carga de StorageGRID está disponible como máquina virtual, contenedor o dispositivo creado específicamente para este fin.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">El SG1000 de StorageGRID facilita el uso de grupos de alta disponibilidad (ha) y el equilibrio de carga inteligente para conexiones de ruta de datos S3. Ningún otro sistema de almacenamiento de objetos en las instalaciones proporciona un equilibrador de carga personalizado.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">El dispositivo SG1000 ofrece las siguientes funciones:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un equilibrador de carga y, opcionalmente, un nodo de administración funciona para un sistema StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">El instalador de dispositivos StorageGRID para simplificar la puesta en marcha y la configuración de nodos</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configuración simplificada de extremos de S3 y SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Ancho de banda dedicado (frente al uso compartido de un equilibrador de carga de terceros con otras aplicaciones)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Hasta 4 x 100 Gbps de ancho de banda total Ethernet</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">La siguiente imagen muestra el dispositivo SG1000 Gateway Services.</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">El dispositivo SG6060 de StorageGRID incluye una controladora de computación (SG6060) y una bandeja de controladoras de almacenamiento (E-Series E2860) con dos controladoras de almacenamiento y 60 unidades. Este dispositivo incluye las siguientes funciones:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Escale verticalmente hasta 400 PB en un único espacio de nombres.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Hasta 4 x ancho de banda total Ethernet de 25 Gbps.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Incluye el instalador de dispositivos StorageGRID para simplificar la puesta en marcha y la configuración de nodos.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Cada dispositivo SG6060 puede tener una o dos bandejas de expansión adicionales para un total de 180 unidades.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Dos controladoras E-Series E2800 (configuración doble) para admitir conmutación por error de una controladora de almacenamiento.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Bandeja de unidades de cinco cajones que aloja sesenta unidades de 3.5 pulgadas (dos unidades de estado sólido y 58 unidades NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">La siguiente imagen muestra el dispositivo SG6060.</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Diseño de Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">En la siguiente tabla se enumera la configuración de Splunk para un solo sitio.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Núcleos</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 núcleos</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB DE RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gestiona los datos de usuario</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">La interfaz de usuario busca datos en indizadores</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Gestiona las actualizaciones de los clústeres de cabezales de búsqueda</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gestiona la instalación e los indizadores de Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Supervisión de consola y maestro de licencias</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Realiza supervisión centralizada de toda la puesta en marcha de Splunk y gestiona las licencias de Splunk</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">En las tablas siguientes se describe la configuración de Splunk para configuraciones de varios sitios.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Esta tabla enumera la configuración de Splunk para una configuración multisitio (sitio A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsable de la incorporación de datos y el reenvío de datos a los indizadores.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Realiza supervisión centralizada de toda la puesta en marcha de Splunk y gestiona las licencias de Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Esta tabla enumera la configuración de Splunk para una configuración multisitio (sitio B).</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">Siguiente: Rendimiento de SmartStore para un único sitio.</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">En este caso de uso, el requisito del cliente es crear de forma rápida y eficiente clústeres Hadoop/Spark basados en un clúster de Hadoop existente que contenga una gran cantidad de datos de análisis para DevTest y fines de generación de informes en el mismo centro de datos y en ubicaciones remotas.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Caso de uso 3: Activación de DevTest en datos de Hadoop existentes</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">Anterior: Caso de uso 2: Backup y recuperación ante desastres del cloud a las instalaciones.</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">En este escenario, se han creado varios clústeres de Spark/Hadoop a partir de una implementación de lagos de datos de Hadoop en las instalaciones y en ubicaciones de recuperación ante desastres.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Cree varios clústeres de Hadoop para DevTest, QA o cualquier otro propósito que requiera el acceso a los mismos datos de producción. El reto que se plantea es clonar un clúster de Hadoop de gran tamaño varias veces al instante y con una gestión muy eficiente del espacio.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Sincronice los datos de Hadoop con los equipos de generación de informes y DevTest para obtener eficiencia operativa.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribuya los datos de Hadoop mediante las mismas credenciales en los clústeres de producción y nuevos.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Use directivas programadas para crear de forma eficaz clústeres de control de calidad sin que ello afecte al clúster de producción.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">La tecnología FlexClone se utiliza para responder a los requisitos que acabamos de describir. La tecnología FlexClone es la copia de lectura/escritura de una copia Snapshot. Lee los datos de la copia snapshot principal y consume únicamente espacio adicional para los bloques nuevos o modificados. Es rápida y permite ahorrar espacio.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">En primer lugar, se creó una copia Snapshot del clúster existente mediante un grupo de consistencia de NetApp.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">Las copias de Snapshot dentro de NetApp System Manager o del símbolo del sistema del administrador del almacenamiento. Las copias Snapshot del grupo de consistencia son copias Snapshot de grupos coherentes con las aplicaciones y el volumen FlexClone se crea en función de las copias Snapshot del grupo de consistencia. Vale la pena mencionar que un volumen FlexClone hereda la política de exportación NFS del volumen principal. Una vez creada la copia snapshot, debe instalarse un nuevo clúster de Hadoop con fines de DevTest y generación de informes, como se muestra en la siguiente figura. El módulo de análisis in situ accede al volumen NFS clonado desde el nuevo clúster de Hadoop a través de los usuarios del módulo de análisis in situ y de la autorización del grupo para los datos de NFS.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">Para tener acceso adecuado, el nuevo clúster debe tener el mismo UID y GUID para los usuarios configurados en los usuarios del módulo de análisis in situ y las configuraciones de grupo.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Esta imagen muestra el clúster de Hadoop para DevTest.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">Siguiente: Caso práctico 4 - Protección de datos y conectividad multicloud.</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">En esta configuración, le mostramos cómo leer y escribir temas en almacenamiento de objetos de Kafka directamente con el conector Kafka s3 sink. Para esta prueba, utilizamos un clúster Confluent independiente, pero esta configuración se aplica a un clúster distribuido.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Conector confluent s3</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Anterior: Pruebas de rendimiento con escalabilidad.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">El conector Amazon S3 Sink exporta datos de temas de Apache Kafka a objetos de S3 en formato Avro, JSON o bytes. El conector hunk de Amazon S3 sondea periódicamente datos de Kafka y, a su vez, los carga en S3. Se utiliza un particionador para dividir los datos de cada partición de Kafka en fragmentos. Cada fragmento de datos se representa como un objeto S3. El nombre de clave codifica el tema, la partición Kafka y el desplazamiento inicial de este fragmento de datos.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Descargar Confluent Kafka desde el sitio web de Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Desembale el paquete en una carpeta del servidor.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exportar dos variables.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Para una configuración independiente Confluent Kafka, el clúster crea una carpeta raíz temporal en<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>. También crea Zookeeper, Kafka, un registro de esquemas, Connect, un ksql-Server, y las carpetas del centro de control y copia sus archivos de configuración respectivos desde<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>. Consulte el siguiente ejemplo:</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Configure Zookeeper. No es necesario cambiar nada si utiliza los parámetros predeterminados.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">En la configuración anterior, actualizamos la<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> propiedad. De forma predeterminada, se necesitan tres Zookeepers para la selección de líder de Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Hemos creado un archivo myid en<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> Con un ID único:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Utilizamos el último número de direcciones IP para el archivo myid. Hemos utilizado los valores predeterminados para Kafka, Connect, control-centre, Kafka, Kafka-Rest, ksql-server y configuraciones de registro de esquema.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Inicie los servicios de Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Hay una carpeta de registro para cada configuración, lo que ayuda a solucionar problemas. En algunos casos, los servicios tardan más tiempo en iniciarse. Asegúrese de que todos los servicios estén activos y en funcionamiento.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Instale Kafka Connect con<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block>.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">También puede instalar una versión específica mediante<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">De forma predeterminada,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> está instalado en<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Actualice la ruta de plugins con el nuevo<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Detenga los servicios Confluent y reinícielos.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configure el ID de acceso y la clave secreta en la<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Verifique que se pueda acceder al cucharón.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configure el archivo de propiedades s3-hunden para la configuración de bloques y s3.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importe unos pocos registros en el bloque de s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Cargue el conector del receptor s3.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Compruebe el estado del receptor s3.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Revise el registro para asegurarse de que el receptor s3 esté listo para aceptar temas.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Consulta los temas en Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Compruebe los objetos en el bloque de s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Para verificar el contenido, copie cada archivo desde S3 en el sistema de archivos local ejecutando el siguiente comando:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archivos Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Para imprimir los registros, utilice avro-tools-1.11.0.1.jar (disponible en<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>).</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">Siguiente: Clústeres de autoreequilibrio confluentes.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">En esta sección se describen las ventajas empresariales de esta solución.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Beneficios empresariales</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">Anterior: HDFS y MapR-FS para NFS de ONTAP.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Mover datos de análisis de Big Data a IA proporciona los siguientes beneficios:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">La capacidad de extraer datos de diferentes sistemas de archivos Hadoop y GPFS en un sistema de almacenamiento NFS unificado</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Una forma automatizada e integrada en Hadoop de transferir datos</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Reducción del coste del desarrollo de bibliotecas para el traslado de datos desde sistemas de archivos Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Máximo rendimiento mediante el procesamiento agregado de varias interfaces de red desde una única fuente de datos mediante NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Métodos programados y bajo demanda para la transferencia de datos</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">La eficiencia del almacenamiento y la capacidad de gestión empresarial para los datos de NFS unificados mediante el software de gestión de datos ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Coste cero del movimiento de datos con el método de transferencia de datos de Hadoop</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">Siguiente: GPFS a los pasos detallados de NFS.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp ofrece una solución sencilla y escalable para Splunk SmartStore que maximiza el rendimiento y la resiliencia, a la vez que proporciona un TCO atractivo.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">En esta validación, utilizamos cuatro servidores como servidores de disco compartido de red (NSD) para proporcionar discos físicos para GPFS. GPFS se crea en la parte superior de los discos NSD para exportarlos como exportaciones NFS, de modo que los clientes NFS puedan acceder a ellos, como se muestra en la siguiente figura. Utilizamos XCP para copiar los datos de GPFS- exportó NFS a un volumen NFS de NetApp.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS a NFS de ONTAP de NetApp</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">Anterior: Solución de movimiento de datos para IA.</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Aspectos básicos GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Los siguientes tipos de nodo se utilizan en GPFS:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Nodo Admin.* especifica un campo opcional que contiene un nombre de nodo utilizado por los comandos de administración para comunicarse entre nodos. Por ejemplo, el nodo de administración<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> se puede pasar una comprobación de red a los demás nodos del clúster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Nodo de quórum.* determina si se incluye un nodo en el grupo de nodos a partir del cual se deriva el quórum. Necesita al menos un nodo como nodo de quórum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nodo del administrador.* indica si un nodo forma parte del grupo de nodos desde el que se pueden seleccionar los administradores del sistema de archivos y los gestores de token. Se recomienda definir más de un nodo como nodo de gestión. La cantidad de nodos que designe como administrador depende de la carga de trabajo y el número de licencias de servidores GPFS que tenga. Si ejecuta trabajos paralelos grandes, es posible que necesite más nodos de gestión que en un clúster de cuatro nodos que admita una aplicación web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Servidor NSD.* el servidor que prepara cada disco físico para su uso con GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Nodo de protocolo.* el nodo que comparte datos GPFS directamente a través de cualquier protocolo Secure Shell (SSH) con el NFS. Este nodo requiere una licencia de servidor GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Lista de operaciones para GPFS, NFS y XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">En esta sección se proporciona la lista de operaciones que crean GPFS, exportan GPFS como una exportación NFS y transfieren los datos mediante XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Cree GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Para crear GPFS, complete los siguientes pasos:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Descargue e instale el acceso a datos a escala de espectro para la versión Linux en uno de los servidores.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Instale el paquete de requisitos previos (chef, por ejemplo) en todos los nodos y deshabilite Security-Enhanced Linux (SELinux) en todos los nodos.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configure el nodo de instalación y añada el nodo admin y el nodo GPFS al archivo de definición de clúster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Añada el nodo de gestión, el nodo de quórum, los servidores NSD y el nodo GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Añada los nodos GUI, admin y GPFS y añada un servidor GUI adicional, si es necesario.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Añada otro nodo GPFS y compruebe la lista de todos los nodos.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Especifique un nombre de clúster, un perfil, un binario de shell remoto, un binario de copia de archivos remota y un rango de puertos que se establecerá en todos los nodos GPFS en el archivo de definición de clúster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Vea las opciones de configuración de GPFS y añada un nodo de administración adicional.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Deshabilite la recogida de datos y cargue el paquete de datos en el Centro de soporte de IBM.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Habilite NTP y realice las comprobaciones previas de las configuraciones antes de realizar la instalación.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurar, crear y comprobar los discos NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Cree el GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Monte el GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Verifique y proporcione los permisos necesarios para el GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Verifique que GPFS lea y escriba mediante la ejecución del<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Exporte GPFS a NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Para exportar GPFS a NFS, complete los siguientes pasos:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exporte GPFS como NFS a través de la<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Instale los paquetes de servidor NFS necesarios.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Inicie el servicio NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Enumere los archivos de los en GPFS para validar el cliente NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configuración del cliente NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Para configurar el cliente NFS, realice los siguientes pasos:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exporte el GPFS como NFS a través del<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Inicie los servicios del cliente NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Monte el GPFS a través del protocolo NFS en el cliente NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Valide la lista de archivos GPFS en la carpeta montada de NFS.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Mueva los datos de GPFS exportados NFS a NFS de NetApp mediante XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Valide los archivos GPFS en el cliente NFS.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">Siguiente: HDFS y MapR-FS para NFS de ONTAP.</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Este informe técnico destaca las ventajas que NetApp ofrece a una solución SmartStore de Splunk, a la vez que demuestra un marco para diseñar y dimensionar Splunk SmartStore en su entorno. El resultado es una solución sencilla, escalable y flexible que ofrece un TCO atractivo.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: StorageGRID de NetApp con Splunk SmartStore</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">Karthikeyan Nagalingam, Bobby Oommen, Joseph Kandatillparambil</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise es la solución de gestión de eventos e información de seguridad (SIEM) líder del mercado que promueve los resultados en los equipos de seguridad, TI y DevOps. Los volúmenes de datos siguen creciendo a tasas exponencial y creando oportunidades masivas para las empresas que pueden aprovechar este gran recurso. Splunk Enterprise sigue mejorando la adopción en una gran variedad de casos de uso. A medida que aumentan los casos de uso, también lo hace la cantidad de datos que procesa y procesa Splunk Enterprise. La arquitectura tradicional de Splunk Enterprise es un diseño de escalado horizontal distribuido que proporciona un excelente acceso a los datos y disponibilidad. Sin embargo, las empresas que utilizan esta arquitectura deben enfrentarse a costes cada vez mayores asociados a la ampliación para satisfacer el rápido crecimiento del volumen de datos.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore con StorageGRID de NetApp soluciona este reto ofreciendo un nuevo modelo de puesta en marcha en el que la tecnología y el almacenamiento son independientes. Esta solución también libera una flexibilidad y un escalado inigualables para entornos Splunk Enterprise, ya que permite a los clientes escalar en uno o varios sitios, todo ello al tiempo que reducen los costes, al permitir que la computación y el almacenamiento se escalan de forma independiente y añaden un almacenamiento de objetos inteligente por niveles en el cloud rentable basado en el almacenamiento de objetos S3.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">La solución optimiza la cantidad de datos en el almacenamiento local al tiempo que mantiene el rendimiento de las búsquedas, lo que permite escalar la computación y el almacenamiento bajo demanda. SmartStore evalúa automáticamente los patrones de acceso a datos para determinar qué datos deben estar accesibles para los análisis en tiempo real y qué datos deben residir en el almacenamiento de objetos S3 de menor coste.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Este informe técnico destaca las ventajas que NetApp ofrece a una solución SmartStore de Splunk, a la vez que demuestra un marco para diseñar y dimensionar Splunk SmartStore en su entorno. El resultado es una solución sencilla, escalable y flexible que ofrece un TCO atractivo. StorageGRID proporciona el almacenamiento de objetos basado en API/protocolo S3 escalable y rentable, también conocido como almacenamiento remoto, lo que permite a las organizaciones escalar su solución Splunk a un coste menor y, a la vez, aumentar la resiliencia.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore hace referencia al almacenamiento de objetos como almacenes remotos o niveles de almacenamiento remoto.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Información sobre StorageGRID de NetApp</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">StorageGRID de NetApp es una solución de almacenamiento de objetos definida por software para grandes archivos, repositorios de medios y almacenes de datos web. Con StorageGRID, NetApp aprovecha dos décadas de experiencia al ofrecer soluciones líderes en el sector en innovación y gestión de datos, mientras ayuda a las organizaciones a gestionar y maximizar el valor de su información tanto en las instalaciones como en puestas en marcha de cloud público, privado o híbrido.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID proporciona almacenamiento seguro y duradero para datos no estructurados a escala. Las políticas integradas de gestión del ciclo de vida basadas en metadatos optimizan la ubicación de los datos a lo largo de toda su vida. El contenido se sitúa en la ubicación adecuada, en el momento justo y en el nivel de almacenamiento adecuado para reducir los costes. El espacio de nombre único permite acceder a los datos mediante una única llamada, independientemente de la ubicación geográfica del almacenamiento de StorageGRID. Los clientes pueden poner en marcha y gestionar varias instancias de StorageGRID entre centros de datos y en la infraestructura de cloud.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un sistema StorageGRID está compuesto por nodos heterogéneos, redundantes y distribuidos globalmente que se pueden integrar con aplicaciones de cliente existentes y de próxima generación.</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape recientemente ha nombrado a NetApp como líder en el último informe, IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment. Con casi 20 años de puestas en marcha en producción en los sectores más exigentes, StorageGRID es un líder reconocido en datos no estructurados.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Con StorageGRID, puede lograr lo siguiente:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Ponga en marcha varias instancias de StorageGRID para acceder a los datos desde cualquier ubicación entre los centros de datos y el cloud a través de un único espacio de nombres que puede ampliarse fácilmente a cientos de petabytes.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Proporciona flexibilidad para poner en marcha y gestionar de forma centralizada las diferentes infraestructuras.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Proporcione una durabilidad sin igual con una durabilidad de quince nueves aprovechando el código de borrado por capas (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Habilite funcionalidades multicloud híbridas más completas con integraciones validadas en Amazon S3 Glacier y Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Cumpla las obligaciones normativas y facilite el cumplimiento gracias a una retención de datos a prueba de manipulaciones, sin necesidad de contar con API propias ni de bloqueo del proveedor.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Página de inicio de StorageGRID de NetApp</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Si quiere más información sobre cómo StorageGRID puede ayudarle a solucionar sus problemas de gestión de datos no estructurados más complejos, consulte<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>.</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Acerca de Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise es una plataforma para convertir los datos en algo más que hacer. Los indizadores de Splunk envían y analizan los datos generados por diversas fuentes, como archivos de registro, sitios web, dispositivos, sensores y aplicaciones, lo que le permite obtener información valiosa a partir de los datos. Puede identificar infracciones de seguridad de los datos, señalar tendencias de clientes y productos, buscar oportunidades para optimizar la infraestructura o crear información procesable en una amplia variedad de casos de uso.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Acerca de Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore amplía las ventajas de la arquitectura de Splunk a la vez que simplifica su capacidad de escalar de forma rentable. La separación de los recursos informáticos y de almacenamiento provoca que los nodos de indexación se optimicen para I/o con una necesidad de almacenamiento reducida significativamente, ya que solo almacenan un subconjunto de datos como caché. No es necesario añadir almacenamiento o computación adicional cuando solo se necesita uno de esos recursos, lo que le permite obtener un ahorro significativo en costos. Puede usar un almacenamiento de objetos rentable y fácilmente escalable basado en S3, que simplifica aún más el entorno, reduce los costes y le permite mantener un conjunto de datos más masivo.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore ofrece un valor significativo a las organizaciones, incluidos los siguientes:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Reducción de los costes de almacenamiento al mover los datos calientes a un almacenamiento de objetos S3 optimizado y rentable</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Un escalado sin problemas gracias a la disociación del almacenamiento y la computación</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Simplifica la continuidad del negocio aprovechando el almacenamiento resiliente nativo del cloud</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">Siguiente: Beneficios de esta solución.</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">Este documento describe cómo trasladar datos de análisis de Big Data y de sistemas de computación de alto rendimiento (HPC) para que se puedan utilizar en flujos de trabajo de inteligencia artificial (IA). Normalmente, la IA procesa datos NFS mediante exportaciones NFS. Sin embargo, es posible que tenga sus datos de IA en una plataforma de análisis de Big Data y de computación de alto rendimiento (HPC). Este podría ser el sistema de archivos distribuidos de Hadoop (HDFS), un objeto grande binario (Blob), el almacenamiento S3 o el sistema de archivos paralelos generales (GPFS) de IBM. En este documento, describimos cómo mover datos desde una plataforma de análisis de Big Data y GPFS a NFS mediante comandos nativos de Hadoop, el módulo de análisis in situ de NetApp (NIPAM) y NetApp XCP. En este documento también se tratan las ventajas empresariales del traslado de datos de grandes volúmenes de datos y de computación de alto rendimiento a la IA.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">En un clúster de Big Data, los datos se almacenan en HDFS o HCFS, como MapR-FS, Windows Azure Storage Blob, S3 o el sistema de archivos de Google. Realizamos pruebas con HDFS, MapR-FS y S3 como origen para copiar datos a exportación NFS de ONTAP de NetApp con la ayuda DE NIPAM mediante el comando distcp de hadoop de la fuente.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">Anterior: Retos del cliente.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">En un clúster de Big Data, los datos se almacenan en HDFS o HCFS, como MapR-FS, Windows Azure Storage Blob, S3 o el sistema de archivos de Google. Realizamos pruebas con HDFS, MapR-FS y S3 como origen para copiar datos a exportación NFS de ONTAP de NetApp con la ayuda DE NIPAM mediante el<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> desde el origen.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">El siguiente diagrama muestra el movimiento de datos típico de un clúster Spark que se ejecuta con almacenamiento HDFS a un volumen NFS de ONTAP de NetApp de manera que NVIDIA pueda procesar las operaciones de IA.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">La<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> El comando utiliza el programa MapReduce para copiar los datos. NIPAM trabaja con MapReduce para actuar como un controlador para el clúster de Hadoop al copiar datos. NIPAM puede distribuir una carga a través de varias interfaces de red para una sola exportación. Este proceso maximiza el rendimiento de la red distribuyendo los datos por varias interfaces de red cuando copia los datos de HDFS o HCFS a NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM no es compatible ni certificado con MapR.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">Siguiente: Solución de movimiento de datos para IA.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">La solución de movimiento de datos para IA se basa en las necesidades del cliente de procesar datos de Hadoop desde operaciones de IA. NetApp mueve datos de HDFS a NFS mediante EL COMANDO NIPAM. En un caso de uso, el cliente necesitaba mover datos a NFS en las instalaciones y otro cliente necesitaba mover datos de Windows Azure Storage Blob a Cloud Volumes Service para procesar los datos de las instancias de cloud de la GPU en el cloud.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Solución de movimiento de datos para IA</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">Anterior: Solución de movimiento de datos.</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">El siguiente diagrama muestra los detalles de la solución del transportador de datos.</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Para crear la solución de movimiento de datos se requieren los siguientes pasos:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">SAN de ONTAP proporciona HDFS y NAS proporciona el volumen NFS a través DE NIPAM al clúster de lago de datos de producción.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">Los datos del cliente se encuentran en HDFS y NFS. Los datos de NFS pueden ser datos de producción de otras aplicaciones que se usan para el análisis de Big Data y operaciones de IA.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La tecnología FlexClone de NetApp crea un clon del volumen NFS de producción y lo aprovisiona al clúster de IA en las instalaciones.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Los datos de un LUN DE SAN HDFS se copian en un volumen NFS con NIPAM y el<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando. NIPAM utiliza el ancho de banda de varias interfaces de red para transferir datos. Este proceso reduce el tiempo de copia de datos para poder transferir más datos.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Ambos volúmenes NFS se aprovisionan en el clúster de IA para operaciones de IA.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Para procesar datos NFS en las instalaciones con GPU en el cloud, los volúmenes NFS se duplican en el almacenamiento privado de NetApp (NPS) con la tecnología SnapMirror de NetApp y se montan en proveedores de servicios cloud para GPU.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">El cliente desea procesar datos en servicios EC2/EMR, HDInsight o DataProc en GPU de proveedores de servicios cloud. El transportador de datos de Hadoop mueve los datos de servicios de Hadoop a Cloud Volumes Services con NIPAM y el<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Los datos de Cloud Volumes Service se aprovisionan para IA a través del protocolo NFS. Los datos que se procesan mediante IA se pueden enviar en una ubicación local para análisis de Big Data, además del clúster de NVIDIA a través DE NIPAM, SnapMirror y NPS.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">En esta situación, el cliente tiene grandes datos con recuento de archivos en el sistema NAS en una ubicación remota necesaria para procesar IA en la controladora de almacenamiento de NetApp en las instalaciones. En este caso, es mejor utilizar la herramienta de migración XCP para migrar los datos a una velocidad más rápida.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">El cliente de caso de uso híbrido puede usar Cloud Sync para migrar datos en las instalaciones desde datos NFS, CIFS y S3 al cloud y viceversa para procesar la IA utilizando GPU como las de un clúster de NVIDIA. Se utilizan tanto Cloud Sync como la herramienta de migración XCP para la migración de datos NFS a ONTAP NFS de NetApp.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">Siguiente: GPFS a ONTAP NFS de NetApp.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Este documento proporciona directrices de prácticas recomendadas para el uso de Kafka con almacenamiento de NetApp, como pruebas de certificación Confluent Kafka, resultados de rendimiento, ajuste, conectores Kafka y la función de reequilibrio automático.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">Anterior: Ajuste de tamaño.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Este documento proporciona directrices de prácticas recomendadas para el uso del almacenamiento por niveles con fluidez de NetApp, como pruebas de verificación, resultados de rendimiento del almacenamiento por niveles, ajuste, conectores Confluent S3 y la función de equilibrio automático. Teniendo en cuenta las políticas de ILM, el rendimiento fluido con varias pruebas de rendimiento para la verificación y las API S3 estándares del sector, el almacenamiento de objetos StorageGRID de NetApp es una opción óptima para el almacenamiento por niveles fluido.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Qué es Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Detalles de los parámetros S3-hunk</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Almacenamiento infinito en plataforma confluente</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage: Mejores prácticas y ajuste de tamaño</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Conector de receptor Amazon S3 para la plataforma Confluent</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Tamaño de Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Ajuste de tamaño de StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Casos de uso de Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Clústeres de Kafka con equilibrio automático en una plataforma con fluidez 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">Diciembre de 2021</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">El Data Fabric con tecnología de NetApp simplifica e integra la gestión de datos en entornos cloud y en las instalaciones para acelerar la transformación digital. El Data Fabric con la tecnología de NetApp proporciona servicios y aplicaciones de gestión de datos consistentes e integrados (elementos básicos) para ofrecer visibilidad, información, acceso, control, protección y seguridad para los datos.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data Fabric con la tecnología de NetApp para la arquitectura de Big Data</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">El Data Fabric con tecnología de NetApp simplifica e integra la gestión de datos en entornos cloud y en las instalaciones para acelerar la transformación digital.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">El Data Fabric con tecnología de NetApp proporciona servicios y aplicaciones de gestión de datos consistentes e integrados (elementos básicos) para ofrecer visibilidad, información, acceso, control, protección y seguridad, como se muestra en la figura siguiente.</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Casos prácticos de clientes de Data Fabric demostrados</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">El Data Fabric con tecnología de NetApp ofrece los siguientes nueve casos prácticos contrastados a los clientes:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Acelere las cargas de trabajo de análisis</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Acelere la transformación DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Cree una infraestructura de host en el cloud</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integre los servicios de datos en el cloud</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Proteja y asegure sus datos</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimice los datos no estructurados</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Aumente la eficiencia del centro de datos</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Proporcione información y control de los datos</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Simplifique y automatice</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">En este documento se tratan dos de los nueve casos prácticos (junto con sus soluciones):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Acceso directo de NFS de NetApp</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">El acceso directo a NFS de NetApp (anteriormente conocido como módulo de análisis in situ de NetApp) (que se muestra en la siguiente figura) permite a los clientes ejecutar tareas de análisis de Big Data en sus datos NFSv3 o NFSv4 nuevos y existentes sin necesidad de mover ni copiar los datos. Evita múltiples copias de datos y elimina la necesidad de sincronizar los datos con un origen. Por ejemplo, en el sector financiero, el movimiento de datos de un lugar a otro debe cumplir con las obligaciones legales, lo que no es una tarea fácil. En esta situación, el acceso directo NFS de NetApp analiza los datos financieros desde su ubicación original. Otra ventaja clave es que el uso del acceso directo NFS de NetApp simplifica la protección de los datos de Hadoop mediante comandos nativos de Hadoop y permite que los flujos de trabajo de protección de datos aprovechen la amplia cartera de gestión de datos de NetApp.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">El acceso directo de NFS de NetApp proporciona dos tipos de opciones de puesta en marcha para clústeres Hadoop/Spark:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">De forma predeterminada, los clústeres de Hadoop/Spark utilizan el sistema de archivos distribuidos Hadoop (HDFS) para el almacenamiento de datos y el sistema de archivos predeterminado. El acceso directo NFS de NetApp puede sustituir el HDFS predeterminado por el almacenamiento NFS como sistema de archivos predeterminado, lo que permite operaciones de análisis directos en datos NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">En otra opción de puesta en marcha, el acceso directo de NFS de NetApp admite la configuración de NFS como almacenamiento adicional junto con HDFS en un único clúster de Hadoop/Spark. En este caso, el cliente puede compartir datos a través de las exportaciones NFS y acceder a ellos desde el mismo clúster junto con los datos de HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Las ventajas clave del uso del acceso directo de NFS de NetApp incluyen:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analiza los datos desde su ubicación actual, lo que evita la tarea que requiere tiempo y rendimiento, consistente en mover datos de análisis a una infraestructura de Hadoop como HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Reduce el número de réplicas de tres a una.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Permite a los usuarios desacoplar los recursos informáticos y del almacenamiento para escalar los recursos de forma independiente.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Proporciona protección de datos empresariales aprovechando las funcionalidades de gestión de datos enriquecidos de ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Está certificado con la plataforma de datos Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Habilita la puesta en marcha de análisis de datos híbridos.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Reduce el tiempo de copia de seguridad aprovechando la capacidad de multisubproceso dinámica.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Elementos básicos para Big Data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">El Data Fabric con tecnología de NetApp integra servicios y aplicaciones de gestión de datos (elementos básicos) para el acceso, control, protección y seguridad de los datos, como se muestra en la siguiente figura.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">*Acceso directo NFS de NetApp.* proporciona los últimos clústeres Hadoop y Spark con acceso directo a volúmenes NFS de NetApp sin requisitos adicionales de software o controlador.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">*La tecnología SnapMirror de NetApp*. Proporciona funcionalidades de protección de datos entre instancias locales y de ONTAP Cloud o NPS.</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">Siguiente: Protección de datos de Hadoop y NetApp.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Este caso de uso es relevante para un partner de servicio cloud que se encarga de proporcionar conectividad multicloud para los datos de análisis de Big Data de los clientes.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Caso de uso 4: Protección de datos y conectividad multicloud</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">Anterior: Caso de uso 3 - activación de DevTest en datos de Hadoop existentes.</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">En esta situación, los datos de IoT que se reciben en AWS de diferentes orígenes se almacenan en una ubicación central en NPS. El almacenamiento NPS está conectado a clústeres de Spark/Hadoop ubicados en AWS y Azure y permite que las aplicaciones de análisis de Big Data se ejecuten en varios clouds accedan a los mismos datos.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Los clientes quieren ejecutar trabajos de análisis en los mismos datos utilizando varios clouds.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Los datos deben recibirse de diferentes fuentes, como on-premises y en el cloud, mediante distintos sensores y concentradores.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La solución debe ser eficiente y rentable.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">El principal reto es crear una solución rentable y eficiente que ofrezca servicios de análisis híbridos entre sus instalaciones y clouds diferentes.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Esta imagen ilustra la solución de conectividad de múltiples clouds y protección de datos.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">Como se muestra en la figura anterior, los datos de los sensores se transmiten y ingieren en el clúster de AWS Spark a través de Kafka. Los datos se almacenan en un recurso compartido de NFS que reside en NPS, que se encuentra fuera del proveedor de cloud en un centro de datos Equinix. Dado que el almacenamiento privado de NetApp se conecta con Amazon AWS y Microsoft Azure mediante las conexiones Direct Connect y Express Route respectivamente, los clientes pueden aprovechar el módulo de análisis in situ para acceder a los datos desde los clústeres de análisis de Amazon y AWS. Este enfoque soluciona el tener que hacer análisis en cloud en varios proveedores a hiperescala.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Como consecuencia, tanto el almacenamiento en las instalaciones como el almacenamiento privado de NetApp ejecutan el software ONTAP, SnapMirror puede reflejar los datos del almacenamiento privado de NetApp en el clúster en las instalaciones, lo cual proporciona análisis del cloud híbrido entre las instalaciones y varios clouds.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Para obtener el mejor rendimiento, NetApp suele recomendar el uso de varias interfaces de red, así como rutas de conexión directa/exprés para acceder a los datos desde instancias del cloud.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">Siguiente: Caso de uso 5: Acelere las cargas de trabajo analíticas.</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise es la solución SIEM líder del mercado que impulsa los resultados en los equipos de seguridad, TECNOLOGÍA y DevOps. El uso de Splunk ha aumentado considerablemente en las organizaciones de nuestros clientes. Por lo tanto, es necesario añadir más orígenes de datos y conservar los datos durante un periodo más largo, haciendo hincapié en la infraestructura Splunk.</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">Anterior: Rendimiento de SmartStore para un único sitio.</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">La combinación de SmartStore de Splunk y StorageGRID de NetApp está diseñada para proporcionar una arquitectura escalable a las organizaciones que consigan un rendimiento de introducción de datos mejorado con el almacenamiento de objetos de SmartStore y StorageGRID, y una mayor escalabilidad para un entorno de Splunk en diversas regiones geográficas.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">Recursos de documentación de StorageGRID de NetApp</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Documentación de Splunk Enterprise</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise sobre SmartStore</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Manual de puesta en marcha distribuida de Splunk Enterprise</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterprise gestiona indizadores y clústeres de indizadores</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">Julio de 2022</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">En esta sección se presentan las lecciones aprendidas en esta certificación.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Directrices de prácticas recomendadas</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">Anterior: Clústeres de autoreequilibrio confluentes.</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Basado en nuestra validación, el almacenamiento de objetos S3 es la mejor opción para Confluent mantener los datos.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Podemos usar SAN de alto rendimiento (específicamente FC) para mantener el intermediario de datos activos o el disco local, ya que, en la configuración de almacenamiento por niveles fluido, el tamaño de los datos contenidos en el directorio de datos del brokers se basa en el tamaño del segmento y el tiempo de retención en el que se mueven los datos al almacenamiento de objetos.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Los almacenes de objetos proporcionan un mejor rendimiento cuando el segmento.bytes es mayor; probamos 512 MB.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">En Kafka, la longitud de la clave o el valor (en bytes) para cada registro producido en el tema se controla mediante el<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> parámetro. Para StorageGRID, la ingesta de objetos S3 y la recuperación de rendimiento aumentaron a valores más altos. Por ejemplo, 512 bytes proporcionaron una recuperación de 5,8 Gbps, 1024 bytes proporcionaban una recuperación de 7,5 Gbps s3 y 2048 bytes proporcionados cerca de 10 Gbps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">En la figura siguiente, se presenta la ingesta y la recuperación de objetos de S3 según<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Ajuste Kafka.* para mejorar el rendimiento del almacenamiento por niveles, puede aumentar TierFetcherNumThreads y TierArchiverNumThreads. Como guía general, desea aumentar TierFetcherNumThreads para que coincida con el número de núcleos de CPU físicos y aumentar TierArchiverNumThreads a la mitad del número de núcleos de CPU. Por ejemplo, en las propiedades del servidor, si tiene una máquina con ocho núcleos físicos, establezca confluent.tier.fetcher.num.threads = 8 y confluent.tier.archivver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervalo de tiempo para las eliminaciones de temas.* cuando se elimina un tema, la eliminación de los archivos del segmento de registro en el almacenamiento de objetos no comienza inmediatamente. En su lugar, hay un intervalo de tiempo con un valor predeterminado de 3 horas antes de que se elimine dichos archivos. Puede modificar la configuración, confluent.tier.topic.delete.check.interval.ms, para cambiar el valor de este intervalo. Si elimina un tema o clúster, también puede eliminar manualmente los objetos en el bloque correspondiente.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACL en temas internos de almacenamiento por niveles.* una práctica recomendada para implementaciones en las instalaciones es habilitar un autorizador de ACL en los temas internos utilizados para el almacenamiento por niveles. Defina las reglas de ACL para limitar el acceso a estos datos sólo al usuario de broker. De este modo, se protegen los temas internos y se evita el acceso no autorizado a metadatos y datos de almacenamiento por niveles.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Sustituya al usuario<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> con el agente principal en la puesta en marcha.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Por ejemplo, el comando<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> Define las ACL en el tema interno para el almacenamiento por niveles. Actualmente, solo existe un solo tema interno relacionado con el almacenamiento por niveles. El ejemplo crea una ACL que proporciona el permiso Kafka principal para todas las operaciones del tema interno.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">Siguiente: Ajuste de tamaño.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Este documento se centra en la arquitectura Apache Spark, los casos prácticos de clientes y la cartera de almacenamiento de NetApp relacionada con el análisis de Big Data e inteligencia artificial. También presenta diversos resultados de pruebas utilizando IA, aprendizaje automático y herramientas de aprendizaje profundo estándar del sector en comparación con un sistema Hadoop típico, de modo que puede elegir la solución Spark adecuada.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Soluciones de almacenamiento de NetApp para Apache Spark: Arquitectura, casos prácticos y resultados de rendimiento</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Este documento se centra en la arquitectura Apache Spark, los casos prácticos de clientes y la cartera de almacenamiento de NetApp relacionada con el análisis de Big Data e inteligencia artificial (IA). También presenta diversos resultados de pruebas utilizando herramientas estándar del sector de IA, aprendizaje automático (ML, por sus siglas en inglés) y aprendizaje profundo (DL, por sus siglas en inglés) frente a un sistema Hadoop típico, de modo que pueda elegir la solución Spark adecuada. Para empezar, necesita una arquitectura Spark, componentes adecuados y dos modos de puesta en marcha (clúster y cliente).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Este documento también proporciona casos de uso para clientes que se ocupan de problemas relacionados con la configuración. En él se aborda una descripción general de la cartera de almacenamiento de NetApp relevante para análisis de Big Data e IA, ML y DL con Spark. Después, terminamos con los resultados de las pruebas obtenidas de los casos prácticos específicos de Spark y la cartera de soluciones de NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Retos del cliente</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Esta sección se centra en los retos de los clientes con análisis de Big Data e IA/ML/DL en sectores de crecimiento de datos como el comercio minorista, el marketing digital, la banca, la fabricación discreta, la fabricación de procesos, ee. uu. y servicios profesionales.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Rendimiento imprevisible</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Las puestas en marcha tradicionales de Hadoop suelen usar hardware genérico. Para mejorar el rendimiento, debe ajustar la red, el sistema operativo, el clúster de Hadoop, los componentes del ecosistema como Spark y el hardware. Aunque ajuste cada capa, puede resultar difícil lograr los niveles de rendimiento deseados, porque Hadoop utiliza hardware genérico que no se ha diseñado para ofrecer un alto rendimiento en su entorno.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Fallos de medios y nodos</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Incluso en condiciones normales, el hardware genérico es propenso a sufrir fallos. Si falla un disco en un nodo de datos, el maestro de Hadoop considera de forma predeterminada que ese nodo no está en buen estado. A continuación, copia datos específicos de ese nodo a través de la red de réplicas en un nodo en buen estado. Este proceso ralentiza los paquetes de red para cualquier trabajo de Hadoop. A continuación, el clúster debe volver a copiar los datos y eliminar los datos replicados en exceso cuando el nodo que no está en buen estado vuelva.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Bloqueo del proveedor de Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Los distribuidores de Hadoop tienen su propia distribución de Hadoop con su propio control de versiones, lo que bloquea al cliente para dichas distribuciones. Sin embargo, muchos clientes requieren compatibilidad con el análisis en memoria que no enlaza al cliente con distribuciones específicas de Hadoop. Necesitan tener libertad para cambiar las distribuciones y llevar sus análisis con ellas.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Falta de apoyo para más de un idioma</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Los clientes a menudo requieren soporte para varios idiomas además de los programas Java de MapReduce para ejecutar sus trabajos. Las opciones como SQL y scripts proporcionan más flexibilidad para obtener respuestas, más opciones para organizar y recuperar datos y formas más rápidas de mover datos a un marco de análisis.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Dificultad de uso</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Desde hace algún tiempo, la gente se ha quejado de que Hadoop es difícil de usar. Aunque Hadoop se ha vuelto más sencillo y potente con cada nueva versión, esta crítica se ha mantenido. Hadoop requiere que comprenda los patrones de programación de Java y MapReduce, un reto para los administradores de bases de datos y las personas con conjuntos de habilidades de scripting tradicionales.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Marcos y herramientas complicados</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">Los equipos de IA de las empresas se enfrentan a diferentes retos. Incluso con conocimientos especializados en ciencia de datos, es posible que las herramientas y los marcos para diferentes ecosistemas y aplicaciones de puesta en marcha no se traduzcan simplemente de uno a otro. Una plataforma de ciencia de datos debe integrarse perfectamente con las plataformas de big data correspondientes basadas en Spark con facilidad de movimiento de datos, modelos reutilizables, código listo para usar y herramientas que admiten las mejores prácticas para la creación de prototipos, la validación, el control de versiones, el uso compartido, la reutilización, y poner en marcha rápidamente modelos para la producción.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">¿Por qué elegir NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp puede mejorar su experiencia con Spark de las siguientes maneras:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">El acceso directo de NFS de NetApp (que se muestra en la siguiente figura) permite a los clientes ejecutar trabajos de análisis de Big Data en sus datos NFSv3 o NFSv4 existentes o nuevos sin necesidad de mover ni copiar los datos. Evita múltiples copias de datos y elimina la necesidad de sincronizar los datos con un origen.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Almacenamiento más eficiente y menos replicación de servidor. Por ejemplo, la solución E-Series para Hadoop de NetApp requiere dos en lugar de tres réplicas de los datos y la solución para Hadoop de FAS requiere un origen de datos pero no una replicación o copias de estos. Las soluciones de almacenamiento de NetApp también producen menos tráfico de servidor a servidor.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Mejor comportamiento del clúster y de las tareas de Hadoop durante el fallo de unidades y nodos.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Mejor rendimiento de procesamiento de datos.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configuraciones alternativas de Apache Spark.</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Por ejemplo, en el sector financiero y sanitario, el traslado de datos de un lugar a otro debe cumplir con obligaciones legales, lo que no es una tarea fácil. En esta situación, el acceso directo NFS de NetApp analiza los datos financieros y sanitarios desde su ubicación original. Otra ventaja clave es que el uso del acceso directo de NFS de NetApp simplifica la protección de datos de Hadoop mediante comandos nativos de Hadoop y permite flujos de trabajo de protección de datos con la cartera de gestión de datos enriquecidos de NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">El acceso directo de NFS de NetApp proporciona dos tipos de opciones de puesta en marcha para clústeres Hadoop/Spark:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">De forma predeterminada, los clústeres de Hadoop o Spark utilizan el sistema de archivos distribuidos de Hadoop (HDFS) para el almacenamiento de datos y el sistema de archivos predeterminado. El acceso directo de NFS de NetApp puede sustituir el HDFS predeterminado por el almacenamiento NFS como sistema de archivos predeterminado, lo que permite el análisis directo de datos NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">En otra opción de puesta en marcha, el acceso directo de NFS de NetApp admite la configuración de NFS como almacenamiento adicional junto con HDFS en un único clúster de Hadoop o Spark. En este caso, el cliente puede compartir datos a través de las exportaciones NFS y acceder a ellos desde el mismo clúster junto con los datos de HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Algunas de las ventajas clave del acceso directo de NFS de NetApp son las siguientes:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Análisis de los datos desde su ubicación actual, lo que evita la tarea que requiere tiempo y rendimiento, consistente en mover datos de análisis a una infraestructura de Hadoop como HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Reducción del número de réplicas de tres a una.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Permitiendo a los usuarios desacoplar los recursos informáticos y del almacenamiento para escalarlos de forma independiente.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Protege los datos empresariales aprovechando las funcionalidades de gestión de datos enriquecidos de ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certificado en la plataforma de datos Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Habilitar la puesta en marcha de análisis de datos híbridos.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Reducción del tiempo de backup aprovechando la funcionalidad de multisubproceso dinámica.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link">TR-4657: Soluciones de datos para el cloud híbrido de NetApp: Spark y Hadoop en función de casos prácticos de clientes</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">Consulte<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Para realizar backups de los datos de Hadoop, realice backups y recuperación ante desastres desde el cloud a las instalaciones, y permita DevTest en los datos de Hadoop existentes, la protección de datos y la conectividad multicloud, así como acelerar las cargas de trabajo analíticas.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">En las siguientes secciones se describen las funcionalidades de almacenamiento que son importantes para los clientes de Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Niveles de almacenamiento</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Con el almacenamiento por niveles de Hadoop, puede almacenar archivos con diferentes tipos de almacenamiento según una normativa de almacenamiento. Los tipos de almacenamiento incluyen<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block>,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block>,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block>,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block>, y.<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>.</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD validamos el almacenamiento por niveles de Hadoop en una controladora de almacenamiento AFF de NetApp y una controladora de almacenamiento E-Series con unidades SSD y SAS con políticas de almacenamiento diferentes. El clúster Spark con AFF-A800 tiene cuatro nodos de trabajo de computación, mientras que el clúster con E-Series tiene ocho. Esto se compara principalmente con el rendimiento de las unidades de estado sólido (SSD) en comparación con los discos de disco duro (HDD).</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">Validamos el almacenamiento por niveles de Hadoop en una controladora de almacenamiento AFF de NetApp y una controladora de almacenamiento E-Series con unidades SSD y SAS con políticas de almacenamiento diferentes. El clúster Spark con AFF-A800 tiene cuatro nodos de trabajo de computación, mientras que el clúster con E-Series tiene ocho. Esto se realizó principalmente para comparar el rendimiento de las unidades de estado sólido con los discos duros. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca61120ce05edc7b0b9607b96eae</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La siguiente figura muestra el rendimiento de las soluciones de NetApp para SSD de Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Tiempo para ordenar 1 TB de datos.</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 solución E-Series de NetApp para Hadoop</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">La configuración de NL-SAS de referencia utilizó ocho nodos de computación y 96 unidades NL-SAS. Esta configuración generó 1 TB de datos en 4 minutos y 38 segundos. Consulte<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> para obtener detalles sobre el clúster y la configuración de almacenamiento.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Con TeraGen, la configuración de SSD generó 1 TB de datos 15,6 veces más rápido que la configuración NL-SAS. Además, la configuración de SSD utilizó la mitad de la cantidad de nodos de computación y la mitad de la cantidad de unidades de disco (24 unidades SSD en total). Según el tiempo para completar la tarea, era casi el doble de rápido que la configuración de NL-SAS.</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">Con TeraSort, la configuración de SSD ordena 1 TB de datos 1138.36 veces más rápido que la configuración de NL-SAS. Además, la configuración de SSD utilizó la mitad de la cantidad de nodos de computación y la mitad de la cantidad de unidades de disco (24 unidades SSD en total). Por lo tanto, por unidad, era aproximadamente tres veces más rápida que la configuración de NL-SAS. &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; CABEZA</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">La ventaja es que la transición de los discos giratorios a all-flash mejora el rendimiento. El número de nodos de computación no era el cuello de botella. Con el almacenamiento all-flash de NetApp, el rendimiento del tiempo de ejecución se escala bien.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Con NFS, los datos eran funcionalmente equivalentes a los agrupados en pools, lo que puede reducir el número de nodos de computación en función de la carga de trabajo. Los usuarios del clúster de Apache Spark no tienen que reequilibrar manualmente los datos cuando se cambia el número de nodos de computación.</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">En resumen, la transición de discos giratorios a all-flash mejora el rendimiento. El número de nodos de computación no era el cuello de botella. Con el almacenamiento all-flash de NetApp, el rendimiento del tiempo de ejecución se escala bien.</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">Con NFS, los datos eran funcionalmente equivalentes a los agrupados en pools, lo que puede reducir el número de nodos de computación en función de la carga de trabajo. Los usuarios de clúster de Apache Spark no necesitan reequilibrar manualmente los datos cuando se cambia el número de nodos de computación. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca61120ce05edc7b0b9607b96eae</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Escalado del rendimiento: Escalado horizontal</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Cuando necesite más capacidad informática de un clúster de Hadoop en una solución AFF, puede añadir nodos de datos con un número adecuado de controladoras de almacenamiento. NetApp recomienda comenzar con cuatro nodos de datos por cabina de controladora de almacenamiento y aumentar el número a ocho nodos de datos por controladora de almacenamiento, en función de las características de la carga de trabajo.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF y FAS son perfectos para análisis in situ. En función de los requisitos de computación, puede agregar administradores de nodos y las operaciones no disruptivas le permiten agregar una controladora de almacenamiento bajo demanda sin tiempo de inactividad. Ofrecemos completas funciones con AFF y FAS, como soporte de medios NVME, eficiencia garantizada, reducción de datos, CALIDAD DE SERVICIO, análisis predictivos, organización en niveles del cloud, replicación, puesta en marcha de cloud y seguridad. Para ayudar a los clientes a cumplir sus requisitos, NetApp ofrece funciones como análisis del sistema de archivos, cuotas y equilibrio de carga integrado sin costes de licencia adicionales. NetApp ofrece un mejor rendimiento en el número de tareas simultáneas, menor latencia, operaciones más sencillas y un mayor rendimiento de gigabytes por segundo que el de la competencia. Además, Cloud Volumes ONTAP de NetApp se ejecuta en los tres principales proveedores de cloud.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Escalado del rendimiento: Escalado vertical</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Las funciones de escalado vertical le permiten agregar unidades de disco a sistemas AFF, FAS y E-Series cuando necesita capacidad de almacenamiento adicional. Con Cloud Volumes ONTAP, el escalado del almacenamiento a nivel de PB es una combinación de dos factores: La organización en niveles de los datos que se usan con poca frecuencia en el almacenamiento de objetos desde el almacenamiento de bloques y la apilamiento de licencias Cloud Volumes ONTAP sin necesidad de procesamiento adicional.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Múltiples protocolos</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">Los sistemas NetApp son compatibles con la mayoría de protocolos para puestas en marcha de Hadoop, como SAS, iSCSI, FCP, InfiniBand, Y NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Soluciones operativas y compatibles</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MAPR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certificación</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">como partner</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">Las soluciones para Hadoop que se describen en este documento son compatibles con NetApp. Estas soluciones también están certificadas con los principales distribuidores de Hadoop. Para obtener más información, consulte<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> sitio, el<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> Local y Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> y..<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> sitios web.</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">Siguiente: Público objetivo.</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">En esta sección se trata el hardware y el software empleados para la certificación Confluent. Esta información se aplica a la puesta en marcha de Kafka con el almacenamiento de NetApp.</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Anterior: Directrices de mejores prácticas.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">El ajuste de tamaño de Kafka se puede realizar con cuatro modos de configuración: Sencillo, granular, inverso y particiones.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Sencillo</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">El modo simple es apropiado por primera vez para los usuarios de Apache Kafka o los casos de uso de estado anteriores. Para este modo, se proporcionan requisitos como el rendimiento en Mbps, el ventilador de lectura, la retención y el porcentaje de utilización de recursos (el 60% es el predeterminado). También puede entrar al entorno, como en las instalaciones (con configuración básica, VMware, Kubernetes u OpenStack) o en el cloud. Basándose en esta información, el tamaño de un clúster Kafka proporciona el número de servidores necesarios para el corredor, el zookeeper, los trabajadores de Apache Kafka connect, el registro de esquemas, un proxy REST, ksqlDB y el centro de control de Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">En el caso del almacenamiento por niveles, tenga en cuenta el modo de configuración granular para ajustar el tamaño de un clúster Kafka. El modo granular es adecuado para usuarios con experiencia de Apache Kafka o casos de uso bien definidos. En esta sección se describe el dimensionamiento para los productores, los procesadores de flujo y los consumidores.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Productores</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Para describir a los productores de Apache Kafka (por ejemplo, un cliente nativo, proxy REST o conector Kafka), proporcione la siguiente información:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nombre.* Spark.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">*Tipo de productor.* aplicación o servicio, proxy (REST, MQTT, otros) y base de datos existente (RDBMS, NOSQL, otros). También puede seleccionar “no lo sé”.</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Rendimiento medio.* en eventos por segundo (1,000,000 por ejemplo).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Rendimiento máximo.* en eventos por segundo (4,000,000 por ejemplo).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Tamaño medio del mensaje.* en bytes, sin comprimir (máx. 1 MB; 1000 por ejemplo).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">*Formato de mensaje.* las opciones incluyen Avro, JSON, búferes de protocolo, binario, texto, “No lo sé” y otros.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* Factor de replicación.* las opciones son 1, 2, 3 (recomendación de fluidez), 4, 5, o 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Tiempo de retención.* un día (por ejemplo). ¿Cuánto tiempo quiere que sus datos se almacenen en Apache Kafka? Introduzca -1 con cualquier unidad durante un tiempo infinito. La calculadora asume un tiempo de retención de 10 años para retención infinita.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Active la casilla de comprobación para "Habilitar el almacenamiento por niveles para reducir el número de agentes y permitir el almacenamiento por Infinite Volume?"</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Cuando se habilita el almacenamiento por niveles, los campos de retención controlan el conjunto de datos activos que se almacenan de forma local en el agente. Los campos de retención de archivado controlan el tiempo que se almacenan los datos en el almacenamiento de objetos de archivado.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Retención de almacenamiento de ficheros.* un año (por ejemplo). ¿Cuánto tiempo desea que los datos se almacenen en el almacenamiento de archivado? Introduzca -1 con cualquier unidad para una duración infinita. La calculadora asume una retención de 10 años para retención infinita.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Multiplicador de crecimiento.* 1 (por ejemplo). Si el valor de este parámetro se basa en el rendimiento actual, configúrelo en 1. Para ajustar el tamaño en función del crecimiento adicional, establezca este parámetro en un multiplicador de crecimiento.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Número de instancias de productores.* 10 (por ejemplo). ¿Cuántas instancias de productor se estarán ejecutando? Esta entrada es necesaria para incorporar la carga de la CPU en el cálculo de tamaño. Un valor en blanco indica que la carga de la CPU no está integrada en el cálculo.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Basándose en este ejemplo, el dimensionamiento tiene el siguiente efecto sobre los productores:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Promedio de rendimiento en bytes sin comprimir: 1 Gbps. Rendimiento máximo en bytes sin comprimir: 4Gbps. Rendimiento promedio en bytes comprimidos: 400 Mbps. Máximo rendimiento en bytes comprimidos: 1,6 Gbps. Esto se basa en una tasa de compresión predeterminada del 60 % (puede cambiar este valor).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Total de almacenamiento con hotset de On-broker requerido: 31,104 TB, incluyendo replicación y compresión. Almacenamiento total de archivado fuera de agentes necesario: 378,432 TB, comprimidos. Uso <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> Para ajustar el tamaño de StorageGRID.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Stream Processor debe describir sus aplicaciones o servicios que consumen datos de Apache Kafka y los vuelven a producir en Apache Kafka. En la mayoría de los casos se construyen en arroyos ksqlDB o Kafka.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nombre.* Spark streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Tiempo de procesamiento.* ¿Cuánto tarda este procesador en procesar un solo mensaje?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (simple, transformación sin estado) [ejemplo], 10 ms (funcionamiento con estado en memoria).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (funcionamiento de disco o red con estado), 1000 ms (llamada REST de terceros).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">He evaluado este parámetro y sé exactamente cuánto tiempo lleva.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Retención de salida.* 1 día (ejemplo). Un procesador de secuencias devuelve su salida a Apache Kafka. ¿Cuánto tiempo desea que estos datos de salida se almacenen en Apache Kafka? Introduzca -1 con cualquier unidad para una duración infinita.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Marque la casilla de comprobación "Habilitar el almacenamiento por niveles para reducir el número de agentes y permitir Infinite Storage?"</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Retención de almacenamiento de ficheros.* 1 año (por ejemplo). ¿Cuánto tiempo desea que los datos se almacenen en el almacenamiento de archivado? Introduzca -1 con cualquier unidad para una duración infinita. La calculadora asume una retención de 10 años para retención infinita.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Porcentaje de paso a través de salida.* 100 (por ejemplo). Un procesador de secuencias devuelve su salida a Apache Kafka. ¿Qué porcentaje de rendimiento de entrada se propondrá en Apache Kafka? Por ejemplo, si el rendimiento de entrada es de 20 Mbps y este valor es de 10, el rendimiento de salida será de 2 Mbps.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">¿De qué aplicaciones se lee? Seleccione “Spark” (Spark), el nombre utilizado en el ajuste de tamaño basado en el tipo de productor. En función de la entrada anterior, puede esperar los siguientes efectos del ajuste de tamaño en las instancias del procesador de secuencias y las estimaciones de las particiones de temas:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Esta aplicación de procesador de secuencias requiere el siguiente número de instancias. Es probable que los temas entrantes también requieran muchas particiones. Contacte con Confluent para confirmar este parámetro.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 para un rendimiento medio sin multiplicador de crecimiento</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4,000 para un rendimiento máximo sin multiplicador de crecimiento</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 para un rendimiento medio con un multiplicador de crecimiento</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4,000 para obtener el máximo rendimiento con un multiplicador de crecimiento</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consumidores</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Describa sus aplicaciones o servicios que consumen datos de Apache Kafka y no vuelven a producir en Apache Kafka; por ejemplo, un cliente nativo o un conector Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nombre.* Cliente de Spark.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Tiempo de procesamiento.* ¿Cuánto tarda este consumidor en procesar un solo mensaje?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (por ejemplo, una tarea simple y sin estado, como el registro)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (escrituras rápidas en un almacén de datos)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (escrituras lentas en un almacén de datos)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (llamada DE REST de terceros)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Algún otro proceso de referencia de duración conocida.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Tipo de consumidor.* aplicación, proxy o receptor a un almacén de datos existente (RDBMS, NoSQL, otros).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">¿De qué aplicaciones se lee? Conecte este parámetro con el tamaño del productor y del flujo determinado anteriormente.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Basándose en la información anterior, debe determinar la configuración de las instancias de cliente y las estimaciones de las particiones del tema. Una aplicación de cliente requiere el siguiente número de instancias.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2,000 para un rendimiento medio, sin multiplicador de crecimiento</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8,000 para un rendimiento máximo, sin multiplicador de crecimiento</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2,000 para un rendimiento medio, incluido el multiplicador de crecimiento</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8,000 para un rendimiento máximo, incluido el multiplicador de crecimiento</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Es probable que los temas entrantes también necesiten este número de particiones. Póngase en contacto con Confluent para confirmar.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Además de los requisitos para los productores, los procesadores de flujo y los consumidores, debe proporcionar los siguientes requisitos adicionales:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Tiempo de regeneración.* por ejemplo, 4 horas. Si un host de Apache Kafka Broker falla, sus datos se pierden y se aprovisiona un nuevo host para sustituir el host fallido, ¿con qué rapidez debe reconstruir este nuevo host? Deje este parámetro en blanco si el valor es desconocido.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Objetivo de utilización de recursos (porcentaje).* por ejemplo, 60. ¿Cómo se hace uso de los hosts durante el rendimiento medio? Confluent recomienda un aprovechamiento del 60% a menos que se utilicen clústeres de equilibrio automático Confluent, en cuyo caso el uso puede ser mayor.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Describa su entorno</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*¿En qué entorno se estará ejecutando su clúster?* Amazon Web Services, Microsoft Azure, plataforma en nube de Google, configuración básica en las instalaciones, VMware en las instalaciones, ¿OpenStack en las instalaciones o Kubas en el entorno local?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Detalles del host.* número de núcleos: 48 (por ejemplo), tipo de tarjeta de red (10 GbE, 40 GbE, 16 GbE, 1 GbE u otro tipo).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volúmenes de almacenamiento.* Host: 12 (por ejemplo). ¿Cuántos discos duros o SSD son compatibles por host? Confluent recomienda 12 unidades de disco duro por host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacidad de almacenamiento/volumen (en GB).* 1000 (por ejemplo). ¿Cuánto almacenamiento puede almacenar un volumen único en gigabytes? Confluent recomienda discos de 1 TB.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configuración de almacenamiento.* ¿Cómo se configuran los volúmenes de almacenamiento? Confluent recomienda RAID10 para aprovechar todas las características de Confluent. JBOD, SAN, RAID 1, RAID 0, RAID 5, y también se admiten otros tipos.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Rendimiento de volumen único (Mbps).* 125 (por ejemplo). ¿Con qué rapidez puede leer o escribir un único volumen de almacenamiento en megabytes por segundo? Confluent recomienda unidades de disco duro estándar, que normalmente tienen un rendimiento de 125 MBps.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacidad de memoria (GB).* 64 (por ejemplo).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Una vez que haya determinado sus variables de entorno, seleccione Size my Cluster. Basándonos en los parámetros de ejemplo indicados anteriormente, hemos determinado el tamaño siguiente para Confluent Kafka:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* Apache Kafka.* número de broker: 22. El clúster está vinculado al almacenamiento. Considere la posibilidad de habilitar el almacenamiento por niveles para reducir el número de hosts y permitir el almacenamiento infinito.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache ZooKeeper.* Conde: 5; Apache Kafka Connect Workers: Count: 2; Registro de esquema: Cuenta: 2; Proxy REST: Cuenta: 2; ksqlDB: Cuenta: 2; Centro de Control de Confluente: Cuenta: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilice el modo inverso para los equipos de plataformas sin tener en cuenta un caso de uso. Utilice el modo Partitions para calcular cuántas particiones necesita un solo tema. Consulte<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> para ajustar el tamaño en función de los modos inverso y de particiones.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Esta página describe los componentes utilizados para completar esta solución, incluidos StorageGRID de NetApp, Splunk Enterprise y Splunk SmartStore.</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">Anterior: Organización en niveles inteligente y ahorro de costes.</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">StorageGRID de NetApp es una plataforma de almacenamiento de objetos rentable y de alto rendimiento. Ofrece gestión de datos inteligente y global condicionada por políticas mediante una arquitectura de grid distribuida basada en nodos. Simplifica la gestión de petabytes de datos no estructurados y de miles de millones de objetos mediante su espacio de nombre de objetos global omnipresente combinado con funciones sofisticadas de gestión de datos. El acceso en una única llamada a objetos abarca varios sitios y simplifica las arquitecturas de alta disponibilidad al tiempo que garantiza un acceso continuo al objeto, independientemente de las interrupciones del servicio del sitio o de la infraestructura.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">El multi-tenancy permite que varias aplicaciones de datos empresariales no estructurados y cloud se puedan mantener de forma segura dentro del mismo grid, lo que aumenta el retorno de la inversión y los casos de uso de StorageGRID. Puede crear múltiples niveles de servicio con políticas de ciclo de vida de objetos condicionados por metadatos, y así optimizar la durabilidad, la protección, el rendimiento y la localidad en varias geografías. Los usuarios pueden ajustar las políticas y el entorno de los datos sin interrupciones a medida que cambien sus requisitos.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore utiliza StorageGRID como nivel de almacenamiento remoto y permite a los clientes implementar múltiples sitios distribuidos geográficamente para obtener una disponibilidad y durabilidad sólidas, presentes como espacio de nombres de objetos único. Esto permite a Splunk SmartStore aprovechar el alto rendimiento, la capacidad densa y la capacidad de StorageGRID, así como la posibilidad de escalar a cientos de nodos en varios sitios físicos utilizando una única URL para interactuar con los objetos. Esta URL única también permite que la expansión, las actualizaciones y las reparaciones del almacenamiento sean no disruptivas, incluso más allá de un sitio. El motor de políticas de gestión de datos único de StorageGRID proporciona niveles optimizados de rendimiento, durabilidad y cumplimiento de los requisitos de ubicación de los datos.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, líder en la recopilación y análisis de datos generados por máquinas, ayuda a simplificar y modernizar LA TECNOLOGÍA gracias a sus funciones de análisis operativos. También se amplía a casos de uso de análisis empresarial, seguridad y del Internet de las cosas. El almacenamiento es un habilitador crucial para una correcta puesta en marcha del software Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Los datos generados por equipos son el tipo de Big Data de más rápido crecimiento. El formato es impredecible y proviene de muchas fuentes diferentes, a menudo a altas tasas y en grandes volúmenes. Estas características de la carga de trabajo se denominan a menudo escape digital. Splunk SmartStore ayuda a detectar estos datos y proporciona una organización en niveles inteligente para optimizar la ubicación de los datos calientes y templados en el nivel de almacenamiento más rentable.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore es una funcionalidad de indizador que utiliza almacenamiento de objetos (también conocido como almacenamiento remoto o niveles de almacenamiento remoto) como StorageGRID para almacenar datos calientes mediante el protocolo S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">A medida que aumenta el volumen de datos de una instalación, la demanda de almacenamiento suele ser superior a la demanda de recursos informáticos. SmartStore permite gestionar el almacenamiento de indizadores y los recursos informáticos de forma rentable mediante el escalado de los recursos informáticos y de almacenamiento por separado.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore introduce un nivel de almacenamiento remoto, mediante el protocolo S3 y un gestor de caché. Estas funciones permiten que los datos residan de forma local en indizadores o en almacenamiento remoto. El gestor de caché, que reside en el indizador, gestiona el movimiento de datos entre el indizador y el nivel de almacenamiento remoto. Los datos se almacenan en bloques (activos y templados) junto con metadatos de bloques.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Con SmartStore, puede reducir al mínimo el espacio de almacenamiento de los indizadores y elegir recursos informáticos optimizados para I/o, puesto que la mayoría de los datos residen en el nivel de almacenamiento remoto. El indexador mantiene una caché local, que representa la cantidad mínima de datos necesaria para devolver los resultados solicitados y previstos. La caché local contiene bloques activos, copias de bloques activos que participan en búsquedas activas o recientes y metadatos de bloques.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore con StorageGRID permite a los clientes escalar de forma incremental el entorno con un almacenamiento remoto de alto rendimiento y rentable, al tiempo que ofrece un alto grado de elasticidad en la solución global. Esto permite a los clientes añadir cualquier componente (almacenamiento activo o almacenamiento S3 templado) en una cantidad determinada en un momento dado, tanto si se necesitan más indizadores como si se cambia la retención de los datos o si se aumenta la tasa de consumo sin interrupciones.</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">Siguiente: Funciones flexibles de StorageGRID para Splunk SmartStore.</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Esta sección proporciona los pasos detallados necesarios para mover datos de MapR-FS a NFS de ONTAP mediante NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MAPR-FS para NFS de ONTAP</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">Anterior: GPFS a NFS: Pasos detallados.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Aprovisione tres LUN por cada nodo de MapR y dé la propiedad de los LUN de todos los nodos de MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Durante la instalación, seleccione LUN recientemente añadidas para discos de clúster de MapR que se utilizan para MapR-FS.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">Documentación de MAPR 6.1</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">Instale un clúster de MapR de acuerdo con<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Compruebe las operaciones básicas de Hadoop mediante comandos MapReduce como<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Mantenga los datos de sus clientes en MapR-FS. Por ejemplo, generamos aproximadamente un terabyte de datos de muestra en MapR-FS con Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configure MapR-FS como exportación NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Deshabilite el servicio nlockmgr en todos los nodos de MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exporte carpetas específicas de MapR-FS en todos los nodos de MapR del<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> archivo. No exporte la carpeta principal con permisos diferentes al exportar subcarpetas.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Actualice el servicio NFS de MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Asigne un rango IP virtual a un servidor específico o un conjunto de servidores del clúster de MapR. A continuación, el clúster de MapR asigna una IP a un servidor específico para el acceso a los datos NFS. Las IP posibilitan la alta disponibilidad, lo cual significa que, si se produce un error en un servidor o una red con una IP en particular, se puede utilizar la siguiente IP del rango de IP para el acceso a NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Si desea proporcionar acceso NFS desde todos los nodos de MapR, puede asignar un conjunto de IP virtuales a cada servidor y usar los recursos de cada nodo de MapR para el acceso a datos NFS.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Compruebe las IP virtuales asignadas en cada nodo de MapR y utilícela para el acceso a los datos NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Monte MapR-FS exportado por NFS con la IP virtual asignada para comprobar la operación NFS. Sin embargo, este paso no es necesario para la transferencia de datos con NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configure XCP de NetApp para transferir datos desde la puerta de enlace NFS de MapR-FS a NFS de ONTAP.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configure la ubicación del catálogo para XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copie el archivo de licencia en<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Active XCP mediante<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> comando.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Compruebe el origen de la exportación NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Transfiera los datos con XCP de varios nodos de MapR de varias IP de origen y varias IP de destino (LIF ONTAP).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Compruebe la distribución de carga en el controlador de almacenamiento.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: Carga de trabajo de Apache Spark con la solución de almacenamiento de NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY describe el rendimiento y la validación de la funcionalidad de Apache Spark SQL en los sistemas de almacenamiento NFS AFF de NetApp. Revisa la configuración, la arquitectura y las pruebas de rendimiento en función de varios escenarios, así como recomendaciones para el uso de Spark con el software para la gestión de datos ONTAP de NetApp. Asimismo, cubre los resultados de pruebas basados en un grupo de discos (JBOD) frente a la controladora de almacenamiento A800 de AFF de NetApp.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Este documento proporciona directrices para trasladar datos de análisis de Big Data y datos de HPC a IA mediante NetApp XCP y NIPAM. También hablamos de las ventajas empresariales que supone trasladar datos de Big Data y de HPC a IA.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">Informe técnico TR-4732: Big Data Analytics datos en inteligencia artificial</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Este documento describe cómo trasladar los datos de análisis de Big Data y los datos de computación de alto rendimiento a IA. La IA procesa datos de NFS a través de exportaciones NFS, mientras que los clientes suelen tener sus datos de IA en una plataforma de análisis de Big Data, como HDFS, Blob o S3, así como plataformas HPC como GPFS. Este documento proporciona directrices para trasladar datos de análisis de Big Data y datos de HPC a IA mediante NetApp XCP y NIPAM. También hablamos de las ventajas empresariales que supone trasladar datos de Big Data y de HPC a IA.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Conceptos y componentes</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Almacenamiento de análisis de Big Data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">Los análisis de Big Data son el principal proveedor de almacenamiento para HDFS. Un cliente suele utilizar un sistema de archivos compatible con Hadoop (HCFS), como almacenamiento blob de Windows Azure, MapR File System (MapR-FS) y almacenamiento de objetos S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Sistema de archivos paralelos general</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">GPFS de IBM es un sistema de archivos empresariales que ofrece una alternativa a HDFS. GPFS proporciona flexibilidad para que las aplicaciones decidan el tamaño del bloque y el diseño de replicación, lo que proporciona un buen rendimiento y eficiencia.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Módulo de análisis in situ de NetApp</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382: Módulo de análisis in situ de NetApp.</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">El módulo de análisis in situ (NIPAM, in situ) de NetApp sirve como controlador para que los clústeres de Hadoop accedan a datos NFS. Consta de cuatro componentes: Un pool de conexión, un InputStream NFS, una caché de gestión de archivos y un OutputStream NFS. Para obtener más información, consulte<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copia distribuida de Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">La copia distribuida de Hadoop (DistCp) es una herramienta de copia distribuida que se usa para las tareas de adaptación entre clústeres y dentro de clústeres de gran tamaño. Esta herramienta utiliza MapReduce para la distribución de datos, el manejo de errores y los informes. Amplía la lista de archivos y directorios e introduce las tareas de asignación para copiar los datos de la lista de origen. La siguiente imagen muestra la operación DistCp en HDFS y no HDFS.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp mueve datos entre los dos sistemas HDFS sin necesidad de utilizar un controlador adicional. NetApp proporciona el controlador para sistemas que no son HDFS. En un destino NFS, NIPAM proporciona el controlador para copiar datos que Hadoop DistCp utiliza para comunicarse con destinos NFS al copiar datos.</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">Cloud Volumes Service de NetApp es un servicio de archivos nativo del cloud con un rendimiento extremo. Este servicio ayuda a sus clientes a acelerar el plazo de comercialización mediante el rápido aumento y reducción de los recursos, así como el uso de las funciones de NetApp para mejorar la productividad y reducir el tiempo de inactividad del personal. Cloud Volumes Service es la alternativa adecuada para la recuperación ante desastres y sus backups en el cloud, ya que reduce el espacio global del centro de datos y consume menos almacenamiento en cloud público nativo.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP es un software cliente que permite una migración de datos de cualquiera a NetApp y de NetApp a NetApp rápida y fiable. Esta herramienta está diseñada para copiar una gran cantidad de datos NAS no estructurados de cualquier sistema NAS a una controladora de almacenamiento de NetApp. La herramienta de migración XCP utiliza un motor de transmisión de E/S multicanal y de varios canales que puede procesar muchas solicitudes en paralelo, como la migración de datos, listas de archivos o directorios y la creación de informes de espacio. Esta es la herramienta de migración de datos de NetApp predeterminada. Puede utilizar XCP para copiar datos de un clúster de Hadoop y de una HPC al almacenamiento NFS de NetApp. El siguiente diagrama muestra la transferencia de datos de un clúster Hadoop y HPC a un volumen NFS de NetApp mediante XCP.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">Cloud Sync de NetApp es un software como servicio de replicación de datos híbrida que transfiere y sincroniza datos NFS, S3 y CIFS de forma continua y segura entre el almacenamiento en las instalaciones y el almacenamiento en cloud. Este software se utiliza para migración de datos, archivado, colaboración, análisis, etc. Una vez transferidos los datos, Cloud Sync sincroniza continuamente los datos entre el origen y el destino. De cara al futuro, luego transfiere el delta. También protege los datos dentro de su propia red, en el cloud o en las instalaciones. Este software se basa en el modelo de pago por uso, que ofrece una solución rentable y ofrece capacidades de supervisión y generación de informes para su transferencia de datos.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">Siguiente: Los retos de los clientes.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Esta prueba de verificación alcanzó 31,74 Gbps de rendimiento en niveles en Confluent con una controladora de almacenamiento ONTAP de NetApp.</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">Anterior: Directrices de mejores prácticas de rendimiento.</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Esta prueba de verificación alcanzó 31,74 Gbps de rendimiento en niveles en Confluent con la controladora de almacenamiento ONTAP de NetApp.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">¿Qué es Confluente?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 en prácticas recomendadas de ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestión del almacenamiento de objetos S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">Septiembre de 2022</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Para esta solución, NetApp validó la migración de datos de un lago de datos (HDFS) y datos de clúster de MapR a NFS de ONTAP. Los datos residían en MapR-FS y HDFS. XCP de NetApp presentó una nueva función que migra directamente los datos de un sistema de archivos distribuido como HDFS y MapR-FS a NFS de ONTAP.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS y MapR-FS para NFS de ONTAP</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">Anterior: GPFS a ONTAP NFS de NetApp.</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">Para esta solución, NetApp validó la migración de datos de un lago de datos (HDFS) y datos de clúster de MapR a NFS de ONTAP. Los datos residían en MapR-FS y HDFS. XCP de NetApp presentó una nueva función que migra directamente los datos de un sistema de archivos distribuido como HDFS y MapR-FS a NFS de ONTAP. XCP utiliza subprocesos asíncronos y llamadas a la API C de HDFS para comunicar y transferir datos de MapR- FS y HDFS. La siguiente figura muestra la migración de datos del lago de datos (HDFS) y MapR-FS a NFS de ONTAP. Con esta nueva función, no es necesario exportar el origen como recurso compartido NFS.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">¿Por qué los clientes cambian de HDFS y MapR-FS a NFS?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">La mayoría de las distribuciones de Hadoop como Cloudera y Hortonworks utilizan HDFS y las distribuciones de MapR utilizan su propio sistema de archivos denominado MAPR-FS para almacenar datos. Los datos de HDFS y MapR-FS proporcionan información valiosa a los científicos de datos que pueden aprovecharse en aprendizaje automático (ML) y aprendizaje profundo (DL). Los datos en HDFS y MapR-FS no son compartidos, lo que significa que otras aplicaciones no pueden usarla. Los clientes buscan datos compartidos, especialmente en el sector bancario, donde varias aplicaciones utilizan los datos confidenciales de los clientes. La última versión de Hadoop (3.x o posterior) admite un origen de datos NFS, al que se puede acceder sin necesidad de software adicional de terceros. Con la nueva función XCP de NetApp, los datos pueden moverse directamente desde HDFS y MapR-FS a NFS de NetApp para proporcionar acceso a varias aplicaciones</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Las pruebas se realizaron en Amazon Web Services (AWS) para transferir los datos de MapR-FS a NFS para la prueba de rendimiento inicial con 12 nodos MAPR y 4 servidores NFS.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Tamaño</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">VCPU</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Red</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">Servidor NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xgrande</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488 GIB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 7500 SSD NVMe</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nodos MAPR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xLarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384 GIB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 SSD NVMe</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Basándonos en la prueba inicial, obtuvimos un rendimiento de 20 Gbps y pudimos transferir 2 PB por día de datos.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863: TR-4863: Directrices sobre las mejores prácticas para NetApp XCP: Movimiento de datos, migración de archivos y análisis</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">Para obtener más información acerca de la migración de datos HDFS sin exportar HDFS a NFS, consulte la sección «pasos de puesta en marcha: NAS» en<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">Siguiente: Ventajas empresariales.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">En esta sección se describen la naturaleza y los componentes de Apache Spark y cómo contribuyen a esta solución.</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">Anterior: Público objetivo.</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark es un popular marco de programación para escribir aplicaciones de Hadoop que funciona directamente con el sistema de archivos distribuidos de Hadoop (HDFS). Spark está lista para la producción, admite el procesamiento de datos en streaming y es más rápida que MapReduce. Spark cuenta con un almacenamiento en caché de datos en memoria configurable para una iteración eficiente y la shell Spark es interactiva para aprender y explorar datos. Con Spark puede crear aplicaciones en Python, Scala o Java. Las aplicaciones SPARK consisten en uno o más trabajos que tienen una o más tareas.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Cada aplicación Spark tiene un controlador Spark. En el modo YARN-Client, el controlador se ejecuta en el cliente localmente. En el modo HILADO-Cluster, el controlador se ejecuta en el clúster en el maestro de aplicaciones. En el modo de clúster, la aplicación continúa ejecutándose incluso si el cliente se desconecta.</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Hay tres administradores de clústeres:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Independiente.* este administrador forma parte de Spark, lo que facilita la configuración de un clúster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">* Apache Mesos.* este es un gestor general de clusters que también ejecuta MapReduce y otras aplicaciones.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN.* esto es un gestor de recursos en Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">El conjunto de datos distribuido resiliente (RDD) es el componente principal de Spark. RDD recrea los datos perdidos y que faltan de los datos almacenados en la memoria del clúster y almacena los datos iniciales que provienen de un archivo o que se crean mediante programación. Los RDD se crean a partir de archivos, datos en memoria u otro RDD. La programación SPARK realiza dos operaciones: Transformación y acciones. La transformación crea una RDD nueva basada en una existente. Las acciones devuelven un valor de un RDD.</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">Las transformaciones y acciones también se aplican a los conjuntos de datos de Spark y DataFrames. Un conjunto de datos es una colección distribuida de datos que proporciona las ventajas de los RDD (escritura sólida, uso de funciones lambda) con las ventajas del motor de ejecución optimizado de Spark SQL. Un conjunto de datos se puede construir a partir de objetos JVM y, a continuación, manipular mediante transformaciones funcionales (mapa, mapa plano, filtro, etc.). Un DataFrame es un conjunto de datos organizado en columnas con nombre. Es conceptualmente equivalente a una tabla de una base de datos relacional o un marco de datos de R/Python. Los DataFrames pueden construirse a partir de una amplia variedad de orígenes como archivos de datos estructurados, tablas en Hive/HBase, bases de datos externas en las instalaciones o en el cloud, o RDDs existentes.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Las aplicaciones SPARK incluyen uno o más trabajos de Spark. Los trabajos ejecutan tareas en los ejecutores y los ejecutores se ejecutan en contenedores DE HILADOS. Cada ejecutor se ejecuta en un único contenedor, y existen ejecutores a lo largo de la vida de una aplicación. Un ejecutor se fija después de que se inicia la aplicación, Y EL HILADO no cambia el tamaño del contenedor ya asignado. Un ejecutor puede ejecutar tareas de forma simultánea en los datos de la memoria.</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">Siguiente: Información general de las soluciones Spark de NetApp.</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">Esta página describe el rendimiento de Splunk SmartStore en una controladora StorageGRID de NetApp. Splunk SmartStore mueve los datos templados a un almacenamiento remoto, lo cual es el almacenamiento de objetos StorageGRID en la validación del rendimiento.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Rendimiento de SmartStore en un único sitio</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">Anterior: Arquitectura de Splunk.</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">En esta sección se describe el rendimiento de Splunk SmartStore en una controladora StorageGRID de NetApp. Splunk SmartStore mueve los datos calientes al almacenamiento remoto, lo que en este caso es el almacenamiento de objetos StorageGRID en la validación del rendimiento.</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Utilizamos EF600 para el almacenamiento en caché/caliente y StorageGRID 6060 para el almacenamiento remoto. Utilizamos la siguiente arquitectura para la validación del rendimiento. Se utilizaron dos cabezales de búsqueda, cuatro reenviadores pesados para reenviar los datos a los indizadores, siete generadores de eventos de Splunk (Eventgens) para generar los datos en tiempo real y 18 indizadores para almacenar los datos.</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Esta tabla enumera el hardware utilizado para la validación del rendimiento de SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Transportista pesado</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 núcleos</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">La interfaz de usuario busca datos en indizadores</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validación del rendimiento del almacén remoto SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">En esta validación del rendimiento, configuramos el almacenamiento en caché SmartStore en el almacenamiento local de todos los indizadores para 10 días de datos. Habilitamos la<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (Tamaño de bloque de 750 MB) en el gestor de clústeres de Splunk y presionó los cambios a todos los indizadores. Para medir el rendimiento de carga, ingerimos 10 TB al día durante 10 días y repasamos todos los depósitos activos a calentarse al mismo tiempo y capturamos el rendimiento medio y pico por instancia y la puesta en marcha en todo el panel de la consola de supervisión de SmartStore.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Esta imagen muestra los datos procesados en un día.</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Se ejecutó el siguiente comando desde cluster master (el nombre de índice es<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>). A continuación, capturamos el rendimiento de carga máxima y media por instancia y de toda la implementación a través de los paneles de control de SmartStore Monitoring Console.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">El maestro de clústeres tiene autenticación sin contraseña para todos los indizadores (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Para medir el rendimiento de las descargas, expulsamos todos los datos de la caché ejecutando la CLI de expulsar dos veces mediante el siguiente comando.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Ejecutamos el siguiente comando del maestro de clústeres y ejecutamos la búsqueda desde el jefe de búsqueda en los 10 días de datos del almacén remoto desde StorageGRID. A continuación, capturamos el rendimiento de carga máxima y media por instancia y de toda la implementación a través de los paneles de control de SmartStore Monitoring Console.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Las configuraciones de indizadores se han empujado desde el maestro de clústeres de SmartStore. El maestro del clúster tenía la siguiente configuración para el indexador.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Realizamos la siguiente consulta de búsqueda en el cabezal de búsqueda para recopilar la matriz de rendimiento.</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Recopilamos la información de rendimiento del maestro de clústeres. El máximo rendimiento fue de 61,34 Gbps.</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">El rendimiento medio era de aproximadamente 29 Gbps.</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Rendimiento de StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">El rendimiento de SmartStore se basa en la búsqueda de patrones y cadenas específicos de grandes cantidades de datos. En esta validación, los eventos se generan mediante<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> En un índice específico de Splunk (eventgen-test) a través del jefe de búsqueda y la solicitud se dirige a StorageGRID para la mayoría de las consultas. La siguiente imagen muestra los aciertos y omisiones de los datos de consulta. Los datos de aciertos son del disco local y los datos de pérdidas se corresponden con la controladora StorageGRID.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">El color verde muestra los datos de aciertos y el color naranja muestra los datos de pérdidas.</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Cuando se ejecuta la consulta para la búsqueda en StorageGRID, la hora de la tasa de recuperación de S3 de StorageGRID se muestra en la siguiente imagen.</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Uso de hardware de StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">La instancia de StorageGRID tiene un equilibrador de carga y tres controladoras de StorageGRID. El uso de CPU de las tres controladoras es del 75 % al 100 %.</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore con la controladora de almacenamiento de NetApp: Ventajas para el cliente</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Disociación de la computación y el almacenamiento.* el SmartStore de Splunk separa la computación y el almacenamiento, lo que ayuda a escalarlas de forma independiente.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Datos bajo demanda.* SmartStore acerca los datos a la informática bajo demanda y proporciona elasticidad de cálculo y almacenamiento y rentabilidad para lograr una retención de datos más prolongada a escala.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Compatible con la API de AWS S3.* SmartStore utiliza la API de AWS S3 para comunicarse con el almacenamiento de restauración, que es un almacén de objetos compatible con la API de AWS S3 y S3, como StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Reduce los requisitos y el coste de almacenamiento.* SmartStore reduce los requisitos de almacenamiento de los datos antiguos (en frío/calor). Solo necesita una copia única de los datos porque el almacenamiento de NetApp proporciona protección de datos y se ocupa de fallos y alta disponibilidad.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Error de hardware.* error de nodo en una implementación de SmartStore no hace que los datos sean inaccesibles y tiene una recuperación mucho más rápida del indexador debido a fallos de hardware o desequilibrio de datos.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Caché compatible con aplicaciones y datos.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Añada los indizadores y el clúster de configuración-desmontaje bajo demanda.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">El nivel de almacenamiento ya no está ligado al hardware.</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Esta prueba se basa en la función de clústeres de equilibrio automático, que automatiza el reequilibrio en función de cambios en la topología del clúster o carga desigual.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Clústeres de equilibrio automático confluente</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">Anterior: Conector Kafka s3.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Si ha gestionado antes un clúster Kafka, probablemente esté familiarizado con los retos que surgen con la reasignación manual de particiones a distintos agentes para garantizar que la carga de trabajo se equilibre a través del clúster. Para las organizaciones con grandes puestas en marcha de Kafka, cambiar grandes cantidades de datos puede ser abrumador, tedioso y arriesgado, especialmente si las aplicaciones vitales para el negocio se basan en el clúster. Sin embargo, incluso para los casos de uso más pequeños de Kafka, el proceso consume mucho tiempo y es propenso a errores humanos.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">En nuestro laboratorio, probamos la función de clústeres de equilibrio automático con fluidez, que automatiza el reequilibrado en función de cambios de topología de clúster o carga irregular. La prueba de reequilibrado fluido ayuda a medir el tiempo para agregar un nuevo intermediario cuando el fallo del nodo o el nodo de escalado requiere reequilibrar los datos entre los distintos intermediarios. En las configuraciones clásicas de Kafka, la cantidad de datos que se deben reequilibrar crece a medida que crece el clúster, pero, en almacenamiento por niveles, el reequilibrio se limita a una pequeña cantidad de datos. Según nuestra validación, el reequilibrio en el almacenamiento por niveles se demora segundos o minutos en una arquitectura Kafka clásica y crece de forma lineal a medida que crece el clúster.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">En los clústeres de equilibrio automático, los reequilibrios de las particiones están totalmente automatizados para optimizar el rendimiento de Kafka, acelerar el escalado de los intermediarios y reducir la carga operativa de ejecutar un gran clúster. En clústeres de estado constante, los clústeres de equilibrio automático supervisan el desfase de datos a través de los intermediarios y reasignan continuamente particiones para optimizar el rendimiento del clúster. Al escalar la plataforma de forma horizontal o vertical, los clústeres de equilibrio automático reconocen automáticamente la presencia de nuevos agentes o la eliminación de agentes antiguos y activan la reasignación posterior de particiones. Esto le permite añadir y retirar agentes fácilmente, lo que hace que sus clústeres Kafka sean mucho más elásticos. Estas ventajas se obtienen sin necesidad de intervención manual, matemáticas complejas o el riesgo de error humano que suelen implicar la reasignación de particiones. Como resultado, los reequilibrios de los datos se completan en mucho menos tiempo y puede centrarse en proyectos de streaming de eventos de mayor valor, en lugar de tener que supervisar constantemente los clústeres.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">Siguiente: Directrices de mejores prácticas.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Esta página describe los principales casos prácticos de IA, ML y DL y arquitecturas en mayor detalle.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principales casos de uso y arquitecturas de IA, APRENDIZAJE AUTOMÁTICO y aprendizaje profundo</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">Anterior: Resumen de casos de uso.</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Los principales casos de uso y metodología de IA, APRENDIZAJE AUTOMÁTICO y aprendizaje profundo pueden dividirse en las siguientes secciones:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Canalizaciones NLP Spark y la inferencia distribuida TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">La siguiente lista contiene las bibliotecas NLP de código abierto más populares que han adoptado la comunidad de ciencias de datos bajo diferentes niveles de desarrollo:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Kit de herramientas de lenguaje natural (NLMK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>. El kit de herramientas completo para todas las técnicas de NLP. Se mantiene desde principios de los años 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>. Una herramienta NLP de fácil uso API de Python construida sobre NLMK y Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>. Servicios y paquetes NLP en Java desarrollados por el Grupo NLP de Stanford.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>. Modelado de Temas para humanos comenzó como una colección de scripts de Python para el proyecto de la Biblioteca Checa de Matemáticas digitales.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">La piratería</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>. Flujos de trabajo NLP industrial integrales con Python y Cython con aceleración de GPU para transformadores.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Fasttext</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>. Una biblioteca gratuita, ligera y de código abierto de NLP para el aprendizaje de textos y clasificación de frases creada por el laboratorio DE investigación DE IA (FAIR) de Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Estimular ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">Spark NLP es una solución única y unificada para todas las tareas y requisitos de NLP que permite un software escalable, de alto rendimiento y de alta precisión impulsado por NLP para casos de uso reales de producción. Aprovecha el aprendizaje de transferencia e implementa los últimos algoritmos y modelos de última generación en investigación y en diferentes industrias. Debido a la falta de pleno apoyo por parte de Spark para las bibliotecas anteriores, Spark NLP se creó sobre la base de<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Aprovechar el motor de procesamiento de datos distribuidos en memoria de uso general de Spark como biblioteca de NLP de clase empresarial para flujos de trabajo de producción esenciales. Sus anotadores utilizan algoritmos basados en reglas, aprendizaje automático y TensorFlow para impulsar las implementaciones de aprendizaje profundo. Esto cubre las tareas comunes de las NLP, incluyendo, entre otras cosas, la tokenización, la limmatización, la secución, el marcado parcial del habla, el reconocimiento de entidades denominadas, revisión ortográfica y análisis de confianza.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Representaciones del codificador bidireccional de Transformers (BERT) es una técnica de aprendizaje automático basada en transformadores para NLP. Popularizó el concepto de preentrenamiento y ajuste fino. La arquitectura del transformador en BERT se originó a partir de la traducción automática, que modela las dependencias a largo plazo mejor que los modelos de lenguaje basados en Red neuronal recurrente (RNN). También introdujo la tarea Modelización de Lenguaje Mask (MLM), donde un 15% aleatorio de todos los tokens están enmascarados y el modelo los predice, permitiendo una verdadera bidirectionality.</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Banco de frases financieras</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">Análisis de confianza para las noticias financieras</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Explicar el documento DL</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">El análisis de la confianza financiera es un reto debido al lenguaje especializado y a la falta de datos etiquetados en ese dominio.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, Un modelo de idioma basado en BERT preformado, fue adaptado el dominio en<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>, un corpus financiero y ajustado con datos etiquetados (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>) para la clasificación de la confianza financiera. Los investigadores extrajeron 4, 500 frases de artículos de noticias con términos financieros. Luego 16 expertos y maestros estudiantes con fondos financieros etiquetaron las frases como positivas, neutrales y negativas. Hemos creado un flujo de trabajo completo de Spark para analizar el sentimiento de las transcripciones de llamadas de beneficios de empresas del mejor de los 10 NASDAQ de 2016 a 2020 usando FinBERT y otros dos oleoductos preentrenados (<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>) Desde Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">El motor de aprendizaje profundo subyacente para Spark NLP es TensorFlow, una plataforma integral de código abierto para el aprendizaje automático que permite una creación de modelos fácil, una producción de ML sólida en cualquier lugar y una experimentación potente para la investigación. Por lo tanto, al ejecutar nuestras tuberías en Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> Modo, estábamos ejecutando TensorFlow distribuido con datos y paralelización de modelos en un nodo maestro y varios de trabajadores, además de almacenamiento conectado a la red montado en el clúster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod distribuyó entrenamiento</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969: Soluciones de NetApp para Hadoop</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">La validación principal de Hadoop para el rendimiento relacionado con MapReduce se realiza con TeraGen, TeraSort, TeraValidate y DFSIO (lectura y escritura). Los resultados de la validación TeraGen y TeraSort se presentan en<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> Para E-Series y en la sección “Storage Tiering” (xref) para AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod en Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">En función de las solicitudes de los clientes, consideramos que la formación distribuida con Spark es una de las más importantes de las distintas situaciones de uso. En este documento, utilizamos la<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> Para validar el rendimiento de Spark con NetApp en las instalaciones, nativas del cloud e híbridas mediante las controladoras de almacenamiento All Flash FAS (AFF) de NetApp, Azure NetApp Files y StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">El paquete Horovod en Spark proporciona un contenedor adecuado en torno a Horovod que simplifica la ejecución de cargas de trabajo de entrenamiento distribuidas en clústeres de Spark, lo cual permite crear un bucle de diseño de modelo ajustado en el que el procesamiento de datos, el entrenamiento de modelos y la evaluación de modelos se llevan a cabo en Spark donde se encuentran los datos de entrenamiento e inferencia.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Ventas de la tienda Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Hay dos API para ejecutar Horovod en Spark: Una API de Estimator de alto nivel y una API de Run de bajo nivel. Aunque ambos usan el mismo mecanismo subyacente para lanzar Horovod en los ejecutores de Spark, la API de Estimator abstrae el procesamiento de datos, el bucle de entrenamiento del modelo, la verificación del modelo, la recopilación de métricas y la formación distribuida. Utilizamos Horovod Spark Estimators, TensorFlow y Keras para una preparación de datos completa y un flujo de trabajo de entrenamiento distribuido basado en la<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> competencia.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Scripts Python para cada caso de uso principal.</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">El script<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> puede encontrarse en la sección <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> Contiene tres partes:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La primera parte realiza varios pasos de preprocesamiento de datos sobre un conjunto inicial de archivos CSV proporcionados por Kaggle y reunidos por la comunidad. Los datos de entrada se separan en un grupo de entrenamiento con un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> un subconjunto y un conjunto de datos de pruebas.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La segunda parte define un modelo de red neuronal profunda Keras (DNN) con función de activación sigmoide logarítmica y un optimizador Adam, y realiza un entrenamiento distribuido del modelo mediante Horovod en Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La tercera parte realiza predicciones en el conjunto de datos de pruebas utilizando el mejor modelo que minimiza el error absoluto de la media general del conjunto de validación. A continuación, crea un archivo CSV de salida.</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">“Aprendizaje automático”</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">Consulte la sección <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> para varios resultados de comparación de tiempo de ejecución.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Aprendizaje profundo para múltiples trabajadores usando Keras para la predicción CTR</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">Con los recientes avances en las plataformas Y aplicaciones DE ML, ahora se presta mucha atención al aprendizaje a escala. La tasa de clics (CTR) se define como el número medio de clics-throughs por cien impresiones de anuncios en línea (expresado como porcentaje). Se ha adoptado ampliamente como métrica clave en diversos mercados verticales del sector y casos de uso, incluidos el marketing digital, el comercio minorista, el comercio electrónico y los proveedores de servicios. Consulte nuestra<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> Para obtener más información sobre las aplicaciones de CTR y una implementación de flujo de trabajo integral de Cloud AI con Kubernetes, ETL de datos distribuidos y entrenamiento de modelos con DASK y CUDA ML.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte haga clic en el conjunto de datos Logs</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">En este informe técnico se utilizó una variación del<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (Consulte TR-4904) para el aprendizaje profundo distribuido por varios trabajadores mediante Keras para crear un flujo de trabajo de Spark con modelos Deep and Cross Network (DCN), donde se compara su rendimiento en términos de una función de error de pérdida de registro con un modelo de regresión logística de Spark ML básico. DCN capta eficazmente las interacciones eficaces de funciones de grados limitados, aprende interacciones muy no lineales, no requiere ingeniería de funciones manuales ni búsqueda exhaustiva y tiene un bajo coste computacional.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Los datos para los sistemas de recomendación a escala web son en su mayoría discretos y categóricos, lo que conduce a un gran espacio de funciones escasas que resulta difícil para la exploración de funciones. Esto ha limitado la mayoría de los sistemas a gran escala a modelos lineales como la regresión logística. Sin embargo, la clave para hacer buenas predicciones es identificar las características predictivas más frecuentes y, al mismo tiempo, explorar características cruzadas poco visibles o raras. Los modelos lineales son simples, interpretables y fáciles de escalar, pero están limitados en su poder expresivo.</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">Por otro lado, se ha demostrado que las características cruzadas son significativas para mejorar la expresividad de los modelos. Desafortunadamente, a menudo requiere ingeniería de funciones manual o búsqueda exhaustiva para identificar estas funciones. Generalizar a interacciones de características no vistas es a menudo difícil. El uso de una red neuronal cruzada como DCN evita la ingeniería de funciones específicas de una tarea mediante la aplicación explícita de un cruce de funciones de forma automática. La red cruzada consta de varias capas, donde el grado más alto de interacciones se determina de forma comprobable por la profundidad de la capa. Cada capa produce interacciones de mayor orden basadas en las existentes y mantiene las interacciones de capas anteriores.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Una red neuronal profunda (DNN) tiene la promesa de capturar interacciones muy complejas entre características. Sin embargo, en comparación con DCN, requiere casi un orden de magnitud más parámetros, no es capaz de formar características cruzadas explícitamente y puede no aprender eficazmente algunos tipos de interacciones de características. La red cruzada es eficiente en la memoria y fácil de implementar. El entrenamiento conjunto de los componentes cross y DNN captura de forma eficiente las interacciones predictivas con las características y proporciona un rendimiento de última generación en el conjunto de datos Criteo CTR.</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">ml</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">mllib</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">Un modelo DCN comienza con una capa de incrustación y apilado, seguido por una red transversal y una red profunda en paralelo. A su vez, están seguidas por una última capa de combinación que combina las salidas de las dos redes. Los datos de entrada pueden ser un vector con características dispersas y densas. En Spark, ambas<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> y..<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> las bibliotecas contienen el tipo<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>. Por lo tanto, es importante que los usuarios distingan entre los dos y sean conscientes cuando llaman a sus respectivas funciones y métodos. En sistemas de recomendación a escala web, como la predicción CTR, los insumos son, en su mayoría, características categóricas, por ejemplo<block ref="bf8b858b1d67b8d7c2676d6a7353c3c9" prefix=" " category="inline-code"></block>. Tales características se codifican a menudo como vectores de una caliente, por ejemplo,<block ref="624411787ac52373d7cc41183768999c" prefix=" " category="inline-code"></block>. Codificación en caliente (OHE) con<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> es útil cuando se trata de conjuntos de datos del mundo real con vocabularios en constante cambio y crecimiento. Hemos modificado ejemplos en<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> Procesar grandes vocabularios, creando vectores de incrustación en la capa de incrustación y apilado de nuestro DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Conjunto de datos de anuncios de visualización Criteo</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">La<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> predice la velocidad de clic del ads. Tiene 13 características de enteros y 26 características categóricas en las cuales cada categoría tiene una cardinalidad alta. Para este conjunto de datos, una mejora de 0.001 en pérdida de registro es prácticamente significativa debido al gran tamaño de entrada. Una pequeña mejora en la precisión de la predicción para una gran base de usuarios puede conducir potencialmente a un gran aumento en los ingresos de una empresa. El conjunto de datos contiene 11 GB de registros de usuarios de un periodo de 7 días, lo que equivale a unos 41 millones de registros. Utilizamos Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> dividir de forma aleatoria los datos para el entrenamiento (80%), la validación cruzada (10%) y el 10% restante para las pruebas.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN se implementó en TensorFlow con Keras. La aplicación del proceso de formación modelo con DCN consta de cuatro componentes principales:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Procesamiento e incrustación de datos.* las características con valor real se normalizan aplicando una transformación de registro. Para las características categóricas, incrustamos las características en vectores densos de la dimensión 6×(cardinalidad de categoría)1/4. La concatenación de todos los embeddings da como resultado un vector de dimensión 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">* Optimización.* aplicamos la optimización estocástica de minilotes con el optimizador Adam. El tamaño de lote se estableció en 512. La normalización por lotes se aplicó a la red profunda y la norma de clip degradado se estableció en 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regularización.* utilizamos la parada temprana, ya que la regularización o el abandono L2 no se encontró para ser eficaz.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">* Hiperparámetros.* reportamos resultados basados en una búsqueda de cuadrícula sobre el número de capas ocultas, el tamaño de la capa oculta, la tasa de aprendizaje inicial y el número de capas cruzadas. El número de capas ocultas oscilaba entre 2 y 5, con un tamaño de capa oculto que oscilaba entre 32 y 1024. Para DCN, el número de capas cruzadas fue de 1 a 6. La tasa de aprendizaje inicial se ajustó de 0.0001 a 0.001 con incrementos de 0.0001. Todos los experimentos se pararon temprano en la etapa de entrenamiento 150,000, más allá de la cual empezó a ocurrir el ajuste excesivo.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">XDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">Además de DCN, también hemos probado otros modelos populares de aprendizaje profundo para la predicción CTR, como<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>,<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>, y.<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>.</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Arquitecturas que se utilizan para la validación</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Para esta validación, hemos utilizado cuatro nodos de trabajo y uno de nodo maestro con un par de alta disponibilidad de AFF-A800. Todos los miembros del clúster se conectaron mediante switches de red de 10 GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Para esta validación de la solución Spark de NetApp, se utilizaron tres controladoras de almacenamiento distintas: El E5760, el E5724 y AFF-A800. Las controladoras de almacenamiento E-Series se conectaron a cinco nodos de datos con conexiones SAS de 12 Gbps. La controladora de almacenamiento de la pareja de alta disponibilidad de AFF proporciona volúmenes NFS exportados a través de conexiones 10 GbE a los nodos de trabajo de Hadoop. Los miembros de los clústeres de Hadoop se conectaron mediante conexiones 10 GbE en las soluciones E-Series, AFF y Hadoop de StorageGRID.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Arquitecturas que se utilizan para la validación.</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">Siguiente: Resultados de las pruebas.</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Se utilizaron los scripts TeraSort y TeraValidate en la herramienta de prueba de rendimiento TeraGen para medir la validación del rendimiento de Spark con las configuraciones E5760, E5724 y AFF-A800. Además, se probaron tres casos prácticos principales, las canalizaciones Spark NLP y el entrenamiento distribuido TensorFlow, el entrenamiento distribuido Horovod y el aprendizaje profundo multi-trabajador usando Keras para la predicción CTR con DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Resultados de las pruebas</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">Anterior: Principales casos prácticos de IA, ML y DL, y arquitecturas.</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Se utilizaron los scripts TeraSort y TeraValidate en la herramienta de prueba de rendimiento TeraGen para medir la validación del rendimiento de Spark con las configuraciones E5760, E5724 y AFF-A800. Además se probaron tres casos de uso principales: Las canalizaciones SPARK NLP y el entrenamiento distribuido TensorFlow, el entrenamiento distribuido Horovod y el aprendizaje profundo multi-trabajador usando Keras para la predicción de CTR con DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Para la validación E-Series y StorageGRID, utilizamos el factor de replicación de Hadoop 2. Para la validación AFF, solo utilizamos una fuente de datos.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">En la siguiente tabla se enumera la configuración de hardware para la validación del rendimiento de Spark.</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nodos de trabajo de Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Tipo de unidad</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Unidades por nodo</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Un único par de alta disponibilidad</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Un único par de alta disponibilidad</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">En la siguiente tabla se enumeran los requisitos de software.</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Entorno de ejecución de OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Servidor OpenJDK VM de 64 bits</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Chispa</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Análisis de la confianza financiera</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">SDK de NVIDIA Riva</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Marco Tao</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">Publicamos<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>, En el que se ha creado una canalización de IA conversacional integral con el<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Almacenamiento AFF y NVIDIA DGX System. La canalización realiza el procesamiento de señales de audio por lotes, el reconocimiento automático de voz (ASR), el aprendizaje de transferencia y el análisis de sentimiento con el conjunto de herramientas DataOPS,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>, y la<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>. Ampliando el caso de uso del análisis de sentimiento al sector de los servicios financieros, construimos un flujo de trabajo SparkNLP, cargamos tres modelos BERT para diversas tareas de NLP, como el reconocimiento de entidades con nombre, y obtuvimos un sentimiento a nivel de frase para las llamadas trimestrales de beneficios de las empresas incluidas en el NASDAQ Top 10.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">El siguiente script<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> Utiliza el modelo FinBERT para procesar transcripciones en HDFS y producir recuentos de sentimientos positivos, neutros y negativos, como se muestra en la siguiente tabla:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">En la tabla siguiente se enumera el análisis del sentimiento de «llamada a los beneficios» a nivel de frase de las empresas NASDAQ Top 10 de 2016 a 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Recuentos de confianza y porcentaje</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Todas las 10 empresas</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AIRBUS</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Recuentos positivos</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Recuentos de punto muerto</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Recuentos negativos</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Conteos sin categorizar</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(recuentos totales)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">En términos de porcentajes, la mayoría de las sentencias pronunciadas por los CEOs y CFO son fácticas y, por lo tanto, tienen un sentimiento neutral. Durante una llamada de beneficios, los analistas hacen preguntas que podrían transmitir un sentimiento positivo o negativo. Vale la pena investigar cuantitativamente cómo la confianza negativa o positiva afecta los precios de las acciones el mismo día o día siguiente de las operaciones.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">En la siguiente tabla se enumera el análisis de sentimiento a nivel de frase para las empresas NASDAQ Top 10, expresado en porcentaje.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Porcentaje de confianza</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positivo</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13 %</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06 %</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69 %</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24 %</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07 %</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08 %</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44 %</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25 %</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23 %</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutro</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17 %</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02 %</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82 %</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87 %</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42 %</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50 %</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65 %</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77 %</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44 %</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativo</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43 %</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92 %</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49 %</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52 %</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51 %</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42 %</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91 %</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96 %</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33 %</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Sin clasificar</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27 %</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37 %</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01 %</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">En cuanto al tiempo de ejecución del flujo de trabajo, observamos una mejora significativa de 4.78x con respecto a<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Mode a un entorno distribuido en HDFS y una mejora adicional del 0.14 % gracias al aprovechamiento de NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Como se muestra en la siguiente figura, el paralelismo de datos y modelos mejoró el procesamiento de datos y la velocidad de inferencia del modelo TensorFlow distribuido. La ubicación de los datos en NFS produjo un tiempo de ejecución ligeramente mejor porque el cuello de botella del flujo de trabajo es la descarga de modelos preentrenados. Si aumentamos el tamaño de los conjuntos de datos de transcripciones, la ventaja de NFS es más evidente.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Tiempo de ejecución completo del flujo de trabajo de análisis de sentimiento de Spark NLP.</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Distribuye la formación con el rendimiento de Horovod</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">“Guiones de Python para cada caso de uso principal”</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">El siguiente comando produjo información de tiempo de ejecución y un archivo de registro en nuestro clúster de Spark mediante una sola<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nodo con 160 ejecutores cada uno con un núcleo. La memoria del ejecutor estaba limitada a 5 GB para evitar errores de memoria insuficiente. Consulte la sección <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> para obtener más información sobre el procesamiento de datos, el entrenamiento de modelos y el cálculo de precisión de modelos en<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">El tiempo de ejecución resultante con diez épocas de entrenamiento fue el siguiente:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Se necesitaron más de 43 minutos para procesar datos de entrada, entrenar un modelo DNN, calcular la precisión y generar puntos de control TensorFlow y un archivo CSV para resultados de predicción. Limitamos el número de épocas de entrenamiento a 10, que en la práctica a menudo se establece a 100 para garantizar una precisión satisfactoria del modelo. El tiempo de entrenamiento se escala linealmente con el número de épocas.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">A continuación, utilizamos los cuatro nodos de trabajo disponibles en el clúster y ejecutamos el mismo script en<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Modo con datos en HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">El tiempo de ejecución resultante se mejoró de la siguiente manera:</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">Con el modelo y paralelismo de datos de Horovod en Spark, vimos una aceleración del tiempo de ejecución de 5.29x de<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> vs<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modo con diez épocas de entrenamiento. Se muestra en la siguiente figura con las leyendas<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> y..<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>. El entrenamiento del modelo TensorFlow DNN subyacente puede acelerarse más con GPU, si está disponible. Tenemos pensado llevar a cabo estas pruebas y publicar los resultados en un futuro informe técnico.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">En nuestra siguiente prueba se compararon los tiempos de ejecución con los datos de entrada almacenados en NFS frente a HDFS. Se montó el volumen NFS en el AFF A800<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> En los cinco nodos (un maestro, cuatro trabajadores) de nuestro clúster de Spark. Hicimos un comando similar al de pruebas anteriores, con el<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> Ahora el parámetro señala el montaje NFS:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">El tiempo de ejecución resultante con NFS fue el siguiente:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Hubo otro 1,3x de aceleración, como se muestra en la siguiente figura. Por lo tanto, con un almacenamiento all-flash de NetApp conectado a su clúster, los clientes disfrutan de las ventajas de una transferencia y distribución de datos rápidas para flujos de trabajo de Horovod Spark, obteniendo una aceleración de 7,55 veces superior en comparación con ejecutarse en un único nodo.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Tiempo de ejecución de Horovod Spark Workflow.</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modelos de aprendizaje profundo para el rendimiento de la predicción CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Para sistemas de recomendación diseñados para maximizar CTR, debe aprender sofisticadas interacciones de funciones detrás de comportamientos de usuario que se pueden calcular matemáticamente desde orden bajo hasta orden alto. Tanto las interacciones de funciones de bajo orden como las de alto nivel deben ser igualmente importantes para un buen modelo de aprendizaje profundo sin orientarse hacia uno o hacia otro. DeepFM, una red neuronal basada en máquinas para la factorización profunda, combina máquinas de factorización para recomendaciones y aprendizaje profundo para el aprendizaje de funciones en una nueva arquitectura de redes neuronales.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modelos amplios &amp;amp; profundos</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">Aunque las máquinas de factorización convencionales modelan las interacciones de funciones emparejadas como producto interno de vectores latentes entre las características y pueden teóricamente capturar información de alto orden, en la práctica, los profesionales de aprendizaje automático normalmente solo utilizan interacciones de funciones de segundo orden debido a la alta complejidad del almacenamiento y la computación. Variantes de redes neuronales profundas como las de Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> por otro lado, aprende sofisticadas interacciones de características en una estructura de red híbrida combinando un modelo lineal amplio y un modelo profundo.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Hay dos entradas para este modelo ancho y profundo, uno para el modelo ancho subyacente y el otro para el profundo, la última parte de la cual todavía requiere ingeniería de características expertas y por lo tanto hace la técnica menos generalizable a otros dominios. A diferencia del modelo ancho y profundo, DeepFM puede ser entrenado eficientemente con características RAW sin ninguna ingeniería de características porque su gran parte y la parte profunda comparten la misma entrada y el vector de incrustación.</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">“Guiones de Python para cada caso de uso principal”.</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">Primero procesamos el Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) en un archivo CSV denominado<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Almacenados en un montaje NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> uso<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> de la sección <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> Dentro de este script, la función<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> realiza varios métodos de cadena para quitar fichas e insertar<block ref="f89bb99ea60d9e9cbbc95ce1a8f1a63a" prefix=" " category="inline-code"></block> como delimitador y.<block ref="918d67b3695a9c52a0e182a621fc33da" prefix=" " category="inline-code"></block> como nueva línea. Tenga en cuenta que sólo necesita procesar el original<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> una vez, para que el bloque de código se muestre como comentarios.</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">Para las siguientes pruebas de distintos modelos de aprendizaje profundo, utilizamos<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> como archivo de entrada. En las pruebas posteriores, el archivo CSV de entrada se leyó en un Spark DataFrame con un esquema que contiene un campo de<block ref="cdb10f764735165c687209f811432621" prefix=" " category="inline-code"></block>, funciones densas de enteros<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>, y las características dispersas<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>. Lo siguiente<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> El comando toma en una entrada CSV, entrena modelos DeepFM con 20% de división para validación cruzada y elige el mejor modelo después de diez épocas de entrenamiento para calcular la precisión de predicción en el conjunto de pruebas:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Tenga en cuenta que desde el archivo de datos<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Es superior a 11 GB, debe establecer un valor suficiente<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> mayor que el tamaño del conjunto de datos para evitar errores.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Flecha Apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">En el anterior<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> la configuración también está activada<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>, Que convierte un DataFrame de Spark en un DataFrame de Pandas con el<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> método.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Tras la división aleatoria, hay más de 36 M de filas en el conjunto de datos de entrenamiento y 9M de muestras en el conjunto de pruebas:</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">Dado que este informe técnico se centra en las pruebas de CPU sin utilizar ninguna GPU, es imprescindible crear TensorFlow con indicadores adecuados del compilador. Este paso evita llamar a bibliotecas aceleradas por GPU y aprovecha al máximo las instrucciones de TensorFlow Advanced Vector Extensions (AVX) y AVX2. Estas características están diseñadas para cálculos algebraicos lineales como adición vectorizada, multiplicaciones de matrices dentro de un avance de alimentación o entrenamiento DNN de reproducción posterior. La instrucción Multiply Add (FMA) fusionada disponible con AVX2 utilizando registros de coma flotante de 256 bits (FP) es ideal para código entero y tipos de datos, lo que da como resultado una aceleración de hasta dos veces. En lo que respecta a los tipos de datos y código FP, AVX2 logra una aceleración del 8 % con respecto a AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Para crear TensorFlow a partir de origen, NetApp recomienda usar<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>. Para nuestro entorno, hemos ejecutado los siguientes comandos en el intérprete de comandos del shell para instalar<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block>, Y Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Debe habilitar GCC 5 o posterior para utilizar las funciones C++17 durante el proceso de compilación, que proporciona RHEL con la biblioteca de colecciones de software (SCL). Los siguientes comandos se instalan<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> Y GCC 11.2.1 en nuestro clúster RHEL 7.9:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">artículo</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Tenga en cuenta que los dos últimos comandos se habilitan<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>, que utiliza<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1). También, asegúrese de que su<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> La versión es superior a 1.8.3 (se incluye con RHEL 7.9). Consulte este apartado<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> para la actualización<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> a 2.24.1.</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">“Guiones de Python para cada caso de uso principal”,</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">Asumimos que ya ha clonado el repo maestro TensorFlow más reciente. A continuación, cree un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> directorio con un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> Archivo para crear TensorFlow a partir de origen con AVX, AVX2 y FMA. Ejecute el<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> Y especifique la ubicación binaria Python correcta.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> Está deshabilitado para nuestras pruebas porque no utilizamos una GPU. A.<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> el archivo se genera de acuerdo con su configuración. Además, hemos editado el archivo y configurado<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> Para habilitar el soporte de HDFS. Consulte<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> en la sección <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> para ver una lista completa de valores y marcas.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Después de crear TensorFlow con los indicadores correctos, ejecute la siguiente secuencia de comandos para procesar el conjunto de datos de anuncios de visualización Criteo, formar un modelo DeepFM y calcular el área bajo la curva de características operativas del receptor (AUC ROC) a partir de las puntuaciones de predicción.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Después de diez épocas de entrenamiento, hemos obtenido la puntuación del AUC en el conjunto de datos de pruebas:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">De un modo similar a los casos de uso anteriores, comparamos el tiempo de ejecución del flujo de trabajo de Spark con los datos alojados en diferentes ubicaciones. En la siguiente figura, se muestra una comparación de la predicción del CTR de aprendizaje profundo para un tiempo de ejecución de los flujos de trabajo de Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Comparación de la predicción del CTR de aprendizaje profundo para un tiempo de ejecución de los flujos de trabajo de Spark.</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">Siguiente: Solución de cloud híbrido.</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: E5700 E-Series de NetApp y Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 describe la arquitectura integrada del diseño de E-Series y Splunk de NetApp. Optimizado para un equilibrio de almacenamiento en nodos, fiabilidad, rendimiento, capacidad de almacenamiento y densidad, Este diseño emplea el modelo de nodo de índice en clúster de Splunk, con una mayor escalabilidad y un TCO menor. Separar el almacenamiento de la computación permite escalar cada uno de manera independiente, lo que se traduce en un ahorro del coste derivado del sobreaprovisionamiento entre uno y otro. Además, este documento resume los resultados de las pruebas de rendimiento obtenidos a partir de una herramienta de simulación de eventos de registro de equipos Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Esta sección abarca el hardware y el software empleados para la verificación del rendimiento en la puesta en marcha de plataformas Confluent con ONTAP de NetApp para el almacenamiento por niveles. La siguiente tabla abarca la arquitectura de la solución y los componentes base.</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent y la controladora de almacenamiento AFF A900 de NetApp con ONTAP son sistemas distribuidos diseñados para flujos de datos. Ambos son escalables horizontalmente, tolerantes a fallos y proporcionan un excelente rendimiento con carga. Estas tecnologías se complementan entre sí en el procesamiento de streaming y flujo de datos distribuidos con un coste de almacenamiento inferior, gracias a las tecnologías de reducción de datos que minimizan el espacio utilizado. La controladora de almacenamiento AFF A900 proporciona un gran rendimiento, a la vez que permite desconectar los recursos de computación y almacenamiento de datos. De este modo se simplifica la administración del sistema y se pueden escalar los recursos de forma independiente.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Imagen que muestra la descripción general de la solución.</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">Detalles de la arquitectura de la solución</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Componente de plataforma</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configuración del entorno</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Plataforma Confluente, versión 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 zookeepers</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 servidores de broker</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 servidores de herramientas</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centro de control</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Sistema operativo en todos los nodos</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (ubuntu 18.04)</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">ONTAP de NetApp para cubos calientes</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 par de alta disponibilidad (ha) AFF A900</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocolo S3</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100 GbE</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 servidores PRIMERGY RX2540 de Fujitsu</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPU; 16 núcleos físicos en total</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Xeon de Intel</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB de memoria física</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Puerto doble de 100 GbE</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">Las siguientes referencias se han utilizado en este informe técnico:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Arquitectura y componentes de Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Casos de uso de Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Problemas de Apache</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="list-text">Chispa NLP</block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Red profunda y cruzada para predicciones de clic de anuncios</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">Streaming ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Soluciones E-Series de NetApp para Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">Análisis de confianza en las comunicaciones con el cliente con IA de NetApp</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Soluciones de análisis de datos modernas de NetApp</block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Kit de herramientas de operaciones de datos</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Esta página describe la tecnología utilizada en esta solución.</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">Anterior: Solución.</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Controladora de almacenamiento ONTAP de NetApp</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">ONTAP de NetApp es un sistema operativo de almacenamiento empresarial de alto rendimiento.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">ONTAP 9.8 de NetApp presenta compatibilidad con las API de Amazon simple Storage Service (S3). ONTAP admite un subconjunto de acciones de la API de Amazon Web Services (AWS) S3 y permite que los datos se representen como objetos en sistemas basados en ONTAP, en proveedores de cloud (AWS, Azure y GCP) y en las instalaciones.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">El software StorageGRID de NetApp es la solución estrella de NetApp para el almacenamiento de objetos. ONTAP complementa a StorageGRID proporcionando un punto de procesamiento y procesamiento previo en el perímetro, ampliando el Data Fabric impulsado por NetApp para los datos de objetos y aumentando el valor de la cartera de productos de NetApp.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">El acceso a un bloque de S3 se proporciona mediante aplicaciones de cliente y usuario autorizados. En el siguiente diagrama se muestra la aplicación que accede a un bloque de S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">En este gráfico se muestra la aplicación que accede a un bloque de S3.</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Principales casos de uso</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">El objetivo principal de admitir las API S3 es proporcionar acceso a objetos en ONTAP. La arquitectura de almacenamiento unificado de ONTAP ahora admite archivos (NFS y SMB), bloques (FC e iSCSI) y objetos (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Aplicaciones S3 nativas</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Un número cada vez mayor de aplicaciones puede aprovechar la compatibilidad con ONTAP para el acceso a objetos mediante S3. Si bien está indicada para cargas de trabajo de archivado de gran capacidad, la necesidad de un alto rendimiento en las aplicaciones nativas de S3 crece rápidamente e incluye:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Análisis</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Inteligencia artificial</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Ingesta del perímetro al núcleo</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="list-text">Aprendizaje automático</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Los clientes ahora pueden usar herramientas de capacidad de gestión conocidas como System Manager de ONTAP para aprovisionar rápidamente almacenamiento de objetos de alto rendimiento para el desarrollo y las operaciones en ONTAP, aprovechando las eficiencias y la seguridad del almacenamiento de ONTAP al igual que lo hacen.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Extremos de FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">A partir de ONTAP 9.8, FabricPool admite la organización en niveles en ONTAP, lo que permite la organización en niveles de ONTAP a ONTAP. Esta es una excelente opción para los clientes que desean reorganizar su infraestructura de FAS existente como un extremo de almacenamiento de objetos.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool permite organizar en niveles en ONTAP de dos formas:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Distribución local del clúster.* los datos inactivos se organizan por niveles en un bloque ubicado en el clúster local mediante LIF de clúster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Distribución remota del clúster.* los datos inactivos se organizan en niveles en un bloque ubicado en un clúster remoto de forma similar a un nivel de cloud FabricPool tradicional mediante LIF de IC en el cliente FabricPool y LIF de datos en el almacén de objetos ONTAP.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 es adecuado si se desean funcionalidades de S3 en los clústeres existentes sin necesidad de hardware ni gestión adicionales. Para implementaciones de más de 300 TB, el software StorageGRID de NetApp sigue siendo la solución insignia de NetApp para el almacenamiento de objetos. No es necesaria una licencia de FabricPool cuando se usa ONTAP o StorageGRID como nivel de cloud.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">ONTAP de NetApp para el almacenamiento por niveles fluido</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Todos los centros de datos deben mantener las aplicaciones vitales para el negocio en funcionamiento y los datos importantes disponibles y seguros. El nuevo sistema AFF A900 de NetApp cuenta con el software ONTAP Enterprise Edition y un diseño de gran flexibilidad. Nuestro nuevo sistema de almacenamiento NVMe increíblemente rápido elimina las interrupciones en las operaciones de misión crítica, minimiza el ajuste del rendimiento y protege sus datos de ataques de ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Desde la puesta en marcha inicial hasta el escalado de su clúster Confluent, su entorno requiere una rápida adaptación a los cambios que no son disruptivos para las aplicaciones vitales para el negocio. La gestión de datos empresariales, la calidad de servicio y el rendimiento de ONTAP le permiten planificar y adaptarse al entorno.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">El uso conjunto de ONTAP de NetApp y Confluent Storage simplifica la gestión de clústeres de Apache Kafka aprovechando ONTAP como destino de almacenamiento de escalado horizontal y permite un escalado independiente de los recursos de computación y almacenamiento para Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un servidor ONTAP S3 se basa en las funcionalidades de almacenamiento maduro de escalado horizontal de ONTAP. El escalado de su clúster de ONTAP se puede realizar sin problemas mediante la ampliación de sus bloques de S3 para usar nodos recién añadidos al clúster de ONTAP.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestión sencilla con System Manager de ONTAP</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">System Manager de ONTAP es una interfaz gráfica basada en navegador que permite configurar, gestionar y supervisar la controladora de almacenamiento de ONTAP en ubicaciones distribuidas por todo el mundo en una única consola.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Este gráfico muestra el espacio de trabajo del Administrador del sistema de ONTAP.</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Puede configurar y gestionar ONTAP S3 con System Manager y la interfaz de línea de comandos de ONTAP. Cuando se habilita S3 y se crean bloques con System Manager, ONTAP proporciona valores predeterminados de prácticas recomendadas para una configuración simplificada. Si configura el servidor y los bloques de S3 desde la CLI, puede seguir gestionarlos con System Manager si lo desea o viceversa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Cuando se crea un bloque de S3 con System Manager, ONTAP configura un nivel de servicio de rendimiento predeterminado que es el más alto disponible en el sistema. Por ejemplo, en un sistema AFF, la configuración predeterminada sería extrema. Los niveles de servicio de rendimiento son grupos de políticas de calidad de servicio adaptativos predefinidos. En lugar de uno de los niveles de servicio predeterminados, puede especificar un grupo de políticas de calidad de servicio personalizado o ningún grupo de políticas.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Los grupos de políticas de calidad de servicio adaptativas predefinidos incluyen los siguientes:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extreme.* se utiliza para aplicaciones que requieren la latencia más baja y el rendimiento más alto.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Rendimiento.* utilizado para aplicaciones con necesidades de rendimiento y latencia modestos.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valor.* utilizado para aplicaciones para las que el rendimiento y la capacidad son más importantes que la latencia.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Personalizado.* especifique una directiva QoS personalizada o ninguna directiva QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Si selecciona *usar para clasificación por niveles*, no se seleccionan niveles de servicio de rendimiento y el sistema intenta seleccionar medios de bajo costo con un rendimiento óptimo para los datos organizados por niveles.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP intenta aprovisionar este bloque en niveles locales que tengan los discos más adecuados para cumplir el nivel de servicio elegido. Sin embargo, si necesita especificar qué discos se incluirán en el bloque, considere la configuración del almacenamiento de objetos S3 desde la CLI especificando los niveles locales (agregado). Si configura el servidor S3 desde la CLI, puede seguir gestionarlo con System Manager si lo desea.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Si desea la capacidad de especificar qué agregados se utilizan para bloques, solo puede hacerlo mediante la CLI.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform es una plataforma de transmisión de datos a escala completa que le permite acceder, almacenar y gestionar los datos fácilmente como flujos continuos y en tiempo real. Diseñado por los creadores originales de Apache Kafka, Confluent amplía las ventajas de Kafka con funciones de nivel empresarial al tiempo que elimina la carga de la gestión o supervisión de Kafka. Hoy en día, más del 80 % de las empresas Fortune 100 cuentan con tecnología de transmisión de datos y la mayoría utilizan Confluent.</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Gracias a la plataforma Confluent podrá centrarse en cómo obtener valor empresarial de sus datos en lugar de preocuparse por los mecanismos subyacentes, como por ejemplo, cómo se transportan datos o se integran entre sistemas dispares. En concreto, Confluent Platform simplifica la conexión de fuentes de datos a Kafka, la creación de aplicaciones de streaming y la protección, supervisión y gestión de la infraestructura de Kafka. En la actualidad, Confluent Platform se utiliza en una amplia variedad de casos de uso en numerosos sectores, desde servicios financieros, ventas al por menor de todos los canales y coches autónomos, hasta detección de fraude, microservicios e Internet de las cosas.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La siguiente figura muestra los componentes de Confluent Platform.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Este gráfico muestra los componentes de Confluent Platform.</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Descripción general de la tecnología de transmisión de eventos Confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">En el centro de la plataforma Confluente lo es<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>, la plataforma de transmisión distribuida de código abierto más popular. Entre las capacidades clave de Kafka se incluyen las siguientes:</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Descripción general de las funciones empresariales de la plataforma Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">* Confluent Control Center.* un sistema basado en la interfaz de usuario para la gestión y monitorización de Kafka. Le permite gestionar fácilmente Kafka Connect y crear, editar y gestionar conexiones a otros sistemas.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Conectores Kafka Connect.* Utilice la API Kafka Connect para conectar Kafka a otros sistemas como bases de datos, almacenes de clave-valor, índices de búsqueda y sistemas de archivos. Confluent Hub tiene conectores descargables para las fuentes de datos y los sumideros más populares, incluidas versiones totalmente probadas y compatibles de estos conectores con Confluent Platform. Encontrará más información<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Clústeres de equilibrio automático.* proporciona equilibrio de carga automatizado, detección de fallos y autorreparación. También ofrece soporte para la adición o retirada de agentes según sea necesario, sin ajustes manuales.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">* Confluent auto data equilibrador.* supervisa su clúster para el número de corredores, el tamaño de particiones, el número de particiones y el número de líderes dentro del clúster. Permite mover datos para crear una carga de trabajo uniforme en su clúster, a la vez que se desregula el tráfico del reequilibrio para minimizar el efecto en las cargas de trabajo de producción al mismo tiempo que se reequilibran.</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">Siguiente: Validación de rendimiento fluido.</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">A medida que los clientes obtienen la capacidad y la facilidad de usar los análisis de datos de Splunk, buscan, naturalmente, indexar una cantidad de datos cada vez mayor. A medida que aumenta la cantidad de datos, también lo hace la infraestructura de informática y almacenamiento necesaria para prestar servicios.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Organización en niveles inteligente y ahorro de costes</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">Anterior: Ventajas de esta solución.</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">A medida que los clientes obtienen la capacidad y la facilidad de usar los análisis de datos de Splunk, buscan, naturalmente, indexar una cantidad de datos cada vez mayor. A medida que aumenta la cantidad de datos, también lo hace la infraestructura de informática y almacenamiento necesaria para prestar servicios. Dado que a los datos más antiguos se hace referencia con menos frecuencia, la Comisión de la misma cantidad de recursos informáticos y, en este caso, consume un almacenamiento principal caro es cada vez más ineficiente. Para operar a escala, los clientes se benefician del traslado de datos calientes a un nivel más rentable, lo que libera recursos informáticos y almacenamiento primario para los datos activos.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore con StorageGRID ofrece a las organizaciones una solución escalable, de alto rendimiento y rentable. Dado que SmartStore tiene en cuenta los datos, evalúa automáticamente los patrones de acceso a los datos para determinar qué datos deben estar accesibles para análisis en tiempo real (datos activos) y qué datos deben residir en un almacenamiento a largo plazo de menor coste (datos templados). SmartStore utiliza la API estándar del sector de AWS S3 de forma dinámica e inteligente, ubicando los datos en el almacenamiento S3 proporcionado por StorageGRID. La arquitectura flexible de escalado horizontal de StorageGRID permite que el nivel de datos calientes crezca de forma rentable según sea necesario. La arquitectura de StorageGRID basada en nodos garantiza que los requisitos de rendimiento y coste se satisfacen de forma óptima.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">En la siguiente imagen se ilustra la organización en niveles de Splunk y StorageGRID.</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinación líder del sector de Splunk SmartStore con StorageGRID de NetApp proporciona las ventajas de la arquitectura desacoplada a través de una solución de pila completa.</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Análisis de datos moderno: Diferentes soluciones para diferentes estrategias de análisis</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">Este whitepaper describe las estrategias de soluciones de análisis de datos modernas de NetApp. Incluye información detallada sobre los resultados empresariales, retos de los clientes, tendencias tecnológicas, arquitectura heredada de la competencia, flujos de trabajo modernos, casos de uso, sectores, cloud, partners de tecnología, transportadores de datos, Active IQ de NetApp, kit de herramientas de operaciones de datos de NetApp, Hadoop to Spark, almacenamiento definido por software con Astra Control de NetApp, contenedores, gestión de datos empresariales, archivado y organización en niveles hacia el logro de los objetivos de la IA y el análisis y cómo NetApp y los clientes modernizan su arquitectura de datos de manera conjunta.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">En esta sección se resume este documento en relación con las soluciones de almacenamiento de NetApp para Apache Spark.</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">Anterior: Scripts de Python para cada caso de uso principal.</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">En este documento, comentamos la arquitectura Apache Spark, los casos de uso de clientes y la cartera de almacenamiento de NetApp en relación a Big Data, análisis modernos e IA, ML y DL. En nuestras pruebas de validación del rendimiento basadas en herramientas de pruebas de rendimiento estándares del sector y la demanda de los clientes, las soluciones de Spark de NetApp demostraron un rendimiento superior en comparación con los sistemas Hadoop nativos. Una combinación de los casos de uso de clientes y los resultados de rendimiento que se presentan en este informe puede ayudarle a elegir la solución Spark adecuada para su puesta en marcha.</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">La solución permite añadir recursos informáticos, de almacenamiento activo o de S3 para satisfacer la creciente demanda en términos del número de usuarios o la tasa de procesamiento en puestas en marcha únicas y multisitio.</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Rendimiento.* la combinación de Splunk SmartStore y NetApp StorageGRID proporciona una rápida migración de datos entre bloques activos y depósitos calientes mediante el almacenamiento de objetos. StorageGRID potencia el proceso de migración ofreciendo un rendimiento rápido para grandes cargas de trabajo de objetos.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Preparado para varios sitios.* la arquitectura distribuida de StorageGRID permite a Splunk SmartStore ampliar las implementaciones en uno o varios sitios a través de un único espacio de nombres global donde se puede acceder a los datos desde cualquier sitio independientemente de dónde residan.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Escalabilidad mejorada.* Escale los recursos de almacenamiento de forma independiente de los recursos informáticos para satisfacer las necesidades y demandas en evolución de su entorno Splunk, con lo que se mejora el TCO.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacidad.* satisfaga los volúmenes de rápido crecimiento en la implementación de Splunk con StorageGRID mediante el escalado de un espacio de nombres único a más de 560 PB.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilidad de datos.* optimizar la disponibilidad de datos, el rendimiento, la distribución geográfica, la retención, la protección, de almacenamiento y costes con políticas condicionadas por metadatos que pueden adaptarse de forma dinámica a medida que evoluciona el valor de negocio de sus datos.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Directrices proporcionadas por Splunk</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">Aumente el rendimiento con el almacenamiento en caché SmartStore, que es un componente del indizador que gestiona la transferencia de copias de bloques entre el almacenamiento local (activo) y remoto (en caliente). La configuración de tamaño de Splunk para esta solución se basa en la<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>. La solución permite añadir recursos informáticos, de almacenamiento activo o de S3 para satisfacer la creciente demanda en términos del número de usuarios o la tasa de procesamiento en puestas en marcha únicas y multisitio.</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">Siguiente: Organización en niveles inteligente y ahorro de costes.</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">Scripts Python para cada caso de uso principal</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">Anterior: Solución de cloud híbrido.</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Las tres secuencias de comandos de Python siguientes corresponden a los tres casos de uso principales probados. La primera es<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>.</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">El segundo guión es<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">El tercer guión es<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>.</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Este documento describe las pruebas de rendimiento para la plataforma Confluent en ONTAP de NetApp mediante un kit de pruebas de rendimiento de almacenamiento por niveles.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Relaciones con las controladoras de almacenamiento ONTAP de NetApp</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluente</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Para que la plataforma Confluent sea más escalable y elástica, debe poder escalar y equilibrar las cargas de trabajo muy rápidamente. El almacenamiento por niveles permite que el almacenamiento de grandes volúmenes de datos en Confluent sea gestionable reduciendo esta carga operativa. La idea fundamental es separar el almacenamiento de datos del procesamiento de datos, lo que facilita en gran medida el escalado de cada uno de ellos independientemente.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Cargado con innovaciones líderes en el sector, el software de gestión de datos ONTAP de NetApp proporciona fluidez con muchas ventajas en cualquier lugar en el que residen los datos.</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">Siguiente: Solución.</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">En esta página, se tratan los retos a los que se puede enfrentar un cliente al intentar acceder a los datos desde análisis de Big Data para operaciones de IA.</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Los clientes pueden enfrentarse a los siguientes retos al intentar acceder a los datos desde los análisis de Big Data para operaciones de IA:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Los datos del cliente se encuentran en un repositorio de lago de datos. El lago de datos puede contener diferentes tipos de datos, como datos estructurados, no estructurados, semiestructurados, registros y datos entre equipos. Todos estos tipos de datos deben procesarse en sistemas de IA.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">La IA no es compatible con los sistemas de archivos Hadoop. Una arquitectura de IA típica no puede acceder directamente a los datos de HDFS y HCFS, que deben moverse a un sistema de archivos comprensible para IA (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">La transferencia de datos sobre el lago de datos a la IA normalmente requiere procesos especializados. La cantidad de datos en el lago de datos puede ser muy grande. Un cliente debe tener un método eficiente, de alto rendimiento y rentable para mover datos a sistemas de IA.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Sincronizando datos. Si un cliente desea sincronizar datos entre la plataforma de Big Data e IA, en ocasiones los datos procesados mediante la IA se pueden usar con Big Data para su procesamiento analítico.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">Siguiente: Solución de movimiento de datos.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Realizamos pruebas de almacenamiento por niveles con cinco u ocho nodos de intermediario durante una carga de trabajo de consumo de producto con la controladora de almacenamiento NetApp de par de alta disponibilidad AFF A900. De acuerdo con nuestras pruebas, el tiempo de finalización y los resultados del rendimiento se ampliaron con el número de nodos de broker hasta que la utilización de recursos de AFF A900 alcanzaba el 100%. La configuración de la controladora de almacenamiento de ONTAP requería un mínimo de un par de alta disponibilidad.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Pruebas de rendimiento con generador de cargas de trabajo que consumen productos</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">Anterior: Validación de rendimiento fluido.</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">El rendimiento de la operación de recuperación de S3 aumentó linealmente en función del número de nodos de intermediarios converfluentes. La controladora de almacenamiento ONTAP admite hasta 12 pares de alta disponibilidad en una única puesta en marcha.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">En el siguiente gráfico, se muestra el tráfico combinado de organización en niveles de S3 con cinco u ocho nodos de agente. Hemos maximizado el rendimiento del par de alta disponibilidad único de AFF A900.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">En este gráfico de datos, se muestra el tráfico de organización en niveles de S3 combinado con cinco u ocho nodos de agente.</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">El siguiente gráfico muestra el rendimiento de Kafka con aproximadamente 31.74Gbps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">En este gráfico de datos se muestra el rendimiento de Kafka con aproximadamente 31,74 Gbps.</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">También observamos un rendimiento similar en la controladora de almacenamiento de ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> informes.</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">Siguiente: Directrices de mejores prácticas de rendimiento.</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">En esta página se describe la validación del rendimiento de Confluent dentro de los parámetros de esta solución.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validación del rendimiento fluido</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Hemos realizado la verificación con la plataforma Confluent para el almacenamiento por niveles en ONTAP de NetApp. Los equipos de NetApp y Confluent trabajaron juntos en esta verificación y ejecutaron los casos de prueba necesarios para TI.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configuración con fluidez</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Para la configuración, utilizamos tres zoookeepers, cinco brokers y cinco servidores de prueba con 256 GB de RAM y 16 CPU. En el almacenamiento de NetApp, utilizamos ONTAP con un par de alta disponibilidad A900 de AFF. El almacenamiento y los agentes se conectaron a través de conexiones de 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La siguiente figura muestra la topología de red de la configuración utilizada para la verificación del almacenamiento por niveles.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Este gráfico muestra la topología de red de la configuración utilizada para la verificación del almacenamiento por niveles.</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Los servidores de herramientas actúan como clientes de aplicación que envían o reciben eventos desde o hacia los nodos Confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Utilizamos los siguientes parámetros de prueba:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Para la verificación, utilizamos ONTAP con el protocolo HTTP, pero HTTPS también funcionó. La clave de acceso y la clave secreta se almacenan en el nombre de archivo que se proporciona en el<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parámetro.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Controladora de almacenamiento de NetApp: ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Hemos configurado una configuración de par de alta disponibilidad único en ONTAP para su verificación.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">En este gráfico se muestra cómo se configuró el entorno como un único par de alta disponibilidad para la verificación.</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Resultados de verificación</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Completamos los cinco casos de prueba siguientes para la verificación. Las dos primeras fueron pruebas de funcionalidad y las tres restantes fueron pruebas de rendimiento.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Esta prueba realiza operaciones básicas como Get, put y delete en el almacén de objetos utilizado para el almacenamiento organizado en niveles mediante llamadas API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Esta prueba comprueba la funcionalidad integral del almacenamiento de objetos. Crea un tema, produce un flujo de eventos al tema recién creado, espera a que los agentes archiven los segmentos en el almacenamiento de objetos, consume la secuencia de eventos y valida la secuencia consumida coincide con la secuencia producida. Hemos realizado este test con y sin inyección de fallo del almacén de objetos. Simulamos el fallo del nodo deteniendo el servicio de gestor de servicios en uno de los nodos en ONTAP y validando que la funcionalidad integral funciona con almacenamiento de objetos.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Generador de cargas de trabajo que consumen productos</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Esta prueba genera indirectamente la carga de trabajo de escritura en el almacén de objetos mediante el archivado de segmentos. La carga de trabajo de lectura (segmentos leídos) se generó desde el almacenamiento de objetos cuando los grupos de consumidores obtuvieron los segmentos. Esta carga de trabajo fue generada por un script TOCC. En esta prueba se verificó el rendimiento de lectura y escritura en el almacenamiento de objetos en subprocesos paralelos. Hemos probado con y sin inyección de fallo en el almacén de objetos como lo hicimos con la prueba de corrección de la funcionalidad de organización en niveles.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Generador de cargas de trabajo de retención</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">En esta prueba se comprobó el rendimiento de eliminación de un almacenamiento de objetos en una carga de trabajo con una gran retención de temas. La carga de trabajo de retención se generó mediante un script TOCC que produce muchos mensajes en paralelo a un tema de prueba. El tema de prueba se configuraba con una configuración de retención agresiva basada en tamaño y en tiempo que provocaba que la secuencia de eventos se purgaran continuamente del almacén de objetos. A continuación, se archivaron los segmentos. Esto provocó muchas eliminaciones en el almacenamiento de objetos por parte del agente y la colección del rendimiento de las operaciones de eliminación de almacén de objetos.</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Para obtener detalles de verificación, consulte<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> sitio web.</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">Siguiente: Pruebas de rendimiento con generador de cargas de trabajo de producción-consumo.</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Esta sección proporciona una descripción detallada de los casos de uso de protección de datos que constituyen el centro de este documento. En el resto de secciones, se proporcionan más detalles sobre cada caso práctico, como el problema del cliente (escenario), los requisitos y retos, y las soluciones.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Descripción general de los casos prácticos de protección de datos de Hadoop</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">Anterior: Protección de datos de Hadoop y NetApp.</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="817ac2975197bd6c376a7918a798981f" category="section-title">Caso de uso 1: Backup de datos de Hadoop</block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">En este caso de uso, el módulo de análisis in situ ayudó a una institución financiera de gran tamaño a reducir el tiempo prolongado para hacer backup de más de 24 horas a poco menos de unas pocas horas.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Al utilizar Data Fabric con la tecnología de NetApp como elementos básicos, una gran empresa de retransmisión pudo cumplir los requisitos de realizar backups de los datos del cloud en su centro de datos en las instalaciones en función de los diferentes modos de transferencia de datos, como, por ejemplo, bajo demanda, de forma instantánea. O basado en la carga del clúster de Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Las soluciones de NetApp ayudaron a un distribuidor de música en línea a crear rápidamente varios clústeres de Hadoop con una gestión eficiente del espacio en diferentes sucursales, con el fin de crear informes y ejecutar tareas diarias de DevTest mediante políticas programadas.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un gran proveedor de servicios utilizó el Data Fabric con tecnología de NetApp para proporcionar análisis multicloud a sus clientes de diferentes instancias de cloud.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="section-title">Caso de uso 5: Acelerar las cargas de trabajo analíticas</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Uno de los mayores bancos de inversión y servicios financieros utilizó la solución de almacenamiento conectado a la red de NetApp para reducir el tiempo de espera de I/o y acelerar su plataforma de análisis financiero cuantitativo.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">Siguiente: Caso de uso 1: Backup de los datos de Hadoop.</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Esta página describe las mejores prácticas para mejorar el rendimiento en esta solución.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Directrices de mejores prácticas de rendimiento</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">Anterior: Pruebas de rendimiento con generador de cargas de trabajo de producción-consumo.</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Para ONTAP, si es posible, UTILICE OBTENER tamaño &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Aumentando<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> y..<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> pulg<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> En los nodos de agente, puede pasar la actividad aumentada de organización en niveles a nivel de S3. Estos resultados son con<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> y..<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> establezca el valor 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">Los bloques de S3 deben apuntar a ocho constituyentes por agregado del miembro.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Los enlaces Ethernet que impulsan el tráfico S3 deben usar un MTU de 9k cuando sea posible en el almacenamiento y en el cliente.</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Este documento describe las soluciones de datos en el cloud híbrido mediante los sistemas de almacenamiento AFF y FAS de NetApp, Cloud Volumes ONTAP de NetApp, el almacenamiento conectado de NetApp y la tecnología FlexClone de NetApp para Spark y Hadoop. Estas arquitecturas de soluciones permiten a los clientes elegir una solución de protección de datos adecuada para su entorno. NetApp ha diseñado estas soluciones basándose en la interacción con los clientes y sus casos prácticos empresariales.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam y Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Este documento describe las soluciones de datos en el cloud híbrido mediante los sistemas de almacenamiento AFF y FAS de NetApp, Cloud Volumes ONTAP de NetApp, el almacenamiento conectado de NetApp y la tecnología FlexClone de NetApp para Spark y Hadoop. Estas arquitecturas de soluciones permiten a los clientes elegir una solución de protección de datos adecuada para su entorno. NetApp ha diseñado estas soluciones basándose en la interacción con los clientes y sus casos prácticos empresariales. Este documento proporciona información detallada siguiente:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Por qué necesitamos protección de datos para entornos Spark y Hadoop y nuestros retos a los clientes.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">Data Fabric impulsado por la visión de NetApp y sus elementos básicos y servicios.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Cómo se pueden utilizar estos elementos básicos para diseñar flujos de trabajo de protección de datos flexibles.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Ventajas e inconvenientes de varias arquitecturas basadas en casos de uso de clientes reales. Cada caso de uso proporciona los siguientes componentes:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Situaciones de clientes</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">NetApp</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Resumen de las soluciones</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">¿Por qué la protección de datos de Hadoop?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">En un entorno Hadoop y Spark, se deben solucionar las siguientes preocupaciones:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Fallos de software o humanos.* error humano en las actualizaciones de software mientras se realizan operaciones de datos de Hadoop puede provocar un comportamiento defectuoso que puede causar resultados inesperados del trabajo. En tal caso, necesitamos proteger los datos para evitar fallas o resultados irrazonables. Por ejemplo, como resultado de una actualización de software mal ejecutada en una aplicación de análisis de señales de tráfico, una nueva característica que no analiza correctamente los datos de señales de tráfico en forma de texto sin formato. El software sigue analizando JSON y otros formatos de archivos que no sean de texto, lo que provoca que el sistema de análisis del control de tráfico en tiempo real produzca resultados de predicción que faltan puntos de datos. Esta situación puede causar salidas defectuosas que podrían provocar accidentes en las señales de tráfico. La protección de datos puede resolver este problema proporcionando la capacidad de volver rápidamente a la versión anterior de la aplicación de trabajo.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Tamaño y escala.* el tamaño de los datos de análisis aumenta día a día debido al número cada vez mayor de fuentes de datos y volumen. Las redes sociales, las aplicaciones móviles, los análisis de datos y las plataformas de cloud computing son las principales fuentes de datos del mercado actual de Big Data, que aumenta con gran rapidez y, por tanto, los datos deben protegerse para garantizar operaciones de datos precisas.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">*Protección de datos nativos de Hadoop.* Hadoop tiene un comando nativo para proteger los datos, pero este comando no proporciona coherencia de datos durante la copia de seguridad. Solo admite backups a nivel de directorio. Las copias Snapshot que crea Hadoop son de solo lectura y no se pueden utilizar para reutilizar los datos de backup directamente.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Retos de la protección de datos para los clientes de Hadoop y Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Un reto común para los clientes de Hadoop y Spark es reducir el tiempo de backup y aumentar la fiabilidad de éste sin que se vea afectado negativamente el rendimiento del clúster de producción durante la protección de datos.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Los clientes también deben minimizar el objetivo de punto de recuperación (RPO) y el tiempo de inactividad del objetivo de tiempo de recuperación (RTO) y controlar sus sitios de recuperación ante desastres internos y basados en el cloud para obtener una continuidad empresarial óptima. Normalmente, este control se debe a que dispone de herramientas de gestión de nivel empresarial.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Los entornos Hadoop y Spark son complicados porque no solo el volumen de datos es enorme y está creciendo, sino que la velocidad a la que llegan estos datos está aumentando. Esta situación dificulta la creación rápida de entornos eficientes y actualizados de DevTest y QA a partir de los datos de origen. NetApp reconoce estos retos y ofrece las soluciones presentadas en este documento.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">Siguiente: Data Fabric con la tecnología de NetApp para la arquitectura de Big Data.</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Un centro de datos empresarial moderno es un cloud híbrido que conecta varios entornos de infraestructura distribuidos a través de un plano de gestión de datos continua con un modelo operativo consistente, en las instalaciones o en varios clouds públicos. Para sacarle el máximo partido a un cloud híbrido, debe ser capaz de mover datos con fluidez entre sus entornos locales y varios cloud sin necesidad de realizar conversiones de datos o refactorizaciones de aplicaciones.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Solución de cloud híbrido</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">Anterior: Resultados de las pruebas.</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Los clientes han indicado que inician su transición al cloud híbrido mediante el movimiento de almacenamiento secundario al cloud para casos de uso como la protección de datos o trasladando cargas de trabajo menos vitales para el negocio como el desarrollo de aplicaciones y DevOps al cloud. Después, se mueven a cargas de trabajo más críticas. El alojamiento web y de contenido, DevOps y el desarrollo de aplicaciones, bases de datos, análisis y aplicaciones en contenedores son algunas de las cargas de trabajo de cloud híbrido más populares. La complejidad, el coste y los riesgos de los proyectos de IA empresarial han dificultado históricamente la adopción de la IA desde la fase experimental hasta la producción.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Con una solución de cloud híbrido de NetApp, los clientes se benefician de las herramientas integradas de seguridad, gobernanza de datos y cumplimiento de normativas, con un único panel de control para la gestión de datos y flujos de trabajo en entornos distribuidos, al tiempo que optimizan el coste total de propiedad en función de su consumo. La siguiente figura representa una solución de ejemplo de un partner de servicio de cloud que ha encargado de proporcionar conectividad multicloud para los datos de análisis de Big Data de los clientes.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Ejemplo de solución de un socio de servicios en nube.</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">En este escenario, los datos de IoT recibidos en AWS de diferentes orígenes se almacenan en una ubicación central en el almacenamiento privado de NetApp (NPS). El almacenamiento NPS está conectado a clústeres de Spark o Hadoop ubicados en AWS y Azure y permite que se ejecuten aplicaciones de análisis de Big Data en varios clouds accediendo a los mismos datos. Entre los principales requisitos y retos para este caso de uso se encuentran los siguientes:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Los datos deben recibirse de diferentes fuentes, como los entornos locales y de cloud, mediante distintos sensores y concentradores.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La solución debe ser eficiente y rentable.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">El principal reto consiste en crear una solución rentable y eficiente que ofrezca servicios de análisis híbridos entre diferentes entornos de cloud y locales.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Nuestra solución de conectividad multicloud y protección de datos resuelve el problema de tener aplicaciones de análisis en cloud en múltiples proveedores a hiperescala. Como se muestra en la figura anterior, los datos de los sensores se transmiten y ingieren en el clúster de AWS Spark a través de Kafka. Los datos se almacenan en un recurso compartido de NFS que reside en NPS, que se encuentra fuera del proveedor de cloud en un centro de datos Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Dado que el almacenamiento privado de NetApp se conecta con Amazon AWS y Microsoft Azure mediante las conexiones Direct Connect y Express Route respectivamente, los clientes pueden aprovechar el módulo de análisis in situ para acceder a los datos desde los clústeres de análisis de Amazon y AWS. Por lo tanto, dado que tanto el almacenamiento local como el NPS ejecutan el software ONTAP,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> Puede reflejar los datos de NPS en el clúster en las instalaciones, lo que proporciona análisis en el cloud híbrido entre las instalaciones y varios clouds.</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">Para obtener el mejor rendimiento, NetApp suele recomendar el uso de varias interfaces de red, así como una conexión directa o rutas exprés para acceder a los datos desde instancias del cloud. Tenemos otras soluciones de movimiento de datos, incluyendo<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> y..<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> Para ayudar a los clientes a crear clústeres de Spark de cloud híbrido rentables, seguros y compatibles con aplicaciones.</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">Siguiente: Scripts de Python para cada caso de uso principal.</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">En este escenario, el cliente tiene un gran repositorio local de Hadoop y desea realizar un backup para fines de recuperación ante desastres. Sin embargo, la solución de backup actual del cliente es costosa y padece una larga duración de backup de más de 24 horas.</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">Anterior: Descripción general de los casos de uso de protección de datos de Hadoop.</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Compatibilidad con versiones anteriores del software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La solución de backup alternativa propuesta debe ser compatible con las versiones de software que se estén ejecutando actualmente y que se utilicen en el clúster de Hadoop de producción.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Con el fin de cumplir los acuerdos de nivel de servicio comprometidos, la solución alternativa propuesta debería alcanzar unos objetivos de punto de recuperación y de tiempo de recuperación muy bajos.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">El backup creado por la solución de backup de NetApp se puede usar en el clúster de Hadoop, creado localmente en el centro de datos, así como en el clúster de Hadoop que se ejecuta en la ubicación de recuperación ante desastres del sitio remoto.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La solución propuesta debe ser rentable.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La solución propuesta debe reducir el efecto sobre el rendimiento de las tareas de análisis en producción que se están ejecutando actualmente durante los tiempos de backup.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">Solución de backup existente del cliente</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La siguiente ilustración muestra la solución original de backup nativo de Hadoop.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Los datos de producción se protegen a cinta a través del clúster de backup intermedio:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">Los datos HDFS1 se copian en HDFS2 ejecutando el<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">El clúster de backup actúa como una puerta de enlace NFS y los datos se copian manualmente en cinta a través de Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> a través de la biblioteca de cintas.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Las ventajas de la solución original de backup nativo de Hadoop incluyen:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La solución se basa en comandos nativos de Hadoop, que evitan que el usuario tenga que aprender nuevos procedimientos.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La solución aprovecha el hardware y la arquitectura estándar del sector.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Las desventajas de la solución original de backup nativo de Hadoop son las siguientes:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">El tiempo de backup prolongado supera las 24 horas, lo que hace que los datos de producción sean vulnerables.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Degradación significativa del rendimiento del clúster durante los tiempos de backup.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">Copiar en cinta es un proceso manual.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La solución de backup es costosa en términos de hardware necesario y de las horas humanas necesarias para los procesos manuales.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Backup y recuperación de datos</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Teniendo en cuenta estos retos y requisitos, y teniendo en cuenta el sistema de backup existente, se sugirieron tres posibles soluciones de backup. En las siguientes subsecciones se describe cada una de estas tres soluciones de backup distintas, se describe una solución A través de la solución C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Solución A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">La solución A agrega este módulo de análisis in situ al clúster Hadoop de backup, que permite realizar backups secundarios en sistemas de almacenamiento NFS de NetApp y elimina los requisitos de cinta, como se muestra en la siguiente figura.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Las tareas detalladas de la solución A incluyen:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">El clúster de producción de Hadoop tiene los datos de análisis del cliente en HDFS que requiere protección.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">El clúster de Hadoop de backup con HDFS actúa como una ubicación intermedia de los datos. Un solo grupo de discos (JBOD) proporciona almacenamiento para HDFS tanto en los clústeres de producción como en los de Hadoop de backup.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Proteja los datos de producción de Hadoop están protegidos del clúster de producción HDFS al clúster de backup HDFS con la ejecución de<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">La snapshot de Hadoop se usa para proteger los datos de producción para el clúster de Hadoop de backup.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">La controladora de almacenamiento ONTAP de NetApp proporciona un volumen exportado de NFS, que se aprovisiona para el clúster de Hadoop de backup.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">Ejecutando el<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Comando aprovechando MapReduce y varios asignadores, los datos de análisis están protegidos del clúster de Hadoop de backup a NFS mediante el módulo de análisis in situ.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Una vez que los datos se almacenan en NFS en el sistema de almacenamiento de NetApp, las tecnologías Snapshot, SnapRestore y FlexClone de NetApp se utilizan para realizar backups, restaurar y duplicar los datos de Hadoop según sea necesario.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Los datos de Hadoop pueden protegerse en el cloud y en ubicaciones de recuperación ante desastres con la tecnología SnapMirror.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Las ventajas de la solución A incluyen:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Los datos de producción de Hadoop se protegen del clúster de backup.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Los datos HDFS están protegidos por NFS, lo que permite la protección en el cloud y en ubicaciones de recuperación ante desastres.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Mejora el rendimiento mediante la descarga de las operaciones de backup al cluster de backup.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Elimina las operaciones manuales en cintas</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Permite funciones de gestión empresarial mediante herramientas de NetApp.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Requiere unos cambios mínimos en el entorno existente.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">Es una solución rentable.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">La desventaja de esta solución es que requiere un clúster de backup y asignadores adicionales para mejorar el rendimiento.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">El cliente ha puesto en marcha recientemente una solución debido a su simplicidad, coste y rendimiento general.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">En esta solución, los discos SAN de ONTAP pueden utilizarse en vez de JBOD. Esta opción transfiere la carga de almacenamiento del clúster de backup a ONTAP; sin embargo, la desventaja es que se necesitan los switches de la estructura SAN.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Solución B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">La solución B agrega el módulo de análisis in situ al clúster de producción de Hadoop, lo que elimina la necesidad de tener el clúster de Hadoop de backup, como se muestra en la siguiente figura.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Entre las tareas detalladas de la solución B se incluyen las siguientes:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">La controladora de almacenamiento ONTAP de NetApp aprovisiona la exportación NFS al clúster Hadoop de producción.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Hadoop de forma nativa<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> El comando protege los datos de Hadoop del clúster de producción HDFS a NFS mediante el módulo de análisis in situ.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Una vez que los datos se almacenan en NFS en el sistema de almacenamiento de NetApp, las tecnologías Snapshot, SnapRestore y FlexClone se utilizan para realizar backups, restaurar y duplicar los datos de Hadoop según sea necesario.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Las ventajas de la solución B incluyen:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">El clúster de producción está ligeramente modificado para la solución de backup, lo que simplifica la implementación y reduce los costes adicionales de infraestructura.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">No se necesita un clúster de backup para la operación de backup.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">Los datos de producción HDFS se protegen en la conversión a datos NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La solución posibilita funciones de gestión empresarial mediante las herramientas de NetApp.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">La desventaja de esta solución es que se implementa en el clúster de producción, que puede agregar tareas adicionales de administrador en el clúster de producción.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Solución C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">En la solución C, los volúmenes SAN de NetApp se aprovisionan directamente en el clúster de producción de Hadoop para el almacenamiento HDFS, tal y como se muestra en la siguiente figura.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Los pasos detallados de la solución C incluyen:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">El almacenamiento SAN ONTAP de NetApp se aprovisiona en el clúster Hadoop de producción para el almacenamiento de datos HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Las tecnologías Snapshot y SnapMirror de NetApp se usan para realizar backups de los datos HDFS desde el clúster de producción de Hadoop.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">No existe ningún efecto sobre el rendimiento en la producción del clúster Hadoop/Spark durante el proceso de backup de copias de Snapshot debido a que el backup se encuentra en la capa de almacenamiento.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La tecnología Snapshot ofrece backups que se realizan en cuestión de segundos independientemente del tamaño de los datos.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Las ventajas de la solución C incluyen:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">Los backups con gestión eficiente del espacio pueden crearse utilizando la tecnología Snapshot.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">Siguiente: Caso de uso 2: Backup y recuperación ante desastres del cloud a las instalaciones.</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">En esta sección se proporciona un resumen de los casos de uso y las soluciones que ofrece NetApp para satisfacer diversos requisitos de protección de datos de Hadoop.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">Anterior: Caso de uso 5: Acelere las cargas de trabajo analíticas.</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">En esta sección se proporciona un resumen de los casos de uso y las soluciones que ofrece NetApp para satisfacer diversos requisitos de protección de datos de Hadoop. Gracias al Data Fabric con tecnología de NetApp, los clientes pueden:</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">Disponga de la flexibilidad necesaria para elegir las soluciones de protección de datos adecuadas aprovechando las completas funcionalidades de gestión de datos de NetApp y su integración con los flujos de trabajo nativos de Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Reduzca el tiempo necesario para realizar backups en clústeres de Hadoop en casi un 70 %.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Elimine cualquier efecto en el rendimiento que se pueda obtener gracias a los backups de clústeres de Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Ofrezca protección de datos multicloud y acceso a los datos desde distintos proveedores de cloud simultáneamente a una única fuente de datos de análisis.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Cree copias de clúster de Hadoop rápidas y con gestión eficiente del espacio mediante la tecnología FlexClone.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y/o sitios web:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Soluciones de análisis de Big Data de NetApp</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Carga de trabajo de Apache Spark con el almacenamiento de NetApp</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Soluciones de almacenamiento de NetApp para Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop en Data Fabric habilitado por NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Reconocimientos</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, representante de ventas, ANZ Victoria District Sales, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Director de Desarrollo Empresarial de NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, director de MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, ingeniero de sistemas, ANZ Victoria District se, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Enero de 2018</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Actualizado con el caso de uso n.o 5: Acelere la carga de trabajo analítica</block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">Las soluciones modernas de análisis de datos de NetApp son un conjunto de funcionalidades tecnológicas y estratégicas que demuestran las funcionalidades del almacenamiento de NetApp en el espacio de IA.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">En esta sección se describe quién podría estar interesado en el contenido de esta solución.</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">El mundo del análisis y la ciencia de datos tiene múltiples disciplinas DE TECNOLOGÍA y negocio:</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un ingeniero de DevOps necesita las herramientas necesarias para integrar nuevas aplicaciones de IA y ML en sus canalizaciones de CI y de CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Los administradores y arquitectos de cloud deben poder configurar y gestionar recursos de cloud híbrido.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Los usuarios empresariales quieren tener acceso a aplicaciones de análisis, IA, APRENDIZAJE AUTOMÁTICO y aprendizaje profundo.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">En este informe técnico, describimos cómo AFF, E-Series, StorageGRID, acceso directo NFS, Apache Spark, Horovod, y Keras ayudan a cada uno de estos papeles a aportar valor a las empresas.</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">Siguiente: Tecnología de soluciones.</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">En esta sección se proporcionan los pasos detallados necesarios para configurar GPFS y mover datos a NFS mediante NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS a pasos detallados de NFS</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">Anterior: Ventajas empresariales.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configure GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Descargue e instale Spectrum Scale Data Access para Linux en uno de los servidores.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Instale el paquete de requisitos previos (incluidos el chef y los encabezados del kernel) en todos los nodos.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Desactive SELinux en todos los nodos.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configure el nodo de instalación.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Añada el nodo administrador y el nodo GPFS al archivo de definición de clúster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Añada el nodo Manager y el nodo GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Añada el nodo de quórum y el nodo GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Añada los servidores NSD y el nodo GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Añada los nodos GUI, admin y GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Añadir otro servidor GUI</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Añada otro nodo GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Verifique y enumere todos los nodos.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Especifique un nombre de clúster en el archivo de definición del clúster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Especifique el perfil.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Especifique el binario de shell remoto que debe utilizar GPFS; utilice<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Especifique el binario de la copia remota que debe utilizar GPFS; utilice<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Especifique el rango de puertos que se establecerá en todos los nodos GPFS; utilice<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Vea la configuración de GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Añada un nodo de administración.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Habilite NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Compruebe previamente las configuraciones antes de instalar.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configure los discos NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Cree los discos NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Compruebe el estado del disco de NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Compruebe y proporcione los permisos necesarios para el GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Compruebe el GPFS de lectura y escritura, mediante la ejecución del<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Para exportar GPFS a NFS, complete los siguientes pasos:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Enumere los archivos en GPFS para validar el cliente NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configure el cliente NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Instale los paquetes en el cliente NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Valide la lista de archivos GPFS en la carpeta montada en NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Mueva los datos de GPFS- exportaron NFS al NFS de NetApp mediante XCP.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">Siguiente: MAPR-FS para ONTAP NFS.</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Esta sección trata sobre el hardware y el software utilizados para la verificación de Confluent. Esta información se aplica a la puesta en marcha de plataformas Confluent con el almacenamiento de NetApp. La siguiente tabla recoge los componentes básicos y la arquitectura probada de la solución.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluente Kafka versión 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Tres zookeepers</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinco servidores de broker</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinco servidores de herramientas</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Un Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centro de control</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Todos los servidores</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">StorageGRID de NetApp para el almacenamiento por niveles</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Software StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (equilibrador de carga)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (conectividad de red entre instancias de intermediarios y StorageGRID)</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Cada una equipada con: * 2 CPU, 16 núcleos físicos en total * Intel Xeon * 256 GB de memoria física * 100 GbE de doble puerto</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">En este escenario, se modernizó la plataforma de análisis de un gran banco de inversiones y servicios financieros mediante la solución de almacenamiento NFS de NetApp para lograr mejoras significativas en el análisis de riesgos de inversión y derivados para su unidad de negocio cuantitativa y gestión de activos.</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">Anterior: Caso de uso 4 - Protección de datos y conectividad multicloud.</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">En el entorno existente del cliente, la infraestructura Hadoop utilizada para la plataforma de análisis aprovechó el almacenamiento interno de los servidores Hadoop. Debido a la naturaleza propia del entorno JBOD, muchos clientes internos de la organización no pudieron aprovechar su modelo cuantitativo de Monte Carlo, una simulación que se basa en muestras recurrentes de datos en tiempo real. La capacidad subóptima para comprender los efectos de la incertidumbre en los movimientos del mercado no era favorable para la unidad de negocio de gestión de activos cuantitativos.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">La unidad de negocios cuantitativos del banco quería un método eficiente de pronóstico para lograr predicciones precisas y oportunas. Para ello, el equipo reconoció la necesidad de modernizar la infraestructura, reducir el tiempo de espera de I/o existente y mejorar el rendimiento en las aplicaciones analíticas como Hadoop y Spark para simular de manera eficiente modelos de inversiones, medir posibles ganancias y analizar riesgos.</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">El cliente tenía JBOD para su solución de Spark existente. Entonces, se aprovechó ONTAP de NetApp, StorageGRID de NetApp y Minio Gateway a NFS para reducir el tiempo de espera de I/o para el grupo financiero cuantitativo del banco que ejecuta simulación y análisis en modelos de inversión que evalúan posibles ganancias y riesgos. Esta imagen muestra la solución Spark con el almacenamiento de NetApp.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Como se muestra en la figura anterior, los sistemas AFF A800, A700 y StorageGRID se pusieron en marcha para acceder a archivos de parqué a través de protocolos NFS y S3 en un clúster Hadoop de seis nodos con Spark y los servicios de metadatos DE YARN y Hive para operaciones de análisis de datos.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">Una solución de almacenamiento de conexión directa (DAS) en el antiguo entorno del cliente tenía la desventaja de escalar los recursos informáticos y el almacenamiento de forma independiente. Con la solución ONTAP de NetApp para Spark, la unidad de negocio de análisis financieros del banco pudo desvincular el almacenamiento de la computación y ofrecer sin problemas recursos de infraestructura de una manera más eficiente posible según lo necesite.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">Al utilizar ONTAP con NFS, las CPU de los servidores de computación se utilizaron casi por completo para tareas de Spark SQL y el tiempo de espera de I/o se redujo en casi un 70 % y, así, se obtuvo una mejor potencia informática y un mejor impulso de rendimiento para las cargas de trabajo de Spark. Posteriormente, el aumento del uso de la CPU también permitió al cliente aprovechar las GPU, como GPUDirect, para una mayor modernización de la plataforma. Además, StorageGRID proporciona una opción de almacenamiento de bajo coste para las cargas de trabajo de Spark y Minio Gateway proporciona acceso seguro a los datos NFS mediante el protocolo S3. Para los datos en el cloud, NetApp recomienda Cloud Volumes ONTAP, Azure NetApp Files y Cloud Volumes Service de NetApp.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Esta página describe las diferentes áreas en las que se puede utilizar esta solución.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Resumen de casos de uso</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">Anterior: Información general de las soluciones Spark de NetApp.</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Transmisión de datos</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark puede procesar datos en streaming, que se utilizan para extraer, transformar y cargar en streaming procesos (ETL); enriquecimiento de datos; activación de la detección de eventos; y análisis de sesiones complejas:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.* los datos se limpian y se agregan continuamente antes de que se insertan en almacenes de datos. Netflix usa las secuencias de Kafka y Spark para crear una solución en línea de recomendación de películas y supervisión de datos en tiempo real que puede procesar miles de millones de eventos al día de diferentes fuentes de datos. Sin embargo, las ETL tradicionales para el procesamiento por lotes se tratan de forma distinta. Estos datos se leen primero, y luego se convierten en un formato de base de datos antes de ser escritos en la base de datos.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Enriquecimiento de datos.* la transmisión de Spark enriquece los datos en directo con datos estáticos para permitir un análisis de datos en tiempo real más completo. Por ejemplo, los anunciantes en línea pueden entregar anuncios personalizados y orientados dirigidos por información sobre el comportamiento del cliente.</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*Detección de sucesos de disparo.* la transmisión de Spark le permite detectar y responder rápidamente a comportamientos inusuales que podrían indicar problemas potencialmente graves. Por ejemplo, las instituciones financieras utilizan desencadenantes para detectar y detener las transacciones de fraude, y los hospitales utilizan desencadenadores para detectar cambios sanitarios peligrosos detectados en los signos vitales de un paciente.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Análisis complejo de sesiones.* Spark Streaming recopila eventos como la actividad del usuario después de iniciar sesión en un sitio web o aplicación, que se agrupan y analizan a continuación. Por ejemplo, Netflix utiliza esta funcionalidad para proporcionar recomendaciones de películas en tiempo real.</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">Para obtener más información sobre la configuración de los datos en streaming, la verificación de Confluent Kafka y las pruebas de rendimiento, consulte<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>.</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">El marco integrado de Spark le ayuda a ejecutar consultas repetidas en conjuntos de datos mediante la biblioteca de aprendizaje automático (MLlib). MLlib se utiliza en áreas tales como agrupación en clúster, clasificación y reducción de la dimensionalidad para algunas funciones comunes de big data como inteligencia predictiva, segmentación del cliente para fines de marketing y análisis de sentimiento. MLlib se utiliza en la seguridad de la red para realizar inspecciones en tiempo real de los paquetes de datos en busca de indicaciones de actividad maliciosa. Ayuda a los proveedores de seguridad a conocer las nuevas amenazas y a mantenerse por delante de los hackers mientras protegen a sus clientes en tiempo real.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Aprendizaje profundo</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow es un marco de aprendizaje profundo más popular que se utiliza en el sector. TensorFlow admite el entrenamiento distribuido en un clúster de CPU o GPU. Este entrenamiento distribuido permite a los usuarios ejecutarlo en una gran cantidad de datos con muchas capas profundas.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Hasta hace poco, si queríamos utilizar TensorFlow con Apache Spark, teníamos que realizar todas las operaciones ETL necesarias para TensorFlow en PySpark y luego escribir datos en el almacenamiento intermedio. Esos datos se cargarán en el clúster TensorFlow para el proceso de entrenamiento real. Este flujo de trabajo requería que el usuario mantuviera dos clústeres diferentes: Uno para ETL y otro para el entrenamiento distribuido de TensorFlow. Ejecutar y mantener varios clústeres era normalmente tedioso y laborioso.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">DataFrames y RDD en versiones anteriores de Spark no estaban bien adaptados para el aprendizaje profundo debido a que el acceso aleatorio era limitado. En Spark 3.0 con hidrógeno del proyecto, se añade soporte nativo a los marcos de aprendizaje profundo. Este enfoque permite la programación basada en MapReduce en el clúster de Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Análisis interactivo</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark es lo suficientemente rápido como para realizar consultas exploratorias sin necesidad de muestreo con idiomas de desarrollo distintos de Spark, incluidas SQL, R y Python. Spark utiliza herramientas de visualización para procesar datos complejos y visualizarlos de forma interactiva. Spark with Structured streaming realiza consultas interactivas contra datos en directo en análisis web que le permiten ejecutar consultas interactivas en la sesión actual de un visitante web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Sistema de recomendación</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Con el paso de los años, los sistemas de recomendación han traído consigo enormes cambios a nuestras vidas, ya que las empresas y los consumidores han respondido a los cambios drásticos en las compras en línea, el entretenimiento en línea y muchos otros sectores. De hecho, estos sistemas se encuentran entre los casos de éxito más evidentes de la IA en la producción. En muchos casos de uso práctico, los sistemas de recomendación se combinan con IA conversacional o bots conversacionales interpuestos con un back-end NLP para obtener información relevante y producir inferencias útiles.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Hoy en día, muchos minoristas están adoptando nuevos modelos de negocios como comprar en línea y recoger en la tienda, recoger en la acera, hacer el autocheck-out, escanear y llevar, entre otros. Estos modelos se han convertido en algo más destacado durante la pandemia del COVID-19, al hacer que las compras sean más seguras y convenientes para los consumidores. La IA es crucial para estas tendencias digitales en aumento, que están influenciadas por el comportamiento de los consumidores y viceversa. Para satisfacer las crecientes demandas de los consumidores, con el fin de aumentar la experiencia del cliente, mejorar la eficiencia operativa y aumentar los ingresos, NetApp ayuda a sus clientes empresariales y empresas a usar algoritmos de aprendizaje automático y aprendizaje profundo para diseñar sistemas de recomendación más rápidos y precisos.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Existen varias técnicas utilizadas para ofrecer recomendaciones, como el filtrado colaborativo, los sistemas basados en contenido, el modelo de recomendación de aprendizaje profundo (DLRM) y las técnicas híbridas. Anteriormente, los clientes utilizaban PySpark para implementar un filtrado colaborativo para crear sistemas de recomendación. Spark MLlib implementa cuadrados alternos mínimos (ALS) para el filtrado colaborativo, un algoritmo muy popular entre las empresas antes del ascenso de DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Procesamiento de lenguaje natural</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Informe de Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">La IA conversacional, posible gracias al procesamiento del lenguaje natural (NLP), es la rama de la IA que ayuda a los ordenadores a comunicarse con los seres humanos. NLP tiene una gran prevalencia en todos los sectores verticales y en muchos casos de uso, desde asistentes inteligentes y bots conversacionales hasta búsquedas en Google y texto predictivo. Según a<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Predicción, para 2022, el 70 % de las personas interactuará con plataformas de IA conversacionales diariamente. Para mantener una conversación de alta calidad entre un ser humano y una máquina, las respuestas deben ser rápidas, inteligentes y naturales.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Los clientes necesitan una gran cantidad de datos para procesar y entrenar sus modelos NLP y de reconocimiento automático de voz (ASR). También necesitan mover datos en el perímetro, el núcleo y el cloud, y necesitan poder realizar inferencia en milisegundos para establecer una comunicación natural con las personas. NetApp AI y Apache Spark es una combinación ideal de computación, almacenamiento, procesamiento de datos, entrenamiento de modelos, ajuste preciso e implementación.</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">El análisis de sentimiento es un campo de estudio dentro de las BPL en el que se extraen sentimientos positivos, negativos o neutrales del texto. El análisis de confianza tiene una variedad de casos de uso, desde determinar el rendimiento del empleado del centro de soporte en conversaciones con personas que llaman hasta proporcionar respuestas automatizadas apropiadas al bot conversacional. También se ha utilizado para predecir el precio de las acciones de una empresa en función de las interacciones entre representantes de la empresa y la audiencia en llamadas trimestrales sobre ganancias. Además, el análisis de confianza se puede utilizar para determinar la visión de un cliente sobre los productos, servicios o asistencia proporcionados por la Marca.</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">confianza en las noticias financieras</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">Utilizamos la<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> biblioteca desde<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> Cargar tuberías preentrenadas y Representaciones bidireccionales de Encoder desde los modelos Transformers (BERT) incluyendo<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> y..<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, realizando tokenización, reconocimiento de entidades con nombre, entrenamiento modelo, ajuste y análisis de sentimiento a escala. Spark NLP es la única biblioteca de código abierto de NLP en producción que ofrece transformadores de última generación como BERT, ALBERT, ELECTRA, XLNet, DistilBERT, Roberta, DeBERTa, XLM- Roberta, Longexer, ELMO, Codificador universal de frases, Google T5, MarianMT y GPT2. La biblioteca funciona no sólo en Python y R, sino también en el ecosistema JVM (Java, Scala y Kotlin) a escala ampliando Apache Spark de forma nativa.</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">Siguiente: Principales casos prácticos de IA, APRENDIZAJE AUTOMÁTICO y aprendizaje profundo.</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">Anterior: MAPR-FS para ONTAP NFS.</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">Prácticas recomendadas del módulo de análisis local de NetApp</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Prácticas recomendadas y guía de implementación de los volúmenes FlexGroup de NetApp</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Versión 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">Enero de 2022</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">Mueva directamente datos de HDFS y MapR-FS a NFS mediante NetApp XCP.</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">Enero de 2020</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">XCP incluido como el transportador de datos predeterminado. MapR-FS añadió a NFS y GPFS a la transferencia de datos NFS.</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">Noviembre de 2018</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Realizamos las pruebas de almacenamiento por niveles con de tres a cuatro nodos para cargas de trabajo de producción y consumo con la configuración de StorageGRID de NetApp.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Pruebas de rendimiento con escalabilidad</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">Anterior: Verificación confluente.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Realizamos las pruebas de almacenamiento por niveles con de tres a cuatro nodos para cargas de trabajo de producción y consumo con la configuración de StorageGRID de NetApp. Según nuestras pruebas, el tiempo hasta el final y los resultados del rendimiento eran directamente proporcionales al número de nodos StorageGRID. La configuración de StorageGRID requería un mínimo de tres nodos.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">El tiempo para completar el funcionamiento del producto y del consumidor disminuyó linealmente cuando aumentó el número de nodos de almacenamiento.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">El rendimiento de la operación de recuperación de s3 aumentó de forma lineal en función del número de nodos StorageGRID. StorageGRID admite hasta 200 nodos StorageGRID.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">Siguiente: Conector Confluent s3.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="f0a30c2a34036665913459cc735f4786" category="doc">TR-4704: Puesta en marcha de Veritas NetBackup con almacenamiento E-Series de NetApp</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash Gupta y Principled Technologies, NetApp</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704 describe la puesta en marcha de Veritas NetBackup en el almacenamiento E-Series de NetApp.</block>
  <block id="7ff53b7713dd7f38a4729f8a1a48f24e" category="paragraph"><block ref="7ff53b7713dd7f38a4729f8a1a48f24e" category="inline-link-macro-rx"></block></block>
  <block id="849bdf40e7fa0e2cab1cb845682e6f56" category="doc">TR-4471: Arquitectura de referencia de E-Series y EF-Series y prácticas recomendadas de almacenamiento con Veeam Backup &amp; Replication 9.5</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta, NetApp Shawn Lieu (América), Stefan Renner (EMEA) y Michael Cade (rendimiento), Veeam</block>
  <block id="3bad2cd66e539f0136fbf484133914dd" category="paragraph">En TR-4471 se describen la arquitectura de referencia y las prácticas recomendadas al usar el almacenamiento E-Series de NetApp en un entorno Veeam Backup &amp; Replication 9.5.</block>
  <block id="f86686bed105d7053fbb06167a05f38e" category="inline-link-macro">TR-4471: Prácticas recomendadas de almacenamiento y arquitectura de referencia de E-Series y EF-Series con Veeam Backup &amp;amp; Replication 9.5</block>
  <block id="8a9473d2b45da95a2d08524f5b182c4d" category="paragraph"><block ref="30941a222a593c860776bbf0831d36d0" category="inline-link-macro-rx"></block></block>
  <block id="97b39392e3b66691f26174f9392c96d0" category="doc">NVA-1143: NetApp HCI: Controles de seguridad del NIST para FISMA con HyTrust para infraestructura multitenant: Diseño y puesta en marcha de NVA</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">Arvind Ramakrishnan, Abhinav Singh, NetApp</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143 describe cómo se puede diseñar e implementar NetApp HCI para cumplir con el Instituto Nacional de estándares y Tecnología (NIST) SP 800-53 Revisión 4 controles de seguridad y privacidad, que son cruciales para las infraestructuras de cloud privado y las puestas en marcha multitenant.</block>
  <block id="86e20b04ba1f19de7a30d7843155e285" category="paragraph"><block ref="86e20b04ba1f19de7a30d7843155e285" category="inline-link-macro-rx"></block></block>
  <block id="5e8c99d8eb1f9fde413c715abb6fa392" category="doc">TR-4320: E-Series de NetApp y CommVault Data Platform V11: Prácticas recomendadas de almacenamiento y arquitectura de referencia</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Akash Gupta, NetApp Girish Chanchlani, CommVault</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">El TR-4320 resume la arquitectura de referencia y las mejores prácticas al usar almacenamiento E-Series de NetApp en un entorno CommVault Data Platform V11. CommVault y NetApp han desarrollado conjuntamente esta arquitectura de referencia para ofrecer una guía para las puestas en marcha de CommVault Data Platform V11 con almacenamiento E-Series de NetApp que acelerará el tiempo de aplicación de esta solución.</block>
  <block id="b5132c157b5da84909699e1aad5ea13d" category="inline-link-macro">TR-4320: E-Series de NetApp y CommVault Data Platform V11: Prácticas recomendadas de almacenamiento y arquitectura de referencia</block>
  <block id="65c8e697e97b6ce1bd59d8334eaaab6f" category="paragraph"><block ref="65c8e697e97b6ce1bd59d8334eaaab6f" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">Primeros pasos</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">Infraestructuras convergentes para cargas de trabajo de IA</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">ONTAP AI con NVIDIA</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">EF-Series AI con NVIDIA</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">IBM Spectrum Scale con almacenamiento E-Series de NetApp</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Inferencia de IA en el Edge: NetApp con Lenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">ONTAP de NetApp y Lenovo ThinkSystem SR670 para IA</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">AFF A800 de NetApp y Fujitsu Server PRIMERGY GX2570 M5 para IA</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">Lagos de datos y canalizaciones de datos</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">Lago de datos de StorageGRID para cargas de trabajo de la conducción autónoma</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">Movimiento de datos con E-Series y BeeGFS para IA</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">IA de cloud híbrido con almacenamiento en caché de datos</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">Orquestación y gestión</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">Plano de control de IA de NetApp para canalización de IA y orquestación de espacio de trabajo</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">MLRun Pipeline con Iguazio</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">Solución de orquestación de NetApp con Run:AI</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">Análisis de confianza</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">Predicción de frecuencia mediante clic: Formación distribuida en Azure</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">Detección de carriles: Formación distribuida en Azure</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">IA conversacional con NVIDIA Jarvis</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">Conducción autónoma</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">Atención médica - Diagnóstico de imágenes</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">Detección de fraude de tarjeta de crédito</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD: Solución de NetApp y NVIDIA</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">BeeGFS en NetApp (guía de diseño)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">BeeGFS en NetApp (guía de puesta en marcha)</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NVIDIA DGX SuperPOD con NetApp (guía de diseño)</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">Anthos con NetApp</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="sidebar">Integraciones de almacenamiento de NetApp</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">Red Hat OpenShift con NetApp</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">VMware Tanzania con NetApp</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">DevOps con NetApp</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">Acerca de nuestros recursos para contenedores</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">Acerca de nuestras soluciones para partners</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Sitio web de Anthos</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Sitio Web de Red Hat OpenShift</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">Sitio web de VMware Tanzania</block>
  <block id="879f2366c198b1fc05740657cacebcc1" category="sidebar">Implementación y protección de bases de datos de Oracle en Azure NetApp Files</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">Bases de datos RAC Oracle 19c en centro de datos FlexPod</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">SAP con Oracle en UNIX y NFS con Clustered Data ONTAP de NetApp</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">Ponga en marcha la base de datos Oracle en NetApp ONTAP</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="sidebar">Puesta en marcha automatizada de Oracle 19c para ONTAP en NFS</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Protección de datos automatizada de Oracle</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Bases de datos de Oracle en EF-Series de NetApp</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">Servidor SQL</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">SAP con Microsoft SQL Server en Windows mediante Clustered Data ONTAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Modernización de Microsoft SQL Server</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Guía de prácticas recomendadas de Microsoft SQL Server con EF-Series de NetApp</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">Soluciones de bases de datos en el cloud híbrido</block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">Puesta en marcha de bases de datos Oracle en prácticas recomendadas de EC2/FSX</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">SQL Server en Azure NetApp Files</block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">SQL Server en AWS EC2 mediante Amazon FSX para ONTAP de NetApp</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">Soluciones de bases de datos de cloud híbrido con SnapCenter</block>
  <block id="a54420e6e0f519f841f4280cf2545365" category="sidebar">Bases de datos de código abierto</block>
  <block id="67bb2ef7cf3c5ff59f35f28e513bfda3" category="sidebar">Puesta en marcha de alta disponibilidad y recuperación ante desastres de PostgreSQL en AWS FSX/EC2</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">Primeros pasos / mejores prácticas</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp y VMware: Introducción</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">Ventajas de ONTAP de NetApp para administradores de VMware vSphere</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">Prácticas recomendadas de VMware vSphere con ONTAP</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">Novedades de la virtualización de VMware</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">VMware en el cloud público</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">Multicloud híbrido de NetApp con VMware</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp para AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp para Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp para Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">Seguridad y protección de datos</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware Site Recovery Manager (SRM) con ONTAP 9 de NetApp</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">Herramientas de ONTAP para VMware vSphere: Seguridad del producto</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">Automatización de VMware vSphere</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">Demostraciones y tutoriales</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">Más recursos</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Soluciones de puestos de trabajo virtuales</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">Configure el entorno de virtualización</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">Información general complementaria sobre el almacén de datos NFS</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">Opciones de almacén de datos NFS complementario</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">Opciones de almacenamiento conectado a invitado</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">Soluciones de protección de cargas de trabajo</block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">Soluciones de migración de cargas de trabajo</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">Herramientas</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">ANF + AVS CALCULADORA TCO</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + AVS Simulator</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">Compatibilidad de regiones para almacenes de datos NFS</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">Almacén de datos NFS suplementario: Vista previa pública (Microsoft)</block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">Soluciones de NetApp para VMware en clouds de proveedores a hiperescala</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">Opciones de almacenamiento compatibles</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">Soluciones compatibles</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp en AWS (VMC)</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">Multicloud híbrido de NetApp con VMware para VMC</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">FSX ONTAP como almacén de datos NFS suplementario: Descripción general</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP como almacenamiento conectado como invitado</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO como almacenamiento conectado invitado</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">Soluciones de multicloud híbrido para VMC</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">Region Support for NFS datastores in AWS</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp en Azure (AVS)</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">Multicloud híbrido de NetApp con VMware para AVS</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">ANF como Datastore NFS suplementario: Descripción general</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ANF como almacenamiento conectado como invitado</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">Soluciones de multicloud híbrido para AVS</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">Compatibilidad de regiones para almacenes de datos NFS en Azure</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">NetApp en Google Cloud Platform (GCVE)</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">Multicloud híbrido de NetApp con VMware para GCVE</block>
  <block id="2284540fd2f120164fbe2ca5d318f1f4" category="sidebar">Anuncio suplementario de almacén de datos NFS</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS como almacenamiento conectado invitado</block>
  <block id="92db868215c2d725770eeb14e1e377e1" category="sidebar">CVS como almacén de datos suplementario (blog de NetApp)</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">Soluciones de multicloud híbrido para GCVE</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">Descripción general de la seguridad: CVS de NetApp en Google Cloud</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">FSX para ONTAP + calculadora del coste total de propiedad de VMC</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">FSX para ONTAP + simulador VMC</block>
  <block id="46d1e37416bef4df8c1962b95c983bb0" category="sidebar">GCVE + CVS TCO ESTIMATOR</block>
  <block id="d99ca343caa90da336986677343c31fa" category="sidebar">Opciones de almacén de datos de NFS suplementario (blog de NetApp)</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">Google Cloud VMware Engine con NetApp Cloud Volumes Service</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">Descripción general de la seguridad: Cloud Volumes Service de NetApp (CVS) en Google Cloud</block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">Almacén de datos NFS complementario: Descripción general</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">Almacén de datos NFS complementario: Opciones</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">VMware Cloud en AWS: Nueva región, almacenamiento externo y opciones de compra</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">Carga de trabajo de Apache Spark con la solución de almacenamiento de NetApp</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">Breve descripción de la solución de análisis de datos moderna</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Prácticas recomendadas para Confluent Kafka</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">E-Series E5700 de NetApp y Splunk Enterprise</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">EF600 de NetApp con Splunk Enterprise</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">Soluciones de cloud híbrido: Casos prácticos de Spark y Hadoop</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">Recursos adicionales</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark juega en el patio de juegos de análisis de datos de NetApp</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Utilice XCP para la migración de datos de un lago de datos y HPC a NFS de ONTAP</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Lista de reproducción de análisis de Big Data</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">Documentación de las soluciones de NetApp</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="sidebar">Aplicaciones empresariales</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP Y SAP HANA</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">Soluciones FlexPod</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">Soluciones NetApp HCI heredadas</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">Información sobre las soluciones de NetApp</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">Avisos legales</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">Historial de cambios</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">Vídeos y demostraciones</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">Páginas de destino de soluciones</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">Bases de datos empresariales</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">Multicloud híbrido de NetApp con VMware</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP Y SAP HANA</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">Automatización de solicitudes</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod: Una solución de NetApp y Cisco</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">Contenido técnico de soluciones FlexPod</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">Página de ventas de FlexPod</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">Proponer una nueva solución</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">Envíe sus comentarios sobre la solución</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">Introducción a Ansible y la automatización de la solución de NetApp</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">Configurar el entorno de automatización</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatización de solicitudes</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">Migración de datos XCP de NetApp</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">Directrices de las prácticas recomendadas para NetApp XCP</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">Migración de datos CIFS con ACL de un equipo de almacenamiento de origen a ONTAP</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">Infraestructuras convergentes de IA</block>
  <block id="f0cbafc85a7a8d2836dd3a3d51266f61" category="sidebar">AFF A400 de NetApp con Lenovo ThinkSystem SR670 V2 para formación de modelos de IA y ML</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">Guía de diseño de sistemas ONTAP AI con NVIDIA DGX A100</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">Guía de puesta en marcha de sistemas ONTAP AI con NVIDIA DGX A100</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">Guía de diseño de ONTAP AI con sistemas NVIDIA DGX A100 y switches Ethernet Mellanox Spectrum</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">Guía de puesta en marcha de ONTAP AI con sistemas NVIDIA DGX A100 y switches Ethernet Mellanox Spectrum</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">EF-Series AI con sistemas NVIDIA DGX A100 y diseño BeeGFS</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">EF-Series AI con sistemas NVIDIA DGX A100 y puesta en marcha de BeeGFS</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">Guía de puesta en marcha de BeeGFS con E-Series de NetApp</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS con la arquitectura de referencia de E-Series de NetApp</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">Puesta en marcha de IBM Spectrum Scale con almacenamiento E-Series de NetApp</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">AFF A800 de NetApp y Fujitsu Server PRIMERGY GX2570 M5 para cargas de trabajo de entrenamiento de modelos AI y ML</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">Canalizaciones de datos, lagos de datos y gestión</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">Lago de datos StorageGRID de NetApp para cargas de trabajo de la conducción autónoma</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Implementación de Trident</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">Movimiento de datos con E-Series y BeeGFS para flujos de trabajo de IA y análisis</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">IA responsable e inferencia confidencial: IA de NetApp con transformación de imagen Protopía</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">Análisis de la confianza con IA de NetApp</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">Poner en marcha el análisis de confianza del centro de soporte</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Formación distribuida en Azure: Predicción de frecuencias mediante clic</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">Versiones de conjuntos de datos y modelos con el kit de herramientas de Data OPS de NetApp</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Portátiles Jupyter para referencia</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Formación de Azure distribuida: Detección de carriles</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">Detección de carriles: Formación distribuida con RUAI</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">Sistema operativo de IA de cloud híbrido con almacenamiento en caché de datos</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Trasladar los datos de un entorno de Big Data a un entorno de IA</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inferencia de IA en el perímetro - NetApp con Lenovo ThinkSystem - Diseño de la solución</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">IA conversacional con NVIDIA</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">Óptimo uso del clúster y de la GPU con Run AI</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">Ejecute la instalación de IA</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">Ejecute paneles de IA y vistas</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Envío de trabajos en la CLI de Run AI</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">Diseño de soluciones de ONTAP AI de NetApp para cargas de trabajo de conducción autónoma</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">Arquitectura de referencia de IA de ONTAP de NetApp para el sector sanitario: Imágenes de diagnóstico</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">Arquitectura de referencia ONTAP AI de NetApp para cargas de trabajo de servicios financieros</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">Puesta en marcha de IA con E-Series de NetApp y BeeGFS</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">StorNext de Quantum con guía de diseño de sistemas E-Series de NetApp</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Guía de puesta en marcha de Quantum StorNext con sistemas E-Series de NetApp</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">Descripción general de los sistemas de almacenamiento de NetApp</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">Descripción general de las integraciones de almacenamiento de NetApp</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">Descripción general de Astra Trident de NetApp</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Opciones de configuración avanzada para Anthos</block>
  <block id="e131204502a58630f2f72937238604c8" category="sidebar">Vídeos / demostraciones</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">Descripción general de Astra Control Center de NetApp</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">Utilizar validaciones de casos</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Visión general de Red Hat OpenShift</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Registre sus Red Hat OpenShift Clusters</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">Seleccione las aplicaciones que desea proteger</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">Proteja sus aplicaciones</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">Opciones de configuración avanzadas para OpenShift</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">Configuración de multi-tenancy en Red Hat OpenShift con ONTAP de NetApp</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">Tareas del administrador de clúster</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">Tareas del administrador de almacenamiento</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Escalado</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">Despliegue a través del operador</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">Flujos de trabajo</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">Clonado de equipos virtuales</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">Gestión del ciclo de vida de las aplicaciones</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">Gobernanza y riesgo</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">Crear recursos</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">Información general sobre VMware TKG (Tanzania Kubernetes Grid)</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">Descripción general del servicio VMware TKGS (Tanzu Kubernetes Grid Service)</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">Información general sobre VMware TKGI (Tanzu Kubernetes Grid Integrated Edition)</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Registre sus clústeres tanzu Kubernetes</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">Soluciones archivadas</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">Bases de datos Oracle 19c RAC en centros de datos FlexPod con Cisco UCS y AFF A800 over FC de NetApp</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Implementación de Oracle Database</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">Primeros pasos y requisitos</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Implementación automatizada de Oracle 19c AWX/Tower</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Implementación de CLI automatizada de Oracle 19c</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Protección de datos de bases de datos de Oracle</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">Protección automatizada de datos de Oracle para AWX/Tower</block>
  <block id="d842058c0e8814799a596324a98e5323" category="sidebar">Puesta en marcha de bases de datos Oracle en prácticas recomendadas de AWS EC2 y FSX</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">Procedimientos de implantación</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">Gestión de bases de datos</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">Migración de bases de datos</block>
  <block id="fc305603a3cb90ea71cabdf327aaf437" category="sidebar">Protección de bases de datos</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">Diseño de referencia (diseño de alto nivel en tiempo real)</block>
  <block id="1ae3eccde141a365ede8f18b188ae588" category="sidebar">Puesta en marcha y recuperación ante desastres automatizadas de PostgreSQL en AWS FSX/EC2</block>
  <block id="6fabfc29f0b3a196c8407c190bb67293" category="sidebar">SnapCenter para bases de datos</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">Empezar a trabajar en las instalaciones</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">Empiece a usar NetApp y VMware</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">Virtualización de VMware para ONTAP</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Gestión basada en volúmenes virtuales y políticas de almacenamiento</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">VMware Site Recovery Manager con NetApp ONTAP 9</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">Complemento de SnapCenter para VMware vSphere: Seguridad del producto</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">Aprovisionamiento de almacenamiento en bloques tradicional</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS: Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS: Fibre Channel sobre Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS: ISCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS: NVMe sobre Fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">Aprovisionamiento de almacenamiento de ficheros tradicional</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS - v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS: V4.1</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware para el cloud público</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">Casos de uso de cloud híbrido de VMware</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">Descripción general de casos de uso</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">Escritorios virtuales</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">Servicios de puestos de trabajo virtuales (VDS)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Prueba de carga de un solo servidor con Login VSI</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">Gestión de operaciones</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">Consideraciones sobre la GPU</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">De NetApp para el sector</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">Validación técnica de ESG: VDI a escala empresarial con Virtual Desktop Service de NetApp</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">Horizon de VMware</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">Soluciones de virtualización de puestos de trabajo FlexPod</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">VMware Cloud en clouds de proveedores a hiperescala</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">Configuraciones compatibles</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">Configurar VMC para AWS</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Configure AVS para Azure</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">Configurar GCVE para GCP</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">Almacenamiento NetApp en clouds de proveedores a hiperescala</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">Almacén de datos NFS complementario para VMC</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">Almacenamiento conectado como invitado para VMC</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">Almacén de datos NFS complementario para AVS</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">Almacenamiento conectado invitado para AVS</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">Almacenamiento conectado como invitado para GCVE</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">Resumen y conclusión</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">NetApp para AWS / VMC</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">Proteger cargas de trabajo</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">Migración de cargas de trabajo</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">Migrar cargas de trabajo a FSX para el almacén de datos ONTAP mediante VMware HCX</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp para Azure / AVS</block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">Migrar cargas de trabajo al almacén de datos ANF mediante VMware HCX</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp para GCP/GCVE</block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">Recuperación ante desastres de aplicaciones con replicación de SnapCenter, CVO y Veeam</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">Información general de la arquitectura</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">Otras dependencias de servicios de infraestructura NAS (KDC, LDAP, DNS)</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka con las controladoras de almacenamiento ONTAP de NetApp</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Resumen de casos de uso</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Big Data Analytics datos a la inteligencia artificial</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS a NFS: Pasos detallados</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Prácticas recomendadas para Confluent Kafka</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Clústeres de autobalanceo confluido</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Soluciones de datos para el cloud híbrido de NetApp: Spark y Hadoop en función de casos prácticos de clientes</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Caso de uso 1: Backup de datos de Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Caso de uso 2: Backup y recuperación ante desastres del cloud a las instalaciones</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Caso de uso 3 - activación de DevTest en datos de Hadoop existentes</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Caso práctico 4 - Protección de datos y conectividad multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Caso de uso 5: Acelere las cargas de trabajo analíticas</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Resumen de la solución de diferentes soluciones para diferentes estrategias de análisis</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">StorageGRID de NetApp con Splunk SmartStore</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Carga de trabajo de Apache Spark con la solución de almacenamiento de NetApp (guía de puesta en marcha)</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">E-Series de NetApp y CommVault Data Platform V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">Prácticas recomendadas de almacenamiento y arquitectura de referencia de E-Series y EF-Series con Veeam Backup &amp; Replication 9.5</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">Implementación de Veritas NetBackup con almacenamiento E-Series de NetApp</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">Controles de seguridad del NIST para FISMA con HyTrust para infraestructura multitenant</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">La automatización de las soluciones de NetApp permite al cliente automatizar la puesta en marcha, la configuración y la ejecución de muchas tareas comunes de infraestructura y aplicaciones.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">Automatización de soluciones de NetApp</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">La automatización simplifica el consumo de soluciones de NetApp.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">Esta página proporciona información detallada para recopilar los tokens de actualización necesarios y las claves de acceso/secreto para las puestas en marcha de CVO y Cloud Manager Connector a través de Cloud Manager de NetApp.</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">Requisitos de autenticación de AWS para CVO y conector mediante Cloud Manager de NetApp</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">Para configurar las puestas en marcha automatizadas de CVO y los conectores mediante libros de estrategia de Ansible a través de AWX/Ansible Tower, se necesita la siguiente información:</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">Adquiriendo claves de acceso/Secreto de AWS</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Para poner en marcha CVO y conector en Cloud Manager, necesitamos AWS Access/Secret Key. Adquiera las claves en la consola de AWS iniciando IAM--&gt;usuarios--&gt;su nombre de usuario-&gt;credenciales de seguridad--&gt;Crear clave de acceso.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">Copie las claves de acceso y manténgalos protegidos para su uso en la implementación de conector y CVO.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">Si pierde la clave, puede crear otra clave de acceso y eliminar la que ha perdido</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">Actualizar token</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">Adquirir un token de actualización de NetApp Cloud Central</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="inline-link"></block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">Inicie sesión en su cuenta central de la nube con las credenciales de su cuenta en<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">Generar un token de actualización y guardarlo para las puestas en marcha.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">Adquiriendo ID de cliente</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">Acceda a la página API para copiar el ID de cliente en<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">Haga clic en "aprender a autenticar", en la esquina superior derecha.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">En la ventana autenticación que aparece, copie el ID de cliente de acceso normal si necesita un nombre de usuario o contraseña para iniciar sesión. Los usuarios federados con SSO deben copiar el ID de cliente de la "pestaña Actualizar token".</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">ID del cliente</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">Adquiriendo Key Pair de AWS</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">En la consola de AWS, busque “par de claves” y cree un par de claves con “pem”. Recuerde el nombre de Key_Pair, lo utilizaremos para desplegar el conector.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">Par de claves</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">Adquiriendo ID de cuenta</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">En Cloud Manager, haga clic en cuenta –&gt; gestionar cuentas y, a continuación, copie el ID de cuenta para utilizarlo en variables para AWX.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introducción</block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">Al ofrecer soluciones para los retos empresariales actuales, NetApp ofrece soluciones con los siguientes objetivos:</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">Proporcionar pasos validados de instalación y configuración,</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">Ofrece soluciones fáciles de consumibles,</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">Ofrecer una puesta en marcha de una solución con un resultado previsible, se repite fácilmente y se puede escalar en toda la empresa del cliente.</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">Para poder alcanzar estos objetivos, es fundamental que la implementación y configuración de la infraestructura y/o las aplicaciones que ofrecemos a través de nuestras soluciones se simplifique mediante la automatización. NetApp se compromete a simplificar el consumo de soluciones mediante la automatización.</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">Las soluciones de NetApp, que utilizan herramientas de automatización de código abierto como Red Hat Ansible, HashiCorp Terraform o Microsoft PowerShell, tienen la capacidad de automatizar la puesta en marcha de aplicaciones, el aprovisionamiento del cloud, la gestión de la configuración y muchas otras tareas TECNOLÓGICAS comunes. Las soluciones de NetApp aprovechan los artefactos de automatización disponibles de forma pública, así como ofrecen la automatización escrita por NetApp, para simplificar la puesta en marcha general de una solución.</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">Cuando haya capacidades de automatización disponibles, el material complementario de la solución guiará al usuario a través del proceso de automatización de los pasos de la solución o de la solución a través de las herramientas de automatización específicas.</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">Esta página describe el método automatizado para poner en marcha volúmenes de NetApp en proveedores de cloud (AWS, Azure, GCP) mediante terraform.</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Automatización de Cloud Volumes a través de Terraform</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">Esta solución documenta las puestas en marcha automatizadas de Cloud Volumes en AWS (nodo único de CVO, CVO ha y FSX ONTAP) y Azure (nodo único de CVO, CVO ha y ANF) mediante módulos de Terraform. El código se puede encontrar en<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">Requisitos previos</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;= 0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cuenta de Cloud Manager</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">Cuenta de proveedor de cloud: AWS, Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">Máquina host (cualquier sistema operativo admitido por Terraform)</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">Documentación del proveedor</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">La documentación del proveedor de Terraform para Cloud Manager está disponible en: <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">Control de la versión del proveedor</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">Tenga en cuenta que también puede controlar la versión del proveedor. Esto se controla mediante un bloque Required_Providers en la configuración de Terraform.</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">La sintaxis es la siguiente:</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">Más información sobre el control de versiones del proveedor.</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">Ejecución de módulos específicos</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="example-title">AWS</block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">Puesta en marcha de un solo nodo de CVO</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">Archivos de configuración Terraform para la puesta en marcha de NetApp CVO (instancia de nodo único) en AWS</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">Esta sección contiene varios archivos de configuración Terraform para poner en marcha/configurar un solo nodo CVO (Cloud Volumes ONTAP) de NetApp en AWS (Amazon Web Services).</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Documentación de Terraform:<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">Procedimiento</block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">Para ejecutar la plantilla:</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">Clonar el repositorio.</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">Desplácese hasta la carpeta deseada</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">Configure las credenciales de AWS desde la interfaz de línea de comandos.</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">ID de clave de acceso de AWS [Ninguno]: clave de acceso</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">Clave de acceso secreta de AWS [None]: Clave secreta</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">Nombre de región predeterminado [Ninguno]: US-West-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">Formato de salida predeterminado [Ninguno]: json</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">Actualice los valores de variable en<block ref="138255b51837a8bb57dce615f0b58218" prefix=" " category="inline-code"></block></block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">Puede optar por implementar el conector estableciendo el valor de la variable "aws_Connector_deploy_bool" en true/false.</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Inicialice el repositorio de Terraform para instalar todos los requisitos previos y prepárese para la puesta en marcha.</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">Verifique los archivos de Terraform mediante el comando terraform validate.</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">Realice una ejecución en seco de la configuración para obtener una vista previa de todos los cambios que espera la implementación.</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">Ejecute la implementación</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">Para eliminar la implementación</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">Precipitación:</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph"><block ref="edf21d7ecb364e8210ddd3dfaeca6fbf" prefix="" category="inline-code"></block></block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">Variables de Terraform para la instancia del conector AWS de NetApp para la puesta en marcha de CVO.</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">*Nombre*</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">*Tipo*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Descripción*</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">*aws_connector_deploy_bool*</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">Bool</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">(Necesario) Compruebe el despliegue del conector.</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">*nombre_conector_aws*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">Cadena</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">(Obligatorio) el nombre del conector de Cloud Manager.</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">*región_conector_aws*</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">(Obligatorio) la región donde se creará el conector de Cloud Manager.</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">*aws_connector_key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">(Obligatorio) el nombre del par de claves que se va a utilizar para la instancia de conector.</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">*empresa_conector_aws*</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">(Obligatorio) el nombre de la empresa del usuario.</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">*aws_connector_instance_type*</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">(Requerido) Tipo de instancia (por ejemplo, t3.xlarge). Se necesitan al menos 4 CPU y 16 GB de memoria.</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">*id_subred_conector_aws*</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">(Obligatorio) el ID de la subred para la instancia.</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">*aws_connector_security_group_id*</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">(Obligatorio) el código del grupo de seguridad para la instancia, se pueden proporcionar varios grupos de seguridad separados por ','.</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">*aws_connector_iam_instance_profile_name*</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">(Obligatorio) Nombre del perfil de instancia del conector.</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">*aws_connector_account_id*</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">(Opcional) el ID de cuenta de NetApp con el que se asociará el conector. Si no se proporciona, Cloud Manager utiliza la primera cuenta. Si no existe ninguna cuenta, Cloud Manager crea una cuenta nueva. Para encontrar el ID de cuenta, vaya a la pestaña de cuenta de Cloud Manager en<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">*aws_connector_public_ip_bool*</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">(Opcional) indica si se asocia una dirección IP pública a la instancia. Si no se proporciona, la asociación se realizará en función de la configuración de la subred.</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph"><block ref="2642a0976dba96af7529d6e1d27bff5f" prefix="" category="inline-code"></block></block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">Variables de Terraform para una única instancia de CVO de NetApp.</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">*nombre_cvo*</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">(Obligatorio) el nombre del entorno de trabajo de Cloud Volumes ONTAP.</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">*cvo_region*</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">(Requerido) la región donde se creará el entorno de trabajo.</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">*cvo_subnet_id*</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">(Requerido) el identificador de subred donde se creará el entorno de trabajo.</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">*cvo_vpc_id*</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">(Opcional) el ID de VPC donde se creará el entorno de trabajo. Si no se proporciona este argumento, el VPC se calculará utilizando el ID de subred proporcionado.</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">*cvo_svm_password*</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">(Obligatorio) la contraseña de administrador para Cloud Volumes ONTAP.</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">*cvo_writing_speed_state*</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">(Opcional) el ajuste de velocidad de escritura para Cloud Volumes ONTAP: ['NORMAL','ALTO']. El valor predeterminado es "NORMAL".</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">Puesta en marcha de CVO para alta disponibilidad</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">Archivos de configuración de Terraform para la puesta en marcha de NetApp CVO (par de alta disponibilidad) en AWS</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar NetApp CVO (Cloud Volumes ONTAP) en par de alta disponibilidad en AWS (Amazon Web Services).</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">Actualice los valores de variable en<block ref="d8fbe289f1062e79a6ecf2cb41d4650c" prefix=" " category="inline-code"></block>.</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph"><block ref="c6f18f9568d343bc6accef19de501a79" prefix="" category="inline-code"></block></block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">Variables de Terraform para instancias de NetApp CVO en par de alta disponibilidad.</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">*cvo_is_ha*</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">(Opcional) indique si el entorno de trabajo es un par de alta disponibilidad o no [true, false]. El valor predeterminado es false.</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">*cvo_1_subnet_id*</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">(Necesario) el ID de subred donde se creará el primer nodo.</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">*cvo_2_subnet_id*</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">(Obligatorio) el identificador de subred donde se creará el segundo nodo.</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">*cvo_failover_mode*</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">(Opcional) para alta disponibilidad, el modo de conmutación por error del par ha: ['PrivateIP', 'FloatingIP']. 'PrivateIP' es para una sola zona de disponibilidad y 'FloatingIP' es para múltiples zonas de disponibilidad.</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">*cvo_mediador_subred_id*</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">(Opcional) para alta disponibilidad, el ID de subred del mediador.</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">*cvo_mediador_key_pair_name*</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">(Opcional) para alta disponibilidad, el nombre del par de claves de la instancia del mediador.</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">*cvo_cluster_floating_ip*</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">(Opcional) para ha FloatingIP, la dirección IP flotante de gestión del clúster.</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">*cvo_data_floating_ip*</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">(Opcional) para ha FloatingIP, la dirección IP flotante de datos.</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">*cvo_data_floating_ip2*</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">*cvo_svm_floating_ip*</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">(Opcional) para ha FloatingIP, la dirección IP flotante de gestión de SVM.</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">*cvo_route_table_ids*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">Lista</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">(Opcional) para ha FloatingIP, la lista de identificadores de tabla de rutas que se actualizarán con las IP flotantes.</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">Puesta en marcha de FSX</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">Archivos de configuración de Terraform para la implementación de ONTAP FSX de NetApp en AWS</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para implementar/configurar ONTAP FSX de NetApp en AWS (Amazon Web Services).</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">Formato de salida predeterminado [Ninguno]:</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">Actualice los valores de variable en<block ref="15f7e426a035ec7faf6715523364f143" prefix=" " category="inline-code"></block></block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">Recetas:</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">Variables de Terraform para la instancia del conector AWS de NetApp.</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph"><block ref="8fa643108c81bb359c39d110fa732b76" prefix="" category="inline-code"></block></block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">Variables de Terraform para la instancia de ONTAP FSX de NetApp.</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">*fsx_name*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">*fsx_region*</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">*fsx_primary_subnet_id*</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">(Obligatorio) el ID de subred principal donde se creará el entorno de trabajo.</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">*fsx_secondary_subnet_id*</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">(Requerido) el ID de subred secundaria donde se creará el entorno de trabajo.</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">*fsx_account_id*</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">(Obligatorio) el ID de cuenta de NetApp con el que se asociará la instancia de FSX. Si no se proporciona, Cloud Manager utiliza la primera cuenta. Si no existe ninguna cuenta, Cloud Manager crea una cuenta nueva. Para encontrar el ID de cuenta, vaya a la pestaña de cuenta de Cloud Manager en<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">*fsx_workspace_id*</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">(Obligatorio) el ID del espacio de trabajo de Cloud Manager del entorno de trabajo.</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">*fsx_admin_password*</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">*fsx_throughput_capacity*</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">(Opcional) capacidad del rendimiento.</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">*fsx_storage_capacity_size*</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">(Opcional) Tamaño de volumen de EBS para el primer agregado de datos. Para GB, la unidad puede ser: [100 o 500]. Para TB, la unidad puede ser: [1,2,4,8,16]. El valor predeterminado es "1".</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">*fsx_storage_capacity_size_unit*</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">(Opcional) ['GB' o 'TB']. El valor predeterminado es 'TB'.</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">*fsx_cloudmanager_aws_credential_name*</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">(Obligatorio) el nombre de la cuenta de credenciales de AWS.</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="example-title">Azure</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">Archivos de configuración de Terraform para la implementación de ANF Volume en Azure</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un volumen de ANF (Azure NetApp Files) en Azure.</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Documentación de Terraform:<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Inicie sesión en la CLI de Azure (se debe instalar el CLI de Azure).</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">Actualice los valores de variable en<block ref="8c39601b8ab8961ff411cd5068a67f11" prefix=" " category="inline-code"></block>.</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">Puede optar por implementar el volumen ANF utilizando un vnet y una subred existentes estableciendo en falso la variable "vnet_Creation_bool" y el valor "Subnet_Creation_bool" y suministrando el valor "Subnet_id_for_anf_vol". También puede establecer esos valores en true y crear un nuevo vnet y una subred en cuyo caso, el identificador de subred se tomará automáticamente de la subred recién creada.</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">Variables de Terraform para un volumen único de ANF de NetApp.</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">*az_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">(Obligatorio) especifica la ubicación de Azure compatible donde existe el recurso. Al cambiar esto, se fuerza la creación de un recurso nuevo.</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">*az_prefix*</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">(Obligatorio) el nombre del grupo de recursos en el que se debe crear el volumen de NetApp. Al cambiar esto, se fuerza la creación de un recurso nuevo.</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">*az_vnet_address_space*</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">(Necesario) el espacio de direcciones que debe utilizar el vnet recién creado para la implementación del volumen ANF.</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">*az_subnet_address_prefix*</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">(Obligatorio) el prefijo de dirección de subred que utilizará el vnet recién creado para la implementación de volúmenes ANF.</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">*az_volume_path*</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">(Obligatorio) una ruta de archivo única para el volumen. Se utiliza al crear destinos de montaje. Al cambiar esto, se fuerza la creación de un recurso nuevo.</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">*az_capacity_pool_size*</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">Entero</block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">(Obligatorio) Tamaño de pool de capacidad mencionado en TB</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">*az_vnet_creation_bool*</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">Booleano</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si desea crear una nueva vnet. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar un vnet existente.</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">*az_subnet_creation_bool*</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> para crear una nueva subred. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar una subred existente.</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">*az_subnet_id_for_anf_vol*</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">(Obligatorio) mencione el ID de subred en caso de que decida utilizar una subred existente mediante la configuración<block ref="1cceaecaa3b91a9f1e23ecb4681ce8af" prefix=" " category="inline-code"></block> a verdadero. Si se establece en falso, déjelo en el valor predeterminado.</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">*az_netapp_pool_service_level*</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">(Necesario) el rendimiento objetivo del sistema de archivos. Los valores válidos incluyen<block ref="8d5e7e72f12067991186cdf3cb7d5d9d" prefix=" " category="inline-code"></block> ,<block ref="eb6d8ae6f20283755b339c0dc273988b" prefix=" " category="inline-code"></block> , o.<block ref="7057376a419b3334cc7b8b7a9f064abb" prefix=" " category="inline-code"></block>.</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">*az_netapp_vol_service_level*</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">*az_netapp_vol_protocol*</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">(Opcional) el protocolo del volumen objetivo expresado como una lista. El valor único admitido incluye<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, o.<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Si no se define el argumento, se tomará de forma predeterminada<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Si se cambia esto, se debe crear un nuevo recurso y se perderán los datos.</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">*az_netapp_vol_security_style*</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">(Opcional) estilo de seguridad de volumen, los valores aceptados son<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> o.<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Si no se proporciona ningún valor, se crea de forma por omisión el volumen de un único protocolo<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> si es así<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block> o.<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block> volume, si<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>, de forma predeterminada, se establece en<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. En un volumen de protocolo doble, si no se proporciona, su valor será<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>.</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">*az_netapp_vol_storage_quota*</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">(Obligatorio) la cuota de almacenamiento máxima permitida para un sistema de archivos en gigabytes.</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF Protección de datos</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">Archivos de configuración de Terraform para la implementación de un volumen ANF con protección de datos en Azure</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un volumen de ANF (Azure NetApp Files) con protección de datos en Azure.</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">Actualice los valores de variable en<block ref="7faa6da7e229d163db53602f424f1f82" prefix=" " category="inline-code"></block>.</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph"><block ref="7bc40f4d4f846e8c7177d752ac52b775" prefix="" category="inline-code"></block></block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">Variables de Terraform para un solo volumen de ANF con protección de datos habilitada.</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">*az_alt_location*</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">(Necesario) la ubicación de Azure donde se creará el volumen secundario</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">*az_vnet_primary_address_space*</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">(Necesario) el espacio de direcciones que debe utilizar el vnet recién creado para la implementación del volumen primario ANF.</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">*az_vnet_secondary_address_space*</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">(Necesario) el espacio de direcciones que debe utilizar el vnet recién creado para la implementación de volúmenes secundarios ANF.</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">*az_subnet_primary_address_prefix*</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">(Obligatorio) el prefijo de dirección de subred que utilizará el vnet recién creado para la implementación del volumen primario ANF.</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">*az_subnet_secondary_address_prefix*</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">(Obligatorio) el prefijo de dirección de subred que utilizará el vnet recién creado para la implementación de volumen secundario ANF.</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">*az_volume_path_primary*</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">(Obligatorio) una ruta de archivo única para el volumen primario. Se utiliza al crear destinos de montaje. Al cambiar esto, se fuerza la creación de un recurso nuevo.</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">*az_volume_path_secondary*</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">(Obligatorio) una ruta de archivo única para el volumen secundario. Se utiliza al crear destinos de montaje. Al cambiar esto, se fuerza la creación de un recurso nuevo.</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">*az_capacity_pool_size_primary*</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">*az_capacity_pool_size_secondary*</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">*az_vnet_primary_creation_bool*</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si desea crear un nuevo vnet para el volumen primario. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar un vnet existente.</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">*az_vnet_secondary_creation_bool*</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si desea crear una nueva vnet para el volumen secundario. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar un vnet existente.</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">*az_subnet_primary_creation_bool*</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> para crear una nueva subred para el volumen primario. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar una subred existente.</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">*az_subnet_secondary_creation_bool*</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">(Obligatorio) establezca este booleano en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> para crear una nueva subred para el volumen secundario. Configúrelo como<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> para utilizar una subred existente.</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">*az_primary_subnet_id_for_anf_vol*</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">(Obligatorio) mencione el ID de subred en caso de que decida utilizar una subred existente mediante la configuración<block ref="4480e01b6ddc0f64d89a995dcbd413f6" prefix=" " category="inline-code"></block> a verdadero. Si se establece en falso, déjelo en el valor predeterminado.</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">*az_secondary_subnet_id_for_anf_vol*</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">(Obligatorio) mencione el ID de subred en caso de que decida utilizar una subred existente mediante la configuración<block ref="963bc6d7f5ebc59003b8ef8f3f92a02c" prefix=" " category="inline-code"></block> a verdadero. Si se establece en falso, déjelo en el valor predeterminado.</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">*az_netapp_pool_service_level_primary*</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">*az_netapp_pool_service_level_secondary*</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">*az_netapp_vol_service_level_primary*</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">*az_netapp_vol_service_level_secondary*</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">*az_netapp_vol_protocol_primary*</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">*az_netapp_vol_protocol_secondary*</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">*az_netapp_vol_storage_quota_primary*</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">*az_netapp_vol_storage_quota_secondary*</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">*az_dp_replication_frequency*</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">(Obligatorio) frecuencia de replicación, los valores admitidos son<block ref="3602ffca95e52ce3f66ae1c6de108997" prefix=" " category="inline-code"></block>,<block ref="745fd0ea7f576f350a0eed4b8c48a8e2" prefix=" " category="inline-code"></block>,<block ref="bea79186fd7af2da67e59b4b15df5a26" prefix=" " category="inline-code"></block>, los valores distinguen entre mayúsculas y minúsculas.</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF Protocolo dual</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">Archivos de configuración de Terraform para la implementación de ANF Volume con protocolo doble en Azure</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un volumen ANF (Azure NetApp Files) con el protocolo doble habilitado en Azure.</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">Actualice los valores de variable en<block ref="b81cd75a858f9c9f13b2c366b4254eea" prefix=" " category="inline-code"></block>.</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">Variables de Terraform para un solo volumen de ANF con protocolo dual activado.</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">*az_netapp_vol_protocol1*</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">(Obligatorio) el protocolo del volumen objetivo expresado como una lista. El valor único admitido incluye<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, o.<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Si no se define el argumento, se tomará de forma predeterminada<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Si se cambia esto, se debe crear un nuevo recurso y se perderán los datos.</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">*az_netapp_vol_protocol2*</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">*az_smb_server_username*</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">(Obligatorio) Nombre de usuario para crear un objeto ActiveDirectory.</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">*az_smb_server_password*</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">(Obligatorio) Contraseña de usuario para crear un objeto ActiveDirectory.</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">*az_smb_server_name*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">(Obligatorio) Nombre del servidor para crear un objeto ActiveDirectory.</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">*az_smb_dns_servers*</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">(Requerido) IP del servidor DNS para crear un objeto ActiveDirectory.</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">ANF volumen de Snapshot</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">Archivos de configuración de Terraform para la implementación de ANF Volume desde Snapshot en Azure</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un volumen de ANF (Azure NetApp Files) desde Snapshot en Azure.</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">Actualice los valores de variable en<block ref="ef9d672e94eee49d10d74f858a44d14f" prefix=" " category="inline-code"></block>.</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Variables de Terraform para un solo volumen de ANF mediante instantánea.</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">*az_snapshot_id*</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">(Obligatorio) ID de snapshot con el que se creará el nuevo volumen de ANF.</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">Archivos de configuración Terraform para la implementación de CVO de nodo único en Azure</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un CVO de nodo único (Cloud Volumes ONTAP) en Azure.</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">Actualice las variables en<block ref="094639eff38e0172690a0fb13cd97348" prefix=" " category="inline-code"></block>.</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">Variables de Terraform para Cloud Volumes ONTAP de un solo nodo (CVO).</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">*refrescar_token*</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">(Necesario) el token de actualización de Cloud Manager de NetApp. Esto se puede generar desde Cloud Central de netapp.</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">*az_connector_name*</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">*az_connector_location*</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">(Obligatorio) la ubicación en la que se creará el conector de Cloud Manager.</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">*az_connector_subscription_id*</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">(Obligatorio) el ID de la suscripción de Azure.</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">*az_connector_company*</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">*az_connector_resource_group*</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">(Obligatorio) el grupo de recursos en Azure donde se crearán los recursos.</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">*az_connector_subnet_id*</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">(Obligatorio) el nombre de la subred de la máquina virtual.</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">*az_connector_vnet_id*</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">(Obligatorio) el nombre de la red virtual.</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">*az_connector_network_security_group_name*</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">(Obligatorio) el nombre del grupo de seguridad para la instancia.</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">*az_connector_associate_public_ip_address*</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">(Obligatorio) indica si se debe asociar la dirección IP pública a la máquina virtual.</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">*az_connector_account_id*</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">(Obligatorio) el ID de cuenta de NetApp con el que se asociará el conector. Si no se proporciona, Cloud Manager utiliza la primera cuenta. Si no existe ninguna cuenta, Cloud Manager crea una cuenta nueva. Para encontrar el ID de cuenta, vaya a la pestaña de cuenta de Cloud Manager en<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">*az_connector_admin_password*</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">(Obligatorio) la contraseña del conector.</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">*az_connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">(Obligatorio) el nombre de usuario del conector.</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">*az_cvo_name*</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">*az_cvo_location*</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">(Obligatorio) la ubicación en la que se creará el entorno de trabajo.</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">*az_cvo_subnet_id*</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">(Obligatorio) el nombre de la subred del sistema Cloud Volumes ONTAP.</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">*az_cvo_vnet_id*</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">*az_cvo_vnet_resource_group*</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">(Obligatorio) el grupo de recursos en Azure asociado a la red virtual.</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">*az_cvo_data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">(Necesario) el tipo de cifrado que se debe utilizar en el entorno de trabajo: <block ref="71335a48a021ae2aeb7df636ba3d2483" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. El valor predeterminado es<block ref="71335a48a021ae2aeb7df636ba3d2483" prefix=" " category="inline-code"></block>.</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">*az_cvo_storage_type*</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">(Obligatorio) el tipo de almacenamiento para el primer agregado de datos: <block ref="31034b38323b8bba82b33017ce6c13ff" prefix="[" category="inline-code"></block>,<block ref="410e42479a4a7cfdbe16e3e285d05598" prefix=" " category="inline-code"></block>,<block ref="2d641bc6cd6c1342dced281e583a3993" prefix=" " category="inline-code"></block>]. El valor predeterminado es<block ref="31034b38323b8bba82b33017ce6c13ff" prefix=" " category="inline-code"></block></block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">*az_cvo_svm_password*</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">*az_cvo_workspace_id*</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">(Obligatorio) el ID del espacio de trabajo de Cloud Manager en el que desea poner en marcha Cloud Volumes ONTAP. Si no se proporciona, Cloud Manager utiliza el primer espacio de trabajo. Puede encontrar el ID en la ficha espacio de trabajo en<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">*az_cvo_capacity_tier*</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">(Necesario) Si habilitar la organización en niveles de los datos para el primer agregado de datos: <block ref="e8016c85ada38bdc5fac616ec1318047" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. El valor predeterminado es<block ref="1649cff06611a6025da3dd511a97fb43" prefix=" " category="inline-code"></block>.</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">*az_cvo_writing_speed_state*</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">(Obligatorio) la configuración de velocidad de escritura para Cloud Volumes ONTAP: <block ref="1e23852820b9154316c7c06e2b7ba051" prefix="[" category="inline-code"></block> ,<block ref="b89de3b4b81c4facfac906edf29aec8c" prefix=" " category="inline-code"></block>]. El valor predeterminado es<block ref="1e23852820b9154316c7c06e2b7ba051" prefix=" " category="inline-code"></block>. Este argumento no es relevante para pares de alta disponibilidad.</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">*az_cvo_ontap*</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">(Obligatorio) la versión de ONTAP requerida. Se ignora si 'use_latest_version' se establece en true. El valor predeterminado es utilizar la última versión.</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">*az_cvo_instance_type*</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">(Obligatorio) el tipo de instancia que se va a utilizar, que depende del tipo de licencia elegido: Explore:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Estándar:<block ref="3e47288b0119e2f8cd128c5c1feb02e1" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block><block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix="," category="inline-code"></block>], BYOL: Todos los tipos de instancia definidos para PAYGO. Para obtener más tipos de instancia admitidos, consulte las notas de la versión de Cloud Volumes ONTAP. El valor predeterminado es<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">*az_cvo_license_type*</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">(Obligatorio) el tipo de licencia que se va a usar. Para un solo nodo: <block ref="47dfc9e0cae8289642a649a3d4b6f07f" prefix="[" category="inline-code"></block>,<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>,<block ref="fda853806a97d134c59567534d1aabe6" prefix=" " category="inline-code"></block>,<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block>,<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block>]. Para alta disponibilidad: <block ref="18099bc4697504c468dd18adf279ac68" prefix="[" category="inline-code"></block>,<block ref="87d3f1b34e654923bcf9bc3b1b740e47" prefix=" " category="inline-code"></block>,<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block>,<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block>]. El valor predeterminado es<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Uso<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> o.<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Para alta disponibilidad al seleccionar traiga su propio tipo de licencia basado en capacidad o Freemium. Uso<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> o.<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Para alta disponibilidad en la selección, traiga su propio tipo de licencia basado en nodos.</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">*az_cvo_nss_account*</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">(Obligatorio) este ID de cuenta del sitio de soporte de NetApp se utiliza con este sistema Cloud Volumes ONTAP. Si el tipo de licencia es BYOL y no se proporciona una cuenta NSS, Cloud Manager intenta usar la primera cuenta de NSS existente.</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">*az_tenant_id*</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">(Obligatorio) ID de inquilino de la aplicación/servicio principal registrada en Azure.</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">*az_application_id*</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">(Obligatorio) ID de aplicación del principal de aplicación/servicio registrado en Azure.</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">*az_application_key*</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">(Obligatorio) la clave de aplicación del principal de aplicación/servicio registrado en Azure.</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">Archivos de configuración de Terraform para la puesta en marcha de CVO ha en Azure</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar CVO (Cloud Volumes ONTAP) ha (alta disponibilidad) en Azure.</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">Actualice las variables en<block ref="3bdb269db9a3f1a5b57521aa62658bf3" prefix=" " category="inline-code"></block>.</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph"><block ref="a82b90469ebb90af122c361dbb754fd8" prefix="" category="inline-code"></block></block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">Variables de Terraform para Cloud Volumes ONTAP de par de alta disponibilidad (CVO).</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">(Obligatorio) el tipo de instancia que se va a utilizar, que depende del tipo de licencia elegido: Explore:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Estándar:<block ref="a23549be3ebc980aebe6cb120ab4e310" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block>,<block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix=" " category="inline-code"></block>], BYOL: Todos los tipos de instancia definidos para PAYGO. Para obtener más tipos de instancia admitidos, consulte las notas de la versión de Cloud Volumes ONTAP. El valor predeterminado es<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">(Obligatorio) el tipo de licencia que se va a usar. Para un solo nodo: <block ref="3abe68da9038e8e4aabc1b0e2a6530cc" prefix="[" category="inline-code"></block>]. Para alta disponibilidad: <block ref="86e0c1bceadb9c08ef223996a3e33d86" prefix="[" category="inline-code"></block>]. El valor predeterminado es<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Uso<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> o.<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Para alta disponibilidad al seleccionar traiga su propio tipo de licencia basado en capacidad o Freemium. Uso<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> o.<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Para alta disponibilidad en la selección, traiga su propio tipo de licencia basado en nodos.</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="example-title">GCP</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">Archivos de configuración de Terraform para la puesta en marcha de NetApp CVO (instancia de nodo único) en GCP</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar un solo nodo CVO (Cloud Volumes ONTAP) de NetApp en GCP (Google Cloud Platform).</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">Guarde el archivo JSON de la clave de autenticación GCP en el directorio.</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">Actualice los valores de variable en<block ref="0635645653586768460c826b4f319a80" prefix=" " category="inline-code"></block></block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">Puede elegir desplegar el conector estableciendo el valor de la variable "gcp_Connector_deploy_bool" en true/false.</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">Variables de Terraform para la instancia del conector GCP de NetApp para la puesta en marcha de CVO.</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">*gcp_connector_deploy_bool*</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">*nombre_conector_gcp*</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">*gcp_connector_project_id*</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">(Obligatorio) el Project_id de GCP en el que se creará el conector.</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">*gcp_connector_zone*</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">(Obligatorio) Zona GCP donde se creará el conector.</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">*gcp_connector_company*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">*gcp_connector_service_account_email*</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">(Obligatorio) el correo electrónico de Service_account para la instancia del conector. Esta cuenta de servicio se utiliza para permitir que el conector cree Cloud Volume ONTAP.</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">*gcp_connector_service_account_path*</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">(Obligatorio) la ruta local del archivo JSON Service_account para la autorización de GCP. Esta cuenta de servicio se utiliza para crear el conector en GCP.</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">*gcp_connector_account_id*</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">(Opcional) el ID de cuenta de NetApp con el que se asociará el conector. Si no se proporciona, Cloud Manager utiliza la primera cuenta. Si no existe ninguna cuenta, Cloud Manager crea una cuenta nueva. Para encontrar el ID de cuenta, vaya a la pestaña de cuenta de Cloud Manager en<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">Variables de Terraform para una única instancia de NetApp CVO en GCP.</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">*gcp_cvo_name*</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">*gcp_cvo_project_id*</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">(Obligatorio) el ID del proyecto GCP.</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">*gcp_cvo_zone*</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">(Obligatorio) la zona de la región en la que se creará el entorno de trabajo.</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">*gcp_cvo_gcp_service_account*</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">(Necesario) el correo electrónico de la cuenta gcp_service_account para habilitar la organización en niveles de datos inactivos en Google Cloud Storage.</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">*gcp_cvo_svm_password*</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">*gcp_cvo_workspace_id*</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">(Opcional) el ID del espacio de trabajo de Cloud Manager en el que desea implementar Cloud Volumes ONTAP. Si no se proporciona, Cloud Manager utiliza el primer espacio de trabajo. Puede encontrar el ID en la ficha espacio de trabajo en<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">*gcp_cvo_license_type*</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">(Opcional) el tipo de licencia que se va a utilizar. Para un solo nodo: ['Capacity-paygo', 'gcp-cot-explore-paygo', 'gcp-cot-standard-paygo', 'gcp-cot-Premium-paygo', 'gcp-cot-Premium-byol'], Para ha: ['ha-Capacity-paygo', 'gcp-ha-cot-explore-paygo', 'gcp-ha-cot-standard-paygo', 'gcp-ha-cot-Premium-paygo', 'gcp-ha-cot-Premium-byol']. El valor predeterminado es "Capacity-paygo" para un solo nodo y "ha-Capacity-paygo" para ha.</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">*gcp_cvo_capacity_package_name*</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">(Opcional) el nombre del paquete de capacidad: ['Essential', 'Professional', 'Freemium']. El valor predeterminado es 'esencial'.</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">Archivos de configuración de Terraform para la puesta en marcha de NetApp CVO (par de alta disponibilidad) en GCP</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">En esta sección se incluyen varios archivos de configuración de Terraform para poner en marcha/configurar NetApp CVO (Cloud Volumes ONTAP) en par de alta disponibilidad en GCP (Google Cloud Platform).</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">Actualice los valores de variable en<block ref="aca245204ab77411a71da01b8d6ec7cb" prefix=" " category="inline-code"></block>.</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">Variables de Terraform para instancias de NetApp CVO en el par de alta disponibilidad en GCP.</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">*gcp_cvo_is_ha*</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">*gcp_cvo_1_zona*</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">(Opcional) Zona para el nodo 1.</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">*gcp_cvo_2_zone*</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">(Opcional) Zona para el nodo 2.</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">*gcp_cvo_mediador_zona*</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">(Opcional) Zona de mediador.</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">*gcp_cvo_vpc_id*</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">(Opcional) el nombre del VPC.</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">*gcp_cvo_subnet_id*</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">(Opcional) el nombre de la subred para Cloud Volumes ONTAP. El valor predeterminado es: 'Predeterminado'.</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">*gcp_cvo_vpc0_node_and_data_connectivity*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">(Opcional) VPC para nic1, necesario para la conectividad de los datos y del nodo. Si se utiliza VPC compartido, se debe proporcionar netwrok_project_id.</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">*gcp_cvo_vpc1_cluster_connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">(Opcional) Ruta VPC para nic2, requerida para la conectividad de clúster.</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">*gcp_cvo_vpc2_ha_connectivity*</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">(Opcional) Ruta VPC para nic3, necesaria para la conectividad de alta disponibilidad.</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">*gcp_cvo_vpc3_data_replication*</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">(Opcional) Ruta del VPC para nic4, necesaria para la replicación de datos.</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">*gcp_cvo_subnet0_node_and_data_connectivity*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">(Opcional) Ruta de subred para nic1, obligatoria para la conectividad de nodos y datos. Si se utiliza VPC compartido, se debe proporcionar netwrok_project_id.</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">*gcp_cvo_subnet1_cluster_connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">(Opcional) Ruta de subred para nic2, se requiere para la conectividad del clúster.</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">*gcp_cvo_subnet2_ha_connectivity*</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">(Opcional) Ruta de subred para nic3, obligatoria para conectividad de alta disponibilidad.</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">*gcp_cvo_subnet3_data_replication*</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">(Opcional) Ruta de subred para nic4, necesaria para la replicación de datos.</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">*gcp_cvo_gcp_volume_size*</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">(Opcional) el tamaño del volumen de GCP para el primer agregado de datos. Para GB, la unidad puede ser: [100 o 500]. Para TB, la unidad puede ser: [1,2,4,8]. El valor predeterminado es '1' .</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">*gcp_cvo_gcp_volume_size_unit*</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">Volumen CVS</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">Archivos de configuración de Terraform para la implementación de CVS Volume de NetApp en GCP</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">Esta sección contiene varios archivos de configuración de Terraform para poner en marcha/configurar volúmenes de CVS de NetApp (Cloud Volumes Services) en GCP (Google Cloud Platform).</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Documentación de Terraform:<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">Actualice los valores de variable en<block ref="eb1510c0f29be1d144dce2bfa2e8caab" prefix=" " category="inline-code"></block>.</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph"><block ref="944ce323a5a1ffb09543fd409911cc88" prefix="" category="inline-code"></block></block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">Variables de Terraform para volumen de CVS para GCP de NetApp.</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">*gcp_cvs_name*</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">(Obligatorio) el nombre del volumen CVS de NetApp.</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">*gcp_cvs_project_id*</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">(Requerido) el proyecto_id de GCP donde se creará el volumen CVS.</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">*gcp_cvs_gcp_service_account_path*</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">(Obligatorio) la ruta local del archivo JSON Service_account para la autorización de GCP. Esta cuenta de servicio se utiliza para crear el volumen CVS en GCP.</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">*gcp_cvs_region*</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">(Obligatorio) la zona GCP donde se creará el volumen CVS.</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">*gcp_cvs_network*</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">(Requerido) el VPC de red del volumen.</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">*gcp_cvs_size*</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">(Obligatorio) el tamaño del volumen está entre 1024 y 102400 incluido (en GIB).</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">*gcp_cvs_volume_path*</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">(Opcional) el nombre de la ruta del volumen para el volumen.</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">*gcp_cvs_protocol_types*</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">(Obligatorio) el tipo_protocolo del volumen. Para NFS utilice "NFSv3" o "NFSv4" y para SMB utilice "CIFS" o "MB".</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">La automatización de las soluciones de NetApp permite al cliente automatizar la puesta en marcha, configuración y ejecución de muchas tareas comunes de infraestructura y aplicaciones.</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">Primeros pasos con la automatización de soluciones de NetApp</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">La automatización de soluciones de NetApp proporciona simplicidad y repetibilidad para muchas de las tareas comunes utilizadas por las soluciones de NetApp.</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">Antes de ejecutar la automatización de cualquier solución, debe configurarse el entorno para ejecutar la automatización. Existen opciones para ejecutar la automatización desde la línea de comandos o a través de una herramienta como AWX o Tower.</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">En las siguientes secciones se describen los pasos necesarios para configurar el entorno para cada uno de los entornos especificados.</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="example-title">Configure el nodo de control de Ansible para las puestas en marcha de la CLI en RHEL/CentOS</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Requisitos para el nodo de control de Ansible,:</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">Una máquina RHEL/CentOS con los siguientes paquetes instalados:</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">PIP3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible (versión superior a 2.10.0)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">Si tiene instalada una máquina RHEL/CentOS nueva sin los requisitos anteriores, siga los pasos que se indican a continuación para configurar esa máquina como nodo de control de Ansible:</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">Habilite el repositorio de Ansible para RHEL-8/RHEL-7</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">Para RHEL-8 (ejecute el comando siguiente como raíz)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">Para RHEL-7 (ejecute el comando siguiente como raíz)</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">Cree un archivo .sh</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">Pegue el contenido siguiente en el archivo</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">Haga que el archivo sea ejecutable</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">Ejecutar el script (como root)</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="example-title">Configure el nodo de control de Ansible para las puestas en marcha de la CLI en Ubuntu/Debian</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">Una máquina Ubuntu/Debian con los siguientes paquetes instalados:</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">Si tiene instalada una máquina nueva de Ubuntu/Debian sin los requisitos anteriores, siga los pasos que se indican a continuación para configurar esa máquina como nodo de control de Ansible:</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="example-title">Configure la torre Ansible o AWX para las puestas en marcha de la torre/AWX</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">En esta sección se describen los pasos necesarios para configurar los parámetros en AWX/Ansible Tower que preparan el entorno para consumir soluciones automatizadas de NetApp.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">Configure el inventario.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Desplácese hasta Recursos → inventarios → Agregar y haga clic en Agregar inventario.</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">Escriba el nombre y los detalles de la organización y haga clic en Guardar.</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">En la página inventarios, haga clic en los recursos de inventario que acaba de crear.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">Si hay alguna variable de inventario, péguela en el campo variables.</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">Vaya al submenú grupos y haga clic en Agregar.</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">Introduzca el nombre del grupo, copie las variables de grupo (si es necesario) y haga clic en Guardar.</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">Haga clic en el grupo creado, vaya al submenú hosts y haga clic en Add New Host.</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">Proporcione el nombre de host y la dirección IP del host, pegue las variables del host (si es necesario) y haga clic en Save.</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">Crear tipos de credenciales. Para las soluciones que implican ONTAP, Element, VMware o cualquier otra conexión de transporte basada en HTTPS, debe configurar el tipo de credencial para que coincida con las entradas de nombre de usuario y contraseña.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Desplácese hasta Administration → Credential Types y haga clic en Add.</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">Escriba el nombre y la descripción.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">Pegue el siguiente contenido en la configuración de entrada:</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">Pegue el siguiente contenido en la configuración del inyector:</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">Configurar credenciales.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Desplácese hasta Resources → Credentials y haga clic en Add.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">Introduzca el nombre y los detalles de la organización.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">Seleccione el tipo de credencial correcto; si tiene intención de utilizar el inicio de sesión SSH estándar, seleccione el tipo máquina o, como alternativa, seleccione el tipo de credencial personalizada que ha creado.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">Introduzca los otros detalles correspondientes y haga clic en Guardar.</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">Configure el proyecto.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Desplácese hasta Recursos → proyectos y haga clic en Agregar.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">Seleccione Git para el Tipo de credencial de control de origen.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">Pegue la URL de control de origen (o la URL del clon git) que corresponda a la solución específica.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">De manera opcional, si la URL de Git está controlada por el acceso, cree y adjunte la credencial correspondiente en la credencial de control de origen.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">Haga clic en Guardar.</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">Configure la plantilla de trabajo.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Desplácese hasta Recursos → Plantillas → Agregar y haga clic en Agregar plantilla de trabajo.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">Introduzca el nombre y la descripción.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">Seleccione el tipo de trabajo; Run configura el sistema basado en una tableta playbook y Check realiza una ejecución seca de la tableta playbook sin configurar realmente el sistema.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Seleccione el inventario, el proyecto y las credenciales correspondientes para el libro de estrategia.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">Seleccione el libro de estrategia que desea ejecutar como parte de la plantilla de trabajo.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">Normalmente las variables se pegan durante el tiempo de ejecución. Por lo tanto, para obtener la solicitud de que se rellenen las variables durante el tiempo de ejecución, asegúrese de marcar la casilla de verificación en Iniciar correspondiente al campo variable.</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">Introduzca los demás detalles necesarios y haga clic en Guardar.</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">Inicie la plantilla de trabajo.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">Desplácese hasta Recursos → Plantillas.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">Haga clic en la plantilla deseada y, a continuación, en Iniciar.</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">Rellene las variables si se le solicita en el inicio y haga clic de nuevo en Iniciar.</block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">Serie de blogs que analizan las características de las soluciones de todo el contenido de soluciones de NetApp</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">Soluciones de NetApp: Blogs</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">Descripción general de los blogs en los que se destacan características específicas de muchas de las soluciones de NetApp.</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">Inteligencia artificial</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Inglés</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;F:@faceta_soultion_mktg=[AI,Analytics,artificial-Intelligence]+[AI blogs en NetApp.com]</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">Blogs de IA en thePub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="open-title">Base de datos empresarial</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">Proteja sus cargas de trabajo de SQL Server mediante SnapCenter de NetApp con Amazon FSX para ONTAP de NetApp</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Modernice las operaciones de su base de datos de Oracle en el cloud híbrido con el almacenamiento Amazon FSX</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">Soluciones de bases de datos de cloud híbrido con SnapCenter</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">Automatice la infraestructura de su base de datos de Oracle en el cloud híbrido</block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">Multicloud híbrido con VMware</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">Optimice el almacenamiento para puestas en marcha de VMware basadas en cloud</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">Empiece a usar la solución VMware para Azure con ofertas de cloud basadas en NetApp</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">Configure el cloud híbrido con FSX para ONTAP de NetApp y VMware Cloud en AWS SDDC mediante VMware HCX</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="7c3806f623157e3b19cc1801dd72a85d" category="inline-link-macro">Soporte de almacenes de datos de Cloud Volumes Service de NetApp para Google Cloud VMware Engine (NetApp)</block>
  <block id="5e25da2b2b250c19fcd7efe36b782cc9" category="list-text"><block ref="5e25da2b2b250c19fcd7efe36b782cc9" category="inline-link-macro-rx"></block></block>
  <block id="c540d1dfacf4a64cc435acb640f4cbd4" category="inline-link-macro">Cómo usar CVS de NetApp como almacenes de datos para Google Cloud VMware Engine (Google)</block>
  <block id="4a8385e4a45d508eea692800bf2323d9" category="list-text"><block ref="4a8385e4a45d508eea692800bf2323d9" category="inline-link-macro-rx"></block></block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="open-title">Virtualización</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">Cloud Foundation de NetApp y VMware (VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">Parte 1: Introducción</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">Parte 2: Almacenamiento principal DE VCF y ONTAP</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">Parte 3: VCF y almacenamiento principal de elementos</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">Parte 4: Herramientas de ONTAP para VMware y almacenamiento complementario</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="open-title">Contenedores</block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Casos prácticos de Astra DevOps:</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">Integre fácilmente la protección en su canalización de CI/CD de Kubernetes con Astra Control de NetApp</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps con NetApp: Utilice Astra Control para realizar análisis post mortem y restaurar su aplicación</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">Astra Control Center de NetApp: El botón sencillo para la gestión de datos de sus aplicaciones</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Instalación de Trident de NetApp en Red Hat OpenShift: Cómo resolver el problema de Docker «toomanyRequests»</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="list-text"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">Cómo utilizar VMware Tanzania con ONTAP para acelerar su transición hacia Kubernetes</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">La migración tiene que pasar por diferentes fases para una mejor planificación y finalización de la migración. Para migrar datos desde un almacenamiento NAS de terceros o un almacenamiento exportado NAS conectado directamente mediante NetApp XCP, siga las directrices de migración que se indican en esta sección.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">Flujo de trabajo de migración</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">Anterior: XCP de NetApp.</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">La siguiente figura muestra el flujo de trabajo de migración de cualquier NAS a NAS de NetApp.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Error: Falta la imagen gráfica</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">Localmente</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">El flujo de trabajo de migración desde cualquier NAS a NetApp NAS incluye los siguientes pasos:</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">Descubra los datos y los recursos compartidos de NAS.</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">Analice los datos y genere un informe para buscar la disposición de los datos.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">Cree una línea de base ejecutando el comando XCP Copy. Para realizar migraciones más rápidas, seleccione más instancias XCP y divida la carga de trabajo en el nivel de subcarpeta para iniciar trabajos de migración paralelos.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">Para las actualizaciones incrementales, utilice la sincronización XCP hasta que la tasa de cambio sea baja para la ventana de transposición.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">Marque el origen como de sólo lectura para realizar una sincronización final ejecutando el comando de sincronización XCP para completar la migración.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">Para comprobar que los datos se han transferido correctamente, compare el origen y el destino ejecutando el<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="section-title">Cloud</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">Para el cloud, puede seguir un flujo de trabajo de migración en las instalaciones similar si la conectividad entre on-premises y el cloud es Direct Connect (AWS), ExpressRoute (Azure) o Cloud Interconnect (GCP).</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">La siguiente figura muestra el flujo de trabajo de migración de las instalaciones al cloud.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">Si no hay ninguna conexión a Internet directa entre las instalaciones y el cloud, debe transferir los datos de las instalaciones al cloud a través de un método de transporte de datos sin conexión, como un camión. Cada proveedor de servicios de cloud tiene un método diferente con una terminología diferente para mover datos a su centro de datos.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">En la siguiente figura se muestra la solución de movimiento de datos entre las instalaciones y Azure sin ExpressRoute.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">Puede utilizar una arquitectura similar con los componentes respectivos de los distintos proveedores de servicios cloud.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">Siguiente: Análisis de archivos.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">Esta sección proporciona el tiempo aproximado para realizar las operaciones de copia XCP y sincronización XCP con un tamaño de archivo diferente de un millón de archivos para NFS.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">Directrices de tamaño</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">Anterior: Pasos de implementación.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">Estimación de tiempo basada en las pruebas</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">En las pruebas para las operaciones de copia y sincronización XCP se utilizó la misma plataforma de prueba que se utilizó para la implementación. Se crearon un millón de archivos de tres conjuntos de archivos 8K, 16K y 1MB y los cambios se realizaron en tiempo real. La función de sincronización XCP realizó las actualizaciones incrementales diferenciales del origen al destino a nivel de archivo. La operación de actualización incremental es una o más de estas cuatro operaciones: Cambiar el nombre de archivos y carpetas existentes, anexar datos a archivos existentes, eliminar archivos y carpetas e incluir vínculos físicos, suaves y multivínculos adicionales. Para fines de prueba, nos centramos en las operaciones de cambio de nombre, adición, eliminación y enlaces. En otras palabras, las operaciones de modificación como renombrar, anexar y eliminar se realizaron a una tasa de cambio del 10% al 90% en un millón de archivos.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">La siguiente figura muestra los resultados de la operación de copia XCP.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">En la siguiente figura se muestran los resultados de las operaciones de cambio de nombre y enlace de XCP Sync.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">El tamaño del archivo no es proporcional a la<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> tiempo de finalización para transferir los archivos de origen cuyo nombre ha cambiado; los gráficos son lineales.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">Los tipos de vínculos son enlaces suaves, vínculos duros y vínculos múltiples. Los vínculos de software se consideran archivos normales. El tamaño de los archivos no es relevante para el tiempo que finaliza la operación de sincronización XCP.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">Las siguientes figuras muestran los resultados de las operaciones de adición y eliminación de sinc XCP.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">En las operaciones de adición y eliminación, los tamaños de archivo grandes tardan más tiempo en comparación con los tamaños de archivo pequeños. El tiempo para completar la operación es lineal al porcentaje de cambios de adición y eliminación.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">Comparación de XCP 1.6.1 con XCP 1.5</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">En comparación con las versiones anteriores, XCP 1.6.3 y 1.7 ofrece un rendimiento mejorado. La siguiente sección muestra una comparación de rendimiento de sincronización entre XCP 1.6.3 y 1.7 para los tamaños 8K, 16K y 1MB de un millón de archivos.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">Las siguientes figuras muestran los resultados del rendimiento de sincronización XCP para XCP 1.6.3 frente a 1.7 (con un tamaño de 8K de un millón de archivos).</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">La siguiente figura muestra los resultados del rendimiento de sincronización XCP para XCP 1.6.1 frente a 1.5 (con un tamaño de 16 KB de un millón de archivos).</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">La siguiente figura muestra los resultados del rendimiento de sincronización XCP para XCP 1.6.1 frente a 1.5 con un tamaño de 1 MB de un millón de archivos.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">De media, el rendimiento del XCP 1.7 mejoró en o fue similar al XCP 1.6.3 para el<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Operaciones de actualización incremental diferencial: Cambiar el nombre, anexar, vincular y eliminar con un tamaño de 1 MB de un millón de archivos.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">Según esta validación del rendimiento, NetApp recomienda utilizar XCP 1.7 para la migración de datos en las instalaciones y en el cloud.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">Siguiente: Ajuste del rendimiento.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp recibió una solicitud para buscar archivos duplicados de un único volumen o de varios volúmenes. NetApp proporcionó la siguiente solución.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">Duplicar archivos</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">Anterior: Uso de XCP Data mover para migrar archivos grandes.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">Para un volumen único, ejecute los siguientes comandos:</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">Para varios volúmenes, ejecute los comandos siguientes:</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Siguiente: Análisis específico basado en fecha y copia de datos.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">Historial de versiones</block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Anterior: Dónde encontrar información adicional.</block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Versión</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Fecha</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Historial de versiones del documento</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Versión 1.0</block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">Octubre de 2020</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">Versión inicial.</block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP transfiere datos mediante el uso de multihilos y funciones personalizables. Está diseñado para tres casos de uso principales: Migración o movimiento de datos, análisis de sistema de archivos y eliminación rápida de los árboles de directorios.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="doc">XCP de NetApp</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">Anterior: Introducción.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP transfiere datos mediante el uso de multihilos y funciones personalizables. Está diseñado para tres casos de uso principales: Migración o movimiento de datos, análisis de sistema de archivos y eliminación rápida de árboles de directorios.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">Movimiento o migración de datos</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP transfiere datos desde cualquier NAS a NAS de NetApp. Este proceso consta de cuatro operaciones principales: Exploración, copia, sincronización y verificación. Hay algunas funciones adicionales que ayudan a la supervisión y transferencia de datos:</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">*Scan.* proporciona un diseño de alto nivel de datos NAS y MapR/HDFS.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">*Copy.* realiza una transferencia de datos de línea de base.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">*Sync.* realiza la transferencia de datos incremental.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">*Verif.* realiza una verificación completa del objetivo.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">*Show (opcional).* descubre los recursos compartidos NAS.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">La siguiente figura ilustra las operaciones de migración y replicación de datos XCP.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">Análisis del sistema de archivos</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP le permite identificar, examinar y analizar datos no estructurados de forma nativa para mejorar la información, un requisito clave para los clientes empresariales que desean utilizar esa información para una mejor planificación, operar activos digitales de alto valor y para el gobierno de los datos mediante la elaboración de informes y la evaluación.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">Los clientes que se enfrentan a datos confidenciales pueden utilizar XCP de NetApp para responder a preguntas operativas habituales, como las siguientes:</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">¿Dónde están mis datos?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">¿De qué cantidad de datos y qué tipo de archivos tenemos?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">¿Qué datos se utilizan de forma activa y cuánto se inactiva?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">La siguiente figura muestra la comunicación de análisis de archivos XCP de NetApp desde la interfaz gráfica de usuario.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">Eliminar</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">Para los equipos de almacenamiento y las cargas de trabajo de automatización de diseño electrónico (EDA) puede resultar muy difícil limpiar directorios grandes, ya sean datos obsoletos o datos de prueba que hay que limpiar para recuperar espacio de almacenamiento. XCP proporciona una funcionalidad de eliminación rápida que puede eliminar un árbol de directorios completo. La función NetApp XCP Delete elimina los archivos y las carpetas de una determinada ruta NAS. Puede aprovechar los filtros de coincidencia para eliminar un conjunto específico de archivos y carpetas. Para un gran número de archivos y carpetas, puede utilizar la opción Fuerza, que no requiere confirmación para eliminar.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">Soporte para migración de origen en vivo</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">La compatibilidad con migración de origen en vivo incluida en XCP 1.7 permite la migración desde un origen de datos que está en uso activo (actividad de lectura y escritura). XCP abandona los archivos que se están utilizando durante el trabajo de migración, como la ejecución de copia y sincronización, y la información de archivos omitidos se captura en el registro XCP.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">Esta función admite cambios en el origen pero no admite cambios en el destino. Durante la migración, el destino no debe estar activo. La compatibilidad con la migración de origen activo solo está disponible para migraciones NFS.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">No se requieren ajustes especiales para las migraciones de origen en vivo.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">Requisitos previos para XCP</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">Antes de implementar NetApp XCP, deberá cumplir los siguientes requisitos previos:</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">Compruebe los puertos NFS que utiliza el servidor NFS ejecutando el siguiente comando:</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">Para acceder a la ubicación en la que ejecuta las operaciones XCP, como instancias locales o de cloud (por ejemplo, instancias de Azure, AWS o de máquina virtual Google [VM]), abra los puertos del firewall de los puertos NFS.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">Compruebe que se puede acceder al puerto NFS desde el servidor XCP mediante el comando telnet<block ref="450e3ef5096f09acecd7b33e07b6e190" prefix=" " category="inline-code"></block>. El puerto predeterminado es 2049. Si su entorno tiene un puerto diferente, use esa IP.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">Para NFS, compruebe que se puede acceder a los recursos compartidos desde el servidor XCP mediante el<block ref="3c4a3208b8bf46e9aa41c950ec1a73ba" prefix=" " category="inline-code"></block> comando.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">Aumente el número de inodos en el volumen de destino a más del número de archivos (número de archivos) en los archivos de origen.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">Portal de licencia NetApp XCP</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">Descargue la licencia XCP de<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">Debe tener una cuenta de NetApp en mysupport.netapp.com o registrarse de forma gratuita.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">Descargue la licencia y tenga preparada.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Cree un recurso compartido de NFS en las instalaciones para cada volumen de Azure NetApp o para Cloud Volume Service (nivel de servicio premium) en el cloud para el catálogo XCP.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">Cree un volumen NAS y configure el recurso compartido para el destino de datos.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">Para varias instancias de XCP, debe tener uno o más servidores o instancias de nube para transferir los datos de varias carpetas o archivos de origen al destino.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">El tamaño máximo (el valor predeterminado es 308 MB) define el número máximo de archivos (aproximadamente un millón) en una única carpeta. Aumente el valor maxdir size para aumentar el número de archivos. El aumento del valor tiene efecto en ciclos de CPU adicionales.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">En el cloud, NetApp recomienda que tenga ExpressRoute (Azure), Direct Connect (AWS) o Cloud Interconnect (GCP) entre sus instalaciones y el cloud.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">Siguiente: Flujo de trabajo de migración.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">En esta sección se tratan los pasos de implementación para XCP de NetApp para la transferencia de datos.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">Pasos de la implementación</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">Anterior: Análisis de archivos.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">Detalles de la cama de prueba</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">La siguiente tabla muestra los detalles del banco de pruebas utilizado para esta puesta en marcha y validación del rendimiento.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Componentes de la solución</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Detalles</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP versión 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Un servidor Linux: Linux (RHEL 7.9 o RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Un servidor Windows: Estándar Windows Server 2019</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">Par de alta disponibilidad de la cabina de almacenamiento AFF de NetApp para el volumen de origen</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="list-text">ONTAP 9 de NetApp</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocolo NFS</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">Par de alta disponibilidad de la cabina de almacenamiento AFF de NetApp para el volumen de destino</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="list-text">A800 de AFF</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Servidor PRIMERGY RX2540 de Fujitsu</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">Cada una equipada con: * 48 CPU * Intel Xeon * 256 GB de memoria física * 10 GbE de doble puerto</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Redes</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10 GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">Pasos de puesta en marcha: NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">Guía del usuario de NetApp XCP</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">Para implementar NetApp XCP para la transferencia de datos, primero instale y active el software XCP en la ubicación de destino. Puede revisar los detalles en la<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. Para ello, lleve a cabo los siguientes pasos:</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">“Requisitos previos para XCP”.</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">Cumpla los requisitos previos tal y como se detalla en la sección <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">Página NetApp XCP (descargas)</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">Descargue el software XCP de<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">Copie los archivos tar XCP descargados en el servidor XCP.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">Destar el archivo tarfile.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">Descargue la licencia de<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> Y copie en el servidor XCP.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">Active la licencia.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">Busque el puerto NFS de origen y el servidor NFS de destino. El puerto predeterminado es 2049.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">Compruebe la conexión NFS. Compruebe el servidor NFS (tanto para el origen como para el destino) mediante telnet al puerto del servidor NFS.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">Configure el catálogo.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">Cree un volumen NFS y exporte NFS para el catálogo XCP. También puede aprovechar la exportación NFS del sistema operativo para el catálogo XCP.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">Compruebe la exportación NFS.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">Actualizar<block ref="d509f49d5d9a07934f91eefcf45a7334" prefix=" " category="inline-code"></block>.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">Busque las exportaciones NAS de origen mediante<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block>. Busque:</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(Opcional) analice los datos NAS de origen.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">El análisis de los datos NAS de origen le ayuda a comprender la distribución de los datos y a encontrar posibles problemas relacionados con la migración. El tiempo de operación de exploración XCP es proporcional al número de archivos y a la profundidad del directorio. Puede omitir este paso si está familiarizado con los datos de NAS.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">Compruebe el informe creado por<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>. Busque principalmente carpetas ilegibles y archivos ilegibles.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(Opcional) cambie el inodo. Vea el número de inodos y modifique el número en función del número de archivos que se van a migrar o copiar tanto para los volúmenes de catálogo como de destino (si es necesario).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">Analice el volumen de destino.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">Compruebe el espacio en el volumen de origen y el de destino.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">Copie los datos del origen en el destino mediante<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> y compruebe el resumen.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">De forma predeterminada, XCP crea siete procesos paralelos para copiar los datos. Esto se puede ajustar.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">NetApp recomienda que el volumen de origen sea de solo lectura. En tiempo real, el volumen de origen es un sistema de archivos activo y activo. La<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> La operación puede fallar porque NetApp XCP no admite un origen en directo que cambia continuamente una aplicación.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Para Linux, XCP requiere un ID de índice porque XCP Linux realiza la catalogación.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(Opcional) Compruebe la información de los inodos en el volumen de NetApp de destino.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">Realice la actualización incremental mediante<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">Para este documento, para simular en tiempo real, se cambió el nombre del millón de archivos de los datos de origen y, a continuación, se copiaron los archivos actualizados al destino mediante el uso<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>. Para Windows, XCP necesita tanto rutas de origen como de destino.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">Validar la transferencia de datos. Puede validar que el origen y el destino tienen los mismos datos con<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block>.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">La documentación de XCP proporciona varias opciones (con ejemplos) para<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>,<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block>, y.<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> operaciones. Para obtener más información, consulte<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Los clientes de Windows deben copiar los datos mediante listas de control de acceso (ACL). NetApp recomienda utilizar el comando<block ref="1b5d03dc1e4b5c3623897fd210394888" prefix=" " category="inline-code"></block>. Para obtener el máximo rendimiento, teniendo en cuenta el volumen de origen que tiene datos SMB con ACL y los datos a los que pueden acceder NFS y SMB, el destino debe ser un volumen NTFS. Con XCP (versión NFS), copie los datos del servidor Linux y ejecute la sincronización XCP (versión SMB) con el<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> y..<block ref="0e638f18c7569b1e062f20f430b0a5fc" prefix=" " category="inline-code"></block> Opciones del servidor de Windows para copiar las ACL de los datos de origen en los datos de SMB de destino.</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">Configuración de la directiva "gestionar auditoría y registro de seguridad"</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">Para conocer los pasos detallados, consulte<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">Pasos de implementación: Migración de datos HDFS/MapRFS</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">En esta sección, se trata sobre la nueva función XCP llamada Hadoop Filesystem Data Transfer to NAS, que migra datos de HDFS/MapRFS a NFS y viceversa.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Requisitos previos</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">Para la función MapRFS/HDFS, debe realizar el siguiente procedimiento en un entorno de usuario que no sea raíz. Normalmente, el usuario no raíz es hdfs, mapr o un usuario que tiene permiso para realizar cambios en el sistema de archivos HDFS y MapRFS.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">Establezca las variables CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH y NHDFS_LIBHDFS_PATH en la CLI o en el archivo .bashrc del usuario junto con el<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_PATH apunta al archivo libhdfs.so. Este archivo proporciona las API de HDFS para interactuar y manipular los archivos y sistemas de archivos HDFS/MapRFS como parte de la distribución de Hadoop.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH apunta al archivo libjvm.so. Se trata de una biblioteca DE máquinas virtuales JAVA compartida en la ubicación jre.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH apunta a todos los archivos JAR utilizando los valores (CLasspath –glob) de Hadoop.</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_LIBRARY_PATH apunta a la ubicación de la carpeta de biblioteca nativa de Hadoop.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Consulte el siguiente ejemplo basado en un clúster de Cloudera.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">En esta versión, admitimos el análisis, la copia y la verificación de operaciones y la migración de datos de XCP desde HDFS a NFS. Puede transferir datos desde un solo nodo de trabajo de un clúster de lagos de datos y de varios nodos de trabajo. Con la versión 1.8, los usuarios raíz y no raíz pueden realizar la migración de datos.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">Pasos de implementación: Un usuario que no sea raíz migra los datos de HDFS/MaprFS a NFS de NetApp</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">Siga los mismos pasos que se mencionan en la sección pasos para la implementación en 1-9.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">En el ejemplo siguiente, el usuario migra datos de HDFS a NFS.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">Cree una carpeta y archivos (mediante<block ref="f45bd8fcd9fdd879ec3b59c5cb0cf396" prefix=" " category="inline-code"></block>) En HDFS.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">Compruebe los permisos en la carpeta HDFS.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">Cree una carpeta en NFS y compruebe los permisos.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">Copie los archivos de HDFS a NFS mediante XCP y compruebe los permisos.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">Siguiente: Directrices de configuración.</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">Descripción general</block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Anterior: Ajuste del rendimiento.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">En esta sección se describen los escenarios de clientes y sus arquitecturas.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">Siguiente: Lago de datos para NFS de ONTAP.</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">Este documento proporciona directrices de prácticas recomendadas para NetApp XCP y una solución basada en escenarios de pruebas. Estas mejores prácticas abarcan el flujo de trabajo de migración tanto para las instalaciones como para el cloud, análisis del sistema de archivos, la solución de problemas y el ajuste del rendimiento del XCP.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863: Directrices de mejores prácticas para NetApp XCP: Movimiento de datos, migración de archivos y análisis</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">Este documento proporciona directrices de prácticas recomendadas para NetApp XCP y una solución basada en escenarios de pruebas. Estas mejores prácticas abarcan el flujo de trabajo de migración tanto para las instalaciones como para el cloud, análisis del sistema de archivos, la solución de problemas y el ajuste del rendimiento de XCP. En la sección de escenarios de prueba se tratan los casos de uso de clientes y sus requisitos, la solución de NetApp que usa XCP y las ventajas para el cliente.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">Siguiente: NetApp XCP.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">La GUI de análisis de archivos XCP de NetApp ayuda a ejecutar los análisis del sistema de archivos mediante XCP en el back-end y a visualizar estadísticas como gráficos y vistas de cualquier sistema de archivos NAS (NFS, SMB).</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">Análisis de archivos</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">Anterior: Flujo de trabajo de migración.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">La GUI de análisis de archivos XCP de NetApp ayuda a ejecutar los análisis del sistema de archivos mediante XCP en el back-end y a visualizar estadísticas como gráficos y vistas de cualquier sistema de archivos NAS (NFS, SMB). A partir de 1.6, XCP se puede ejecutar como servicio con la ayuda de sencillos pasos de implementación mediante las opciones Configure y systemctl. La opción Configurar XCP le guía para instalar y configurar Postgres y un servidor web, así como para recopilar credenciales. La opción systemctl ejecuta XCP como servicio para las comunicaciones de API DE REST desde la GUI.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">La siguiente figura ilustra el flujo de análisis de archivos XCP.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 ofrece análisis de archivos abiertos y mejoras en la infraestructura</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">Para obtener más información acerca de la arquitectura de alto nivel del análisis de archivos XCP, las vistas de panel basadas en GUI, como la vista de estadísticas y los detalles de la vista de distribución de archivos, consulte la publicación del blog<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">Hay una interfaz gráfica de usuario limitada en XCP 1.6 para gráficos personalizados. Para crear los gráficos necesarios, puede usar la CLI para ejecutar el<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> comando scan con filtros coincidentes. Consulte los ejemplos siguientes.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">Genere una lista de archivos modificados más allá de un año mediante<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block> y la<block ref="af7e4e4bdf56fd6022afd2b0cf443794" prefix=" " category="inline-code"></block> filtre con el espacio consumido.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">Busque el espacio utilizado por los archivos de más de un año de antigüedad.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">Busque el tamaño total y la vista gráfica de los datos modificados hace más de un año.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">El siguiente informe es un análisis de ejemplo personalizado de archivos modificados hace más de un año.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">Siguiente: Pasos de la implementación.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">En esta sección se ofrece orientación sobre la solución de problemas para la migración de datos mediante NetApp XCP.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Resolución de problemas</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Anterior: Recomendaciones y directrices de mejores prácticas.</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">Error 1: Error XCP con nfs3 error 70: Error de controlador de archivo obsoleto en xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">*Razón y guía.*</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">Monte la carpeta de origen y compruebe que la carpeta existe. Si no existe o si se ha eliminado, recibirá un<block ref="00b68e4b07be7b89e91e391a70e312d1" prefix=" " category="inline-code"></block> error, en cuyo caso, puede ignorar el error.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">Error 2: El volumen de destino NFS de NetApp tiene espacio, pero XCP falló con el error nfs3 28: No queda espacio en el dispositivo</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">Compruebe el espacio del volumen de destino de NFS ejecutando el<block ref="eff7d5dba32b4da32d9a67a519434d3f" prefix=" " category="inline-code"></block> o compruebe el almacenamiento.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">Compruebe los inodos en la controladora de almacenamiento.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">Si se utiliza inodo, aumente el número de inodos ejecutando el siguiente comando:</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">Siguiente: Dónde encontrar información adicional.</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">En esta sección se describe el procedimiento paso a paso para migrar datos CIFS con información de seguridad de un origen a un sistema ONTAP de destino.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">Migración de datos CIFS con ACL de un equipo de almacenamiento de origen a ONTAP</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Anterior: Migración de datos de 7-Mode a ONTAP.</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">Compruebe que el estado del sistema ONTAP de destino es bueno.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">Compruebe que existe al menos un agregado no raíz en el sistema de destino. El agregado es normal.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="admonition">Si no hay ningún agregado de datos, cree uno nuevo mediante el<block ref="b83f9c30c432b834d5aa4c7b46881164" prefix=" " category="inline-code"></block> comando.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">Cree una SVM en el sistema de clúster de destino.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">Cree un nuevo volumen de datos de lectura y escritura en la SVM de destino. Verifique que el estilo de seguridad, la configuración de idioma y los requisitos de capacidad coincidan con el volumen de origen.</block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">Cree una LIF de datos para atender las solicitudes de clientes SMB.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">Compruebe que la LIF se ha creado correctamente.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">Si es necesario, cree una ruta estática con la SVM.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">Compruebe que la ruta se ha creado correctamente.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">Montar el volumen de datos objetivo en el espacio de nombres de la SVM.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">Compruebe que el volumen se haya montado correctamente.</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">Inicie el servicio CIFS en la SVM de destino.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">Compruebe que el servicio se ha iniciado y en ejecución.</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">Compruebe que la política de exportación predeterminada se aplica a la SVM de destino.</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="paragraph">Si es necesario, cree una nueva política de exportación personalizada para la SVM de destino.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">Modifique las reglas de política de exportación para permitir el acceso a los clientes CIFS.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">Compruebe que se han modificado las reglas de la política.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">Compruebe que el cliente tiene acceso al volumen.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">Conéctese al sistema cliente Windows donde está instalado XCP. Vaya a la ruta de instalación de XCP.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">Consulte el nodo de origen exportaciones de SMB ejecutando el<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Comando en el sistema host del cliente Windows XCP.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">Ejecute el<block ref="657f8b8da628ef83cf69101b6817150a" prefix=" " category="inline-code"></block> comando para copia.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">En el sistema ONTAP de destino, obtenga la lista de nombres de usuarios locales y grupos locales que debe proporcionar como valores para el<block ref="7a80adbcbc4a0b2e96e8eb2710f30c85" prefix=" " category="inline-code"></block> y..<block ref="8d03d04d9c44ec2988a893826753f985" prefix=" " category="inline-code"></block> ruta de los argumentos.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">Para migrar los datos CIFS con ACL del origen al destino, ejecute el<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> con el<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> y..<block ref="a72a6079b50973fd59860e6635a4ea62" prefix=" " category="inline-code"></block> opciones.</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">Para la<block ref="a3fe89370a4bb214c60bfe40074b2c43" prefix=" " category="inline-code"></block> Opciones, especifique cualquier usuario o grupo que se encuentre en Active Directory o usuario/grupo local para el sistema de destino.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">Si<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> aparece el mensaje de error<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block>, agregue el cuadro de destino en el archivo hosts <block ref="803976de87f6862821bd3c4d94e0ff2b" prefix="(" category="inline-code"></block>).</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">Use el siguiente formato para la entrada del cuadro de destino del almacenamiento de NetApp.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">Si aún recibe el mensaje de error<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block> después de agregar la entrada del cuadro de destino en los archivos hosts, el usuario/grupo no existe en el sistema de destino.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">Uso<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Para migrar datos CIFS con ACL (con o sin la carpeta raíz).</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">Sin la carpeta raíz, ejecute los siguientes comandos:</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">Con la carpeta raíz, ejecute los siguientes comandos:</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">Siguiente: Directrices y recomendaciones sobre prácticas recomendadas.</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">Este caso de uso se basa en el cliente más grande del sector turístico de NetApp para migrar a cloud millones de pequeños archivos originales.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">Uso de XCP Data mover para migrar millones de archivos pequeños a un almacenamiento flexible</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">Anterior: Informática de alto rendimiento para NFS de ONTAP.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">Este caso de uso se basa en el mayor cliente del sector turístico de NetApp para la migración de datos de las instalaciones al cloud. Como el COVID-19 ha reducido la demanda en el sector de los viajes, los clientes desean ahorrar gastos de capital en almacenamiento de gama alta en su entorno local para la aplicación de precios según demanda. Este cliente tiene un acuerdo de nivel de servicio limitado para migrar millones de archivos pequeños al cloud.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">En la siguiente figura se muestra la migración de datos de las instalaciones a Azure NetApp Files para ficheros pequeños.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">Solución NetApp XCP Data mover: De las instalaciones al cloud</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">Para obtener más información, consulte<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> blog.</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">Siguiente: Uso de XCP Data mover para migrar archivos grandes.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">Este caso de uso se basa en un cliente de la red de televisión. El cliente quería migrar los archivos de backup de Oracle Recovery Manager (RMAN) al cloud y ejecutar la aplicación Oracle E-Business Suite (EBS) usando Azure NetApp Files con el software Pacemaker. El cliente también quería migrar sus archivos de backup de base de datos a un almacenamiento en cloud bajo demanda y transferir archivos de gran tamaño (de 25 GB a 50 GB cada uno) a Azure.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">Uso del transmisor de datos XCP para migrar archivos grandes</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">Anterior: Uso de XCP Data mover para migrar millones de archivos pequeños a almacenamiento flexible.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">La siguiente figura muestra la migración de datos de las instalaciones a Azure NetApp Files para archivos de gran tamaño.</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">Siguiente: Archivos duplicados.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">En esta sección se proporcionan algunos de los parámetros de ajuste que ayudan a mejorar el rendimiento de las operaciones XCP.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">Ajuste del rendimiento</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">Anterior: Directrices de tamaño.</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">En esta sección se proporcionan algunos de los parámetros de ajuste que ayudan a mejorar el rendimiento de las operaciones XCP:</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">Para escalar mejor y distribuir la carga de trabajo a través de varias instancias XCP, divida las subcarpetas para cada instancia de XCP para la migración y transferencia de datos.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP puede utilizar el máximo de recursos de CPU; cuanto más núcleos de CPU, mejor será el rendimiento. Por lo tanto, debería tener más CPU en el servidor XCP. Probamos 128 GB de RAM y 48 CPU de núcleo, lo que proporcionó un mejor rendimiento que 8 veces más CPU y 8 GB de RAM.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">Copia XCP con<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> La opción se basa en el número de CPU. El número predeterminado de subprocesos paralelos (siete) es a veces suficiente para la mayoría de las operaciones de transferencia y migración de datos XCP. Para Windows XCP de forma predeterminada, el número de procesos paralelos es igual al número de CPU. El número máximo para<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> la opción debe ser menor o igual al número de núcleos.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10 GbE es un buen comienzo para la transferencia de datos. Sin embargo, hemos probado con 25 GbE y 100 GbE, que proporcionan una mejor transferencia de datos y están recomendados para transferencias de datos de tamaño de archivo grande.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Para Azure NetApp Files, el rendimiento varía según el nivel de servicio. Para obtener más información, consulte la siguiente tabla, donde se muestran los niveles de servicio y los detalles de rendimiento de Azure NetApp Files.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">Nivel de servicio</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Estándar</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">Ultra</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">Rendimiento</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16 Mbps/terabytes (TB)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64 Mbps/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128 MBps/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">Tipos de carga de trabajo</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">Archivos compartidos, correo electrónico y web de uso general</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS, bases de datos y aplicaciones</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">Aplicaciones sensibles a la latencia</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">Explicación del rendimiento</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">Rendimiento estándar: 1,000 000 IOPS por TB (16K I/o) y 16 Mbps/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">Rendimiento excepcional: 4,000 000 IOPS por TB (16.000 I/o) y 64 Mb/TB</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">Rendimiento extremo: 8,000 000 IOPS por TB (16.000 I/o) y 128 MB/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">Debe elegir el nivel de servicio adecuado según el rendimiento y los tipos de carga de trabajo. La mayoría de los clientes empiezan por el nivel Premium y cambian el nivel de servicio en función de la carga de trabajo.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">Siguiente: Situaciones de clientes.</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dónde encontrar información adicional</block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">Anterior: Resolución de problemas.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y/o sitios web:</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">Blogs XCP de NetApp<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">Guía del usuario de NetApp XCP<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">BigData Analytics data to Artificial Intelligence: Solución de movimiento de datos para IA<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">Siguiente: Historial de versiones.</block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">Este caso de uso se basa en la mayor prueba de concepto financiera de cliente (CPOC, por sus siglas en inglés) que hemos realizado. Históricamente, hemos utilizado EL módulo de análisis in situ de NetApp (NIPAM, "In-Place Analytics Module") para mover datos de análisis a ONTAP AI de NetApp. No obstante, gracias a las recientes mejoras y al mejor rendimiento de XCP de NetApp, así como al enfoque exclusivo de la solución de movimiento de datos de NetApp, hemos publicado de nuevo la migración de datos mediante XCP de NetApp.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">Lago de datos a NFS de ONTAP</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Anterior: Casos de clientes.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">Retos y requisitos del cliente</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">Entre los retos y requisitos del cliente que deben mencionarse se incluyen los siguientes:</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">Los clientes tienen diferentes tipos de datos, como datos estructurados, no estructurados y semiestructurados, registros y datos entre equipos en lagos de datos. Los sistemas de IA requieren que se procesen todos estos tipos de datos para operaciones de predicción. Cuando los datos se encuentran en un sistema de archivos nativo del lago de datos, resulta difícil procesarlos.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">La arquitectura de IA del cliente no puede acceder a los datos desde el sistema de archivos distribuidos de Hadoop (HDFS) y el sistema de archivos compatible con Hadoop (HCFS), de modo que los datos no estén disponibles para las operaciones de IA. La IA requiere los datos en un formato de sistema de archivos comprensible como NFS.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">Son necesarios algunos procesos especiales para mover datos desde el lago de datos debido a la gran cantidad de datos y alto rendimiento; se requiere un método rentable para mover los datos al sistema de IA.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Solución de movimiento de datos</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">En esta solución, MapR (MapR-FS) se crea a partir de discos locales en el clúster de MapR. La puerta de enlace NFS de MapR está configurada en cada nodo de datos con IP virtuales. El servicio de servidor de archivos almacena y gestiona los datos de MapR-FS. La puerta de enlace NFS hace que los datos de Map-FS sean accesibles desde el cliente NFS a través de la IP virtual. Se ejecuta una instancia de XCP en cada nodo de datos de MapR para transferir los datos de la puerta de enlace Map NFS a NFS de ONTAP de NetApp. Cada instancia de XCP transfiere un conjunto específico de carpetas de origen a la ubicación de destino.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">La siguiente figura ilustra la solución de movimiento de datos de NetApp para el clúster de MapR con XCP.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">Uso de XCP para mover datos desde un lago de datos y la informática de alto rendimiento a NFS de ONTAP</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">Para ver más casos de uso de clientes, demostraciones grabadas y resultados de pruebas, consulte<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732: Análisis de Big Data en la inteligencia artificial</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">Si quiere ver pasos detallados sobre el movimiento de datos de MapR-FS a NFS de ONTAP con NetApp XCP, consulte el apéndice B de<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">Siguiente: Informática de alto rendimiento para NFS de ONTAP.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">Esta sección contiene las prácticas recomendadas, directrices y recomendaciones para la migración de datos mediante NetApp XCP.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">Recomendaciones y directrices sobre prácticas recomendadas</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">Anterior: Migración de datos CIFS con ACL de un equipo de almacenamiento de origen a ONTAP.</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">Utilice el sistema operativo cliente XCP, que es compatible con IMT. El cliente compatible con IMT ha sido aprobado por NetApp.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Ejecute XCP como usuario root en el sistema operativo Linux para realizar la migración. Puede ejecutar el comando xcp como usuario sudo, pero no es compatible con XCP.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">Ejecute sólo una instancia de XCP por cliente. Técnicamente, puede ejecutar varias instrucciones de XCP en el mismo host desde una ubicación diferente; sin embargo, no es una práctica compatible. De hecho, ejecutar muchas instancias puede dar como resultado un fallo.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">En la versión XCP actual, Live Source no es compatible. Si el volumen de origen de NetApp está activo y los usuarios lo cambian continuamente, debe realizar una copia Snapshot del volumen de origen para realizar una migración.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">Se recomienda crear una nueva snapshot con un nombre distinto para cada sincronización incremental, de modo que resulta fácil crear una ruta de migración incremental según el nombre de la snapshot en caso de que se produzca un fallo.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Si está realizando una migración basada en Snapshot, se recomienda continuar con la migración basada en Snapshot hasta la transición.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">Si tiene más de 10 millones de archivos y tiene un cambio de datos incremental de más del 50%, se recomienda usar un recuento de núcleos más alto y más memoria que la recomendación mínima de la guía de instalación y administración.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">Siguiente: Resolución de problemas.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">El comando de esta sección vuelca los datos en formato CSV. Puede sumar la columna size para obtener el tamaño total de los datos.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">Creación de un archivo CSV desde un recurso compartido de SMB/CIFS</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Anterior: Exploración específica basada en fecha y copia de datos.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">El siguiente comando vuelca los datos en formato CSV. Puede sumar la columna size para obtener el tamaño total de los datos.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">El resultado debería ser similar a este ejemplo:</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">Para escanear hasta la profundidad de tres subdirectorios y proporcionar el resultado en orden de clasificación, ejecute el<block ref="cadccce7ea0e7fd5923a57bff135b0f1" prefix=" " category="inline-code"></block> comando y volcar el tamaño en cada nivel de directorio hasta la profundidad de tres subdirectorios.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">Para ordenar la información, vuelque la información en un archivo CSV y ordene la información.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">Se trata de un informe personalizado que utiliza<block ref="3c8468c40f21d7ea04242771207b5d3e" prefix=" " category="inline-code"></block> comando. Escanea todos los directorios y vuelca el nombre del directorio, la ruta y el tamaño del directorio en un archivo CSV. Puede ordenar la columna de tamaño de la aplicación de hoja de cálculo.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">Siguiente: Migración de datos de 7-Mode a ONTAP.</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">Esta solución se basa en un cliente que necesita copiar datos basándose en una fecha específica.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">Análisis específico basado en fecha y copia de datos</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">Anterior: Archivos duplicados.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">Esta solución se basa en un cliente que necesita copiar datos basándose en una fecha específica. Compruebe los siguientes detalles:</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">Siguiente: Creación de un archivo CSV desde recursos compartidos de SMB/CIFS.</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">Utilizamos XCP de NetApp para migrar los datos de GPFS a NFS, de modo que las GPU puedan procesar los datos. Por lo general, la IA procesa datos desde un sistema de archivos de red.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">Informática de alto rendimiento para NFS de ONTAP</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">Anterior: Lago de datos para NFS de ONTAP.</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">Este caso de uso se basa en solicitudes de organizaciones de campo. Algunos clientes de NetApp tienen sus datos en un entorno de computación de alto rendimiento que ofrece análisis de datos para modelos de formación y permite que las organizaciones de investigación obtengan información y comprendan una gran cantidad de datos digitales. Los ingenieros de campo de NetApp necesitan un procedimiento detallado para extraer los datos de GPFS de IBM a NFS. Utilizamos XCP de NetApp para migrar los datos de GPFS a NFS, de modo que las GPU puedan procesar los datos. Por lo general, la IA procesa datos desde un sistema de archivos de red.</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">Si quiere más información sobre la informática de alto rendimiento para el caso de uso de NFS de ONTAP, una demostración registrada y los resultados de pruebas, consulte<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">Si quiere ver pasos detallados sobre el movimiento de datos de MapR-FS a NFS de ONTAP mediante XCP de NetApp, consulte el apéndice A: GPFS a NFS―pasos detallados en<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">Siguiente: Uso de XCP Data mover para migrar millones de archivos pequeños a almacenamiento flexible.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">En esta sección se proporcionan los pasos detallados para la migración de datos de Data ONTAP 7-Mode de NetApp a ONTAP.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">Migración de datos de 7-Mode a ONTAP</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">Anterior: Creación de un archivo CSV desde recursos compartidos de SMB/CIFS.</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">Transición del almacenamiento NFSv3 de 7-Mode a ONTAP para datos NFS</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">Esta sección proporciona el procedimiento detallado de la siguiente tabla para realizar la transición de una exportación NFSv3 de 7-Mode de origen a un sistema ONTAP.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp asume que el volumen NFSv3 de 7-Mode de origen se exporta y se monta en el sistema cliente, y que XCP ya está instalado en un sistema Linux.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">Cree una máquina virtual de almacenamiento (SVM) en el sistema de clústeres de destino.</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">Quite los protocolos FCP, iSCSI, NDMP y CIDS de la SVM de destino.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">Compruebe que NFS es el protocolo permitido para esta SVM.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">Cree una LIF de datos para atender las solicitudes de clientes NFS.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">Cree una ruta estática con la SVM, si es necesario.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">Montar el volumen de datos NFS objetivo en el espacio de nombres de la SVM.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">También puede especificar opciones de montaje de volúmenes (ruta de unión) con el<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> comando.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">Inicie el servicio NFS en la SVM de destino.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">Compruebe que la política de exportación NFS predeterminada se haya aplicado a la SVM de destino.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">Compruebe que la nueva política de exportación personalizada se ha creado correctamente.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">Modifique las reglas de la política de exportación para permitir el acceso a los clientes NFS.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Conéctese al servidor NFS de Linux. Cree un punto de montaje para el volumen exportado de NFS.</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">Monte el volumen objetivo exportado de NFSv3 en este punto de montaje.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">Los volúmenes NFSv3 deben exportarse pero no necesariamente montarse por el servidor NFS. Si se pueden montar, el cliente host XCP Linux monta estos volúmenes.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">Compruebe que el punto de montaje se ha creado correctamente.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">Cree un archivo de prueba en el punto de montaje exportado NFS para permitir el acceso de lectura y escritura.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">Una vez finalizada la prueba de lectura y escritura, elimine el archivo del punto de montaje NFS objetivo.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">Conéctese al sistema cliente Linux en el que está instalado XCP. Vaya a la ruta de instalación de XCP.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">Consulte las exportaciones NFSv3 de 7-Mode de origen ejecutando el<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> En el sistema host del cliente Linux XCP.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">Analice las rutas exportadas de NFSv3 de origen e imprima las estadísticas de su estructura de archivos.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">NetApp recomienda poner las exportaciones NFSv3 de origen en modo de solo lectura durante xcp<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, y.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operaciones.</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">Copie las exportaciones NFSv3 de 7-Mode origen a exportaciones NFSv3 en el sistema ONTAP objetivo.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">Una vez finalizada la copia, compruebe que las exportaciones NFSv3 de origen y de destino tienen los mismos datos. Ejecute el<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">Si<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> busca las diferencias entre los datos de origen y destino y, a continuación, el error<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> se notifica en el resumen. Para solucionar este problema, ejecute el<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> comando para copiar los cambios de origen en el destino.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">Antes y durante la transposición, ejecute<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> de nuevo. Si el origen tiene datos nuevos o actualizados, realice actualizaciones incrementales. Ejecute el<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> comando.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">Para reanudar una operación de copia interrumpida previamente, ejecute el<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">Después<block ref="69f2afc2390cec954f7c208b07212d39" prefix=" " category="inline-code"></block> termina de copiar archivos, ejecutar<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> de nuevo, para que el almacenamiento de origen y destino tengan datos idénticos.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">El host del cliente NFSv3 debe desmontar las exportaciones NFSv3 de origen aprovisionadas desde el almacenamiento de 7-Mode y monta las exportaciones NFSv3 de destino desde ONTAP. La transición requiere una interrupción del servicio.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">Transición de copias Snapshot de volumen de 7-Mode a ONTAP</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">En esta sección se describe el procedimiento para realizar la transición de una copia Snapshot de NetApp con volúmenes 7-Mode de origen a ONTAP.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp asume que el volumen 7-Mode de origen se exporta y se monta en el sistema cliente, además de que XCP ya está instalado en un sistema Linux. Una copia Snapshot es una imagen puntual de un volumen que registra los cambios incrementales desde la última copia Snapshot. Utilice la<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Opción con un sistema 7-Mode como origen.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">*Advertencia:* mantenga la copia snapshot básica. No elimine la copia Snapshot básica una vez que se completa la copia base. Se requiere la copia snapshot básica para otras operaciones de sincronización.</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">Quite los protocolos FCP, iSCSI, NDMP y CIFS de la SVM de destino.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">Compruebe que el volumen se haya montado correctamente.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">También puede especificar las opciones de montaje del volumen (ruta de unión) en el<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> comando.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">Compruebe que la política de exportación de NFS predeterminada se aplica a la SVM de destino.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">Modifique las reglas de política de exportación para permitir el acceso a los clientes NFS en el sistema de destino.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">Compruebe que el cliente tiene acceso al volumen de destino.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">NetApp recomienda poner las exportaciones NFSv3 de origen en modo de solo lectura durante<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, y.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operaciones. Pulg<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> en la operación, debe pasar el<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> opción con un valor correspondiente.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">Copie la snapshot NFSv3 de 7-Mode (base) de origen a las exportaciones NFSv3 en el sistema ONTAP de destino.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">Conserve esta snapshot de base para realizar más operaciones de sincronización.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">Una vez finalizada la copia, compruebe que las exportaciones NFSv3 de origen y de destino tienen los mismos datos. Ejecute el<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">Si<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> busca las diferencias entre los datos de origen y destino y, a continuación, el error<block ref="dc84cf44b83b105281c2d7846f1ed44f" prefix=" " category="inline-code"></block> comando para copiar los cambios de origen en el destino.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">Antes y durante la transposición, ejecute<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> de nuevo. Si el origen tiene datos nuevos o actualizados, realice actualizaciones incrementales. Si hay cambios incrementales, cree una nueva copia Snapshot para estos cambios y pase esa ruta de Snapshot con el<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> opción para operaciones de sincronización.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">Ejecute el<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> con el<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> opción y ruta snapshot.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">Para esta operación, se requiere la snapshot base.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">El host del cliente NFSv3 debe desmontar las exportaciones NFSv3 de origen aprovisionadas desde el almacenamiento de 7-Mode y montar las exportaciones NFSv3 de destino desde ONTAP. Esta transición requiere una interrupción del servicio.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">Migración de ACLv4 de NetApp 7-Mode a un sistema de almacenamiento de NetApp</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">En esta sección se describe el procedimiento paso a paso para realizar la transición de una exportación NFSv4 de origen a un sistema ONTAP.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp asume que el volumen NFSv4 de origen se exporta y monta en el sistema cliente y que XCP ya está instalado en un sistema Linux. El origen debe ser un sistema 7-Mode de NetApp compatible con ACL. La migración de ACL es compatible únicamente de NetApp a NetApp. Para copiar archivos con un carácter especial en el nombre, asegúrese de que el origen y el destino admiten el idioma codificado UTF-8.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">Requisitos previos para migrar una exportación de NFSv4 de origen a ONTAP</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">Antes de migrar una exportación NFSv4 de origen a ONTAP, se deben cumplir los siguientes requisitos previos:</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">El sistema de destino debe tener NFSv4 configurado.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">El origen y el destino de NFSv4 se deben montar en el host XCP. Seleccione NFS v4.0 para cumplir el almacenamiento de origen y de destino, y compruebe que las ACL estén habilitadas en el sistema de origen y de destino.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP requiere que la ruta de origen/destino se monte en el host XCP para el procesamiento de ACL.en el siguiente ejemplo,<block ref="d07c77c05891b869ab2111118b006bed" prefix=" " category="inline-code"></block> está montado en el<block ref="dfecb62ab540058a212419f33235e6da" prefix=" " category="inline-code"></block> ruta:</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">Opciones de subdirectorios</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">Las dos opciones para trabajar con subdirectorios son las siguientes:</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">Para que XCP trabaje en un subdirectorio<block ref="9ce87e1289284ccca8cf788db9dd7804" prefix=" " category="inline-code"></block>), monte la ruta completa <block ref="58753164ce38e8977360bb376dda6e76" prefix="(" category="inline-code"></block>) En el host XCP.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">Si la ruta completa no está montada, XCP informa del siguiente error:</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">Utilice la sintaxis del subdirectorio <block ref="ca6c8952cf206b58c7fc63aa1552d665" prefix="(" category="inline-code"></block>), como se muestra en el siguiente ejemplo:</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">Complete los siguientes pasos para migrar ACLv4 de NetApp 7-Mode a un sistema de almacenamiento de NetApp.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">Compruebe que la SVM se ha creado correctamente.</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">Compruebe que la política de exportación NFS predeterminada se aplique a la SVM de destino.</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">Compruebe que las reglas de política se han modificado.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">Monte el volumen de destino exportado de NFSv4 en este punto de montaje.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">Los volúmenes NFSv4 deben exportarse pero no necesariamente montarse por el servidor NFS. Si se pueden montar, el cliente host XCP Linux monta estos volúmenes.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">Compruebe que se ha creado el archivo.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">Consulte las exportaciones de NFSv4 de origen ejecutando la<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> En el sistema host del cliente Linux XCP.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">Analice las rutas exportadas de NFSv4 de origen e imprima las estadísticas de su estructura de archivos.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">NetApp recomienda poner las exportaciones NFSv4 de origen en modo de solo lectura durante<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, y.<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> operaciones.</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">Copie las exportaciones NFSv4 de origen a exportaciones NFSv4 en el sistema ONTAP de destino.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">Después<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Si completa, compruebe que las exportaciones de NFSv4 de origen y destino tienen los mismos datos. Ejecute el<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> comando.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">Si<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> busca las diferencias entre los datos de origen y destino y, a continuación, el error<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> se notifica en el resumen. Para solucionar este problema, ejecute el<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> comando para copiar los cambios de origen en el destino.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">Para esta operación, se requiere el nombre o número de índice de copia anterior.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">Para reanudar una interrumpida anteriormente<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> ejecute la<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">Transición del almacenamiento SMB de 7-Mode a ONTAP para datos CIFS</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">En esta sección se describe el procedimiento paso a paso para realizar la transición de una unidad compartida de SMB de origen 7-Mode a un sistema ONTAP.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp asume que los sistemas 7-Mode y ONTAP tienen licencia para SMB. Se crea la SVM de destino, se exportan los recursos compartidos SMB de origen y de destino y se instala XCP y tiene licencia.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">Analice los recursos compartidos de SMB en busca de archivos y directorios.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">Copie los archivos (con o sin ACL) del origen al recurso compartido SMB de destino. En el ejemplo siguiente se muestra una copia con ACL.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">Si no hay ningún agregado de datos, cree uno nuevo con el almacenamiento<block ref="a3c52ca282dcb77dd824f54a7b270068" prefix=" " category="inline-code"></block> comando.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">Sincronice los archivos en el origen y en el destino.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">Compruebe que los archivos se han copiado correctamente.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">Siguiente: Migración de datos CIFS con ACL de un equipo de almacenamiento de origen a ONTAP.</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Descripción general de la solución</block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">ONTAP AI de NetApp y Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">La arquitectura de ONTAP AI de NetApp, impulsada por los sistemas NVIDIA DGX y los sistemas de almacenamiento conectados al cloud de NetApp, fue desarrollada y verificada por NetApp y NVIDIA. Esta arquitectura de referencia proporciona a las organizaciones DE TI las siguientes ventajas:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Elimina las complejidades de diseño</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">Permite un escalado independiente de las capacidades de computación y almacenamiento</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Permite a los clientes empezar con poco y escalar sin problemas</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">Ofrece una gama de opciones de almacenamiento para diferentes funcionalidades de rendimiento y rentabilidad.ONTAP AI integra a la perfección los sistemas de almacenamiento DGX y AFF A220 de NetApp con redes de vanguardia. Los sistemas ONTAP AI y DGX de NetApp simplifican las puestas en marcha de IA al eliminar complejidades y conjeturas en la fase de diseño. Los clientes pueden empezar poco a poco y aumentar sus sistemas de forma ininterrumpida, a la vez que gestionan de forma inteligente datos entre el perímetro, el núcleo y el cloud.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">Cloud Sync de NetApp le permite mover datos fácilmente a través de diversos protocolos, ya sea entre dos unidades NFS, dos unidades CIFS o una unidad de archivos y el almacenamiento de Amazon S3, Amazon Elastic File System (EFS) o Azure Blob. El funcionamiento activo-activo permite seguir trabajando tanto con el origen como con el objetivo al mismo tiempo, sincronizando de forma incremental los cambios de datos cuando sea necesario. Al permitirle mover y sincronizar datos de forma incremental entre cualquier sistema de origen y de destino, ya sea en las instalaciones o en el cloud, Cloud Sync ofrece una amplia variedad de nuevas formas de utilizar los datos. Es muy fácil llegar a la migración de datos entre sistemas locales, integración en el cloud y migración al cloud, o colaboración y análisis de datos. La siguiente figura muestra los orígenes y destinos disponibles.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">En sistemas de IA conversacionales, los desarrolladores pueden aprovechar Cloud Sync para archivar el historial de conversaciones desde el cloud a los centros de datos para hacer posible la formación sin conexión de los modelos de procesamiento de lenguaje natural (NLP). Gracias a los modelos de formación que permiten reconocer más intenciones, el sistema de IA conversacional estará mejor equipado para gestionar preguntas más complejas por parte de los usuarios finales.</block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="section-title">NVIDIA Jarvis Multimodal Framework</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> Es un marco integral para crear servicios de IA que puedan conversación. Incluye los siguientes servicios optimizados para GPU:</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">Reconocimiento automático de voz (ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">Comprensión del lenguaje natural (NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">Integración con servicios logísticos específicos de dominio</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">Texto a voz (TTS)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">Los servicios basados en Jarvis utilizan modelos de aprendizaje profundo de vanguardia para hacer frente a la compleja y desafiante tarea de IA conversacional en tiempo real. Para permitir la interacción natural y en tiempo real con un usuario final, los modelos deben completar el cálculo en menos de 300 milisegundos. Las interacciones naturales son difíciles, y requieren la integración sensorial multimodal. Los gasoductos son también complejos y requieren coordinación entre los servicios mencionados.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis es un marco de aplicaciones totalmente acelerado para la creación de servicios de IA conversacionales multimodales que usan una canalización de aprendizaje profundo integral. El marco Jarvis incluye modelos de IA conversacionales, herramientas y servicios integrales optimizados para tareas de habla, visión y NLU. Además de los servicios de IA, Jarvis le permite fusionar simultáneamente la visión, el audio y otras entradas de sensores para proporcionar capacidades como conversaciones multiusuario y multicontexto en aplicaciones como asistentes virtuales, diarización multiusuario y asistentes de centros de llamadas.</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="section-title">NVIDIA Nemo</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> Es un kit de herramientas Python de código abierto para crear, formar y ajustar modelos de IA de última generación acelerados por GPU y conversacionales que usan interfaces de programación de aplicaciones (API) fáciles de usar. Nemo ejecuta una computación de precisión mixta mediante núcleos tensores en GPU de NVIDIA y puede escalarse verticalmente hasta varias GPU fácilmente para ofrecer el máximo rendimiento de entrenamiento posible. Nemo se utiliza para crear modelos para aplicaciones ASR, NLP y TTS en tiempo real, como transcripciones de videollamadas, asistentes inteligentes de vídeo y soporte de centros de llamadas automatizados en diferentes sectores verticales, incluyendo servicios sanitarios, financieros, minoristas y telecomunicaciones.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Utilizamos Nemo para entrenar modelos que reconocen intentos complejos de preguntas de usuario en el historial de conversaciones archivadas. Esta capacitación amplía las capacidades del asistente virtual al por menor más allá de lo que Jarvis apoya como se ofrece.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">Resumen del caso de uso de venta al por menor</block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="inline-link">Personalizar Estados y flujos para el caso de uso de comercio minorista</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">Con NVIDIA Jarvis, creamos un asistente de venta al por menor virtual que acepta comentarios o comentarios y responde a preguntas sobre el tiempo, puntos de interés y precios de inventario. El sistema de IA conversacional puede recordar el flujo de conversaciones, por ejemplo, formular una pregunta de seguimiento si el usuario no especifica la ubicación para el clima o los puntos de interés. El sistema también reconoce entidades complejas como “comida tailandesa” o “memoria portátil”. Entiende preguntas de lenguaje natural como “¿lloverá la próxima semana en los Ángeles?” Una demostración del asistente virtual al por menor se puede encontrar en<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">Siguiente: Tecnología de la solución</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">Demostración del asistente de venta al por menor de NetApp</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">este enlace</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">Grabamos un vídeo de demostración del Asistente para minoristas de NetApp (NARA). Haga clic en<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> para abrir la siguiente figura y reproducir el vídeo de demostración.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">Siguiente: Utilice Cloud Sync de NetApp para archivar el historial de conversaciones</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="15a2a7497ac6041e1b73d7cb41406245" category="doc">TR-4811: Arquitectura de referencia de IA ONTAP de NetApp para el sector sanitario: Imágenes de diagnóstico - diseño de la solución</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang, Sung-han Lin, Sathish Thyagarajan, NetApp Jacci Cenci, NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">Esta arquitectura de referencia ofrece directrices para los clientes que crean una infraestructura de inteligencia artificial (IA) con sistemas NVIDIA DGX-2 y almacenamiento AFF de NetApp para casos de uso de sanidad. Incluye información sobre los flujos de trabajo de alto nivel utilizados en el desarrollo de modelos de aprendizaje profundo (DL) para imágenes de diagnóstico médico, casos de prueba validados y resultados. También incluye recomendaciones para el dimensionamiento de las puestas en marcha de los clientes.</block>
  <block id="5c6168ae6047f496e6903dde0fd3033c" category="paragraph"><block ref="5c6168ae6047f496e6903dde0fd3033c" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Este apartado describe los procedimientos de prueba utilizados para validar esta solución.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procedimiento de prueba</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">Anterior: Configuración de prueba.</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">Hemos utilizado el siguiente procedimiento de prueba en esta validación.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configuración de inferencia de IA y sistema operativo</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">codificación</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Para AFF C190, utilizamos Ubuntu 18.04 con controladores NVIDIA y docker con soporte para GPU de NVIDIA y usamos MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Disponible como parte de la presentación de Lenovo a la inferencia MLPerf v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Para EF280, utilizamos Ubuntu 20.04 con controladores NVIDIA y docker con soporte para las GPU de NVIDIA y MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Disponible como parte de la presentación de Lenovo a la inferencia MLPerf v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Para configurar la inferencia de IA, siga estos pasos:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Descargue los conjuntos de datos que requieren registro, el conjunto de datos ImageNET 2012 Validation, el conjunto de datos Criteo Terabyte y el conjunto de entrenamiento Brats 2019 y, a continuación, descomprima los archivos.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Cree un directorio de trabajo con al menos 1 TB y defina una variable ambiental<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> referencia al directorio.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Debe compartir este directorio en el almacenamiento compartido para el caso de uso del almacenamiento de red o en el disco local cuando realice pruebas con datos locales.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Ejecute la Marca<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> comando, que crea e inicia el contenedor docker para las tareas de inferencia necesarias.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Los siguientes comandos se ejecutan desde el contenedor docker en ejecución:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Descargue modelos de IA preformados para tareas de inferencia de MLPerf:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Descargue conjuntos de datos adicionales que se pueden descargar gratuitamente:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Preprocesar los datos: Make<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Ejecución:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block>.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Cree motores de inferencia optimizados para la GPU en servidores informáticos:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Para ejecutar cargas de trabajo de inferencia, ejecute el siguiente (un comando):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">Se ejecuta la inferencia de IA</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Se ejecutaron tres tipos de ejecuciones:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inferencia de IA de un único servidor con almacenamiento local</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inferencia de IA de un único servidor con el almacenamiento en red</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inferencia de la IA en varios servidores con el almacenamiento en red</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">Siguiente: Resultados de las pruebas.</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: Lago de datos de StorageGRID de NetApp para cargas de trabajo de conducción autónoma - Diseño de la solución</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">En el TR-4851 se muestra el uso del almacenamiento de objetos StorageGRID de NetApp como repositorio de datos y sistema de gestión para el desarrollo de software de aprendizaje automático (ML) y aprendizaje profundo (DL). Este documento describe el flujo de datos y los requisitos del desarrollo de software de vehículos autónomos y las funciones de StorageGRID que optimizan el ciclo de vida de los datos. Esta solución se aplica a cualquier flujo de trabajo de canalización de datos multietapa típico en los procesos de desarrollo DE APRENDIZAJE AUTOMÁTICO y aprendizaje profundo.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">Esta página compara el tiempo de entrenamiento del modelo utilizando pandas convencionales en comparación con DASK. Para Pandas, cargamos una cantidad menor de datos debido a la naturaleza del tiempo de procesamiento más lento, para evitar que se desbordara la memoria. Por lo tanto, interpolamos los resultados para ofrecer una comparación justa.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">Comparación del tiempo de entrenamiento</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">Anterior: Supervisión de tarea mediante el panel de control de secuencias de tareas nativas.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">Esta sección compara el tiempo de entrenamiento del modelo utilizando pandas convencionales en comparación con el DASK. Para Pandas, cargamos una cantidad menor de datos debido a la naturaleza del tiempo de procesamiento más lento, para evitar que se desbordara la memoria. Por lo tanto, interpolamos los resultados para ofrecer una comparación justa.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">La siguiente tabla muestra la comparación del tiempo de entrenamiento bruto cuando hay significativamente menos datos utilizados para el modelo de bosque aleatorio de pandas (50 millones de filas de 20 mil millones por día 15 del conjunto de datos). Esta muestra sólo utiliza menos del 0.25% de todos los datos disponibles. Mientras que para DASK-cuML entrenamos el modelo de bosque aleatorio en las 20 mil millones de filas disponibles. Los dos enfoques dieron lugar a un tiempo de capacitación comparable.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">Enfoque</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">Tiempo de entrenamiento</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-Learn: Usando sólo 50 m de filas en el día 15 como datos de entrenamiento</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 minutos y 21 segundos</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-Dask: Utilizando todas las filas 20B del día 15 como datos de entrenamiento</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 hora, 12 minutos y 11 segundos</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">Si interpolamos los resultados del tiempo de entrenamiento linealmente, como se muestra en la siguiente tabla, hay una ventaja significativa a utilizar el entrenamiento distribuido con DASK. Tomaría el enfoque convencional de Pandas scikit-Learn 13 días para procesar y entrenar 45GB de datos para un solo día de registros tecleo, mientras que EL enfoque RAPIDS-DASk procesa la misma cantidad de datos 262.39 veces más rápido.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-Learn: Usando todas las filas 20B en el día15 como datos de entrenamiento</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 días, 3 horas, 40 minutos y 11 segundos</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">En la tabla anterior, puede ver que usando RAPIDS con Dink para distribuir el procesamiento de datos y el entrenamiento de modelos en varias instancias de GPU, el tiempo de ejecución es significativamente más corto en comparación con el procesamiento convencional de Pandas DataFrame con el entrenamiento de modelos scikit-Learn. Este marco permite un escalado vertical y horizontal en el cloud, así como en las instalaciones, en un clúster multinodo con varias GPU.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">Siguiente: Monitorizar a Dink y RAPIDS con Prometheus y Grafana.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">Óptimo uso de clúster y de la GPU con Run:AI</block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">En las siguientes secciones se ofrecen detalles sobre la instalación de Run:AI, escenarios de prueba y resultados realizados en esta validación.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">Validamos el funcionamiento y el rendimiento de este sistema mediante herramientas estándar del sector, incluidas las pruebas de rendimiento TensorFlow. El conjunto de datos ImageNET se utilizó para entrenar ResNet-50, que es un famoso modelo de red neuronal convolucional (CNN) DL para la clasificación de imágenes. RESNET-50 ofrece un resultado de entrenamiento preciso con un tiempo de procesamiento más rápido, lo que nos permitió generar una demanda suficiente sobre el almacenamiento.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">Siguiente: Ejecute la instalación de AI</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Dónde encontrar información adicional</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">Si quiere obtener más información sobre el contenido de este documento, consulte los siguientes recursos:</block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Nvrg.io (<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>):</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">NÚCLEO Cnvrg (plataforma DE ML libre)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Documentos de Cnvrg</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">Servidores DGX-1 de NVIDIA:</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">Servidores DGX-1 de NVIDIA</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="paragraph"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">GPU de núcleo tensor NVIDIA Tesla V100</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="paragraph"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">GPU CLOUD DE NVIDIA (NGC)</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="paragraph"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">Sistemas AFF de NetApp:</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">Especificaciones técnicas de AFF</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">FlashAdvantage de NetApp para AFF</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="paragraph"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">Documentación de ONTAP 9.x.</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="paragraph"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">Informe técnico de NetApp FlexGroup</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="paragraph"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">Almacenamiento persistente de NetApp para contenedores:</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">Trident de NetApp</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="paragraph"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">Matriz de interoperabilidad de NetApp:</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">Herramienta de matriz de interoperabilidad de NetApp</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">Redes de IA de ONTAP:</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Switches Cisco Nexus 3232C</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="paragraph"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Switches Mellanox Spectrum serie 2000</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">Marco Y herramientas DE ML:</block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">DALÍ</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow: Un marco de aprendizaje automático de código abierto para todos</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="paragraph"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod: El marco de Uber para el aprendizaje automático distribuido de código abierto para TensorFlow</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">Habilitación de GPU en el ecosistema Container Runtime</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="paragraph"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">Kubernetes</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="paragraph"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="142f782bb2b326679982208fe40cec31" category="list-text">DeepOps de NVIDIA</block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">Kubeflow</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="paragraph"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Servidor de portátiles Juppyter</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="paragraph"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">Conjuntos de datos y pruebas:</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">Conjunto de datos de radiografía de tórax de los NIH</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang, Yifan Peng, le Lu, Zhiyong Lu, Mohammadadi Bagheri, Ronald Summers, ChestX-ray8: Base de datos de rayos X en el pecho a escala de hospital y puntos de referencia sobre clasificación y localización de enfermedades comunes del tórax, IEEE CVPR, págs 3462-3471, 2017TR-4841-0620</block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">En esta página se describen las tareas que debe completar para poner en marcha Kubeflow en su clúster de Kubernetes.</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="doc">Despliegue de Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">En esta sección se describen las tareas que debe completar para poner en marcha Kubeflow en su clúster de Kubernetes.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Antes de realizar el ejercicio de implementación descrito en esta sección, asumimos que ya ha realizado las siguientes tareas:</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Documentación oficial de Kubeflow</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Ya tiene un clúster de Kubernetes en funcionamiento y ejecuta una versión de Kubernetes que admite ubeflow. Para obtener una lista de las versiones compatibles, consulte<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Implementación y configuración de Trident</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">Ya ha instalado y configurado NetApp Trident en su clúster de Kubernetes, como se indica en <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Establezca el tipo de almacenamiento de Kubernetes predeterminado</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Antes de poner en marcha Kubeflow, debe designar un clase de almacenamiento predeterminado dentro del clúster de Kubernetes. El proceso de implementación de Kubeflow intenta aprovisionar nuevos volúmenes persistentes mediante el tipo de almacenamiento predeterminado. Si no se designa StorageClass como clase de almacenamiento predeterminado, la implementación falla. Para designar un StorageClass predeterminado en el clúster, realice la siguiente tarea desde el host de salto de implementación. Si ya ha designado un tipo de almacenamiento predeterminado en el clúster, puede omitir este paso.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">Designe una de las clases de almacenamiento existentes como clase de almacenamiento predeterminada. Los comandos de ejemplo siguientes muestran la designación de un StorageClass llamado<block ref="b3e01914c123afcd317121eb293386c4" prefix=" " category="inline-code"></block> Como el tipo de almacenamiento predeterminado.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">La<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> El tipo de backend de Trident tiene un tamaño de RVP mínimo que es bastante grande. De manera predeterminada, Kubeflow intenta suministrar EVs que son sólo unos pocos GBS en tamaño. Por lo tanto, no debe designar un StorageClass que utilice<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Tipo back-end como StorageClass predeterminado para la implementación de Kubeflow.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">Utilice NVIDIA DeepOps para poner en marcha Kubeflow</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NetApp recomienda usar la herramienta de puesta en marcha de Kubeflow que proporciona NVIDIA DeepOps. Para poner en marcha Kubeflow en su clúster de Kubernetes con la herramienta de puesta en marcha DeepOps, siga estas tareas desde el host de salto de implementación.</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">instrucciones de instalación</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">Como alternativa, puede implementar Kubeflow manualmente siguiendo la<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> En la documentación oficial de Kubeflow</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Instrucciones de despliegue de Kubeflow</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">Implemente Kubeflow en su clúster siguiendo el<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Tenga en cuenta la URL del panel de Kubeflow que genera la herramienta de puesta en marcha de DeepOps Kubeflow.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Confirmar que todos los POD implementados en el espacio de nombres Kubeflow muestran un<block ref="5f241c8c8f985b3c51e05d39cf030f4c" prefix=" " category="inline-code"></block> de<block ref="5bda814c4aedb126839228f1a3d92f09" prefix=" " category="inline-code"></block> y confirmar que ningún componente puesto en marcha en el espacio de nombres se encuentra en un estado de error. El inicio de todos los pods puede tardar varios minutos.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">En su navegador web, acceda al panel central de Kubeflow navegando hasta la URL que anotó en el paso 2.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">El nombre de usuario predeterminado es<block ref="e0fb0c8707d7da1341e171401e7c9e14" prefix=" " category="inline-code"></block>, y la contraseña predeterminada es<block ref="ed2b1f468c5f915f3f1cf75d7068baae" prefix=" " category="inline-code"></block>. Para crear usuarios adicionales, siga las instrucciones de<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">Siguiente: Ejemplo de operaciones y tareas de Kubeflow.</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">Con las herramientas de modelado preformadas actuales y vanguardistas publicadas por NVIDIA, AWS, Google y otros, ahora es posible ponerse en marcha una canalización integral con modelos complejos con una facilidad relativa personalizada.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="doc">Casos de uso</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">Anterior: Admite análisis del centro de soporte.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">Debido al número de llamadas que procesa estos centros de soporte, la evaluación del rendimiento de la llamada puede llevar un tiempo considerable si se realiza manualmente. Los métodos tradicionales, como el conteo de bolsas de palabras y otros métodos, pueden lograr cierta automatización, pero estos métodos no capturan aspectos más matizados y un contexto semántico del lenguaje dinámico. Las técnicas de modelado de IA se pueden usar para realizar algunos de estos análisis más matices de forma automatizada. Además, con lo último en tecnología y herramientas de modelado preformadas publicadas por NVIDIA, AWS, Google y otras, puede ponerse en marcha una canalización integral con modelos complejos con una facilidad relativa personalizada.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">Una canalización de extremo a extremo para el análisis de confianza del centro de soporte procesa archivos de audio en tiempo real a medida que los empleados converse con las personas que llaman. A continuación, estos archivos de audio se procesan para su uso en el componente voz a texto que los convierte en un formato de texto. Cada frase de la conversación recibe una etiqueta que indica el sentimiento (positivo, negativo o neutro).</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">El análisis de confianza puede proporcionar un aspecto esencial de las conversaciones para evaluar el rendimiento de la llamada. Estos sentimientos añaden un nivel adicional de profundidad a las interacciones entre empleados y personas que llaman. El panel de control de confianza asistido por IA proporciona a los administradores un seguimiento en tiempo real de la opinión dentro de una conversación, junto con un análisis retrospectivo de las llamadas pasadas del empleado.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">Maxine de NVIDIA</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">Existen herramientas prediseñadas que se pueden combinar de manera potente para crear rápidamente una canalización de IA completa para solucionar este problema. En este caso, la biblioteca NVIDIA RIVA se puede utilizar para realizar las dos tareas en serie: Transcripción de audio y análisis de sentimiento. El primero es un algoritmo de procesamiento de señales de aprendizaje supervisado y el segundo es un algoritmo de clasificación NLP de aprendizaje supervisado. Estos algoritmos listos para usar pueden ajustarse para cualquier caso de uso relevante con datos relevantes del negocio mediante el kit de herramientas TAO de NVIDIA. Esto lleva a que se estén creando soluciones más precisas y potentes por una fracción del coste y los recursos. Los clientes pueden incorporar la<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> Marco de trabajo para aplicaciones de videoconferencia aceleradas por GPU en el diseño del centro de soporte.</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">Los siguientes casos de uso son el núcleo de esta solución. En ambos casos de uso, se utiliza TAO Toolkit para realizar un ajuste preciso del modelo y RIVA para su implementación.</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="list-text">Voz a texto</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">Análisis de la confianza</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">Para analizar las interacciones del centro de soporte entre empleados y clientes, cada conversación del cliente en forma de llamadas de audio se puede realizar a través de la canalización para extraer sentimientos a nivel de frase. Esos sentimientos pueden ser verificados por un ser humano para justificar los sentimientos o ajustarlos según sea necesario. A continuación, los datos etiquetados se pasan al paso de ajuste fino para mejorar las predicciones de sentimientos. Si ya existen datos de confianza etiquetados, se puede acelerar el ajuste preciso del modelo. En cualquier caso, el ducto es generalizable a otras soluciones que requieren la ingestión de audio y la clasificación de frases.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">Los resultados de opiniones de la IA se cargan en una base de datos cloud externa o en un sistema de almacenamiento gestionado por la empresa. Los resultados de la confianza se transfieren desde esta base de datos más grande al almacenamiento local para su uso dentro del panel de control que muestra el análisis de opinión de los administradores. La funcionalidad principal del panel es la de interactuar con el empleado del servicio de atención al cliente en tiempo real. Los gerentes pueden evaluar y proporcionar comentarios a los empleados durante sus llamadas con actualizaciones en vivo de la opinión de cada frase, así como una revisión histórica del desempeño pasado del empleado o de las reacciones del cliente.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link-macro">Kit de herramientas de operaciones de datos de NetApp</block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">La <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Puede seguir gestionando sistemas de almacenamiento de datos incluso después de que la canalización de inferencia RIVA genere etiquetas de sentimiento. Estos resultados de la IA pueden cargarse en un sistema de almacenamiento de datos gestionado por el kit de herramientas DataOPS de NetApp. Los sistemas de almacenamiento de datos deben ser capaces de gestionar cientos de inserciones y seleccionar cada minuto. El sistema de almacenamiento del dispositivo local consulta el mayor almacenamiento de datos en tiempo real para su extracción. También es posible consultar a la instancia de almacenamiento de datos de mayor tamaño los datos históricos para mejorar aún más la experiencia de la consola. El kit de herramientas DataOPS de NetApp facilita ambos usos mediante el clonado rápido de los datos y la distribución entre todas las consolas que los utilizan.</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">Público objetivo</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">El público objetivo de la solución incluye los siguientes grupos:</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">Gerentes de empleados</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">Ingenieros/científicos de datos</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">Administradores DE TECNOLOGÍA (en las instalaciones, en cloud o híbrida)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">El seguimiento de los sentimientos a lo largo de las conversaciones es una herramienta valiosa para evaluar el rendimiento de los empleados. Mediante el panel de instrumentos de inteligencia artificial, los administradores pueden ver cómo los empleados y las personas que llaman cambian sus sentimientos en tiempo real, lo que permite evaluaciones en directo y sesiones de orientación. Además, las empresas pueden obtener información valiosa de los clientes que participan en conversaciones vocales, bots de chat de texto y videoconferencias. Dichos análisis de clientes utilizan las funcionalidades de procesamiento multimodal a escala con modernos modelos de IA y flujos de trabajo de vanguardia.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">En cuanto a los datos, el centro de soporte procesa diariamente un gran número de archivos de audio. El kit de herramientas DataOPS de NetApp facilita esta tarea de gestión de datos tanto para la sintonización periódica de modelos como para consolas de análisis de opiniones.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">Los administradores DE TECNOLOGÍA también se benefician del kit de herramientas de NetApp DataOps ya que permite mover datos con rapidez entre entornos de implementación y de producción. Los entornos y servidores de NVIDIA también deben gestionarse y distribuirse para permitir la inferencia en tiempo real.</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">Siguiente: Arquitectura.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Sinopsis</block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">Este informe técnico ofrece directrices para clientes con equipos pequeños y grandes de ciencia e ingeniería de datos que optimizan el clúster de Kubernetes y el uso de la GPU utilizando la CLI Run:AI y la consola del sistema de ONTAP AI de NetApp. También incluye información sobre la instalación de plataformas Run:AI, escenarios de prueba y comandos detallados para casos de prueba validados. La solución de orquestación Run:AI junto con el plano de control de IA de NetApp proporciona un tiempo más rápido para la innovación al mejorar la productividad de los desarrolladores mediante una utilización óptima de los recursos.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">Siguiente: Resumen ejecutivo</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Lugares donde encontrar información adicional</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">Anterior: Ejemplo de caso práctico: Trabajo de formación de TensorFlow.</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Software de gestión de datos ONTAP de NetApp: Biblioteca de información de ONTAP</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise con VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Reconocimientos</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Sr. Sénior, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, Administrador de sistemas, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Ingeniero Técnico de Marketing de NetApp</block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files, RAPIDS y Dink aceleran y simplifican la puesta en marcha del procesamiento Y formación ML a gran escala, integrado con herramientas de orquestación como Docker y Kubernetes. Al unificar la canalización de datos completa, esta solución reduce la latencia y la complejidad inherentes de muchas cargas de trabajo informáticas avanzadas, y permite salvar en la práctica la brecha entre el desarrollo y las operaciones.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusión</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">Anterior: Versiones de conjuntos de datos y modelos con el kit de herramientas de operaciones de datos de NetApp.</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS y Dink aceleran y simplifican la puesta en marcha del procesamiento y formación DE ML a gran escala gracias a la integración con herramientas de orquestación como Docker y Kubernetes. Al unificar la canalización de datos completa, esta solución reduce la latencia y la complejidad inherentes de muchas cargas de trabajo informáticas avanzadas, y permite salvar en la práctica la brecha entre el desarrollo y las operaciones. Los científicos de datos pueden ejecutar consultas en grandes conjuntos de datos y compartir de forma segura datos y modelos algorítmicos con otros usuarios durante la fase de entrenamiento.</block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">Cuando cree sus propias canalizaciones de IA/ML, configurar la integración, la gestión, la seguridad y la accesibilidad de los componentes en una arquitectura es una tarea ardua. Dar a los desarrolladores acceso y control de su entorno presenta otro conjunto de retos.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">Al crear un modelo de entrenamiento distribuido completo y una canalización de datos en el cloud, demostramos dos órdenes de mejora de magnitud en el tiempo de finalización total de los flujos de trabajo en comparación con un enfoque convencional de código abierto que no utilizaba el procesamiento de datos acelerado por GPU y los marcos informáticos.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">La combinación de NetApp, Microsoft, marcos de orquestación de código abierto y NVIDIA reúne las tecnologías más recientes como servicios gestionados con una gran flexibilidad para acelerar la adopción de tecnología y mejorar el plazo de comercialización de las nuevas aplicaciones de IA/ML. Estos servicios avanzados se ofrecen en un entorno nativo del cloud que se puede realizar fácilmente en las instalaciones y en arquitecturas de puesta en marcha híbrida.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, Ingeniero Técnico de Marketing de NetApp</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">Santosh Rao, director técnico sénior, NetApp</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">Siguiente: Dónde encontrar información adicional</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">La solución de plano de control de IA de NetApp no depende de este hardware específico.</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">Requisitos de hardware y software</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Documentación de Trident</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">La solución de plano de control de IA de NetApp no depende de este hardware específico. La solución es compatible con cualquier dispositivo de almacenamiento físico, instancia definida por software o servicio cloud de NetApp compatible con Trident. Entre los ejemplos se incluyen un sistema de almacenamiento AFF de NetApp, Azure NetApp Files, Cloud Volumes Service de NetApp, una instancia de almacenamiento definido por software ONTAP Select de NetApp o una instancia de Cloud Volumes ONTAP de NetApp. Además, la solución puede implementarse en cualquier clúster de Kubernetes, siempre que la versión de Kubernetes utilizada sea compatible con Kubeflow y Trident de NetApp. Si desea ver una lista de las versiones de Kubernetes compatibles con ubeflow, consulte la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Si desea ver una lista de las versiones de Kubernetes compatibles con Trident, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. Consulte las siguientes tablas para obtener información detallada sobre el entorno que se utilizó para validar la solución.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">Componente de la infraestructura</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Cantidad</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">Sistema operativo</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">Host de salto de implementación</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">MÁQUINA VIRTUAL</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Sistema operativo Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Nodos maestros de Kubernetes</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Nodos de trabajo de Kubernetes</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Nodos de trabajo de GPU de Kubernetes</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 (nativo)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 (basado en Ubuntu 18.04.2 LTS)</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Reducida</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 par de alta disponibilidad</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="cell">AFF A220 de NetApp</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">ONTAP 9.7 P6 de NetApp</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Componente de software</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Flujo de aire Apache</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Tabla de Helm para flujo de aire de Apache</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">Funcionalidad de implementación de Trident desde la rama maestra hasta el encargo <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>; Todas las demás funciones de la versión 21.03</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Soporte técnico</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">Póngase en contacto con NetApp</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp no ofrece compatibilidad empresarial con Apache Airflow, Docker, Kubeflow, Kubernetes u NVIDIA DeepOps. Si está interesado en una solución totalmente compatible con funcionalidades similares a la solución del plano de control de IA de NetApp, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> Acerca de soluciones de IA/ML totalmente compatibles que NetApp ofrece en colaboración con partners.</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">Siguiente: Puesta en marcha de Kubernetes.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">Haga clic en el procesamiento de datos de predicción de velocidad y el entrenamiento de modelos</block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">En esta sección, se incluyen ejemplos de varias tareas de alto rendimiento que se pueden ejecutar cuando se pone en marcha Kubernetes en un pod ONTAP AI.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">Ejemplo de tareas de alto rendimiento para puestas en marcha de ONTAP AI</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">Siguiente: Ejecute una carga de trabajo de IA de un solo nodo.</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="837896d23c0eee81106906ab4cef7a6d" category="doc">TR-4799-DESIGN: Arquitectura de referencia ONTAP AI de NetApp para cargas de trabajo de conducción autónoma</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">David Arnette y Sung-han Lin, NetApp</block>
  <block id="63e3877ed0a830d2fb8beed8fffb2df4" category="paragraph">La familia de sistemas NVIDIA DGX es la primera plataforma de inteligencia artificial (IA) integrada del mundo, específicamente diseñada para IA empresarial. Los sistemas de almacenamiento AFF de NetApp proporcionan un rendimiento extremo y funcionalidades de gestión de datos de cloud híbrido líderes en el sector. NetApp y NVIDIA se han asociado para crear la arquitectura de referencia de IA ONTAP de NetApp con el fin de ofrecer a los clientes una solución lista para usar que respalda cargas de trabajo DE IA y aprendizaje automático (ML) con rendimiento, fiabilidad y soporte de nivel empresarial.</block>
  <block id="873b0fe1ee8adb4c5e6401e2fabf0734" category="paragraph"><block ref="873b0fe1ee8adb4c5e6401e2fabf0734" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">En esta página se describen las tareas que se deben completar para instalar y configurar NetApp Trident en el clúster Kubernetes.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">Implementación y configuración de Trident de NetApp</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">En esta sección se describen las tareas que debe completar para instalar y configurar NetApp Trident en su clúster Kubernetes.</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Ya existe un clúster de Kubernetes en funcionamiento y ejecuta una versión de Kubernetes compatible con Trident. Para obtener una lista de las versiones compatibles, consulte<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>.</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Ya existe un dispositivo de almacenamiento de NetApp, una instancia definida por software o un servicio de almacenamiento en cloud que Trident admite.</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">Instale Trident</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Para instalar y configurar NetApp Trident en su clúster de Kubernetes, realice las siguientes tareas desde el host de salto de implementación:</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Implemente Trident mediante uno de los siguientes métodos:</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Instrucciones de puesta en marcha de Trident</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">Si utilizó NVIDIA DeepOps para poner en marcha su clúster de Kubernetes, también puede usar NVIDIA DeepOps para implementar Trident en el clúster de Kubernetes. Para poner en marcha Trident con DeepOps, siga<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">instrucciones de puesta en funcionamiento</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">Back-ends</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">Clases de almacenamiento</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">Si no utilizó NVIDIA DeepOPS para poner en marcha su clúster de Kubernetes, o si simplemente prefiere poner en marcha Trident manualmente, puede implementar Trident siguiendo el<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> En la documentación de Trident. Asegúrese de crear al menos un back-end de Trident y al menos un Kubernetes StorageClass para obtener más información acerca de cómo configurar<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> y..<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> Consulte los subapartados vinculados en los documentos de NetApp.</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="inline-link-macro">Ejemplo de Back-ends de Trident para puestas en marcha de ONTAP AI</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">Ejemplo de una historia Kubernetes para las puestas en marcha de IA de ONTAP</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">Si va a poner en marcha la solución del plano de control de IA de NetApp en un POD de IA de ONTAP, consulte <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> Para algunos ejemplos de diferentes Back-ends de Trident que es posible que desee crear y. <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> Puede que desee crear algunos ejemplos de diferentes clases de almacenamiento de Kubernetes.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">Siguiente: Ejemplo de Back-ends de Trident para la puesta en marcha de ONTAP AI.</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">Esta página enumera los requisitos de software necesarios para esta solución.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="doc">Requisitos de software</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">Anterior: Información general de la tecnología.</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">En la siguiente tabla se enumeran los requisitos de software necesarios para esta solución.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">De NetApp</block>
  <block id="f938809a358080d4c7a941e59abfca40" category="cell">Servicio Azure Kubernetes</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">Imagen de contenedor DE RAPIDS y DASK</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">Repositorio: "Rapidsai/rapidsai" etiqueta: 0.17-cuda11.0-Runtime-ubuntu18.04</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Timón</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">Siguiente: Requisitos de recursos del cloud.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">El procesamiento de imágenes digitales ofrece muchas ventajas, lo que permite a muchas organizaciones aprovechar al máximo los datos asociados con las representaciones visuales. Esta solución de NetApp y Protopia ofrece un diseño único de inferencia de IA para proteger y privatizar datos de IA/ML en TODO el ciclo de vida DE ML/DL. Permite a los clientes conservar la propiedad de datos confidenciales, utilizar modelos de puesta en marcha de cloud público o híbrido para escalar y eficiencia al eliminar las preocupaciones relacionadas con la privacidad y poner en marcha la inferencia de IA en el perímetro.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="doc">Áreas de soluciones</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">Anterior: Descripción general.</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Inteligencia ambiental</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Hay muchas maneras en que las industrias pueden aprovechar los análisis geoespaciales en las áreas de peligros ambientales. Los gobiernos y el departamento de obras públicas pueden obtener información práctica sobre la salud pública y las condiciones climáticas para asesorar mejor al público durante una pandemia o un desastre natural como los incendios forestales. Por ejemplo, puede identificar a un paciente con un COVID positivo en espacios públicos, como aeropuertos o hospitales, sin poner en peligro la privacidad del individuo afectado y alertar a las autoridades respectivas y al público cercano acerca de las medidas de seguridad necesarias.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Dispositivos portátiles</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">En el ejército y en campos de batalla, se puede utilizar la inferencia de IA en el borde como dispositivos portátiles para rastrear la salud de los soldados, monitorear el comportamiento de los conductores y alertar a las autoridades sobre la seguridad y los riesgos asociados de acercarse a los vehículos militares mientras se preserva y protege la privacidad de los soldados. El futuro de los militares está yendo de alta tecnología con el Internet de Battlefield Things (IoBT) y el Internet de las cosas militares (IoMT) por llevar equipos de combate que ayudan a los soldados a identificar a los enemigos y a actuar mejor en la batalla mediante la computación de avanzada. Proteger y preservar los datos visuales recopilados de dispositivos periféricos como aviones teledirigidos y engranajes portátiles es crucial para mantener a raya a los hackers y al enemigo.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Operaciones de evacuación no combatiente</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Las operaciones de evacuación no combatiente (Neos) las lleva a cabo el Departamento de Defensa para ayudar a evacuar a ciudadanos y nacionales estadounidenses, personal civil del Departamento de Defensa y personas designadas (nación anfitriona (HN) y nacionales de terceros países (TCN) cuyas vidas están en peligro de un refugio seguro apropiado. Los controles administrativos vigentes utilizan en gran medida procesos manuales de detección de evacuados. Sin embargo, la precisión, la seguridad y la velocidad de la identificación del evacuado, el seguimiento del evacuado y la detección de amenazas podrían mejorarse utilizando herramientas de IA/ML altamente automatizadas combinadas con tecnologías de ofuscación por vídeo de IA/ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Salud e investigación biomédica</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">El procesamiento de imágenes se utiliza para diagnosticar patologías para la planificación quirúrgica a partir de imágenes 3D obtenidas de tomografía computarizada (TC) o resonancia magnética (RM). Las reglas de privacidad de HIPAA rigen cómo deben recopilarse, procesar y borrar los datos para toda la información personal e imágenes digitales como fotografías. Para que los datos se puedan calificar para que se puedan compartir con la normativa HIPAA Safe Harbor, es necesario eliminar las imágenes fotográficas de cara completa y cualquier imagen comparable. Las técnicas automatizadas como la desidentificación o‐los algoritmos de decapado de cráneo utilizados para ocultar las características faciales de un individuo a partir de las imágenes estructurales de TC/RM se han convertido en una parte esencial del proceso de intercambio de datos para las instituciones de investigación biomédica.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migración al cloud de los análisis de IA/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protección de datos</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Los clientes empresariales han formado y puesto en marcha modelos de IA/ML en sus instalaciones. Por razones de escalado y eficiencia, estos clientes amplían su capacidad para trasladar las funciones de IA/ML a puestas en marcha de cloud público, híbrido o multicloud. Sin embargo, están ligados a qué datos se pueden exponer a otras infraestructuras. Las soluciones de NetApp se plantean una amplia gama de amenazas de ciberseguridad para las que es necesario<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> La evaluación de la seguridad y, cuando se combina con la transformación de datos de Protopía, minimizan los riesgos asociados con la migración de cargas de trabajo DE IA/ML de procesamiento de imágenes al cloud.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886 inferencia de IA en el perímetro</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Inteligencia frente a privacidad</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">Para ver casos de uso adicionales para la computación perimetral y la inferencia de IA en otros sectores, consulte<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> Y el blog de IA de NetApp,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>.</block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">Siguiente: Información general de la tecnología.</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Esta solución se centra tanto en arquitectura de clúster de gama básica como media usando almacenamiento de NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial. Está destinado a equipos pequeños y medianos para los que la mayoría de tareas informáticas sean de un solo nodo (una única o varias GPU) o se distribuyan entre varios nodos computacionales. Esta no es una limitación importante, ya que la mayoría de los trabajos de entrenamiento de IA diarios son un solo nodo.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 para formación de modelos AI y ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Esta solución presenta una arquitectura de clúster de gama media con almacenamiento de NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial (IA). Está destinado a empresas pequeñas y medianas para las que la mayoría de tareas informáticas sean de un único nodo (una única o varias GPU) o distribuidas en varios nodos informáticos. Esta solución se alinea con la mayoría de los trabajos de formación de IA diarios para muchas empresas.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">En este documento se tratan las pruebas y la validación de una configuración de computación y almacenamiento compuesta por ocho servidores Lenovo SR670V2 de la GPU, un sistema de almacenamiento AFF A400 de NetApp de gama media y un switch de interconexión de 100 GbE. Para medir el rendimiento, utilizamos ResNet50 con el conjunto de datos ImageNET, un tamaño de lote de 408, media precisión, CUDA y cuDNN. Esta arquitectura proporciona una solución eficiente y rentable para organizaciones pequeñas y medianas con el inicio de iniciativas de IA que requieren las funcionalidades de clase empresarial del almacenamiento de datos conectado al cloud ONTAP de NetApp.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">Público objetivo</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Este documento está dirigido a los siguientes destinatarios:</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Científicos de datos, ingenieros de datos, administradores de datos y desarrolladores de sistemas de IA</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos de IA</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Científicos e ingenieros de datos que buscan formas eficientes de alcanzar objetivos de desarrollo DE aprendizaje profundo (DL) y aprendizaje automático (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Líderes empresariales y responsables DE la toma de decisiones de OT/TECNOLOGÍA que desean conseguir el plazo de comercialización más rápido posible para iniciativas de IA</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Arquitectura de la solución</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Esta solución con los servidores Lenovo ThinkSystem y el sistema ONTAP de NetApp con almacenamiento AFF ha sido diseñado para gestionar el entrenamiento de IA en grandes conjuntos de datos utilizando la potencia de procesamiento de GPU junto con CPU tradicionales. Esta validación demuestra un alto rendimiento y una gestión de datos óptima con una arquitectura de escalado horizontal que utiliza uno, dos o cuatro servidores Lenovo SR670 V2 junto con un único sistema de almacenamiento AFF A400 de NetApp. En la siguiente figura, se proporciona una descripción general de la arquitectura.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Esta imagen muestra un switch Ethernet rodeado por el servidor de gestión, cuatro SR670 V2s con ocho GPU cada uno y un sistema de almacenamiento ONTAP de NetApp.</block>
  <block id="d0d5bc4c21e600127e347c093cc29e80" category="paragraph"><block ref="d0d5bc4c21e600127e347c093cc29e80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Esta solución de NetApp y Lenovo ofrece las siguientes ventajas clave:</block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Rendimiento muy eficaz y rentable al ejecutar varias tareas de formación en paralelo</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Rendimiento escalable basado en diferentes números de servidores Lenovo y diferentes modelos de controladoras de almacenamiento de NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protección de datos sólida para cumplir con los objetivos de punto de recuperación (RPO) y los objetivos de tiempo de recuperación (RTO) bajos sin pérdida de datos</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestión de datos optimizada con copias Snapshot y clones para optimizar los flujos de trabajo de desarrollo</block>
  <block id="c8da2691d0a05080662301b92e048a74" category="paragraph"><block ref="c8da2691d0a05080662301b92e048a74" category="inline-link-macro-rx"></block></block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915: Movimiento de datos con E-Series y BeeGFS para flujos de trabajo de análisis e IA</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">Cody Harryman y Ryan Rodine, NetApp</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">En TR-4915 se describe cómo mover datos desde cualquier repositorio de datos a un sistema de archivos BeeGFS respaldado por el almacenamiento SAN E-Series de NetApp. En el caso de aplicaciones de inteligencia artificial (IA) y aprendizaje automático (ML), es posible que los clientes deban mover de manera rutinaria grandes conjuntos de datos que superen muchos petabytes de datos en sus clústeres BeeGFS para el desarrollo de modelos. En este documento se analizan cómo lograrlo con las herramientas XCP y Cloud Sync de NetApp.</block>
  <block id="68a03283d8017637709e60ab77052710" category="paragraph"><block ref="68a03283d8017637709e60ab77052710" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">En esta página se describe la configuración de Dask con la implementación DE RAPIDS en AKS con Helm.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Configurar Dask con LA implementación DE RAPIDS en AKS con Helm</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">Anterior: Instale Trident.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Para configurar el despliegue de Dask con RAPIDS en AKS con Helm, lleve a cabo los siguientes pasos:</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Cree un espacio de nombres para instalar DASK con RAPIDS.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">Crear una RVP para almacenar el conjunto de datos con velocidad de clic:</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">Guarde el siguiente contenido de YAML en un archivo para crear un PVC.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Aplique el archivo YAML al clúster de Kubernetes.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">Clone el<block ref="d126903117bcd329e601af7057853376" prefix=" " category="inline-code"></block> repositorio (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>).</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">Modificar<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> E incluya el PVC creado anteriormente para los trabajadores y el espacio de trabajo Juppyter.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">Vaya a la<block ref="47e38535ab0a13ca65c9bba04c686040" prefix=" " category="inline-code"></block> directorio del repositorio.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Actualice el<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Coloque el archivo y monte el volumen con la RVP.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">Vaya al directorio principal del repositorio e implemente Dask con tres nodos de trabajo en AKS utilizando Helm.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">Siguiente: Niveles de rendimiento de Azure NetApp Files.</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">Defina una solicitud de volumen persistente</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">Guarde el siguiente YAML en un archivo para crear un PVC del tipo Basic.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Aplique el archivo YLMA al clúster de Kubernetes de Iguazio.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Adjunte el volumen de NetApp al ordenador portátil Jupyter</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Visión General de Iguazio de Servicios y Herramientas de aplicación</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio ofrece varios servicios gestionados para proporcionar a los científicos de datos una pila completa para el desarrollo y la puesta en marcha de aplicaciones de IA/ML. Puede obtener más información sobre estos componentes en la<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">Uno de los servicios gestionados es el portátil Jupyter. Cada desarrollador obtiene su propia implementación de un contenedor de portátiles con los recursos que necesitan para el desarrollo. Para darles acceso a Cloud Volume de NetApp, puede asignar el volumen a su contenedor y la asignación de recursos, la configuración de usuario en ejecución y la variable de entorno para las reclamaciones de volumen persistente se presentan en la siguiente imagen.</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">Para obtener información sobre una configuración en las instalaciones, puede consultar<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> En la configuración de Trident para habilitar las funcionalidades de gestión de datos de ONTAP de NetApp, como realizar copias Snapshot de sus datos o modelos para el control de versiones. Añada la siguiente línea en su archivo de configuración de back-end de Trident para que sean visibles los directorios de Snapshot:</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Comando Trident</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">Debe crear un archivo de configuración back-end de Trident en formato JSON y, a continuación, ejecutar lo siguiente<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> como referencia:</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">Siguiente: Implementación de la aplicación</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">En este apartado se describen las configuraciones probadas, la infraestructura de red, el servidor SR670 V2 y los detalles de abastecimiento de almacenamiento.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configuración de prueba</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">Anterior: Resultados de la prueba.</block>
  <block id="86473a82da3bbf22df039db481fe256f" category="paragraph"><block ref="86473a82da3bbf22df039db481fe256f" category="inline-link-macro-rx"></block></block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">En este apartado se describen las configuraciones probadas, la infraestructura de red, el servidor SR670 V2 y los detalles sobre el aprovisionamiento de almacenamiento NetApp.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Hemos utilizado los componentes de la solución enumerados en la siguiente tabla para esta validación.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Servidores Lenovo ThinkSystem</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Dos servidores SR670 V2 cada uno con ocho tarjetas GPU NVIDIA A100 de 80 GB</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Cada servidor contiene 2 CPU Intel Xeon Platinum 8360Y (28 núcleos físicos) y 1 TB de RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 con CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Sistema de almacenamiento AFF de NetApp (pareja de alta disponibilidad)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Software ONTAP 9.10.1 de NetApp</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 unidades SSD de 960 GB</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 grupo de interfaces (ifgrp) por controladora, con cuatro direcciones IP lógicas para los puntos de montaje</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">En esta validación, utilizamos ResNet v2.0 con la base ImageNET establecida como lo especifica MLPerf v2.0. El conjunto de datos se almacena en un sistema de almacenamiento AFF de NetApp con el protocolo NFS. Los SR670 se conectaron al sistema de almacenamiento AFF A400 de NetApp a través de un switch de 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNET es un conjunto de datos de imágenes utilizado con frecuencia. Contiene casi 1.3 millones de imágenes por un tamaño de 144 GB. El tamaño medio de la imagen es de 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">En la siguiente figura, se muestra la topología de red de la configuración probada.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Este gráfico muestra la capa informática, un sistema de ThinkSystem SR670 V2 Lenovo, la capa de red, un switch Ethernet Lenovo y la capa de almacenamiento, una controladora de almacenamiento AFF A400 de NetApp. Se incluyen todas las conexiones de red.</block>
  <block id="1ee331a29f95ebce1684e5e998f3e70c" category="paragraph"><block ref="1ee331a29f95ebce1684e5e998f3e70c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="section-title">Controladora de almacenamiento</block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">La siguiente tabla enumera la configuración de almacenamiento.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controladora</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agregado</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volumen FlexGroup</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Tamaño del agregado</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Tamaño del volumen</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Punto de montaje del sistema operativo</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Control1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Agr1</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Control2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Agr2</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">La carpeta /a400-100g contiene el conjunto de datos utilizado para la validación ResNet.</block>
  <block id="1ea4953a2e32bbad1a47dd39cbfe929a" category="inline-link-macro">Siguiente: Procedimiento de prueba y resultados detallados.</block>
  <block id="b20175407b354f0dfc3a4d6a98917f6f" category="paragraph"><block ref="b20175407b354f0dfc3a4d6a98917f6f" category="inline-link-macro-rx"></block></block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">Tecnología de soluciones</block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">Esta solución se implementó con un sistema AFF A800 de NetApp, dos servidores DGX-1 y dos switches Cisco Nexus 3232C 100 GbE. Cada servidor DGX-1 está conectado a los switches Nexus mediante cuatro conexiones 100 GbE que se utilizan para las comunicaciones entre GPU. Para ello se utilizan accesos remotos directos a la memoria (RDMA) sobre Ethernet convergente (roce). En estos enlaces también se producen las comunicaciones IP tradicionales para el acceso al almacenamiento NFS. Cada controladora de almacenamiento está conectado a los switches de red mediante cuatro enlaces 100 GbE. En la siguiente figura se muestra la arquitectura de la solución de IA de ONTAP utilizada en este informe técnico para todos los escenarios de pruebas.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">Hardware utilizado en esta solución</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">Esta solución se validó con la arquitectura de referencia ONTAP AI dos nodos DGX-1 y un sistema de almacenamiento AFF A800. Consulte<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> para obtener más detalles sobre la infraestructura utilizada en esta validación.</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">En la siguiente tabla se enumeran los componentes de hardware necesarios para implementar la solución según se ha probado.</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware subyacente</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">Sistemas DGX-1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Switches Nexus 3232C</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">Requisitos de software</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">Esta solución se validó con una puesta en marcha de Kubernetes básica con el operador Run:AI instalado. Kubernetes se puso en marcha usando el<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> motor de puesta en marcha, que implementa todos los componentes necesarios para un entorno listo para la producción. DeepOps ya se implementa automáticamente<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Para la integración del almacenamiento persistente con el entorno k8S, se crearon las clases de almacenamiento predeterminadas, de modo que los contenedores aprovechan el almacenamiento del sistema de almacenamiento A800 de AFF. Para obtener más información sobre Trident con Kubernetes en ONTAP AI, consulte<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">En la siguiente tabla se enumeran los componentes de software necesarios para implementar la solución según se ha probado.</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">Versión u otra información</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">Software de gestión de datos ONTAP de NetApp</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Firmware de switch Cisco NX-OS</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3)I6(1)</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">SO DGX DE NVIDIA</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">La versión de Kubernetes</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Versión de Trident</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">Ejecución: CLI de IA</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">Ejecutar:versión del operador de Kubernetes de orquestación de IA</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Plataforma contenedora Docker</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-ce [e68fc7a]</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">Ejecutar:requisitos previos del clúster de GPU de IA</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">Requisitos de software adicionales para la ejecución: Se puede encontrar IA en<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">Siguiente: Uso óptimo de la GPU y del clúster con Run AI</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Se llevaron a cabo una multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta. Existen seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeño], detección de objetos [grande], imágenes médicas, voz a texto, Y procesamiento de lenguaje natural [NLP]), que se puede ejecutar en tres escenarios diferentes: Sin conexión, flujo único y multisecuencia.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Resultados de la prueba</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">Anterior: Procedimiento de prueba.</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">Resultados de la prueba para AFF</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">Se llevaron a cabo una multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta. Existen seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeño], detección de objetos [grande], imágenes médicas, voz a texto, Y procesamiento de lenguaje natural [NLP]), que se puede ejecutar en tres escenarios diferentes: Sin conexión, flujo único y multisecuencia.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">El último escenario se implementa sólo para la clasificación de imágenes y la detección de objetos.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Esto permite 15 cargas de trabajo posibles, todas ellas probadas en tres configuraciones diferentes:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Un único servidor/almacenamiento local</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Almacenamiento único de servidor/red</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Almacenamiento en red/multiservidor</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Los resultados se describen en las siguientes secciones.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inferencia de la IA en un escenario sin conexión para AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">En este escenario, todos los datos estaban disponibles para el servidor y se midió el tiempo que se tardaba en procesar todas las muestras. Reportamos los anchos de banda en muestras por segundo como resultados de las pruebas. Cuando se utilizaron más de un servidor informático, hemos indicado el total de ancho de banda total en todos los servidores. En la siguiente figura se muestran los resultados de los tres casos de uso. Para el caso de dos servidores, reportamos un ancho de banda combinado de ambos servidores.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Los resultados muestran que el almacenamiento en red no afecta de manera negativa al rendimiento; el cambio es mínimo y, en algunas tareas, no se encuentra ninguno. Cuando se añade el segundo servidor, el ancho de banda total se duplica exactamente o, en el peor de los casos, el cambio es inferior al 1%.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inferencia de IA en un escenario de flujo único para AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Esta prueba mide la latencia. Para el caso de varios servidores informáticos, reportamos la latencia media. Los resultados del conjunto de tareas se indican en la siguiente figura. Para el caso de dos servidores, hemos registrado la latencia media de ambos servidores.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Los resultados, de nuevo, muestran que el almacenamiento de red es suficiente para manejar las tareas. La diferencia entre el almacenamiento local y el de red en un caso de servidor es mínima o ninguna. De igual modo, cuando dos servidores utilizan el mismo almacenamiento, la latencia de ambos servidores se mantiene igual o se modifica en una cantidad muy pequeña.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inferencia de IA en un escenario de transmisión múltiple para AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">En este caso, el resultado es el número de flujos que el sistema puede manejar mientras se satisface la restricción QoS. Por lo tanto, el resultado siempre es un entero. En más de un servidor, reportamos el número total de flujos sumados en todos los servidores. No todas las cargas de trabajo admiten este escenario, pero hemos ejecutado las que lo hacen. Los resultados de nuestras pruebas se resumen en la siguiente figura. Para el caso de dos servidores, reportamos el número combinado de flujos de ambos servidores.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Los resultados muestran un rendimiento perfecto de la configuración; el almacenamiento local y en red ofrecen los mismos resultados y al añadir el segundo servidor se duplica el número de flujos que puede gestionar la configuración propuesta.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Resultados de la prueba para EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Se llevaron a cabo una multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta. Existen seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeño], detección de objetos [grande], imágenes médicas, voz a texto, Y procesamiento de lenguaje natural [NLP]), que se ejecutaron en dos escenarios diferentes: Offline y de flujo único. Los resultados se describen en las siguientes secciones.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inferencia de la IA en un escenario sin conexión para EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">En este escenario, todos los datos estaban disponibles para el servidor y se midió el tiempo que se tardaba en procesar todas las muestras. Reportamos los anchos de banda en muestras por segundo como resultados de las pruebas. En las ejecuciones de un solo nodo reportamos la media de ambos servidores, mientras que en dos ejecuciones de servidor reportamos un ancho de banda total resumido en todos los servidores. Los resultados de los casos de uso se muestran en la siguiente figura.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inferencia de IA en un escenario de flujo único para EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Esta prueba mide la latencia. En todos los casos, reportamos una latencia media en todos los servidores involucrados en las ejecuciones. Los resultados para el conjunto de tareas se dan.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Los resultados muestran de nuevo que el almacenamiento en red es suficiente para manejar las tareas. La diferencia entre el almacenamiento local y el de red en un caso de servidor es mínima o ninguna. De igual modo, cuando dos servidores utilizan el mismo almacenamiento, la latencia de ambos servidores se mantiene igual o se modifica en una cantidad muy pequeña.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">Siguiente: Opciones de ajuste de tamaño de arquitecturas.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y sitios web.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">Información adicional</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Si quiere más información sobre el contenido de este documento, consulte los siguientes documentos o sitios web:</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">Conjunto de datos: TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">Arquitectura de redes de aprendizaje profundo: Red neuronal convolucional espacial</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">Marco de entrenamiento de aprendizaje profundo distribuido: Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">EJECUCIÓN: Solución de orquestación de contenedores de IA: EJECUCIÓN: Introducción del producto de IA</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">EJECUCIÓN: Documentación de instalación de IA</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">Envío de trabajos EN EJECUCIÓN: Interfaz de línea de comandos de IA</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Recursos de cloud para Azure: Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">SKU de Azure VM</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Azure VM con SKU de GPU</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">Data Fabric con tecnología de NetApp</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentación de productos de NetApp</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Ejemplo de operaciones y tareas de Kubeflow</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">Esta sección incluye ejemplos de diversas operaciones y tareas que puede que desee realizar utilizando Kubeflow.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">Siguiente: Proporcione un espacio de trabajo para portátiles Juppyter para uso científico de datos o desarrollador.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">Esta página describe la configuración de los recursos de cloud para Azure NetApp Files.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">Requisitos de recursos cloud</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Anterior: Requisitos de software.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Configure Azure NetApp Files</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">Inicio rápido: Configure Azure NetApp Files y cree un volumen NFS</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">Configure Azure NetApp Files como se describe en<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">Puede pasar más allá de la sección “Crear volumen NFS para Azure NetApp Files” porque va a crear volúmenes a través de Trident. Antes de continuar, realice los siguientes pasos:</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">enlace</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Regístrese para Azure NetApp Files y el proveedor de recursos de NetApp (a través de la shell de Azure) (<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>).</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Crear una cuenta en Azure NetApp Files (<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>).</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">Configurar un pool de capacidad (un estándar o Premium de 4 TB como mínimo, según sus necesidades) (<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>).la siguiente tabla enumera los requisitos de configuración de red para configurar en la nube. El clúster de DASK y Azure NetApp Files deben estar en la misma red virtual de Azure (vnet) o en una vnet con conexión entre iguales.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">Recursos</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">Tipo/versión</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">Nodo de agente</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">Nodo GPU</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3x Standard_NC63_v3</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="cell">Azure NetApp Files</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">Pool de capacidad estándar</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">Capacidad en TB</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">Siguiente: Resumen de casos de uso de predicción de velocidad mediante clic.</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">EF-Series AI de NetApp con NVIDIA</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">Descripción general de las soluciones de infraestructura convergente de EF-Series de NetApp y NVIDIA.</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="section-title">IA de EF-Series con sistemas NVIDIA DGX A100 y BeeGFS</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">Guía de diseño</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">Guía de puesta en marcha</block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">Guía de implementación de BeeGFS</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">Desde mayo de 2019, Microsoft proporciona un servicio de portal nativo de Azure para servicios de archivos NFS y SMB empresariales basados en la tecnología ONTAP de NetApp.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896: Formación distribuida en Azure: Detección de carriles - diseño de soluciones</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad y Verron Martina, NetApp Ronen dar, RUN:AI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">Desde mayo de 2019, Microsoft proporciona un servicio de portal nativo de Azure para servicios de archivos NFS y SMB empresariales basados en la tecnología ONTAP de NetApp. Este desarrollo está impulsado por una asociación estratégica entre Microsoft y NetApp, y amplía aún más el alcance de los servicios de datos de ONTAP de primera calidad para Azure.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">NetApp, un proveedor líder de servicios de datos en el cloud, se ha Unido para EJECUTARSE: IA, una empresa que virtualiza la infraestructura de IA, para permitir una experimentación de IA más rápida con un uso completo de la GPU. Esta alianza permite a los equipos acelerar la IA ejecutando muchos experimentos en paralelo, con un acceso rápido a los datos y aprovechando recursos informáticos ilimitados. EJECUTAR: La IA permite el uso completo de la GPU al automatizar la asignación de recursos y la arquitectura contrastada de Azure NetApp Files permite que cada experimento se ejecute a la máxima velocidad al eliminar las obstrucciones de la canalización de datos.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp y EJECUTE: La IA ha Unido sus fuerzas para ofrecer a sus clientes una plataforma preparada para el futuro en su viaje a la IA en Azure. Desde el análisis y la computación de alto rendimiento (HPC) hasta las decisiones autónomas (en las que los clientes pueden optimizar sus inversiones EN TECNOLOGÍA pagando solo por lo que necesitan y cuando lo necesitan), la alianza entre NetApp Y RUN: La IA ofrece una única experiencia unificada en el cloud de Azure.</block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Para ejecutar un trabajo de varios nodos de IA y ML en su clúster de Kubernetes, lleve a cabo las tareas enumeradas en esta página en el host de saltos de la puesta en marcha. Este proceso le permite aprovechar los datos almacenados en un volumen de NetApp y utilizar más GPU de las que puede proporcionar un único nodo de trabajo.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Ejecute una carga de trabajo de IA distribuida síncrona</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Para ejecutar un trabajo de IA y ML multinodo síncrono en un clúster de Kubernetes, lleve a cabo las siguientes tareas en el host de saltos de la puesta en marcha. Este proceso le permite aprovechar los datos almacenados en un volumen de NetApp y utilizar más GPU de las que puede proporcionar un único nodo de trabajo. Consulte la siguiente figura para obtener una descripción de un trabajo de IA distribuido sincrónica.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Los trabajos distribuidos síncronos pueden ayudar a aumentar el rendimiento y la precisión de la formación en comparación con los trabajos distribuidos de manera asíncrona. Un análisis de los pros y los contras de los trabajos síncronos frente a los trabajos asincrónicos está fuera del alcance de este documento.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Ejecute una carga de trabajo de IA de un solo nodo</block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">En los siguientes comandos de ejemplo, se muestra la creación de un trabajador que participa en la ejecución síncrona y distribuida de la misma tarea de prueba de rendimiento TensorFlow que se ejecutó en un solo nodo en el ejemplo de la sección <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. En este ejemplo específico, sólo se implementa un único trabajador porque el trabajo se ejecuta en dos nodos de trabajo.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Documentación oficial sobre Kubernetes</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Esta puesta en marcha de trabajo de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un único nodo de trabajo de GPU con ocho o más GPU. Si los nodos de trabajo de la GPU tienen más de ocho GPU, para maximizar el rendimiento, es posible que desee aumentar este número para ser igual al número de GPU que disponen los nodos de trabajo. Para obtener más información sobre las puestas en marcha de Kubernetes, consulte<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">En este ejemplo se crea una puesta en marcha de Kubernetes, ya que este trabajador en contenedor específico nunca lo completaría por sí solo. Por lo tanto, no tiene sentido implementarlo usando la construcción de trabajos de Kubernetes. Si su trabajador está diseñado o escrito para completar por sí solo, entonces podría tener sentido utilizar la construcción del trabajo para desplegar a su trabajador.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">El POD especificado en esta especificación de implementación de ejemplo recibe una<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Este valor significa que el pod utiliza la pila de red del nodo de trabajo del host en lugar de la pila de red virtual que Kubernetes suele crear para cada pod. Esta anotación se utiliza en este caso porque la carga de trabajo específica depende de Open MPI, NCCL y Horovod para ejecutar la carga de trabajo de forma síncrona distribuida. Por lo tanto, requiere acceso a la pila de red del host. Un debate sobre Open MPI, NCCL y Horovod está fuera del alcance de este documento. Si esto o no<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> la anotación es necesaria depende de los requisitos de la carga de trabajo específica que se esté ejecutando. Para obtener más información acerca de<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> consulte<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Confirme que el despliegue del trabajador que creó en el paso 1 se inició correctamente. Los siguientes comandos de ejemplo confirman que se creó un solo pod de trabajadores para la implementación, tal y como se indica en la definición de la puesta en marcha, y que este pod se ejecuta actualmente en uno de los nodos de trabajo de la GPU.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">Cree un trabajo de Kubernetes en un maestro que se inicia, participe y realice un seguimiento de la ejecución de un trabajo de varios nodos síncronos. Los siguientes comandos de ejemplo crean un maestro que inicia sesión, participa en y realiza un seguimiento de la ejecución síncrona distribuida de la misma tarea de prueba de rendimiento TensorFlow que se ejecutó en un solo nodo del ejemplo de la sección <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Este trabajo maestro de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un único nodo de trabajo de GPU con ocho o más GPU. Si los nodos de trabajo de la GPU tienen más de ocho GPU, para maximizar el rendimiento, es posible que desee aumentar este número para ser igual al número de GPU que disponen los nodos de trabajo.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">El POD maestro especificado en esta definición de trabajo de ejemplo recibe una<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>, así como se le dio a la cápsula de trabajo un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> en el paso 1. Consulte el paso 1 para obtener más información acerca de por qué es necesario este valor.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Confirme que el trabajo maestro que creó en el paso 3 se está ejecutando correctamente. El siguiente comando de ejemplo confirma que se creó un único pod maestro para el trabajo, tal como se indica en la definición de trabajos, y que este pod se ejecuta actualmente en uno de los nodos de trabajo de la GPU. También debe ver que el pod de trabajo que originalmente vio en el paso 1 sigue en ejecución y que los pods maestro y trabajador se ejecutan en diferentes nodos.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Confirme que el trabajo maestro que ha creado en el paso 3 se ha completado correctamente. Los siguientes comandos de ejemplo confirman que el trabajo se ha completado correctamente.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Elimine la implementación del trabajador cuando ya no la necesite. Los siguientes comandos de ejemplo muestran la eliminación del objeto de implementación de trabajo que se creó en el paso 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Cuando se elimina el objeto de implementación de trabajo, Kubernetes elimina automáticamente todos los pods de trabajador asociados.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Opcional:* Limpie los artefactos del trabajo maestro. Los siguientes comandos de ejemplo muestran la eliminación del objeto de trabajo maestro que se creó en el paso 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Cuando se elimina el objeto de trabajo maestro, Kubernetes elimina automáticamente todos los pods maestros asociados.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">Siguiente: Pruebas de rendimiento.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">Utilice Cloud Sync de NetApp para archivar el historial de conversaciones</block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="inline-link-macro">Expanda modelos de intención utilizando Nemo Training</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">Al volcar el historial de conversaciones en un archivo CSV una vez al día, podemos utilizar Cloud Sync para descargar los archivos de registro en el almacenamiento local. La siguiente figura muestra la arquitectura de la implementación de Jarvis en las instalaciones y en las nubes públicas, mientras que utiliza Cloud Sync para enviar historia de conversación para la formación de Nemo. En la sección encontrará más información sobre la formación de Nemo <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">Siguiente: Expanda modelos de intención utilizando Nemo Training</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">En esta sección se describen los pasos detallados necesarios para poner en marcha esta solución.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">Implementar el análisis de confianza del centro de soporte</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">Anterior: Consideraciones de diseño.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">La implementación de la solución consta de los siguientes componentes:</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">Configuración de NGC</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">Servidor NVIDIA RIVA</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">Kit de herramientas TAO de NVIDIA</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">Exportar modelos TAO a RIVA</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">Para realizar la implementación, lleve a cabo los siguientes pasos:</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">Kit de herramientas Data OPS de NetApp: Compatibilidad con el análisis de confianza del centro de soporte</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">Para utilizar la<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, lleve a cabo los siguientes pasos:</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">Instalación del kit de herramientas de PIP.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">Configurar la gestión de datos</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">Configuración de NGC: Respaldar el análisis de confianza del centro</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">Para configurar<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>, lleve a cabo los siguientes pasos:</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">Descargar el NGC.</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">Agregue su directorio actual a la ruta de acceso.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">Debe configurar la CLI de NGC para su uso con el fin de poder ejecutar los comandos. Introduzca el siguiente comando, incluida su clave de API cuando se le solicite.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">aquí</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Para sistemas operativos que no están basados en Linux, visite<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA RIVA Server: Análisis de opinión del centro de soporte</block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link">RIVA DE NVIDIA</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">Para configurar<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>, lleve a cabo los siguientes pasos:</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">Descargar los archivos RIVA de NGC.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Inicialice LA configuración DE RIVA <block ref="b57bfc797452f0a8f165771280704dc4" prefix="(" category="inline-code"></block>).</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Inicie EL servidor RIVA <block ref="9578e0f1e91365703f275dd0aa9dd913" prefix="(" category="inline-code"></block>).</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Inicie EL cliente RIVA <block ref="98e192e15ed3b76551ab5ef8d11ef1e8" prefix="(" category="inline-code"></block>).</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFMPEG</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">En EL cliente RIVA, instale la biblioteca de procesamiento de audio (<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="inline-link">Juppyter</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">Inicie el<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> servidor.</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Ejecute el portátil de canalización de inferencia DE RIVA.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">Kit de herramientas TAO de NVIDIA: Análisis de opinión del centro de soporte</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">Para configurar NVIDIA TAO Toolkit, lleve a cabo los siguientes pasos:</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">entorno virtual</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">Prepare y active una<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> Para TAO Toolkit.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">paquetes requeridos</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">Instale el<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">Tire manualmente de la imagen utilizada durante el entrenamiento y ajuste preciso.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">Ejecute el cuaderno TAO de afinación fina.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">Exportar modelos TAO a RIVA: Apoyar el análisis de confianza del centro</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Modelos TAO Toolkit EN RIVA</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">Para usar<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>, lleve a cabo los siguientes pasos:</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">Guarde los modelos en el cuaderno TAO de sintonización fina.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">Copie los modelos TAO entrenados en el directorio del modelo RIVA.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">Obstáculos para la implementación</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">Estas son algunas cosas que debe tener en cuenta a medida que desarrolla su propia solución:</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">El kit de herramientas Data OPS de NetApp se instala primero para garantizar que el sistema de almacenamiento de datos se ejecute de forma óptima.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC debe instalarse antes de cualquier otra cosa porque autentica la descarga de imágenes y modelos.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">RIVA se debe instalar antes que TAO Toolkit. LA instalación DE RIVA configura el demonio docker para extraer imágenes según sea necesario.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">El DGX y el docker deben tener acceso a Internet para descargar los modelos.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">Siguiente: Resultados de validación.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">Detalles de las pruebas para la sección 4.10</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">Justicia por exceso de cuotas</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">Esta sección contiene detalles de la prueba para la sección <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">Enviar trabajos en el siguiente orden para<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, y.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>:</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">Proyecto</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">N.o de GPU</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">Total</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Comentar</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">equipo a</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4/4</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 carga de trabajo en cola</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 cargas de trabajo en cola</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">equipo-b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">equipo-c</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">Consulte la siguiente secuencia de comandos ejecutada:</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">En este punto, debe tener los siguientes estados:</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU asignadas</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">Cargas de trabajo en cola</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">Dos cargas de trabajo que solicitan GPU dos cada una</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">Dos cargas de trabajo que solicitan dos GPU cada una</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">equipo d</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8/8</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">Ninguno</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">A continuación, elimine todas las cargas de trabajo para<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block>:</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">Consulte la sección <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, para las discusiones sobre el escenario de pruebas en curso.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">Configurar entorno de trabajo</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">Copie el<block ref="3a4f8d88ea1eac117f98223609194cb9" prefix=" " category="inline-code"></block><block ref="4931c948234bb20e1915f851691b340a" prefix=" " category="inline-code"></block> como<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Abrir y editar<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Este cuaderno establece variables para las credenciales, ubicaciones de archivos y controladores de ejecución.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">Si sigue las instrucciones anteriores, los pasos siguientes son los únicos cambios que se deben realizar:</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">Obtenga este valor desde el panel de servicios de Iguazio:<block ref="bed2ad53cc10d1f92b477fc7c1476348" prefix=" " category="inline-code"></block></block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">Ejemplo:<block ref="0ddf9a06edec7d150708463603b95f22" prefix=" " category="inline-code"></block></block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">Cambiar<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block> A su nombre de usuario de Iguazio:</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph"><block ref="0458c1c280a715ecb31b33b5269e101b" prefix="" category="inline-code"></block></block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">A continuación, se muestran los detalles de conexión del sistema ONTAP. Incluya el nombre del volumen que se generó al instalar Trident. La siguiente configuración es para un clúster ONTAP en las instalaciones:</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">La siguiente configuración es para Cloud Volumes ONTAP:</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">Cree imágenes Docker básicas</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">Todo lo que necesita para construir un ducto ML está incluido en la plataforma Iguazio. El desarrollador puede definir las especificaciones de las imágenes Docker necesarias para ejecutar la canalización y ejecutar la creación de imágenes desde el portátil Jupyter. Abra el portátil<block ref="61dfd8901a62e0f1e23dd2f5029d2639" prefix=" " category="inline-code"></block> Y ejecute todas las celdas.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">Este cuaderno crea dos imágenes que utilizamos en la canalización.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text"><block ref="b636b23a5b442c01733e45c199c11f56" prefix="" category="inline-code"></block> Se utiliza para manejar tareas ML.</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text"><block ref="c59e60c5a3880eb8018ae68eaa70621c" prefix="" category="inline-code"></block>. Contiene utilidades para gestionar las copias snapshot de NetApp.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Revise los cuadernos Juppyter individuales</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">En la siguiente tabla se enumeran las bibliotecas y los marcos que utilizamos para crear esta tarea. Todos estos componentes se han integrado plenamente con los controles de seguridad y acceso basados en funciones de Iguazio.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">Bibliotecas/Marco</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Descripción</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Un gestionado por Iguazio para permitir el montaje, ejecución y supervisión de una canalización ML/IA.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nuclio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Un marco de funciones sin servidor integrado con Iguazio. También disponible como proyecto de código abierto gestionado por Iguazio.</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">Un marco basado en Kubernetes para poner en marcha la canalización. Este es también un proyecto de código abierto al que colabora Iguazio. Se integra con Iguazio para una mayor seguridad e integración con el resto de la infraestructura.</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Un registro Docker se ejecuta como servicio en la plataforma Iguazio. También puede cambiar esta opción para conectarse al registro.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">Cloud Volumes de NetApp</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">Cloud Volumes que se ejecuta en AWS nos proporciona acceso a grandes cantidades de datos y la capacidad de realizar copias de Snapshot para versiones de los conjuntos de datos utilizados para el entrenamiento.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="cell">Trident</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident es un proyecto de código abierto gestionado por NetApp. Facilita la integración con los recursos de almacenamiento y computación en Kubernetes.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">Hemos utilizado varios portátiles para construir la canalización DE ML. Cada portátil puede probarse individualmente antes de ser reunido en la tubería. Cubrimos cada portátil individualmente tras el flujo de despliegue de esta aplicación de demostración.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">El resultado deseado es una canalización que entrena un modelo basado en una copia Snapshot de los datos y pone en marcha el modelo para la inferencia. En la siguiente imagen se muestra un diagrama de bloque de una canalización MLRun completada.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">Ponga en marcha la función de generación de datos</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">En esta sección se describe cómo utilizamos las funciones de Nuclio serverless para generar datos de dispositivos de red. El caso de uso se adapta a partir de un cliente Iguazio que ha implementado la canalización y utiliza servicios Iguazio para supervisar y predecir los fallos del dispositivo de red.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Sitio Web de Nuclio</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">Simulamos los datos procedentes de dispositivos de red. Ejecución del cuaderno Juppyter<block ref="c2d07e7698686359c0371f481d2cc628" prefix=" " category="inline-code"></block> Crea una función sin servidor que se ejecuta cada 10 minutos y genera un archivo Parquet con nuevos datos. Para implementar la función, ejecute todas las celdas de este portátil. Consulte<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> para revisar cualquier componente desconocido en este cuaderno.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">Al generar la función, se ignora una celda con el siguiente comentario. Se asume que todas las celdas del portátil forman parte de la función. Importe el módulo Nuclio para activarlo<block ref="85b0176bddfe93e918b8de4cb894780c" prefix=" " category="inline-code"></block>.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">En la especificación para la función, definimos el entorno en el que se ejecuta la función, cómo se activa y los recursos que consume.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">La<block ref="b73982aa3ac6ac19ba867eb2f5819797" prefix=" " category="inline-code"></block> La función es invocada por el marco Nuclio tras la inicialización de la función.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">Cualquier código que no esté en una función se invoca cuando se inicializa la función. Cuando lo invoca, se ejecuta una función de controlador. Puede cambiar el nombre del controlador y especificarlo en la especificación de función.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">Puede probar la función desde el portátil antes de la implementación.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">La función puede desplegarse desde el portátil o puede desplegarse a partir de una canalización CI/CD (adaptando este código).</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">Cuadernos de pipeline</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">Estos cuadernos no están diseñados para ejecutarse individualmente para esta configuración. Esto es sólo una revisión de cada bloc de notas. Los invocamos como parte del proyecto. Para ejecutarlas individualmente, revise la documentación MLRun para ejecutarlas como trabajos de Kubernetes.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">snap_cv.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">Este portátil gestiona las copias snapshot de Cloud Volume al principio de la canalización. Pasa el nombre del volumen al contexto de la canalización. Este cuaderno invoca un script de shell para manejar la copia Snapshot. Mientras se ejecuta en la canalización, el contexto de ejecución contiene variables que ayudan a localizar todos los archivos necesarios para su ejecución. Mientras escribe este código, el desarrollador no tiene que preocuparse por la ubicación del archivo en el contenedor que lo ejecuta. Como se describe más tarde, esta aplicación se implementa con todas sus dependencias y es la definición de los parámetros de canalización que proporciona el contexto de ejecución.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">La ubicación de la copia Snapshot creada se coloca en el contexto de MLRun que consumirán los pasos de la canalización.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">Los siguientes tres portátiles se ejecutan en paralelo.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">data-prep.ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">Las métricas sin formato deben convertirse en funciones para permitir el entrenamiento de modelos. Este cuaderno lee las métricas sin formato del directorio Snapshot y escribe las funciones de entrenamiento de modelos en el volumen de NetApp.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">Cuando se ejecuta en el contexto de la canalización, la entrada<block ref="6ca3f4659530db0c27f67623bd27b304" prefix=" " category="inline-code"></block> Contiene la ubicación de la copia Snapshot.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">describa.ipynb</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">Para visualizar las métricas entrantes, implementamos un paso de canalización que proporciona gráficos y gráficos disponibles a través de las interfaces de usuario de Kubeflow y MLRun. Cada ejecución tiene su propia versión de esta herramienta de visualización.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">Supervisamos continuamente las métricas en busca de anomalías. Este bloc de notas crea una función sin servidor que genera las funciones que necesitan ejecutar la predicción en las métricas entrantes. Este cuaderno invoca la creación de la función. El código de función se encuentra en el portátil<block ref="ddc05946399cb9a8e617080738240288" prefix=" " category="inline-code"></block>. Observe que utilizamos el mismo bloc de notas como un paso en la tubería para este propósito.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">training.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">Una vez que creamos las funciones, activamos la formación del modelo. El resultado de este paso es el modelo que se va a utilizar para la inferencia. También recopilamos estadísticas para realizar un seguimiento de cada ejecución (experimento).</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">Por ejemplo, el siguiente comando introduce la puntuación de precisión en el contexto de ese experimento. Este valor es visible en Kubeflow y MLRun.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">despliegue-inferencia-function.ipynb</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">El último paso de la canalización es poner en marcha el modelo como una función sin servidor para la inferencia continua. Este cuaderno invoca la creación de la función sin servidor definida en<block ref="8484275272e5c25a4b20c092eaed5ed3" prefix=" " category="inline-code"></block>.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">Revisar y crear el canalización</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">La combinación de ejecutar todos los portátiles en una tubería permite que la ejecución continua de experimentos reevalúe la precisión del modelo con las nuevas métricas. En primer lugar, abra la<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> portátil. Le repasamos por los detalles que muestran cómo NetApp y Iguazio simplifican la puesta en marcha de esta canalización DE ML.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">Utilizamos MLRun para proporcionar contexto y manejar la asignación de recursos a cada paso de la canalización. El servicio de API MLRun se ejecuta en la plataforma Iguazio y es el punto de interacción con los recursos de Kubernetes. Cada desarrollador no puede solicitar recursos directamente; la API gestiona las solicitudes y habilita los controles de acceso.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">La canalización puede funcionar con Cloud Volumes de NetApp y los volúmenes en las instalaciones. Hemos creado esta demostración para usar Cloud Volumes, pero puede ver en el código la opción para ejecutarse en las instalaciones.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">La primera acción necesaria para convertir un cuaderno Juppyter en un paso de Kubeflow es convertir el código en una función. Una función tiene todas las especificaciones necesarias para ejecutar ese portátil. A medida que se desplaza hacia abajo por el bloc de notas, puede ver que definimos una función para cada paso de la canalización.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">Parte del portátil</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to_function&gt; (parte del módulo MLRun)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">Nombre de la función: Nombre del proyecto. se utiliza para organizar todos los artefactos del proyecto. Esto es visible en la interfaz de usuario de MLRun. Amable. En este caso, un trabajo de Kubernetes. Esto podría ser DASK, mpi, sparkk8s, y más. Consulte la documentación de MLRun para obtener más detalles. Archivo. El nombre del portátil. También puede ser una ubicación en Git (HTTP).</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">imagen</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">El nombre de la imagen de Docker que estamos utilizando para este paso. Lo hemos creado anteriormente con el bloc de notas create-image.ipynb.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">montajes_volúmenes y volúmenes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">Detalles para montar el Cloud Volume de NetApp en tiempo de ejecución.</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">También definimos parámetros para los pasos.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">Después de tener la definición de función para todos los pasos, puede construir la canalización. Utilizamos la<block ref="98dd4155c9c8287a5a8e1d92417d0a99" prefix=" " category="inline-code"></block> módulo para realizar esta definición. La diferencia entre el uso de MLRun y la construcción por su cuenta es la simplificación y el acortamiento de la codificación.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">Las funciones definidas se convierten en componentes de pasos mediante el<block ref="6cebb60f71d9de65143ade7a8388e27a" prefix=" " category="inline-code"></block> Función de MLRun.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">Definición de paso de instantánea</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Inicie una función Snapshot, la salida y el montaje v3io como fuente:</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parámetros</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">Nueva tarea</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">Newtask es la definición de la ejecución de la función.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(Módulo MLRun)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">Manipulador. Nombre de la función Python que se va a invocar. Utilizamos el controlador de nombres en el portátil, pero no es necesario. parámetros. Los parámetros que pasamos a la ejecución. Dentro de nuestro código, utilizamos context.get_param («PARAMETER») para obtener los valores.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">paso_as</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">Nombre. Nombre del paso de la canalización de Kubeflow. salidas. Estos son los valores que el paso agrega al diccionario al terminar. Eche un vistazo al portátil SNAP_cv.ipynb. mount_v3io(). Esto configura el paso para montar /User para el usuario que ejecuta la canalización.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">entradas</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">Puede pasar a un paso las salidas de un paso anterior. En este caso, snap.outsits[napVolumeDetails] es el nombre de la copia Snapshot que creamos en el paso snap.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">ruta de salida</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">Ubicación para colocar artefactos que generan utilizando el módulo MLRun log_Artifacts.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">Puede ejecutar<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> de arriba a abajo. A continuación, puede ir a la pestaña tuberías desde el panel de control de Iguazio para supervisar el progreso tal y como se ve en la pestaña tuberías del panel de control de Iguazio.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">Debido a que hemos registrado la precisión del paso de entrenamiento en cada carrera, tenemos un registro de precisión para cada experimento, como se ve en el registro de precisión de entrenamiento.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Si selecciona el paso Snapshot, puede ver el nombre de la copia Snapshot que se utilizó para ejecutar este experimento.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">El paso descrito tiene artefactos visuales para explorar las métricas que utilizamos. Puede expandir para ver el trazado completo como se ve en la siguiente imagen.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">La base de datos de la API MLRun también realiza un seguimiento de las entradas, salidas y artefactos de cada ejecución organizada por el proyecto. En la siguiente imagen se puede ver un ejemplo de entradas, salidas y artefactos para cada secuencia.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">Para cada trabajo, almacenamos detalles adicionales.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">Sitio de MLRun GitHub</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">Hay más información sobre MLRun que podemos cubrir en este documento. Los artefactos de al, incluida la definición de los pasos y las funciones, se pueden guardar en la base de datos de API, con versiones e invocados individualmente o como un proyecto completo. Los proyectos también se pueden guardar e insertar en Git para su uso posterior. Le animamos a obtener más información en la<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">Siguiente: Implemente la consola de Grafana</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run AI se ha asociado para la creación de este informe técnico con el fin de demostrar las exclusivas funcionalidades de Azure NetApp Files junto con la plataforma DE EJECUCIÓN de IA para simplificar la orquestación de las cargas de trabajo de IA.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp and RUN: IA se ha asociado en la creación de este informe técnico para mostrar las funcionalidades únicas de la Azure NetApp Files junto con LA EJECUCIÓN: Plataforma de IA para simplificar la orquestación de las cargas de trabajo de IA. Este informe técnico proporciona una arquitectura de referencia para optimizar el proceso de canalizaciones de datos y orquestación de cargas de trabajo para la formación en la detección de carriles distribuidos.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">En conclusión, con respecto a la formación distribuida a escala (especialmente en un entorno de cloud público), la orquestación de recursos y el componente de almacenamiento son una parte fundamental de la solución. Asegurarse de que la gestión de datos nunca afecta al procesamiento de varias GPU, por lo que se traduce en una utilización óptima de los ciclos de la GPU. Por lo tanto, hacer que el sistema sea lo más rentable posible para fines de capacitación distribuidos a gran escala.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">El Data Fabric que ofrece NetApp supera el reto al permitir a los científicos e ingenieros de datos conectarse entre sí tanto en las instalaciones como en el cloud disponer de datos síncronos sin realizar ninguna intervención manual. En otras palabras, el tejido de datos suaviza el proceso de gestión del flujo de trabajo de IA expandiéndose por varias ubicaciones. También facilita la disponibilidad de datos basada en demanda al acercar los datos a la computación y realizar análisis, formación y validación donde y cuando sea necesario. Esta funcionalidad no solo permite la integración de datos, sino también la protección y seguridad de toda la canalización de datos.</block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">Descripción general de la configuración</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Instalación de Iguazio</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio se puede instalar de forma local o en un proveedor de cloud. El aprovisionamiento puede realizarse como servicio y gestionado por Iguazio o por el cliente. En ambos casos, Iguazio ofrece una aplicación de despliegue (Proventio) para implementar y gestionar clústeres.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">esta página</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">Para la instalación en las instalaciones, consulte<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> para la configuración de computación, red y almacenamiento. La implantación en las instalaciones de Iguazio es proporcionada por Iguazio sin costes adicionales para el cliente. Consulte<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> Para configuraciones de servidores DNS y SMTP. La página de instalación de Proventio se muestra a continuación.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">Siguiente: Configurar Kubernetes Cluster</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">Resultados de validación</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">Para ejecutar una solicitud de inferencia de ejemplo, lleve a cabo los siguientes pasos:</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">Obtenga un shell en el contenedor/pod del cliente.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">Ejecute una solicitud de inferencia de muestra.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">Esta solicitud de inferencia llama al<block ref="e8121e2c92eb0c17d4d331407502d266" prefix=" " category="inline-code"></block> modelo que se utiliza para el reconocimiento de imágenes. Otros clientes también pueden enviar solicitudes de inferencia simultáneamente siguiendo un enfoque similar y llamando al modelo apropiado.</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">Una vez que todo se pone en marcha, ejecute inferencias sobre nuevos datos. Los modelos predicen si un usuario hace clic en un anuncio basado en actividades de navegación. Los resultados de la predicción se almacenan en un cuDF de DASK. Puede supervisar los resultados con Prometheus y visualizar en paneles Grafana.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Monitorizar Dink y RAPIDS con Prometheus y Grafana</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">Anterior: Comparación de tiempo de entrenamiento.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS AI Media Post</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">Para obtener más información, consulte este tema<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">Siguiente: Versiones de conjuntos de datos y modelos con el kit de herramientas de operaciones de datos de NetApp.</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">En esta sección se proporcionan detalles sobre la configuración de la plataforma para la realización de formación distribuida de detección de carriles a escala mediante EL orquestador RUN AI.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">Detección de carriles: Formación distribuida con RUN:AI</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">En esta sección se ofrecen detalles sobre la configuración de la plataforma para la realización de formación distribuida de detección de carriles a escala mediante EL orquestador de IA. Se trata de la instalación de todos los elementos de la solución y de la ejecución del trabajo de formación distribuido en dicha plataforma. EL versionado DE ML se completa utilizando SnapshotTM de NetApp vinculado A RUN: Experimentos de IA para conseguir la reproducibilidad de los datos y los modelos. LA creación de versiones DE ML desempeña un papel fundamental en el seguimiento de modelos, el intercambio de trabajo entre miembros del equipo, la reproducibilidad de resultados, la implementación de nuevas versiones de modelos a la producción y la procedencia de los datos. El control de versiones DE NetApp ML (Snapshot) puede capturar versiones puntuales de los datos, modelos entrenados y registros asociados con cada experimento. Cuenta con un amplio soporte en la API que facilita la integración con la plataforma DE IA RUN: Solo tiene que activar un evento basado en el estado de entrenamiento. También hay que capturar el estado de todo el experimento sin cambiar nada en el código o los contenedores que se ejecutan sobre Kubernetes (K8s).</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">Por último, este informe técnico se resume en la evaluación del rendimiento en varios nodos habilitados para GPU en toda la serie AKS.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">Formación distribuida para el caso de uso de detección de carriles mediante el conjunto de datos TuSimple</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">En este informe técnico, la formación distribuida se realiza en el conjunto de datos TuSimple para la detección de carriles. Horovod se utiliza en el código de entrenamiento para realizar el entrenamiento con datos distribuidos en varios nodos de GPU simultáneamente en el clúster de Kubernetes a través de AKS. El código se presenta como imágenes de contenedor para la descarga y el procesamiento de datos de TuSimple. Los datos procesados se almacenan en volúmenes persistentes asignados por el complemento Trident de NetApp. Para el entrenamiento, se crea una imagen de contenedor más y utiliza los datos almacenados en volúmenes persistentes creados durante la descarga de los datos.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">Para enviar el trabajo de datos y entrenamiento, use RUN: AI para orquestar la asignación y la gestión de recursos. RUN: AI le permite realizar operaciones de interfaz de paso de mensajes (MPI) que son necesarias para Horovod. Este diseño permite que varios nodos de GPU se comuniquen entre sí para actualizar los pesos de entrenamiento después de cada lote de entrenamiento. También permite supervisar el entrenamiento a través de la interfaz de usuario y la CLI, para facilitar la supervisión del progreso de los experimentos.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot se integra dentro del código de entrenamiento y captura el estado de los datos y el modelo entrenado para cada experimento. Esta funcionalidad le permite realizar un seguimiento de la versión de los datos y el código que se usan y del modelo entrenado asociado generado.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">Instalación e instalación de AKS</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">Cree un clúster de AKS</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">Para la configuración e instalación del clúster de AKS, vaya a.<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. A continuación, siga estos pasos:</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">Al seleccionar el tipo de nodos (ya sean nodos del sistema (CPU) o de trabajadores (GPU), seleccione lo siguiente:</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">Añada el nodo del sistema principal llamado<block ref="917718fb2e3dcf94043ea14d44580bc2" prefix=" " category="inline-code"></block> en la<block ref="2ec023527b0bfb6c720d8dd19493ad0d" prefix=" " category="inline-code"></block> tamaño. Utilice los tres nodos predeterminados.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Agregar nodo de trabajo<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block> con<block ref="801b9db365bdc8cd72301ec3fd4ed2ff" prefix=" " category="inline-code"></block> el tamaño del pool. Utilice un mínimo de tres nodos para los nodos GPU.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">La implementación tarda entre 5 y 10 minutos.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">Instalar herramientas</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">Una vez completada la implementación, haga clic en Connect to Cluster. Para conectarse al clúster AKS recién creado, instale la herramienta de línea de comandos Kubernetes desde su entorno local (portátil/PC). Visite<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> Para instalarlo según el sistema operativo.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">Instale el CLI de Azure en su entorno local</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">Para acceder al clúster AKS desde el terminal, primero introduzca<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> y coloque las credenciales.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">Ejecute los dos comandos siguientes:</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Introduzca este comando en la CLI de Azure:</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">Si los seis nodos están en funcionamiento como se ve aquí, su clúster de AKS estará listo y conectado a su entorno local.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">Cree una subred delegada para Azure NetApp Files</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Para crear una subred delegada para Azure NetApp Files, siga esta serie de pasos:</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Acceda a redes virtuales en el portal de Azure. Busque la red virtual que acaba de crear. Debería tener un prefijo como el de los robles-vnet, como se ve aquí. Haga clic en el nombre de la red virtual.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">Haga clic en subredes y seleccione +Subnet en la barra de herramientas superior.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">Proporcione la subred con un nombre como<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Y en el encabezado Delegación de subred, seleccione Microsoft.NetApp/volumes. No cambie nada más. Haga clic en Aceptar.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Los volúmenes Azure NetApp Files se asignan al clúster de aplicaciones y se consumen como reclamaciones de volúmenes persistentes (RVP) en Kubernetes. A su vez, esta asignación nos proporciona la flexibilidad para asignar volúmenes a diferentes servicios, ya sea ordenadores portátiles Jupyter, funciones sin servidor, etc.</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">Los usuarios de servicios pueden consumir almacenamiento desde la plataforma de muchas maneras. Las principales ventajas de Azure NetApp Files son:</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">Ofrece a los usuarios la capacidad de usar copias Snapshot.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Permite a los usuarios almacenar grandes cantidades de datos en volúmenes de Azure NetApp Files.</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Obtenga las ventajas en el rendimiento de los volúmenes de Azure NetApp Files cuando ejecute sus modelos en conjuntos de archivos de gran tamaño.</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Configuración de Azure NetApp Files</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">Inicio rápido: Configure Azure NetApp Files y cree un volumen NFS</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Para completar la configuración de Azure NetApp Files, primero debe configurarlo como se describe en<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">Sin embargo, puede omitir los pasos para crear un volumen NFS para Azure NetApp Files a medida que creará volúmenes a través de Trident. Antes de continuar, asegúrese de que dispone de:</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Registrado para Azure NetApp Files y el proveedor de recursos de NetApp (a través de Azure Cloud Shell)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Se creó una cuenta en Azure NetApp Files</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">Configure un pool de capacidad</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (Como mínimo, 4 TIB Standard o Premium, según sus necesidades).</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">Agrupación de la red virtual de AKS y la red virtual de Azure NetApp Files</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">A continuación, conecte la red virtual AKS (vnet) con Azure NetApp Files vnet siguiendo estos pasos:</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">En el cuadro de búsqueda de la parte superior del portal de Azure, escriba redes virtuales.</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">Haga clic en vnet aks- vnet-name y, a continuación, escriba peerings en el campo de búsqueda.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">Haga clic en +Agregar e introduzca la información proporcionada en la siguiente tabla:</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">Campo</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Valor o descripción</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">Nombre de enlace de relación entre iguales</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">aks-vnet-name_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">SubscriptionId</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">Suscripción de la red virtual de Azure NetApp Files a la que se está creando una relación de paridad</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">Partner de vnet peering</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Red virtual de Azure NetApp Files</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">Deje todas las secciones que no sean asteriscos por defecto</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">Haga clic en AGREGAR o en Aceptar para agregar la conexión a la red virtual.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">Crear, cambiar o eliminar una conexión de red virtual entre iguales</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">Si desea más información, visite<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident es un proyecto de código abierto que NetApp mantiene para el almacenamiento persistente en contenedores para aplicaciones. Trident se ha implementado como una controladora de aprovisionamiento externa que se ejecuta como un "pod", supervisando volúmenes y automatizando totalmente el proceso de aprovisionamiento.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">Trident de NetApp permite una integración sin problemas con K8S mediante la creación y el montaje de volúmenes persistentes para almacenar conjuntos de datos de entrenamiento y modelos entrenados. Esta funcionalidad facilita a los científicos e ingenieros de datos el uso de K8 sin los problemas de almacenar y gestionar manualmente conjuntos de datos. Trident también elimina la necesidad que tienen los científicos de datos de aprender a gestionar nuevas plataformas de datos a medida que integra las tareas relacionadas con la gestión de datos a través de la integración lógica de las API.</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Para instalar el software Trident, realice los pasos siguientes:</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">Primero instale el timón</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Descargue y extraiga el instalador de Trident 21.01.1.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">Cambie el directorio a.<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block>.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">Copiar<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> a un directorio del sistema<block ref="86657e3985b8aeae39f3d9136b5f3e58" prefix=" " category="inline-code"></block></block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Instale Trident en el clúster K8s con Helm:</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">Cambiar el directorio al directorio del timón.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Instale Trident.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Compruebe el estado de Trident pods de la manera habitual K8s:</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">Si todos los pods están ya en funcionamiento, se instala Trident y se podrá seguir avanzando.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Configure el back-end de Azure NetApp Files y la clase de almacenamiento</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Para configurar el back-end de Azure NetApp Files y la clase de almacenamiento, complete los siguientes pasos:</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">Vuelva al directorio inicial.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">repositorio de proyectos</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">Clone el<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block><block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">Vaya a la<block ref="fb4dc0399a722eface234e077d9b496c" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Crear un principio de servicio de Azure (el principio del servicio es cómo Trident se comunica con Azure para acceder a sus recursos de Azure NetApp Files).</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">El resultado debería ser como el ejemplo siguiente:</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Cree Trident<block ref="27bac05160742a70c80c3e1db9b39988" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">Con el editor de texto preferido, complete los siguientes campos de la tabla siguiente dentro de la<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valor</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">SubscriptionId</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Su ID de suscripción de Azure</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">ID de tenantID</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Su ID de inquilino de Azure (de la salida de az ad sp en el paso anterior)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">ID del Cliente</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">Su AppID (de la salida de az ad sp en el paso anterior)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">ClientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">Su contraseña (de la salida de az ad sp en el paso anterior)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">El archivo debería tener el siguiente ejemplo:</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">Indique a Trident que cree el back-end de Azure NetApp Files en la<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> espacio de nombres, utilizar<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> como el archivo de configuración de la siguiente manera:</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">Cree la clase de almacenamiento:</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">Los usuarios de K8 aprovisionan volúmenes mediante el uso de EVs que especifican una clase de almacenamiento por nombre. Indique a K8S que cree una clase de almacenamiento<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Que hará referencia al back-end de Azure NetApp Files creado en el paso anterior utilizando lo siguiente:</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">Compruebe que la clase de almacenamiento se haya creado mediante el siguiente comando:</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">Ponga en marcha y configure componentes snapshot para volúmenes en AKS</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">Si el clúster no viene preinstalado con los componentes Snapshot de volumen correctos, puede realizar la instalación manual de estos componentes ejecutando los siguientes pasos:</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14 no tiene una controladora Snapshot instalada previamente.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">Instale los CRD de la versión beta de instantánea utilizando los siguientes comandos:</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">Instale el controlador Snapshot con los siguientes documentos de GitHub:</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">clase de snapshot de volumen</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">Configurar K8s<block ref="9431613e59ff5cc956e408e7f55906ef" prefix=" " category="inline-code"></block>: Antes de crear una instantánea de volumen, a.<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> debe estar configurado. Cree una clase de copia Snapshot de volumen para Azure NetApp Files y utilícela para crear versiones ML con la tecnología Snapshot de NetApp. Cree<block ref="0c1b563c97a31c710fb1be0e355b42e2" prefix=" " category="inline-code"></block> y configúrelo como predeterminado "volumesnapshotclass "como tal:</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">Compruebe que la clase de copia Snapshot de volumen se haya creado con el siguiente comando:</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">EJECUCIÓN:instalación de IA</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">Para instalar RUN:AI, realice los siguientes pasos:</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Instalar EJECUTAR:clúster AI en AKS</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">Vaya a app.runai.ai, haga clic en Crear nuevo proyecto y asigne un nombre a la detección de carriles. Creará un espacio de nombres en un clúster K8s a partir de<block ref="26ea39e1cbc12bc8c37993198043ec7c" prefix=" " category="inline-code"></block>- seguido del nombre del proyecto. En este caso, el espacio de nombres creado sería la detección de pistas en ejecución.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">INSTALAR RUN:AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">En el terminal, establezca la detección de carriles como UNA EJECUCIÓN predeterminada: Proyecto de IA mediante el siguiente comando:</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">Crear ClusterRole y ClusterRoleBinding para el espacio de nombres del proyecto (por ejemplo,<block ref="ff4072c643ff862f118d673b2655bd00" prefix=" " category="inline-code"></block> por lo tanto, la cuenta de servicio predeterminada que pertenece a<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> el espacio de nombres tiene permiso para ejecutar<block ref="2bbdf0e0d9e8bddf5f3f89a53a8e524f" prefix=" " category="inline-code"></block> operaciones durante la ejecución de trabajos:</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">Enumere los espacios de nombres para comprobarlo<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> existe usando este comando:</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">El resultado debería aparecer como el ejemplo siguiente:</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">Crear función de clúster<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> Y ClusterRoleBinding<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> con los siguientes comandos:</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">Descargue y procese el conjunto de datos de TuSimple como RUN:AI job</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">El proceso para descargar y procesar el conjunto de datos TuSimple COMO UNA EJECUCIÓN: El trabajo de IA es opcional. Se trata de los siguientes pasos:</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Cree y empuje la imagen del docker, o omita este paso si desea utilizar una imagen del docker existente (por ejemplo,<block ref="c545ab6370eda2ad54aefbe9cf39084c" prefix=" " category="inline-code"></block></block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">Cambie al directorio principal:</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">Vaya al directorio de datos del proyecto<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>:</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">Modificar<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> script de shell y cambiar el repositorio de docker a la suya. Por ejemplo, sustituir<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> con el nombre de repositorio de docker. También puede cambiar el nombre y LA ETIQUETA de la imagen del docker (por ejemplo<block ref="d9ff85f787933e1dd61935daa84a1bdf" prefix=" " category="inline-code"></block> y..<block ref="e4c2e8edac362acab7123654b9e73432" prefix=" " category="inline-code"></block>):</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">Ejecute el script para crear la imagen de docker y empújela al repositorio de docker mediante los siguientes comandos:</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Envíe el TRABAJO RUN: AI para descargar, extraer, preprocesar y almacenar el conjunto de datos de detección de carriles TuSimple en un<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>Creado dinámicamente por Trident de NetApp:</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">Use los siguientes comandos para enviar LA EJECUCIÓN: AI job:</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">Introduzca la información de la siguiente tabla para enviar EL trabajo RUN:AI:</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-name</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">Nombre del trabajo</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-pvc</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">PVC del formato [StorageClassName]:Size:ContainerMountPath en el envío de trabajos anterior, está creando un PVC basado en demanda usando Trident con archivos azurenetappfiles de la clase de almacenamiento. La capacidad de volumen persistente aquí es 100Gi y está montada en path /mnt.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">-imagen</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">Imagen de Docker que se utilizará al crear el contenedor para este trabajo</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">Enumere los trabajos ENVIADOS RUN:AI.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">Compruebe los registros de trabajos enviados.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">Enumere la<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> creado. Utilice esto<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> comando para la formación en el siguiente paso.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">Compruebe el trabajo EN RUN: AI UI (o.<block ref="a008ed925fe48e20407afaf702b23152" prefix=" " category="inline-code"></block>).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Realice la formación de detección de carriles distribuidos con Horovod</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">El entrenamiento de detección de carriles distribuidos con Horovod es un proceso opcional. Sin embargo, estos son los pasos implicados:</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Cree y empuje la imagen del docker o omita este paso si desea utilizar la imagen del docker existente (por ejemplo,<block ref="ff48b891d5ff0bac7c6319fafb5cd296" prefix=" " category="inline-code"></block></block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">Cambie al directorio inicial.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">Vaya al directorio del proyecto<block ref="3154c35109c9015233233f77dfc31bc7" prefix=" " category="inline-code"></block></block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">Modifique el<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> script de shell y cambie el repositorio de docker a la suya (por ejemplo, reemplace<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> con el nombre del repositorio del docker). También puede cambiar el nombre y LA ETIQUETA de la imagen del docker <block ref="40797c3457645b9820c9a3f42dbea93b" prefix="(" category="inline-code"></block> y..<block ref="dfddb1ffc29acf8914bca9a640b6362a" prefix=" " category="inline-code"></block>.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">Ejecute la secuencia de comandos para crear la imagen de docker y empújela al repositorio de docker.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">Enviar LA CARRERA: AI job para llevar a cabo la formación distribuida (MPI):</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">Uso de envío DE LA EJECUCIÓN: La inteligencia artificial para la creación automática de la RVP en el paso anterior (para la descarga de datos) solo le permite tener acceso a RWO, que no permite que varios POD o nodos accedan al mismo RVP para el entrenamiento distribuido. Actualice el modo de acceso a ReadWriteMany y utilice el parche Kubernetes para hacerlo.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">En primer lugar, ejecute el siguiente comando para obtener el nombre del volumen de la RVP:</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">Aplicar patches al modo de acceso de volumen y actualización a ReadWriteMany (reemplace el nombre del volumen por el suyo en el siguiente comando):</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">Envíe el TRABAJO RUN: AI MPI para la ejecución del trabajo de formación distribuida utilizando la información de la tabla siguiente:</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">nombre</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">Nombre del trabajo de formación distribuido</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">gran km</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">Monte un dispositivo /dev/sm de gran tamaño. Es un sistema de archivos compartidos montado en la RAM y proporciona memoria compartida lo suficientemente grande para que varios trabajadores de CPU procesen y carguen lotes en la RAM de la CPU.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">procesos</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">Número de procesos de formación distribuidos</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">gpu</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">Número de GPU/procesos que se van a asignar para la tarea en esta tarea, hay tres procesos de trabajo de GPU (--process=3), cada uno asignado con una única GPU (--gpu 1)</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">rvp</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">Utilice el volumen persistente existente (pvc-download-tusimple-data-0) creado por el trabajo anterior (download-tusimple-data) y se monta en la ruta /mnt</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">Defina las variables de entorno que se van a establecer en el contenedor</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">USE_WORKERS</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">Al establecer el argumento en true, se activa la carga de datos multiproceso</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">NÚM_TRABAJADORES</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">Número de procesos de trabajo del cargador de datos</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">TAMAÑO_LOTE</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">Tamaño de lote de entrenamiento</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">VALOR_USO</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">Establecer el argumento en true permite la validación</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">VAL_BATCH_SIZE</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">Tamaño del lote de validación</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">ENABLE_SNAPSHOT</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">Establecer el argumento en true permite tomar instantáneas de datos y modelos entrenados para el control de versiones EN ML</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">NOMBRE_PVC</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">Nombre de la rvp de la que se va a realizar una instantánea. En la presentación de trabajos anterior, está tomando una instantánea de pvc-download-tusimple-data-0, que consta de conjuntos de datos y modelos entrenados</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">Error: Falta la imagen gráfica</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">Enumera el trabajo enviado.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">Registros de trabajos enviados:</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">Compruebe la tarea de entrenamiento EN EJECUCIÓN: Interfaz gráfica de usuario de IA (o app.runai.ai): RUN: Consola de IA, como se puede ver en las siguientes figuras. La primera figura detalla tres GPU asignadas para el trabajo de entrenamiento distribuido, repartidos en tres nodos en AKS, y la segunda EJECUCIÓN: Trabajos de IA:</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">Una vez finalizada la formación, compruebe la copia de Snapshot de NetApp que se creó y vinculado con RUN: Trabajo de IA.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">Restaure datos de la copia Snapshot de NetApp</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">Para restaurar datos de la copia Snapshot de NetApp, complete los siguientes pasos:</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">Vaya al directorio del proyecto<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">Modificar<block ref="a5fe5fd907cdc55a6a74bfd705214476" prefix=" " category="inline-code"></block> y actualícelo<block ref="d9d448f70687a1aa1f12b2f5ddaa4977" prefix=" " category="inline-code"></block><block ref="b068931cc450442b63f5b3d276ea4297" prefix=" " category="inline-code"></block> Campo de la copia Snapshot desde la que desea restaurar datos. También puede cambiar el nombre del PVC al que se restaurarán los datos, en este ejemplo su<block ref="1fcd0a4cb780ecfc14fadd89d5ad8fd2" prefix=" " category="inline-code"></block>.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">Cree una nueva RVP mediante<block ref="c6c5b510d872174c3b4e59ca4c66fd6e" prefix=" " category="inline-code"></block>.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">Si desea utilizar los datos recién restaurados para el entrenamiento, el envío de trabajos sigue siendo el mismo que antes; sólo sustituya el<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> con el restaurado<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> al enviar el trabajo de formación, como se muestra en los siguientes comandos:</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">Evaluación del rendimiento</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">Para mostrar la escalabilidad lineal de la solución, se han realizado pruebas de rendimiento para dos supuestos: Una GPU y tres GPU. La asignación de GPU, la utilización de la GPU y la memoria, se han capturado diferentes métricas de uno y tres nodos durante el entrenamiento en el conjunto de datos de detección de carriles TuSimple. Los datos se incrementan cinco veces sólo por analizar la utilización de los recursos durante los procesos de entrenamiento.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Niveles de servicio de Azure NetApp Files</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">La solución permite a los clientes comenzar con un conjunto de datos pequeño y unas pocas GPU. Cuando aumentan la cantidad de datos y la demanda de GPU, los clientes pueden escalar horizontalmente de forma dinámica los terabytes del nivel estándar y escalar rápidamente hasta el nivel Premium para obtener el cuádruple de rendimiento por terabyte sin necesidad de mover datos. Este proceso se explica más detalladamente en la sección, <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">El tiempo de procesamiento en una GPU era de 12 horas y 45 minutos. El tiempo de procesamiento en tres GPU en tres nodos era de aproximadamente 4 horas y 30 minutos.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">Las cifras que se muestran a lo largo del resto de este documento muestran ejemplos de rendimiento y escalabilidad basados en las necesidades empresariales individuales.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">La siguiente figura muestra la asignación de 1 GPU y la utilización de memoria.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">La siguiente figura ilustra el uso de GPU de un solo nodo.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">La siguiente figura ilustra el tamaño de la memoria de un solo nodo (16 GB).</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">La siguiente figura muestra el número de GPU de nodo único (1).</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">La siguiente figura muestra la asignación de GPU de un solo nodo (%).</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">La siguiente figura muestra tres GPU en tres nodos: Asignación de GPU y memoria.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">La siguiente figura muestra tres GPU en la utilización de tres nodos (%).</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">La siguiente figura muestra tres GPU en una utilización de la memoria de tres nodos (%).</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">nivel de servicio</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">Es posible cambiar el nivel de servicio de un volumen existente si se mueve el volumen a otro pool de capacidad que utiliza<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> se desea para el volumen. Este cambio de nivel de servicio existente del volumen no requiere la migración de los datos. Además, no afecta el acceso al volumen.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">Cambie dinámicamente el nivel de servicio de un volumen</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">Para cambiar el nivel de servicio de un volumen, siga estos pasos:</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">En la página Volumes, haga clic con el botón derecho en el volumen cuyo nivel de servicio desea cambiar. Seleccione Cambiar pool.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">En la ventana Cambiar pool, seleccione el pool de capacidad al que desea mover el volumen. A continuación, haga clic en Aceptar.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">Automatizar el cambio de nivel de servicio</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">El cambio de nivel de servicio dinámico se encuentra actualmente en la vista previa pública, pero no está habilitado de forma predeterminada. Para activar esta función en la suscripción a Azure, siga estos pasos proporcionados en el documento “<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>.”</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">volumen de archivos de az netapparchivo: Gestione los recursos de volúmenes del Azure NetApp Files (ANF)</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">También puede utilizar los siguientes comandos para Azure: CLI. Para obtener más información sobre cómo cambiar el tamaño del pool de Azure NetApp Files, visite<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Cambiar el pool de un volumen Azure NetApp Files</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">La<block ref="2de1988ae552a465bf4f3a270c8403a4" prefix=" " category="inline-code"></block> El cmdlet que se muestra aquí puede cambiar el pool de un volumen Azure NetApp Files. Para obtener más información sobre el cambio del tamaño del pool de volúmenes y Azure PowerShell, visite<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Crear un asistente virtual mediante Jarvis, Cloud Sync y Nemo</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">Siguiente: Crear un asistente virtual usando Jarvis, Cloud Sync y Nemo Descripción general</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Despliegue de Jarvis</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Programa Jarvis Early Access</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">Puede registrarse para<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> Para obtener acceso a contenedores Jarvis en NVIDIA GPU Cloud (NGC). Después de recibir credenciales de NVIDIA, puede implementar Jarvis siguiendo los pasos siguientes:</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">Firma a NGC.</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">Establezca la organización en NGC:<block ref="7aa2b5d0d3058d0080d19281dc9d071c" prefix=" " category="inline-code"></block>.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Localice Jarvis EA v0.2 activos: Contenedores Jarvis están en<block ref="57383b3fa3bf1fe40b83355ea69945df" prefix=" " category="inline-code"></block> &gt;<block ref="15ce31151446746acfe9a6cb94ac5cbe" prefix=" " category="inline-code"></block>.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">Seleccione Jarvis: Desplácese a.<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> y haga clic en<block ref="29a846043a00b3f8b78a15edcb8ac726" prefix=" " category="inline-code"></block></block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">Compruebe que todos los activos funcionan correctamente.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">Busque la documentación para crear sus propias aplicaciones: Los archivos PDF se pueden encontrar en<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> &gt;<block ref="4ce995c78680dc78d6a0745744c2811b" prefix=" " category="inline-code"></block> &gt;<block ref="b8c128190e09e6c57a1df2180e8c73fb" prefix=" " category="inline-code"></block>.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">Siguiente: Personalice Estados y flujos para el caso de uso minorista</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Este documento sigue el código de inferencia MLPerf v0.7, el código y las reglas de inferencia MLPerf v1.1. Ejecutamos pruebas de rendimiento diseñadas para la inferencia en el perímetro, tal y como se definen en las tablas de esta sección.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Plan de pruebas</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">bases de datos</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Este documento sigue a la inferencia MLPerf v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, Inferencia MLPerf v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, y.<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. Ejecutamos pruebas de rendimiento MLPerf diseñadas para la inferencia en el perímetro tal y como se definen en la tabla siguiente.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Zona</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Tarea</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modelo</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Conjunto de datos</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Tamaño de QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Calidad</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Limitación de latencia de múltiples flujos</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Visión</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Clasificación de imágenes</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNET (224 x 224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% del FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Detección de objetos (grande)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD- ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Detección de objetos (pequeño)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD- MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentación de imagen médica</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">UNET 3D</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">Brats 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% y 99.9% del FP32</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n.a.</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Voz</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Voz a texto</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Llibrispeech dev-Clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Idioma</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Procesamiento de idiomas</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">BERT</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Escuadra v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">En la siguiente tabla se presentan los escenarios de referencia de Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Escenarios</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Clasificación de imágenes</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Flujo único, sin conexión, multisecuencia</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Flujo único, sin conexión</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Realizamos estas pruebas de rendimiento utilizando la arquitectura de almacenamiento en red desarrollada en esta validación y comparamos los resultados de las ejecuciones locales en servidores perimetrales que antes se enviaban al MLPerf. La comparación consiste en determinar cuánto impacto tiene el almacenamiento compartido en el rendimiento de la inferencia.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">Siguiente: Prueba de la configuración.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">En esta sección se ofrece información detallada sobre la implantación del asistente de venta al por menor virtual.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">Siguiente: Despliegue de Jarvis</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">En esta sección se describen las consideraciones de diseño para los distintos componentes de esta solución.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">Consideraciones de diseño</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">Anterior: Arquitectura.</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">Diseño informático y de red</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">En función de las restricciones en la seguridad de los datos, todos los datos deben permanecer dentro de la infraestructura del cliente o en un entorno seguro.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">Diseño del almacenamiento</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">El kit de herramientas Data OPS de NetApp sirve como servicio principal para gestionar los sistemas de almacenamiento. El kit de herramientas DataOps es una biblioteca Python que facilita a los desarrolladores, científicos de datos, ingenieros de DevOps e ingenieros de datos la tarea de gestión de datos realizar varias tareas de gestión de datos, como el aprovisionamiento casi instantáneo de un nuevo volumen de datos o un espacio de trabajo JJupyterLab, el clonado casi instantáneo de un volumen de datos o el espacio de trabajo JuppyterLab. Y una copia de Snapshot casi instantánea de un volumen de datos o un espacio de trabajo JupyterLab para poder seguir su seguimiento o crear una línea de base. Esta biblioteca de Python puede funcionar como una utilidad de línea de comandos o una biblioteca de funciones que se pueden importar a cualquier programa de Python o a cualquier ordenador portátil Jupyter.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">Mejores prácticas de RIVA</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">mejores prácticas de datos</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA proporciona varias funciones generales<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Para utilizar RIVA:</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">*Utilice formatos de audio sin pérdidas si es posible.* el uso de códecs con pérdida como MP3 puede reducir la calidad.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">*Aumentar los datos de entrenamiento.* la adición de ruido de fondo a los datos de entrenamiento de audio puede inicialmente disminuir la precisión y, sin embargo, aumentar la solidez.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">*Limite el tamaño del vocabulario si utiliza texto raspado.* muchas fuentes en línea contienen tipopos o pronombres auxiliares y palabras poco comunes. La eliminación de estos elementos puede mejorar el modelo de idioma.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">*Utilice una frecuencia de muestreo mínima de 16 kHz si es posible.* sin embargo, trate de no resampling, ya que al hacerlo se reduce la calidad de audio.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">Además de estas mejores prácticas, los clientes deben priorizar la recopilación de un conjunto de datos de ejemplo representativo con etiquetas precisas para cada paso de la canalización. En otras palabras, el conjunto de datos de ejemplo debería reflejar proporcionalmente las características especificadas ejemplificadas en un conjunto de datos de destino. De forma similar, los anotadores del conjunto de datos tienen la responsabilidad de equilibrar la precisión y la velocidad del etiquetado, de modo que se maximice la calidad y la cantidad de los datos. Por ejemplo, esta solución de centro de soporte requiere archivos de audio, etiquetas de texto etiquetadas y etiquetas de sentimiento. La naturaleza secuencial de esta solución significa que los errores desde el principio de la canalización se propagan hasta el final Si los archivos de audio son de mala calidad, las transcripciones de texto y las etiquetas de sentimiento también serán.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">Esta propagación de errores también se aplica a los modelos entrenados en estos datos. Si las predicciones de sentimiento son 100% exactas pero el modelo de voz a texto tiene un rendimiento deficiente, entonces la canalización final está limitada por las transcripciones iniciales de audio a texto. Es esencial que los desarrolladores consideren el rendimiento de cada modelo individualmente y como un componente de una canalización mayor. En este caso en particular, el objetivo final es desarrollar una canalización que pueda predecir con precisión el sentimiento. Por lo tanto, la métrica general sobre la cual evaluar la canalización es la precisión de los sentimientos, que afecta directamente la transcripción del habla al texto.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">El kit de herramientas DataOPS de NetApp complementa la canalización de comprobación de la calidad de los datos mediante su tecnología de clonado de datos casi instantánea. Cada archivo etiquetado debe evaluarse y compararse con los archivos etiquetados existentes. La distribución de estas comprobaciones de calidad a través de distintos sistemas de almacenamiento de datos garantiza una ejecución rápida y eficaz de estas comprobaciones.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">Siguiente: Implementar el análisis de confianza del centro de soporte.</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo es un kit de herramientas creado por NVIDIA para crear aplicaciones de IA conversacionales. Este kit de herramientas incluye colecciones de módulos preentrenados para ASR, NLP y TTS, lo que permite a investigadores y científicos de datos componer fácilmente arquitecturas complejas de redes neuronales y centrarse más en el diseño de sus propias aplicaciones.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">Como se muestra en el ejemplo anterior, NARA sólo puede manejar un tipo limitado de preguntas. Esto se debe a que el modelo NLP pre-entrenado sólo entrena en este tipo de preguntas. Si queremos permitir QUE NARA pueda gestionar una gama más amplia de preguntas, debemos volver a formar este con nuestros propios conjuntos de datos. Por lo tanto, aquí mostramos cómo podemos utilizar Nemo para ampliar el modelo NLP para satisfacer los requisitos. Comenzamos convirtiendo el registro recolectado de NARA en el formato de Nemo, y luego entrenamos con el conjunto de datos para mejorar el modelo NLP.</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">Nuestro objetivo es permitir A NARA ordenar los elementos según las preferencias del usuario. Por ejemplo, podemos pedir A NARA que sugiera el restaurante de sushi con mejor calificación o que quiera QUE NARA busque los vaqueros con el precio más bajo. Para ello, utilizamos el modelo de detección de intención y relleno de ranuras proporcionado en Nemo como modelo de entrenamiento. Este modelo permite A NARA comprender la intención de buscar preferencias.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">Preparación de datos</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">Para entrenar el modelo, recopilamos el conjunto de datos para este tipo de preguntas y lo convertimos al formato Nemo. Aquí enumeramos los archivos que utilizamos para entrenar el modelo.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">Este archivo enumera todos los intentos que queremos que el Nemo entienda. Aquí tenemos dos intentos principales y una intención que sólo se utiliza para categorizar las preguntas que no encajan en ninguno de los intentos primarios.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">En este archivo se enumeran todas las ranuras que podemos etiquetar en nuestras preguntas de formación.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">train.tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">Este es el conjunto de datos de entrenamiento principal. Cada línea comienza con la pregunta que sigue a la lista de la categoría de intención en el archivo dict.intent.csv. La etiqueta se enumera a partir de cero.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">train_slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">Entrenar el modelo</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">A continuación, utilizamos el siguiente comando para iniciar el contenedor. En este comando, limitamos el contenedor para usar una única GPU (ID de GPU = 1), ya que se trata de un ejercicio de entrenamiento de poco peso. También mapeamos nuestro espacio de trabajo local /Workspace/nemo/ a la carpeta dentro del contenedor /nemo.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">Dentro del contenedor, si queremos empezar desde el modelo ORIGINAL BERT pre-entrenado, podemos usar el siguiente comando para iniciar el procedimiento de entrenamiento. data_dir es el argumento para establecer la ruta de los datos de entrenamiento. dir_trabajo le permite configurar dónde desea almacenar los archivos de punto de control.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">Si contamos con nuevos conjuntos de datos de entrenamiento y queremos mejorar el modelo anterior, podemos utilizar el siguiente comando para continuar desde el punto que hemos detenido. checkpoint_dir lleva la ruta a la carpeta de puntos de control anteriores.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">Inferencia del modelo</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">Se debe validar el rendimiento del modelo entrenado después de una serie determinada de épocas. El siguiente comando nos permite probar la consulta una por una. Por ejemplo, en este comando, queremos comprobar si nuestro modelo puede identificar adecuadamente la intención de la consulta<block ref="fe494faf7f8c52514a674b8162027072" prefix=" " category="inline-code"></block>.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">A continuación, se muestra la salida de la inferencia. En el resultado, podemos ver que nuestro modelo entrenado puede predecir correctamente la intención find_the_store, y devolver las palabras clave en las que estamos interesados. Con estas palabras clave, permitimos A LA NARA buscar lo que los usuarios desean y realizar una búsqueda más precisa.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">Siguiente: Conclusión</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Los datos existen en tres estados: En reposo, en tránsito y en computación. Una parte importante de cualquier servicio de inferencia de IA debe ser la protección de datos contra amenazas durante todo el proceso. La protección de datos durante la inferencia es vital, ya que el proceso puede exponer información privada tanto sobre clientes externos como sobre la empresa que proporciona el servicio de inferencia.</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">Anterior: Velocidad de ofuscación.</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">Los datos existen en tres estados: En reposo, en tránsito y en computación. Una parte importante de cualquier servicio de inferencia de IA debe ser la protección de datos contra amenazas durante todo el proceso. La protección de datos durante la inferencia es vital, ya que el proceso puede exponer información privada tanto sobre clientes externos como sobre la empresa que proporciona el servicio de inferencia. Protopia AI es una solución no obstrusiva de solo software para la inferencia de IA confidencial en el mercado actual. Con Protopia, la IA solo recibe la información transformada de los registros de datos que es esencial para llevar a cabo la tarea de IA/ML disponible y nada más. Esta transformación estocástica no es una forma de enmascarar y se basa en cambiar matemáticamente la representación de los datos utilizando el ruido curado.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">Los sistemas de almacenamiento de NetApp con funcionalidades de ONTAP ofrecen el mismo rendimiento o incluso mejor que el almacenamiento SSD local y, combinados con el kit de herramientas DataOPS de NetApp, ofrecen las siguientes ventajas a científicos de datos, ingenieros de datos, desarrolladores DE IA/ML y responsables DE la toma DE decisiones TECNOLÓGICAS empresariales o de negocio:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Uso compartido de datos sin esfuerzo entre sistemas de IA, análisis y otros sistemas de negocio cruciales. Este uso compartido de datos reduce la sobrecarga de la infraestructura, mejora el rendimiento y optimiza la gestión de datos en toda la empresa.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Almacenamiento y cálculo escalables de forma independiente para minimizar los costes y mejorar el uso de recursos.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Flujos de trabajo de desarrollo y puesta en marcha optimizados que utilizan copias Snapshot integradas y clones para espacios de trabajo de usuario instantáneos con gestión eficiente del espacio, control de versiones integrado y una puesta en marcha automatizada.</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protección de datos de clase empresarial y regulación de datos para la recuperación ante desastres, la continuidad del negocio y los requisitos normativos.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Invocación simplificada de las operaciones de gestión de datos; realice rápidamente copias Snapshot de los espacios de trabajo de científicos de datos para realizar backups y trazabilidad desde el kit de herramientas de DataOps de NetApp en los portátiles Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La solución de NetApp y Protopía proporciona una arquitectura flexible de escalado horizontal ideal para puestas en marcha de inferencia de IA de clase empresarial. Permite la protección de datos y proporciona privacidad para información confidencial en la que los requisitos confidenciales de inferencia de IA pueden satisfacerse con prácticas responsables de IA tanto en puestas en marcha en el entorno local como en cloud híbrido.</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">Siguiente: Dónde encontrar información adicional, reconocimientos e historial de versiones.</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">Conéctese a API de terceros como motor de cumplimiento</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">Conectamos las siguientes API de terceros como motor de cumplimiento de normativas para responder a las preguntas:</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">API de WeatherStack</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: regresa el clima, la temperatura, las precipitaciones y la nieve en un lugar determinado.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">API de Fusion yelp</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: devuelve la información de la tienda más cercana en una ubicación determinada.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">SDK de Python de eBay</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: devuelve el precio de un artículo determinado.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">Siguiente: Demostración del asistente para minoristas de NetApp</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">Ejecutar:instalación de AI</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Para instalar Run:AI, lleve a cabo los siguientes pasos:</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">Instale el clúster de Kubernetes con DeepOps y configure la clase de almacenamiento predeterminada de NetApp.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">Prepare los nodos de GPU:</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">Compruebe que los controladores de NVIDIA están instalados en los nodos de la GPU.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">Compruebe que<block ref="03550f513b5eb839088628d4a360b865" prefix=" " category="inline-code"></block> se instala y configura como el tiempo de ejecución de docker predeterminado.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">Ejecución de instalación:AI:</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">Ejecución: IU de administración de IA</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">Inicie sesión en el<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> para crear el clúster.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">Descargue el creado<block ref="6b351eac623bdfae151b8db2b05a8131" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Aplique la configuración del operador al clúster de Kubernetes.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">Compruebe la instalación:</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">Vaya a.<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">Vaya a la consola Overview.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Instalar Run:IA en un clúster de Kubernetes en las instalaciones</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Instalación de la CLI Run:AI</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">Compruebe que el número de GPU de la parte superior derecha refleja el número esperado de GPU y los nodos de GPU forman parte de la lista de servidores. Para obtener más información acerca de la puesta en marcha de Run:IA, consulte<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> y..<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">Siguiente: Ejecute paneles de IA y vistas</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Visión general de la tecnología</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Información general de NetApp</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp es un referente en materia de datos para el cloud híbrido. NetApp proporciona una gama completa de servicios de datos en el cloud híbrido que simplifican la gestión de aplicaciones y datos en entornos de cloud y en las instalaciones para acelerar la transformación digital. Junto con nuestros partners, NetApp permite a organizaciones globales aprovechar al máximo todo el potencial de sus datos para ampliar los puntos de contacto con los clientes, fomentar una mayor innovación y optimizar sus operaciones.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">ONTAP AI de NetApp</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">ONTAP AI de NetApp, impulsado por los sistemas NVIDIA DGX y el almacenamiento all-flash conectado al cloud de NetApp, optimiza el flujo de datos con total confianza y acelera el análisis, la formación y la inferencia con su Data Fabric, que abarca desde el perímetro al núcleo y al cloud. Proporciona a las organizaciones DE TI una arquitectura que ofrece las siguientes ventajas:</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Permite un escalado independiente de las capacidades de computación y almacenamiento</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">Ofrece una gama de opciones de almacenamiento para diferentes tipos de rendimiento y coste.ONTAP AI ofrece pilas de infraestructuras convergentes que incorporan NVIDIA DGX-1, un sistema de IA a escala de petaflops y switches Ethernet de alto rendimiento NVIDIA Mellanox para unificar cargas de trabajo de IA, simplificar la puesta en marcha y acelerar el retorno de la inversión. Para este informe técnico, hemos aprovechado la inteligencia artificial de ONTAP con un sistema de almacenamiento DGX-1 y AFF A800 de NetApp. En la siguiente imagen, se muestra la topología de ONTAP AI con el sistema DGX-1 utilizado en esta validación.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">Plano de control de IA de NetApp</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">El plano de control de IA de NetApp permite aprovechar la IA Y EL APRENDIZAJE AUTOMÁTICO con una solución que ofrece una escalabilidad extrema, una puesta en marcha optimizada y una disponibilidad de datos ininterrumpida. La solución de plano de control de IA integra Kubernetes y Kubeflow con una estructura de datos habilitada por NetApp. Kubernetes, la plataforma de orquestación de contenedores estándar del sector para puestas en marcha nativas del cloud, permite la escalabilidad y la portabilidad de las cargas de trabajo. Kubeflow es una plataforma de aprendizaje automático de código abierto que simplifica la gestión y la puesta en marcha, lo que permite a los desarrolladores hacer más ciencia de datos en menos tiempo. Una estructura de datos habilitada por NetApp ofrece una disponibilidad y portabilidad de datos sin concesiones para garantizar que sus datos están accesibles en toda la canalización, desde el perímetro al núcleo y al cloud. En este informe técnico se utiliza el plano de control de IA de NetApp en una canalización MLRun. La siguiente imagen muestra la página de gestión de clústeres de Kubernetes, donde se pueden tener distintos extremos para cada clúster. Conectamos volúmenes persistentes de NFS al clúster de Kubernetes, y las siguientes imágenes muestran un volumen persistente conectado al clúster donde<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> ofrece compatibilidad con almacenamiento persistente y capacidades de gestión de datos.</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Visión General de Iguazio</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">La Plataforma de Ciencias de datos de Iguazio es una plataforma de ciencia de datos como servicio (PaaS) totalmente integrada y segura que simplifica el desarrollo, acelera el rendimiento, facilita la colaboración y aborda los retos operativos. Esta plataforma incorpora los siguientes componentes, y la Plataforma de Ciencias de datos de Iguazio se presenta en la siguiente imagen:</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Banco de trabajo de ciencia de datos que incluye portátiles Juppyter, motores de análisis integrados y paquetes Python</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">Gestión de modelos con seguimiento de experimentos y funcionalidades de canalizaciones automatizadas</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">Datos gestionados y servicios ML a través de un clúster de Kubernetes escalable</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nuclio, un marco de funciones sin servidor en tiempo real</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">Una capa de datos extremadamente rápida y segura compatible con SQL, NoSQL, bases de datos de series temporales, archivos (objetos sencillos) y streaming</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">Integración con fuentes de datos de terceros como NetApp, Amazon S3, HDFS, bases de datos de SQL y protocolos de transmisión o mensajería</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Paneles en tiempo real basados en Grafana</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">Siguiente: Requisitos de software y hardware</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">Esta página enumera las bibliotecas y los marcos utilizados para crear esta tarea. Todos estos componentes se han integrado completamente con los controles de seguridad y acceso basados en roles de Azure.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">Bibliotecas para el procesamiento de datos y el entrenamiento de modelos</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">Anterior: Niveles de rendimiento de Azure NetApp Files.</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">En la tabla siguiente se enumeran las bibliotecas y los marcos que se utilizaron para generar esta tarea. Todos estos componentes se han integrado completamente con los controles de seguridad y acceso basados en roles de Azure.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">Bibliotecas/marco de trabajo</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">CuML DASK</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">Biblioteca de cuML</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">Para QUE EL ML funcione en la GPU, el<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Ofrece acceso al paquete cuML DE RAPIDS con DASK. RAPIDS cuML implementa algoritmos DE ML más conocidos, como los métodos de clustering, reducción de dimensiones y regresión, con implementaciones basadas en GPU de alto rendimiento que ofrecen una velocidad de hasta 100 veces superior a los métodos basados en CPU.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">DASK cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">biblioteca dask-cudf</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF incluye varias otras funciones que admiten la extracción, transformación y carga (ETL) acelerada por GPU, como la subconfiguración de datos, transformaciones, codificación en caliente, etc. El equipo DE RAPIDS mantiene un<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> Eso incluye métodos auxiliares para usar DASK y cuDF.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Formación en Scikit</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">estimator</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">encajar</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn proporciona docenas de algoritmos y modelos de aprendizaje automático integrados, llamados estimadores. Cada uno<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> se puede ajustar a algunos datos mediante su<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> método.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">Hemos utilizado dos cuadernos para construir los gasoductos ML para su comparación; uno es el método convencional de curscikit-aprender de pandas, y el otro es el entrenamiento distribuido con RAPIDS y Dink. Cada portátil se puede probar individualmente para ver el rendimiento en términos de tiempo y escala. Cubrimos cada bloc de notas individualmente para demostrar las ventajas de la formación distribuida con RAPIDS y Dink.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">Siguiente: Cargue Criteo haga clic en el día 15 de los registros en Pandas y entrena un cikit-aprende el modelo de bosque aleatorio.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Esta sección describe la base tecnológica de esta solución de IA.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Información general de la tecnología</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">Sistemas AFF de NetApp</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Los sistemas de almacenamiento AFF de NetApp más innovadores permiten que las puestas en marcha de inferencia de IA en el perímetro satisfagan los requisitos de almacenamiento de la empresa con un rendimiento líder del sector, una flexibilidad superior, integración con el cloud y la mejor gestión de datos de su clase. Los sistemas AFF de NetApp han sido diseñados específicamente para flash y ayudan a acelerar, gestionar y proteger los datos esenciales para la empresa.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Los sistemas de almacenamiento AFF de NetApp de gama básica se basan en hardware FAS2750 y medios flash SSD</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Dos controladoras en configuración de alta disponibilidad</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">Los sistemas de almacenamiento C190 de gama básica de AFF admiten las siguientes funciones:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Un número máximo de unidades de estado sólido de 960 GB</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Dos configuraciones posibles:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10 GbE): 4 puertos 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unificado (FC de 16 GB o 10 GbE): 4 puertos de adaptador de destino unificado 2 (UTA2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Una capacidad efectiva máxima de 50,5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">En el caso de cargas de trabajo NAS, un único sistema AFF C190 de gama básica admite un rendimiento de 4,4 GB/s para lecturas secuenciales y 230 000 IOPS para lecturas aleatorias pequeñas con latencias de 1 ms o menos.</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp también ofrece otros sistemas de almacenamiento de gama básica que proporcionan un mayor rendimiento y escalabilidad para las puestas en marcha a gran escala. En el caso de cargas de trabajo NAS, un único sistema AFF A220 de gama básica admite:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Rendimiento de 6,2 Gbps para lecturas secuenciales</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">3375 000 IOPS para lecturas aleatorias pequeñas con latencias de 1 ms o menos</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Recuento máximo de unidades de SSD 144 TB, 3,8 TB o 7,6 TB</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 es escalable a más de 1 PB de capacidad efectiva</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">AFF A250 de NetApp</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacidad efectiva máxima es de 35 PB con el escalado horizontal máximo de 2-24 nodos (12 parejas de alta disponibilidad).</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Ofrece un aumento del rendimiento de ≥ 45 % con respecto a AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 000 IOPS lecturas aleatorias a 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basado en el último lanzamiento de ONTAP de NetApp: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Aprovecha dos Ethernet de 25 GB para alta disponibilidad e interconexión de clúster</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Sistemas E-Series EF de NetApp</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF-Series es una familia de cabinas DE almacenamiento SAN all-flash de gama básica y media que pueden acelerar el acceso a sus datos y ayudarle a obtener valor de ella más rápido con el software SANtricity de NetApp. Estos sistemas ofrecen almacenamiento flash SAS y NVMe y le proporcionan IOPS asequibles hasta extremas, tiempos de respuesta inferiores a 100 microsegundos y un ancho de banda de hasta 44 Gbps, lo cual los convierte en ideales para cargas de trabajo mixtas y aplicaciones exigentes como la inferencia de IA y la computación de alto rendimiento (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La siguiente figura muestra el sistema de almacenamiento EF280 de NetApp.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">EF280 de NetApp</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Compatibilidad con FC de 32 GB/16 GB, iSCSI de 25 GB/10 GB y SAS de 12 GB</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacidad efectiva máxima es 96 unidades que totalizan 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Rendimiento de 10 Gbps (lecturas secuenciales)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPS (lectura aleatoria)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">El sistema EF280 de NetApp es la cabina all-flash (AFA) más económica de la cartera de NetApp</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">EF300 de NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 unidades SSD NVMe para una capacidad total de 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Opciones de expansión con un total de 240 HDD NL-SAS, 92 SSD SAS o una combinación de ambos</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 GB NVMe/IB, NVMe/roce, Iser/IB y SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">NVME DE 32 GB/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">ISCSI de 25 GB</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbps (lecturas secuenciales)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS (lecturas aleatorias)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Especificaciones técnicas de las cabinas all-flash EF-Series de NetApp EF600, F300, EF570 y EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Para obtener más información, consulte<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, la última generación del software de gestión del almacenamiento de NetApp, permite a las empresas modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. ONTAP ofrece las mejores capacidades de gestión de datos y permite la gestión y protección de los datos con un solo conjunto de herramientas, sin importar dónde residan. También puede mover los datos libremente a donde sea necesario: El perímetro, el núcleo o el cloud. ONTAP 9.8.1 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen los datos esenciales y permiten disfrutar de funcionalidades de infraestructura de nueva generación en arquitecturas de cloud híbrido.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Simplificar la gestión de los datos</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestión de los datos es crucial para las operaciones TECNOLÓGICAS empresariales, de modo que se utilicen recursos apropiados para las aplicaciones y conjuntos de datos. ONTAP incluye las siguientes funciones para facilitar y simplificar las operaciones, y reducir el coste total de las operaciones:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compactación de datos inline y deduplicación expandida.* la compactación de datos reduce el espacio perdido dentro de los bloques de almacenamiento, y la deduplicación aumenta significativamente la capacidad efectiva. Esto es aplicable a los datos almacenados localmente y a los datos organizados en niveles en el cloud.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Calidad de servicio (AQoS) mínima, máxima y adaptativa.* los controles de calidad de servicio (QoS) granulares ayudan a mantener los niveles de rendimiento para aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">*FabricPool de NetApp.* esta función ofrece una organización automática por niveles de datos inactivos a opciones de almacenamiento en cloud privado o público, como la solución de almacenamiento Amazon Web Services (AWS), Azure y StorageGRID de NetApp. Para obtener más información sobre FabricPool, consulte <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Acelere y proteja sus datos</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 ofrece niveles superiores de rendimiento y protección de datos, y amplía estas capacidades de las siguientes maneras:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Rendimiento y menor latencia.* ONTAP ofrece el rendimiento más alto posible con la menor latencia posible.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protección de datos.* ONTAP ofrece capacidades integradas de protección de datos con administración común en todas las plataformas.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">*Cifrado de volumen de NetApp (NVE).* ONTAP ofrece cifrado nativo a nivel de volumen con compatibilidad para gestión de claves incorporada y externa.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Multitenancy y autenticación multifactor.* ONTAP permite compartir recursos de infraestructura con los niveles más altos de seguridad.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Infraestructura preparada para futuros retos</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 ayuda a satisfacer las exigentes y siempre cambiantes necesidades de la empresa con las siguientes funciones:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Escalado sencillo y operaciones no disruptivas.* ONTAP admite la adición sin interrupciones de capacidad a las controladoras existentes y a los clústeres de escalado horizontal. Los clientes pueden empezar a utilizar tecnologías punteras como NVMe y FC 32 GB, sin necesidad de realizar costosas migraciones de datos y sin cortes.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">*Conexión en cloud.* ONTAP es el software de gestión del almacenamiento con mejor conexión en cloud, con opciones de almacenamiento definido por software (ONTAP Select) e instancias nativas del cloud (Cloud Volumes Service de NetApp) en todos los clouds públicos.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integración con aplicaciones emergentes.* ONTAP ofrece servicios de datos de clase empresarial para plataformas y aplicaciones de última generación, como vehículos autónomos, ciudades inteligentes e Industria 4.0, utilizando la misma infraestructura que soporta las aplicaciones empresariales existentes.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">SANtricity de NetApp</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Especificaciones técnicas del software SANtricity para E-Series de NetApp</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">SANtricity de NetApp está diseñado para ofrecer un rendimiento líder del sector, fiabilidad y simplicidad en las cabinas all-flash EF-Series y flash híbrido. Logre el máximo rendimiento y aprovechamiento de sus cabinas all-flash EF-Series y flash híbridas de E-Series para aplicaciones de cargas de trabajo pesadas, como análisis de datos, videovigilancia y backup y recuperación de datos. Con SANtricity, los ajustes de configuración, el mantenimiento, la expansión de la capacidad y otras tareas se pueden realizar mientras el almacenamiento sigue online. SANtricity también ofrece una protección de datos superior, supervisión proactiva y seguridad certificada: Todo accesible a través de la sencilla interfaz integrada de System Manager. Para obtener más información, consulte<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Rendimiento optimizado</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">El software SANtricity optimizado para el rendimiento ofrece datos —con una alta tasa de IOPS, un alto rendimiento y una baja latencia— a todas sus aplicaciones de análisis de datos, videovigilancia y backup. Acelere el rendimiento en aplicaciones con baja latencia y una alta tasa de IOPS, y en aplicaciones con requisitos de amplio ancho de banda y un rendimiento alto.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximice el tiempo de actividad</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Complete todas las tareas de gestión mientras el almacenamiento sigue en línea. Modifique las configuraciones, realice tareas de mantenimiento o amplíe la capacidad sin interrumpir el flujo de I/O. Proporcione los mayores niveles de fiabilidad posibles con funciones automatizadas, opciones de configuración en línea, la tecnología de pools de discos dinámicos (DPP) de vanguardia, entre otras.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Esté tranquilo</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">El software SANtricity ofrece una protección de datos superior, supervisión proactiva y seguridad certificada: Todo a través de la sencilla interfaz incluida de System Manager. Simplifique las tareas de gestión del almacenamiento. Obtenga la flexibilidad que necesita para realizar un mejor ajuste de todos los sistemas de almacenamiento E-Series. Gestione su sistema E-Series de NetApp en todo momento y en cualquier lugar. Nuestra interfaz integrada basada en web optimiza el flujo de trabajo de gestión.</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> De NetApp es un orquestador de almacenamiento dinámico de código abierto para Docker y Kubernetes que simplifica la creación, la gestión y el consumo de almacenamiento persistente. Trident, una aplicación nativa de Kubernetes, se ejecuta directamente dentro de un clúster de Kubernetes. Trident permite que los clientes implementen sin problemas imágenes de contenedores de DL en el almacenamiento de NetApp y proporciona una experiencia de clase empresarial para implementaciones de contenedores de IA. Los usuarios de Kubernetes (como desarrolladores DE ML y científicos de datos) pueden crear, gestionar y automatizar la orquestación y el clonado para aprovechar las funcionalidades de gestión de datos avanzadas de NetApp, impulsadas por la tecnología de NetApp.</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">Cloud Sync de NetApp</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Es un servicio de NetApp que ofrece una sincronización de datos rápida y segura. Ya tenga que transferir archivos entre recursos compartidos de archivos NFS o SMB en las instalaciones, StorageGRID de NetApp, ONTAP S3 de NetApp, Cloud Volumes Service de NetApp, Azure NetApp Files, Amazon simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage, O el almacenamiento de objetos en el cloud de IBM, Cloud Sync mueve los archivos donde los necesita de forma rápida y segura. Una vez transferidos los datos, estarán completamente disponibles para su uso tanto en origen como en destino. Cloud Sync sincroniza continuamente los datos, en función de su programación predefinida, moviendo solo los deltas, de modo que se minimiza el tiempo y el dinero invertidos en la replicación de datos. Cloud Sync es una herramienta de software como servicio (SaaS) extremadamente fácil de configurar y utilizar. Las transferencias de datos que Cloud Sync activa son llevadas a cabo por agentes de datos. Puede poner en marcha agentes de datos de Cloud Sync en AWS, Azure, Google Cloud Platform o en las instalaciones.</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Los servidores Lenovo ThinkSystem incluyen hardware, software y servicios innovadores que resuelven los desafíos actuales de los clientes y ofrecen un enfoque de diseño modular, evolutivo y adecuado para su propósito para afrontar los desafíos del futuro. Estos servidores se capitalizan en las mejores tecnologías estándar del sector, junto con innovaciones diferenciadas de Lenovo, para proporcionar la mayor flexibilidad posible en servidores x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Las ventajas clave de la implementación de servidores Lenovo ThinkSystem incluyen:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Diseños modulares y altamente escalables que crecen a medida que lo hace su negocio</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Resiliencia líder en el sector para ahorrar horas de costosos tiempos de inactividad no programados</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Tecnologías flash rápidas para reducir las latencias, acelerar los tiempos de respuesta y gestionar los datos de forma más inteligente en tiempo real</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">En el ámbito de la IA, Lenovo está adoptando un enfoque práctico para ayudar a las empresas a comprender y adoptar las ventajas DEL APRENDIZAJE AUTOMÁTICO y la IA para sus cargas de trabajo. Los clientes de Lenovo pueden explorar y evaluar las ofertas de IA de Lenovo en los centros de innovación de IA de Lenovo para comprender por completo el valor de su caso de uso en particular. Con el fin de mejorar la rentabilidad de la inversión, este enfoque centrado en el cliente proporciona a los clientes una prueba de concepto para las plataformas de desarrollo de soluciones que están listas para usar y optimizadas para la IA.</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Servidor Lenovo ThinkSystem SE350 Edge</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">La computación perimetral permite analizar los datos de dispositivos de IoT en el extremo de la red antes de enviarlos al centro de datos o al cloud. El sistema ThinkSystem SE350 de Lenovo, como se muestra en la siguiente figura, está diseñado para los requisitos únicos de implementación en el perímetro, con un enfoque en flexibilidad, conectividad, seguridad y capacidad de gestión remota en un factor de forma compacto y reforzado con el medio ambiente.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Con el procesador Intel Xeon D con la flexibilidad necesaria para admitir la aceleración de las cargas de trabajo de IA perimetral, el SE350 se ha diseñado específicamente para afrontar los retos de las implementaciones de servidores en una gran variedad de entornos fuera del centro de datos.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">Rendim. MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inferencia del rendimiento ML0,7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf es el conjunto de pruebas de rendimiento líder del sector para evaluar el rendimiento de la IA. Cubre muchas áreas de IA aplicada, incluida la clasificación de imágenes, la detección de objetos, las imágenes médicas y el procesamiento del lenguaje natural (NLP). En esta validación, hemos utilizado cargas de trabajo de inferencia v0.7, que es la última iteración de la inferencia MLPerf al finalizar esta validación. La<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> la suite incluye cuatro nuevas pruebas de rendimiento para centros de datos y sistemas periféricos:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.* representación de encoder bidireccional de Transformers (BERT) ajustada para responder preguntas utilizando el conjunto de datos de escuadrón.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.* el modelo de recomendación de aprendizaje profundo (DLRM) es un modelo de personalización y recomendación que se entrena para optimizar las tarifas de clic (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.* la arquitectura 3D U-Net está entrenada en el conjunto de datos de segmentación del tumor cerebral (Brats).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* el transductor de red neural recurrente (RNN-T) es un modelo de reconocimiento automático de voz (ASR) que se entrena en un subconjunto de LibriSpeech. Los resultados y el código de la inferencia de MLPerf están disponibles y se liberan públicamente bajo la licencia de Apache. La inferencia MLPerf tiene una división Edge, que admite los siguientes escenarios:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Flujo único.* este escenario imita a los sistemas en los que la capacidad de respuesta es un factor crítico, como las consultas de IA sin conexión realizadas en smartphones. Las consultas individuales se envían al sistema y se registran los tiempos de respuesta. como resultado, se indica la latencia del percentil 90 de todas las respuestas.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*MultiStream.* este punto de referencia es para sistemas que procesan la entrada de varios sensores. Durante la prueba, las consultas se envían a un intervalo de tiempo fijo. Se impone una limitación de calidad de servicio (latencia máxima permitida). La prueba informa del número de flujos que el sistema puede procesar mientras cumple la restricción QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Fuera de línea.* este es el escenario más sencillo que cubre las aplicaciones de procesamiento por lotes y la métrica es el procesamiento en muestras por segundo. Todos los datos están disponibles para el sistema y el punto de referencia mide el tiempo que tarda en procesar todas las muestras.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo ha publicado puntuaciones de inferencia MLPerf para SE350 con T4, el servidor utilizado en este documento. Consulte los resultados en<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> En la sección “Edge, Closed Division”, en la entrada #0.7-145.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">Siguiente: Plan de pruebas.</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="9892437a073c63ca6232150c28b21c7b" category="doc">NVA-1156-PUESTA en MARCHA: EF-Series AI de NetApp con sistemas NVIDIA DGX A100 y BeeGFS</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick y David Arnette, NetApp</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">En este documento se describe una arquitectura verificada de NetApp para cargas de trabajo de aprendizaje automático (ML) e inteligencia artificial (IA) mediante los sistemas de almacenamiento EF600 NVMe de NetApp, el sistema de archivos en paralelo ThinkParQ BeeGFS, los sistemas NVIDIA DGX A100 y los switches Mellanox Quantum QM8700 InfiniBand (IB) de 200 Gbps. También se incluyen instrucciones para ejecutar pruebas de referencia de validación una vez completada la implementación.</block>
  <block id="ac6445146035971ff06dde08fd7cd295" category="paragraph"><block ref="ac6445146035971ff06dde08fd7cd295" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-PUESTA en MARCHA: Quantum StorNext con la guía de puesta en marcha de sistemas E-Series de NetApp</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="74e37c842f0aa66d129305c85d5f458a" category="paragraph">Este documento proporciona detalles sobre cómo poner en marcha una solución de sistema de archivos paralelo StorNext con sistemas de almacenamiento E-Series de NetApp. Esta solución abarca la cabina all-flash EF280 de NetApp, la cabina NVMe all-flash EF300 de NetApp, la cabina NVMe all-flash EF600 de NetApp y el sistema híbrido E5760 de NetApp. Ofrece una caracterización del rendimiento basada en las pruebas comparativas de Frametest, una herramienta que se utiliza ampliamente para realizar pruebas en el sector del entretenimiento y los medios de comunicación.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">En esta página se describe cómo supervisar Dask mediante el panel de control de flujo de tareas nativo.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">Supervisión de tarea mediante el panel de control de flujos de tareas nativo</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">Anterior: Cargar día 15 en DASK y entrenar un modelo de bosque aleatorio cuML de DASK.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Planificador distribuido DASK</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">La<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> proporciona comentarios en directo de dos formas:</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">Un panel interactivo que contiene muchos trazados y tablas con información en directo</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">Una barra de progreso adecuada para uso interactivo en consolas o portátiles</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">En nuestro caso, la siguiente figura muestra cómo puede supervisar el progreso de la tarea, incluidos los bytes almacenados, el flujo de tareas con un desglose detallado del número de flujos y el progreso por los nombres de tareas con las funciones asociadas ejecutadas. En nuestro caso, debido a que tenemos tres nodos de trabajo, hay tres partes principales del flujo y los códigos de color denotan diferentes tareas dentro de cada flujo.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">Tiene la opción de analizar tareas individuales y examinar el tiempo de ejecución en milisegundos o identificar cualquier obstáculo o impedimento. Por ejemplo, la siguiente figura muestra los flujos de tareas para la etapa de ajuste del modelo de bosque aleatorio. Se están ejecutando muchas más funciones, incluido el fragmento único para el procesamiento de DataFrame, _construct_rf para ajustar el bosque aleatorio, etc. La mayor parte del tiempo se ha empleado en operaciones DataFrame debido al gran tamaño (45GB) de un día de datos de los registros de clic de Criteo.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">Siguiente: Comparación de tiempo de entrenamiento.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">Esta página describe los pasos necesarios para crear una subred delegada para Azure NetApp Files.</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">Anterior: Instale y configure el clúster AKS.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Para crear una subred delegada para Azure NetApp Files, lleve a cabo los siguientes pasos:</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Acceda a Virtual Networks dentro del portal de Azure. Busque la red virtual que acaba de crear. Debe tener un prefijo como<block ref="a3f69ea034ab8b71fed9b8fc221db9b4" prefix=" " category="inline-code"></block>.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">Haga clic en el nombre de la vnet.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">Haga clic en subredes y, a continuación, en +Subnet en la barra de herramientas superior.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">Proporcione la subred con un nombre como<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Y, en el encabezado Delegación de subred, seleccione<block ref="0c20a1ae75c1cc4efae31193e0d47718" prefix=" " category="inline-code"></block>. No cambie nada más. Haga clic en Aceptar.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Los volúmenes Azure NetApp Files se asignan al clúster de aplicaciones y se consumen como reclamaciones de volúmenes persistentes (RVP) en Kubernetes. A su vez, este proceso le proporciona la flexibilidad para asignarlos a diferentes servicios, tales como portátiles Juppyter, funciones sin servidor, etc.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">Los usuarios de servicios pueden consumir almacenamiento desde la plataforma de muchas maneras. Como este informe técnico trata sobre NFSS, los principales beneficios de Azure NetApp Files son:</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">Brindar a los usuarios la capacidad de usar copias de Snapshot.</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">Permitir a los usuarios almacenar grandes cantidades de datos en volúmenes de Azure NetApp Files.</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">Utilización de las ventajas en el rendimiento de los volúmenes Azure NetApp Files cuando se ejecutan sus modelos en conjuntos de archivos de gran tamaño.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">Siguiente: Par AKS vnet y Azure NetApp Files vnet.</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">En esta sección se describe cómo conectar el vnet del AKS con el vnet del Azure NetApp Files.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">AKS vnet y Azure NetApp Files vnet</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">Anterior: Cree una subred delegada para Azure NetApp Files.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">Para conectar el AKS vnet al vnet de Azure NetApp Files, lleve a cabo los siguientes pasos:</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">Introduzca redes virtuales en el campo de búsqueda.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">Seleccione<block ref="c5d2d918f55de1b8309376bc0310c265" prefix=" " category="inline-code"></block> Haga clic en él e introduzca los peerings en el campo de búsqueda.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">Haga clic en +Agregar.</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">Introduzca los siguientes descriptores:</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">El nombre del enlace de relación de paridad es<block ref="5d43607a5a0ebb50f3ea9348485daa15" prefix=" " category="inline-code"></block>.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">SubscriptionId y Azure NetApp Files vnet como partner de vnet peering.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">Deje todas las secciones que no sean asteriscos con los valores predeterminados.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Haga clic en Añadir.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">Para obtener más información, consulte<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">Siguiente: Instale Trident.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Guardar datos en un volumen persistente aprovisionado por Trident</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">Trident de NetApp es un proyecto de código abierto totalmente compatible diseñado para ayudarle a satisfacer las sofisticadas demandas de persistencia de sus aplicaciones en contenedores. Puede leer y escribir datos en un volumen persistente (VP) de Kubernetes aprovisionado por Trident con la ventaja añadida de la organización en niveles de datos, el cifrado, la tecnología Snapshot de NetApp, el cumplimiento de normativas y el alto rendimiento que ofrece el software de gestión de datos ONTAP de NetApp.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">Reutilizar EVs en un espacio de nombres existente</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">Documentación de Trident de NetApp</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">En el caso de proyectos de IA de mayor tamaño, es posible que sea más eficiente que diferentes contenedores para leer y escribir datos en el mismo PV de Kubernetes. Para reutilizar una solicitud de volumen persistente de Kubernetes (PVC), el usuario ya debe haber creado una RVP. Consulte<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> Para obtener más detalles sobre la creación de una RVP. A continuación se muestra un ejemplo de reutilización de un PVC existente:</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">Ejecute el siguiente comando para ver el estado del trabajo<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block> para el proyecto<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>:</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">Debe ver el montaje PV /tmp/pvc1montado a.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> trabajo<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block>. De este modo, se pueden leer varios contenedores desde el mismo volumen, lo que resulta útil cuando hay varios modelos competidores en desarrollo o producción. Los científicos de datos pueden crear un conjunto de modelos y, a continuación, combinar los resultados de las predicciones por voto mayoritario u otras técnicas.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">Utilice lo siguiente para acceder al shell del contenedor:</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">A continuación, puede comprobar el volumen montado y acceder a los datos dentro del contenedor.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">Esta capacidad de reutilización de RVP funciona con volúmenes FlexVol de NetApp y volúmenes ONTAP FlexGroup de NetApp, lo que permite a los ingenieros de datos disfrutar de opciones de gestión de datos más flexibles y sólidas para aprovechar su Data Fabric con tecnología de NetApp.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Antes de poder usar Trident para aprovisionar recursos de almacenamiento de forma dinámica dentro del clúster de Kubernetes, debe crear una o varias clases de almacenamiento de Kubernetes. Los ejemplos de esta página representan diferentes tipos de clases de almacenamiento que puede que desee crear si implementa la solución de plano de control de IA de NetApp en un pod ONTAP AI.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="doc">Ejemplo de clases de almacenamiento Kubernetes para puestas en marcha de IA en ONTAP</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Antes de poder usar Trident para aprovisionar recursos de almacenamiento de forma dinámica dentro del clúster de Kubernetes, debe crear una o varias clases de almacenamiento de Kubernetes. Los siguientes ejemplos representan diferentes tipos de clases de almacenamiento que puede que desee crear si pone en marcha la solución de plano de control de IA de NetApp en un pool de IA de ONTAP. Si desea obtener más información sobre las clases de almacenamiento, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp recomienda crear un tipo de almacenamiento aparte para cada back-end de Trident habilitado para FlexGroup que haya creado en la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 1. Estas clases de almacenamiento granular le permiten añadir montajes NFS que corresponden a LIF específicas (los LIF especificados cuando se crearon las back-ends de Trident) como un back-end concreto especificado en el archivo SPEC de StorageClass. Los comandos de ejemplo siguientes muestran la creación de dos StorageClasses que corresponden a los dos backends de ejemplo que se crearon en la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 1. Si desea obtener más información sobre las clases de almacenamiento, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentación de Kubernetes</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">Para que no se elimine un volumen persistente cuando se elimine la reclamación de volumen persistente (RVP) correspondiente, en el siguiente ejemplo se utiliza un<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valor de<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>. Para obtener más información acerca de<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> consulte el funcionario<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">NetApp también recomienda crear un StorageClass que se corresponda con el back-end Trident habilitado para FlexVol que ha creado en la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 2. Los comandos de ejemplo siguientes muestran la creación de un solo tipo de almacenamiento para volúmenes FlexVol.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">En el siguiente ejemplo, no se ha especificado un back-end determinado en el archivo de definición StorageClass porque solo se creó un back-end Trident habilitado para FlexVol. Cuando se usa Kubernetes para administrar volúmenes que usan este clase de almacenamiento, Trident intenta usar cualquier back-end disponible que utilice<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> controlador.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">NetApp también recomienda crear un tipo de almacenamiento genérico para volúmenes FlexGroup. En los siguientes comandos de ejemplo, se muestra la creación de un solo tipo de almacenamiento genérico para volúmenes FlexGroup.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">Tenga en cuenta que no se ha especificado un back-end determinado en el archivo de definición StorageClass. Por lo tanto, cuando se usa Kubernetes para administrar volúmenes que usan esta clase de almacenamiento, Trident intenta usar cualquier back-end disponible que utilice<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> controlador.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">Siguiente: Visión general de la implementación de Kubeflow.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Implemente el panel de Grafana</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">Una vez que todo se pone en marcha, ejecutamos inferencias sobre nuevos datos. Los modelos predicen fallos en el equipo de dispositivo de red. Los resultados de la predicción se almacenan en una tabla de timbres de Iguazio. Puede visualizar los resultados con Grafana en la plataforma integrada con la política de acceso a datos y seguridad de Iguazio.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">Puede implementar la consola importando el archivo JSON proporcionado en las interfaces de Grafana en el clúster.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Para verificar que el servicio Grafana se está ejecutando, busque Servicios.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">Si no está presente, implemente una instancia en la sección Servicios:</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">Haga clic en Nuevo servicio.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">Seleccione Grafana de la lista.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">Acepte los valores predeterminados.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">Haga clic en Siguiente paso.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">Introduzca su ID de usuario.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">Haga clic en Guardar servicio.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">Haga clic en aplicar cambios en la parte superior.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">Para implementar el panel de control, descargue el archivo<block ref="5399022d93458a73556ae80388186793" prefix=" " category="inline-code"></block> A través de la interfaz Juppyter.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Abra Grafana en la sección Servicios e importe el panel de control.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Haga clic en Upload<block ref="b31ec5f19793e2b7103acd7336754a1c" prefix=" " category="inline-code"></block> File (Archivo) y seleccione el archivo que descargó anteriormente <block ref="5399022d93458a73556ae80388186793" prefix="(" category="inline-code"></block>). El panel se muestra una vez finalizada la carga.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">Despliegue la función de limpieza</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">Cuando genera una gran cantidad de datos, es importante mantener las cosas limpias y organizadas. Para ello, implemente la función de limpieza con<block ref="11652556f686b20fd51b96992986630e" prefix=" " category="inline-code"></block> portátil.</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">Beneficios</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp y Iguazio aceleran y simplifican la puesta en marcha de aplicaciones de IA y ML mediante la creación de marcos esenciales como Kubeflow, Apache Spark y TensorFlow, junto con herramientas de orquestación como Docker y Kubernetes. Al unificar la canalización de datos completa, NetApp y Iguazio reducen la latencia y la complejidad inherentes a muchas cargas de trabajo informáticas avanzadas, y esta brecha entre el desarrollo y las operaciones. Los científicos de datos pueden ejecutar consultas en grandes conjuntos de datos y compartir de forma segura datos y modelos algorítmicos con usuarios autorizados durante la fase de entrenamiento. Después de que los modelos en contenedores están listos para la producción, puede moverlos fácilmente desde entornos de desarrollo a entornos operativos.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">Hemos realizado una comparativa simple del rendimiento como parte de la creación de esta solución. Hemos ejecutado varias tareas estándar de prueba de rendimiento de NetApp mediante Kubernetes, y comparamos los resultados de las pruebas de rendimiento con ejecuciones realizadas mediante un sencillo comando Docker run.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">Pruebas de rendimiento</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">Hemos realizado una comparativa simple del rendimiento como parte de la creación de esta solución. Hemos ejecutado varias tareas estándar de prueba de rendimiento de IA de NetApp mediante Kubernetes, y comparamos los resultados de las pruebas de rendimiento con ejecuciones realizadas mediante un sencillo comando Docker run. No observamos diferencias notables en cuanto al rendimiento. Por lo tanto, llegamos a la conclusión de que el uso de Kubernetes para orquestar trabajos de entrenamiento de IA en contenedores no afecta negativamente al rendimiento. Consulte la siguiente tabla para ver los resultados de nuestra comparativa de rendimiento.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">Prueba de rendimiento</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker Run (imágenes/s)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes (imágenes/s)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">TensorFlow de un solo nodo</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">Datos sintéticos</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNET</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">TensorFlow distribuido síncrono de dos nodos</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">Siguiente: Conclusión.</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="9708ffc88c964c7e13b023f7eba9396b" category="doc">Puesta EN MARCHA de Mellanox-1153: ONTAP AI de NetApp con sistemas NVIDIA DGX A100 y switches NVA Spectrum Ethernet</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">La puesta EN MARCHA de NVA-1153 incluye instrucciones para la puesta en marcha del sistema de almacenamiento para cargas de trabajo de NetApp Verified Architecture para el aprendizaje automático (ML) y de inteligencia artificial (IA) mediante los sistemas de almacenamiento AFF A800 de NetApp, los sistemas NVIDIA DGX A100 y los switches Ethernet de 200 GB de NVIDIA Mellanox Spectrum SN3700V. También incluye instrucciones para ejecutar pruebas de prueba de rendimiento de validación una vez completada la implementación.</block>
  <block id="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="paragraph"><block ref="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="inline-link-macro-rx"></block></block>
  <block id="83c4efb371f86415987632c0baa2d086" category="doc">DISEÑO NVA-1156: EF-Series AI de NetApp con sistemas NVIDIA DGX A100 y BeeGFS</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick y David Arnette, NetApp</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">El DISEÑO de NVA-1156 describe una arquitectura verificada de NetApp para cargas de trabajo de aprendizaje automático (ML) y de inteligencia artificial (IA) mediante los sistemas de almacenamiento EF600 de NetApp, el sistema de archivos en paralelo BeeGFS, los sistemas NVIDIA DGX A100 y los switches IB de NVIDIA Quantum QM8700 de 200 Gbps. Este diseño incluye InfiniBand (IB) de 200 Gbps para la estructura de interconexión de clústeres de almacenamiento e informáticos con el fin de proporcionar a los clientes una arquitectura completamente basada en IB para las cargas de trabajo de alto rendimiento. Este documento también incluye los resultados de las pruebas de rendimiento para la arquitectura tal y como se ha implementado.</block>
  <block id="2003f72965a4dbc9f31bdaa3da5deaa2" category="paragraph"><block ref="2003f72965a4dbc9f31bdaa3da5deaa2" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Configuración inicial</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configuración inicial</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">En esta sección se describen las tareas de configuración inicial que se deben realizar para utilizar NVIDIA AI Enterprise con NetApp y VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matriz de compatibilidad de productos empresariales de NVIDIA AI</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentación sobre las soluciones de NetApp y VMware</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">Antes de realizar los pasos descritos en esta sección, asumimos que ya ha implementado VMware vSphere y ONTAP de NetApp. Consulte la <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> Para obtener más detalles sobre las versiones de vSphere compatibles. Consulte la <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> Para obtener más información sobre cómo implementar VMware vSphere con ONTAP de NetApp.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Instale el software de host de NVIDIA AI Enterprise</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guía de inicio rápido de NVIDIA AI Enterprise</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Para instalar el software host NVIDIA AI Entrprise, siga las instrucciones que se describen en las secciones 1-4 de la <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">Siguiente: Utilice el software NVIDIA NGC.</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">Resumen de casos de uso de predicción de fallos de dispositivos de red</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">Este caso de uso se basa en un cliente de Iguazio en el espacio de telecomunicaciones en Asia. Con 100 000 clientes empresariales y 125 000 eventos de interrupción de la red al año, era muy importante predecir y tomar medidas proactivas para evitar que los fallos de red afecten a los clientes. Esta solución ofreció las siguientes ventajas:</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">Análisis predictivo para fallos de red</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">Integración con un sistema de emisión de boletos</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">Tomar medidas proactivas para evitar fallos de la red como resultado de esta implementación de Iguazio, el 60 % de los fallos se impidieron de forma proactiva.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">Siguiente: Descripción general de la configuración</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="section-title">Plano de control de la IA y la IA con ONTAP de NetApp</block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">La arquitectura de IA de ONTAP de NetApp, desarrollada y verificada por NetApp y NVIDIA, cuenta con la tecnología de sistemas NVIDIA DGX y los sistemas de almacenamiento conectados al cloud de NetApp. Esta arquitectura de referencia proporciona a las organizaciones DE TI las siguientes ventajas:</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Ofrece opciones de almacenamiento para distintos niveles de rendimiento y coste</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">ONTAP AI de NetApp integra perfectamente los sistemas DGX y los sistemas de almacenamiento AFF A800 de NetApp con una red de vanguardia. Los sistemas ONTAP AI y DGX de NetApp simplifican las puestas en marcha de IA al eliminar complejidades y conjeturas en la fase de diseño. Los clientes pueden empezar poco a poco y aumentar sus sistemas de forma ininterrumpida, a la vez que gestionan de forma inteligente datos entre el perímetro, el núcleo y el cloud.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">El plano de control de IA de NetApp es una solución de gestión de experimentos y datos de IA, ML y aprendizaje profundo (DL) para científicos de datos e ingenieros de datos. A medida que las organizaciones aumentan el uso de la IA, deben hacer frente a numerosos retos, como la escalabilidad de la carga de trabajo y la disponibilidad de los datos. El plano de control de IA de NetApp responde a estos retos mediante funcionalidades como clonar rápidamente un espacio de nombres de datos del mismo modo que una repo de Git y definir e implementar flujos de trabajo de entrenamiento de IA que incorporen la creación casi instantánea de bases de datos y modelos para la trazabilidad y versionado. Con el plano de control de IA de NetApp, puede replicar datos sin problemas entre sitios y regiones y aprovisionar rápidamente espacios de trabajo de los portátiles Juppyter con acceso a conjuntos de datos masivos.</block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="section-title">Ejecutar:Plataforma de IA para orquestación de cargas de trabajo de IA</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">Ejecución:la IA ha creado la primera plataforma de orquestación y virtualización del mundo para la infraestructura de IA. Al abstraer las cargas de trabajo del hardware subyacente, Run:AI crea un pool compartido de recursos de GPU que se pueden aprovisionar de forma dinámica, lo que permite una orquestación eficiente de las cargas de trabajo de IA y un uso optimizado de las GPU. Los científicos de datos pueden consumir sin problemas grandes cantidades de potencia de GPU para mejorar y acelerar sus investigaciones mientras los equipos DE TECNOLOGÍA conservan el control centralizado entre sitios y la visibilidad en tiempo real sobre el aprovisionamiento de recursos, la cola y el uso. La plataforma Run:AI se ha creado sobre Kubernetes, por lo que permite una integración sencilla con los flujos de trabajo existentes de tecnología y ciencia de datos.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">La plataforma Run:AI ofrece los siguientes beneficios:</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">*Plazo de innovación más rápido.* con los mecanismos de puesta en cola, priorización y agrupación de recursos de IA junto con un sistema de almacenamiento de NetApp, los investigadores se eliminan de los problemas de gestión de la infraestructura y pueden centrarse exclusivamente en la ciencia de datos. Ejecución:los clientes de NetApp y IA aumentan la productividad ejecutando tantas cargas de trabajo como necesiten sin cuellos de botella en la canalización de datos o en la computación.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">*Aumento de la productividad del equipo.* Ejecutar:los algoritmos de justicia de IA garantizan que todos los usuarios y equipos obtengan su parte justa de los recursos. Es posible predefinir políticas sobre proyectos de prioridad y la plataforma permite la asignación dinámica de recursos de un usuario o equipo a otro, lo que ayuda a los usuarios a obtener un acceso puntual a los recursos de la GPU codiciados.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">*Uso mejorado de la GPU.* el Planificador Run:AI permite a los usuarios utilizar fácilmente GPU fraccionarias, GPU enteros y varios nodos de GPU para el entrenamiento distribuido en Kubernetes. De esta forma, las cargas de trabajo de IA se ejecutan según sus necesidades, no en función de la capacidad. Los equipos de ciencia de datos pueden realizar más experimentos de IA en la misma infraestructura.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">La arquitectura de IA de ONTAP de NetApp, impulsada por los sistemas NVIDIA DGX y los sistemas de almacenamiento conectados al cloud de NetApp. Esta arquitectura de referencia proporciona a las organizaciones DE TI las siguientes ventajas:</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">Ofrece una gama de opciones de almacenamiento para diferentes prestaciones de rendimiento y coste nuestro ONTAP AI integra a la perfección los sistemas de almacenamiento DGX y AFF A800 de NetApp con las redes de vanguardia. Los sistemas ONTAP AI y DGX de NetApp simplifican las puestas en marcha de IA al eliminar complejidades y conjeturas en la fase de diseño. Los clientes pueden empezar poco a poco y aumentar sus sistemas de forma ininterrumpida, a la vez que gestionan de forma inteligente datos entre el perímetro, el núcleo y el cloud.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">El plano de control de IA de NetApp es una solución de gestión de experimentos y datos de IA, ML y aprendizaje profundo (DL) para científicos de datos e ingenieros de datos. A medida que las organizaciones aumentan el uso de la IA, deben hacer frente a numerosos retos, como la escalabilidad de la carga de trabajo y la disponibilidad de los datos. El plano de control de IA de NetApp aborda estos retos mediante funcionalidades como clonar rápidamente un espacio de nombres de datos del mismo modo que utilizaría un Git repo y definir e implementar flujos de trabajo de entrenamiento de IA que incorporen la creación casi instantánea de datos y líneas de base de modelos para la trazabilidad y el control de versiones. Con el plano de control de IA de NetApp, puede replicar datos sin problemas entre sitios y regiones y aprovisionar rápidamente espacios de trabajo de los portátiles Juppyter con acceso a conjuntos de datos masivos.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">Siguiente: Ejecute la plataforma de IA para la orquestación de cargas de trabajo de IA</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">Agosto de 2021</block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Para esta validación, realizamos la inferencia para un caso de uso de detección de imágenes mediante un conjunto de imágenes en bruto. A continuación, realizamos la misma tarea de inferencia en el mismo conjunto de imágenes con la ofuscación Protopía agregada antes de la inferencia. Repetimos la tarea usando diferentes valores DE ALFA para el componente de ofuscación de Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Comparación de precisión de inferencia</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Para esta validación, realizamos la inferencia para un caso de uso de detección de imágenes mediante un conjunto de imágenes en bruto. A continuación, realizamos la misma tarea de inferencia en el mismo conjunto de imágenes con la ofuscación Protopía agregada antes de la inferencia. Repetimos la tarea usando diferentes valores DE ALFA para el componente de ofuscación de Protopia. En el contexto de la ofuscación de Protopia, el valor ALFA representa la cantidad de ofuscación que se aplica, con un valor ALFA más alto que representa un nivel más alto de ofuscación. A continuación, comparamos la precisión de la inferencia en estas carreras diferentes.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">En las dos tablas siguientes se ofrecen detalles sobre nuestro caso de uso y se resumen los resultados.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia trabaja directamente con los clientes para determinar el valor ALFA adecuado para un caso de uso específico.</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Componente</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Conjunto de datos FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Ofuscación Protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALFA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Precisión</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N.A.</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sí</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">Siguiente: Velocidad de ofuscación.</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Configuración</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Descripción general de la tecnología</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">IA Enterprise de NVIDIA</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise es una suite integral y nativa en el cloud de software de IA y análisis de datos optimizado, certificado y compatible con NVIDIA para ejecutarse en VMware vSphere con sistemas certificados por NVIDIA. Este software facilita la puesta en marcha, la gestión y el escalado simples y rápidos de las cargas de trabajo de IA en el entorno de cloud híbrido moderno.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC aloja un catálogo de software optimizado para GPU para que los profesionales de la IA puedan desarrollar sus soluciones de IA. También proporciona acceso a diversos servicios de IA, incluido NVIDIA base Command para el entrenamiento de modelos, NVIDIA Fleet Command para implementar y supervisar modelos, y el registro privado NGC para acceder y gestionar de forma segura el software de IA propio. Además, los clientes de NVIDIA AI Enterprise pueden solicitar soporte a través del portal NGC.</block>
  <block id="8887a9a417a1629326acdb917d224337" category="section-title">VSphere de VMware</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere es la plataforma de virtualización de VMware, que transforma los centros de datos en infraestructuras informáticas globales que incluyen recursos de CPU, almacenamiento y red. VSphere gestiona estas infraestructuras como un entorno operativo unificado y proporciona a los administradores las herramientas necesarias para gestionar los centros de datos que participan en ese entorno.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Los dos componentes principales de vSphere son ESXi y vCenter Server. ESXi es la plataforma de virtualización donde los administradores crean y ejecutan máquinas virtuales y dispositivos virtuales. VCenter Server es el servicio a través del cual los administradores gestionan varios hosts conectados en una red y un pool de recursos de host.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">ONTAP de NetApp</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, la última generación del software de gestión del almacenamiento de NetApp, permite a las empresas modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. ONTAP ofrece las mejores capacidades de gestión de datos y permite la gestión y protección de los datos con un solo conjunto de herramientas, sin importar dónde residan. También puede mover los datos libremente a donde sea necesario: El perímetro, el núcleo o el cloud. ONTAP 9 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen los datos esenciales y permiten disfrutar de funcionalidades de infraestructura de nueva generación en arquitecturas de cloud híbrido.</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestión de los datos es crucial para las operaciones TECNOLÓGICAS empresariales y los científicos de datos, para que se utilicen recursos apropiados para las aplicaciones de IA y para entrenar conjuntos de datos de IA/ML. La siguiente información adicional sobre las tecnologías de NetApp no está disponible para esta validación, pero puede ser relevante en función de su puesta en marcha.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">El software para la gestión de datos ONTAP incluye las siguientes funciones para mejorar y simplificar las operaciones, y reducir el coste total de funcionamiento:</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compactación de datos inline y deduplicación expandida. La compactación de datos reduce el espacio perdido dentro de los bloques de almacenamiento, mientras que la deduplicación aumenta la capacidad efectiva de forma significativa. Esto es aplicable a los datos almacenados localmente y a los datos organizados en niveles en el cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Calidad de servicio (AQoS) mínima, máxima y adaptativa. Los controles granulares de calidad de servicio (QoS) ayudan a mantener los niveles de rendimiento para aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Prácticas recomendadas de FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">FabricPool de NetApp. Proporciona la organización automática en niveles de datos fríos en opciones de almacenamiento en cloud privado como Amazon Web Services (AWS), Azure y la solución de almacenamiento StorageGRID de NetApp. Para obtener más información sobre FabricPool, consulte<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>.</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP no solo ofrece niveles de rendimiento y protección de datos superiores, sino que amplía estas capacidades de las siguientes maneras:</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Rendimiento y menor latencia. ONTAP ofrece la salida más alta posible con la menor latencia posible.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protección de datos. ONTAP ofrece capacidades integradas de protección de datos, con una administración común entre todas las plataformas.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">Cifrado de volúmenes de NetApp (NVE). ONTAP ofrece cifrado nativo en el nivel de volumen y permite la gestión de claves incorporada o externa.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Multi-tenancy y autenticación multifactor. ONTAP permite compartir recursos de infraestructura con los niveles más altos de seguridad.</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP ayuda a satisfacer las exigentes y siempre cambiantes necesidades de su empresa con las siguientes funciones:</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Escalado sencillo y operaciones no disruptivas. ONTAP admite la adición no disruptiva de capacidad a las controladoras existentes y a clústeres de escalado horizontal. Los clientes pueden empezar a utilizar tecnologías punteras como NVMe y FC 32 GB, sin necesidad de realizar costosas migraciones de datos y sin cortes.</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">Conexión de cloud. ONTAP es el software de gestión de almacenamiento con mejor conexión de cloud e incluye opciones de almacenamiento definido por software (ONTAP Select) e instancias nativas del cloud (NetApp Cloud Volumes Service) en todos los clouds públicos.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integración con aplicaciones emergentes. ONTAP ofrece servicios de datos de clase empresarial para plataformas y aplicaciones de última generación, como vehículos autónomos, ciudades inteligentes e Industria 4.0, utilizando la misma infraestructura que da soporte a las aplicaciones empresariales existentes.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">El kit de herramientas DataOps de NetApp es una herramienta basada en Python que simplifica la gestión de espacios de trabajo de desarrollo/formación y servidores de inferencia respaldados por un almacenamiento de NetApp de escalado horizontal y de alto rendimiento. Estas son algunas funcionalidades clave:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Aprovisione con rapidez nuevos espacios de trabajo de JuppyterLab de alta capacidad respaldados por el almacenamiento de NetApp de escalado horizontal y de alto rendimiento.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Aprovisione rápidamente nuevas instancias del servidor de inferencia de NVIDIA Triton, respaldadas por un almacenamiento empresarial de NetApp.</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clone por vía casi instreutilizada los espacios de trabajo de JuppyterLab de gran capacidad para permitir la experimentación o la iteración rápida.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Guarde copias Snapshot casi por vía inutilizada de espacios de trabajo JuppyterLab de gran capacidad para backup o seguimiento o creación de bases.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Aprovisionamiento, clonado y copias Snapshot de alta capacidad y alto rendimiento casi por vía casi instusand.</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">Esta sección enlaza con dos cuadernos Juppyter relevantes para este informe técnico.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Portátiles Juppyter para referencias</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">Existen dos cuadernos Juppyter asociados a este informe técnico:</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR-PandasRF-collated.ipynb.*</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> Este cuaderno carga el día 15 desde el conjunto de datos de registros Criteo Terabyte Click, procesa y formatea datos en un DataFrame de Pandas, entrena un modelo de bosque aleatorio Scikit-Learn, realiza predicción y calcula la precisión.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">*criteo_dask_RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> Este cuaderno carga el día 15 desde el conjunto de datos de registros Criteo Terabyte Click, procesa y formatea datos en un CuDF DASK, entrena un modelo de bosque aleatorio DASK cuML, realiza predicción y calcula la precisión. Al aprovechar varios nodos de trabajo con GPU, este método de procesamiento y entrenamiento de datos distribuidos y modelos es altamente eficiente. Cuantos más datos procese, mayor será el ahorro de tiempo que se consigue con el método DE ML convencional. Puede implementar este portátil en el cloud, en las instalaciones o en un entorno híbrido en el que el clúster de Kubernetes contenga recursos informáticos y de almacenamiento en diferentes ubicaciones, siempre y cuando su configuración de red permita el movimiento libre de datos y la distribución de modelos.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Utilice el software NVIDIA NGC</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">Utilice el software NVIDIA NGC</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">Anterior: Configuración inicial.</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">En esta sección, se describen las tareas que se deben realizar para utilizar el software empresarial NVIDIA NGC en un entorno de NVIDIA AI Enterprise.</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">Siguiente: Configuración.</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">En esta sección se ofrece una descripción general de los distintos componentes técnicos necesarios para completar esta solución.</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">Anterior: Áreas de soluciones.</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopía</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI ofrece una solución discreta y exclusiva de software para la inferencia confidencial en el mercado actual. La solución Protopia ofrece una protección sin igual para servicios de inferencia al minimizar la exposición de información confidencial. La IA solo se alimenta de la información en el registro de datos que es realmente esencial para realizar la tarea a mano y nada más. La mayoría de las tareas de inferencia no utilizan toda la información que existe en cada registro de datos. Independientemente de si su IA consume imágenes, voz, vídeo o incluso datos tabulares estructurados, Protopia solo ofrece lo que el servicio de inferencia necesita. La tecnología de núcleo patentada utiliza el ruido matemáticamente curado para transformar estocamente los datos y engardar la información que no necesita un servicio DE ML dado. Esta solución no enmascara los datos; más bien, cambia la representación de datos mediante el uso de ruido aleatorio curado.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La solución Protopia formula el problema de cambiar la representación como un método de maximización de turbación basado en gradiente que aún conserva la información pertinente en el espacio de características de entrada con respecto a la funcionalidad del modelo. Este proceso de detección se ejecuta como un pase de ajuste preciso al final del entrenamiento del modelo ML. Después de que el paso genera automáticamente un conjunto de distribuciones de probabilidad, una transformación de datos de baja sobrecarga aplica muestras de ruido de estas distribuciones a los datos, ocultando dichos datos antes de pasarlos al modelo para la inferencia.</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">La arquitectura de referencia de ONTAP AI de NetApp, con sistemas DGX A100 y sistemas de almacenamiento conectados al cloud de NetApp, ha sido desarrollada y verificada por NetApp y NVIDIA. Proporciona a las organizaciones DE TI una arquitectura que ofrece las siguientes ventajas:</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI integra perfectamente los sistemas DGX A100 y los sistemas de almacenamiento AFF A800 de NetApp con una red de vanguardia. ONTAP AI simplifica las puestas en marcha de IA eliminando complejidades y conjeturas de diseño. Los clientes pueden empezar con poco e ir creciendo de forma no disruptiva a la vez que gestionan de forma inteligente los datos desde el perímetro hasta el núcleo, pasando por el cloud.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">En la siguiente figura, se muestran varias variaciones de la familia de soluciones de IA de ONTAP con sistemas DGX A100. El rendimiento del sistema AFF A800 se verifica con hasta ocho sistemas DGX A100. Al añadir pares de controladoras de almacenamiento al clúster ONTAP, la arquitectura puede escalarse a varios racks y admitir muchos sistemas DGX A100 y petabytes de capacidad de almacenamiento con rendimiento lineal. Este enfoque permite alterar de forma independiente las tasas de computación a almacenamiento en función del tamaño de los modelos de AP utilizados y de las métricas de rendimiento necesarias.</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: ONTAP AI de NetApp con sistemas NVIDIA DGX A100 y switches Mellanox Spectrum Ethernet.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Para obtener más información sobre ONTAP AI, consulte<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, la última generación del software de gestión del almacenamiento de NetApp, permite a las empresas modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. ONTAP ofrece las mejores capacidades de gestión de datos y permite la gestión y protección de los datos con un solo conjunto de herramientas, sin importar dónde residan. También puede mover los datos libremente a donde sea necesario: El perímetro, el núcleo o el cloud. ONTAP 9.11 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen los datos esenciales y permiten disfrutar de funcionalidades de infraestructura de nueva generación en arquitecturas de cloud híbrido.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">El kit de herramientas DataOps de NetApp es una biblioteca Python que facilita a los desarrolladores, científicos de datos, ingenieros de DevOps e ingenieros de datos la realización de varias tareas de gestión de datos, como el aprovisionamiento casi instantáneo de un nuevo volumen de datos o un espacio de trabajo JuppyterLab, el clonado casi instantáneo de un volumen de datos o un espacio de trabajo JuppyterLab. Y tomar instantáneas de un volumen de datos o espacio de trabajo JupyterLab para su trazabilidad o línea de base. Esta biblioteca de Python puede funcionar como una utilidad de línea de comandos o una biblioteca de funciones que puede importar a cualquier programa de Python o a cualquier cuaderno de Jupyter.</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="section-title">Servidor de inferencia NVIDIA Triton</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">El servidor de inferencia de NVIDIA Triton es un software de servicio de inferencia de código abierto que ayuda a estandarizar la puesta en marcha y ejecución de modelos para ofrecer IA rápida y escalable en producción. Triton Invalidate Server optimiza la inferencia de IA al permitir a los equipos poner en marcha, ejecutar y escalar modelos de IA entrenados desde cualquier marco en cualquier infraestructura basada en GPU o CPU. El servidor de inferencia de Triton admite los principales marcos de trabajo, como TensorRT, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO, etc. Triton se integra con Kubernetes para la orquestación y el escalado, que puede utilizar en las principales plataformas de inteligencia artificial y Kubernetes. También está integrada con muchas soluciones de software de MLOPS.</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> Es un marco DE APRENDIZAJE AUTOMÁTICO de código abierto. Se trata de una biblioteca tensora optimizada para el aprendizaje profundo que utiliza GPU y CPU. El paquete PyTorch contiene estructuras de datos para tensores multidimensionales que proporcionan muchas utilidades para serializar eficazmente los tensores entre otras utilidades útiles. También tiene un par CUDA que permite ejecutar los cálculos tensores en una GPU de NVIDIA con capacidad de computación. En esta validación, utilizamos la biblioteca de OpenCV-Python (cv2) para validar nuestro modelo y aprovechar los conceptos de visión computarizada más intuitivos de Python.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">Control Astra de NetApp</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Servicio de control Astra</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La familia de productos Astra de NetApp ofrece servicios de gestión de datos para aplicaciones y almacenamiento para aplicaciones de Kubernetes en las instalaciones y en el cloud público, con la tecnología de gestión de datos y almacenamiento de NetApp. Le permite realizar fácilmente backups de aplicaciones Kubernetes, migrar datos a un clúster diferente y crear, de forma instantánea, clones de aplicaciones de trabajo. Si necesita gestionar aplicaciones de Kubernetes que se ejecutan en un cloud público, consulte la documentación de<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>. Astra Control Service es un servicio gestionado por NetApp que proporciona gestión de datos para aplicaciones de clústeres de Kubernetes en Google Kubernetes Engine (GKE) y Azure Kubernetes Service (AKS).</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="section-title">Astra Trident de NetApp</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> De NetApp es un orquestador de almacenamiento dinámico de código abierto para Docker y Kubernetes que simplifica la creación, la gestión y el consumo de almacenamiento persistente. Trident, una aplicación nativa de Kubernetes, se ejecuta directamente dentro de un clúster de Kubernetes. Trident permite que los clientes implementen sin problemas imágenes de contenedores de DL en el almacenamiento de NetApp y proporciona una experiencia de clase empresarial para implementaciones de contenedores de IA. Los usuarios de Kubernetes (desarrolladores DE ML, científicos de datos, etc.) pueden crear, gestionar y automatizar la orquestación y el clonado para aprovechar las funcionalidades avanzadas de gestión de datos que se ofrecen con la tecnología de NetApp.</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Es un servicio de NetApp que ofrece una sincronización de datos rápida y segura. Ya tenga que transferir archivos entre recursos compartidos de archivos NFS o SMB en las instalaciones, StorageGRID de NetApp, ONTAP S3 de NetApp, Cloud Volumes Service de NetApp, Azure NetApp Files, Amazon simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage, O el almacenamiento de objetos en el cloud de IBM, Cloud Sync mueve los archivos donde los necesita de forma rápida y segura. Una vez transferidos los datos, estarán completamente disponibles para su uso tanto en origen como en destino. Cloud Sync sincroniza continuamente los datos en función de su programación predefinida, al mover solo los deltas, de modo que se minimiza el tiempo y el dinero invertidos en la replicación de datos. Cloud Sync es una herramienta de software como servicio (SaaS) extremadamente fácil de configurar y utilizar. Las transferencias de datos que Cloud Sync activa son llevadas a cabo por agentes de datos. Puede poner en marcha agentes de datos de Cloud Sync en AWS, Azure, Google Cloud Platform o en las instalaciones.</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">Cloud Data Sense de NetApp</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">Impulsado por potentes algoritmos de IA, <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> proporciona controles automatizados y control de datos en todos sus datos. Puede localizar con facilidad el ahorro de costes, identificar problemas relacionados con el cumplimiento de normativas y la privacidad, y buscar oportunidades de optimización. El panel Cloud Data Sense le ofrece la información necesaria para identificar datos duplicados y eliminar la redundancia, asignar datos personales, no personales y confidenciales, así como activar alertas de datos confidenciales y anomalías.</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">Siguiente: Plan de pruebas y validación.</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="b7c82ef45da5d640a92ce6fb8fb757b7" category="doc">DISEÑO de Mellanox-1153: ONTAP AI de NetApp con sistemas NVIDIA DGX A100 y switches NVA Spectrum Ethernet</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">EL DISEÑO NVA-1153 describe una arquitectura verificada de NetApp para cargas de trabajo de aprendizaje automático (ML) y de inteligencia artificial (IA) con los sistemas de almacenamiento AFF A800 de NetApp, los sistemas NVIDIA DGX A100 y los switches Ethernet de 200 GB de NVIDIA Mellanox Spectrum SN3700V. Este diseño presenta RDMA over Converged Ethernet (roce) para la estructura de interconexión de clústeres informáticos, que ofrece a los clientes una arquitectura completamente basada en ethernet para cargas de trabajo de alto rendimiento. Este documento también incluye los resultados de las pruebas de rendimiento para la arquitectura tal y como se ha implementado.</block>
  <block id="3dbdc92d258dcfc8f4fb9e2723a77875" category="paragraph"><block ref="3dbdc92d258dcfc8f4fb9e2723a77875" category="inline-link-macro-rx"></block></block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Configurar Kubernetes Cluster</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">Esta sección se divide en dos partes para la puesta en marcha en el cloud y en las instalaciones, respectivamente.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Configuración de Kubernetes de puesta en marcha del cloud</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">A través de Cloud Manager de NetApp, puede definir la conexión al clúster de Kubernetes del Iguazio. Trident requiere acceso a varios recursos en el clúster para que el volumen esté disponible.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">Para habilitar el acceso, obtenga el archivo de configuración de Kubernetes desde uno de los nodos de Iguazio. El archivo está ubicado en<block ref="c94d2475115399d9803ef7d9f1fc7b59" prefix=" " category="inline-code"></block> Descargue este archivo en su escritorio.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">Vaya a detectar clúster para configurar.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Cargue el archivo de configuración de Kubernetes. Consulte la siguiente imagen.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Ponga en marcha Trident y asocie un volumen con el clúster. Vea la siguiente imagen sobre la definición y asignación de un volumen persistente al clúster de Iguazio. Este proceso crea un volumen persistente (PV) en el clúster Kubernetes de Iguazio. Antes de poder usarlo, debe definir una solicitud de volumen persistente (PVC).</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">Configuración de Kubernetes de puesta en marcha en las instalaciones</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">Para ver la instalación local de Trident de NetApp, consulte<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> para obtener más detalles. Tras configurar su clúster de Kubernetes e instalar Trident de NetApp, puede conectar Trident al clúster Iguazio para habilitar las capacidades de gestión de datos de NetApp, como realizar copias Snapshot de sus datos y su modelo.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Siguiente: Defina una solicitud de volumen persistente</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Ejemplos de Juppyter Notebooks y Kubeflow Pipelines</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">Ejemplos de cuadernos y canalizaciones</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kit de herramientas para la ciencia de datos de NetApp para Kubernetes</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">La<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Se puede utilizar junto con Kubeflow. El uso del kit de herramientas para la ciencia de datos de NetApp con Kubeflow ofrece las siguientes ventajas:</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">Los científicos de datos pueden llevar a cabo operaciones avanzadas de gestión de datos de NetApp directamente desde un portátil Juppyter.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Las operaciones avanzadas de gestión de datos de NetApp pueden incorporarse en flujos de trabajo automatizados mediante el marco de canalizaciones de Kubeflow.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Ejemplos de Kubeflow</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">Consulte la<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Sección dentro del repositorio de Data Science Toolkit de NetApp, GitHub para obtener información sobre el uso del kit de herramientas con Kubeflow.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">Siguiente: Implementación de Apache Airflow.</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="c83553858a60514501e9751c0747dea0" category="doc">Equidad en la asignación de recursos básicos</block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">En esta sección, lo mostramos cuando<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Solicita más GPU (están por debajo de su cuota), el sistema coloca en pausa las cargas de trabajo de<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> y los mueve a un estado pendiente de manera equitativa.</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="inline-link-macro">Detalles de las pruebas para la sección 4.9</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">Para obtener información detallada, incluidos los envíos de trabajos, las imágenes contenedoras utilizadas y las secuencias de comandos ejecutadas, consulte la sección <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">La siguiente figura muestra el uso resultante del clúster, las GPU asignadas por equipo y los trabajos pendientes debido al equilibrio de carga automático y a la programación preventiva. Podemos observar que cuando el número total de GPU solicitado por todas las cargas de trabajo de equipo supera el total de GPU disponibles en el clúster, el algoritmo de integridad interno de Run:AI pone en pausa un trabajo por cada una<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> porque han cumplido con su cuota de proyecto. Esto proporciona una utilización elevada del clúster global, mientras que los equipos de ciencia de datos siguen trabajando con las limitaciones de recursos definidas por un administrador.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">Los resultados de este escenario de prueba demuestran lo siguiente:</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">*Equilibrio de carga automático.* el sistema equilibra automáticamente la cuota de las GPU, de modo que cada equipo utiliza ahora su cuota. Las cargas de trabajo en pausa pertenecen a equipos que se encontraban por encima de su cuota.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">*Pausa de uso compartido justo.* el sistema elige detener la carga de trabajo de un equipo que estaba por encima de su cuota y luego detener la carga de trabajo del otro equipo. Ejecutar:la IA tiene algoritmos internos de justicia.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">Siguiente: Equidad sobre las cuotas</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Para esta validación, aplicamos la ofuscación de Protopia a una imagen de 1920 x 1080 píxeles cinco veces y medimos la cantidad de tiempo que tardó en completar el paso de ofuscación cada vez.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Velocidad de ofuscación</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">Anterior: Comparación de precisión de inferencia.</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">Para esta validación, aplicamos la ofuscación de Protopia a una imagen de 1920 x 1080 píxeles cinco veces y medimos la cantidad de tiempo que tardó en completar el paso de ofuscación cada vez. Utilizamos PyTorch ejecutándose en una única GPU NVIDIA V100 para aplicar la ofuscación y borramos la memoria caché de la GPU entre ejecuciones. El paso de ofuscación tomó 5,47 ms, 5.27 ms, 4,54 ms, 5.24 ms y 4,84 ms respectivamente para completar las cinco carreras. La velocidad media era de 5,072 ms.</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Puede ajustar la configuración utilizada para la validación y adaptarla a otros casos prácticos.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Opciones de ajuste de tamaño de arquitectura</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Servidor de computación</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Utilizamos una CPU Intel Xeon D-2123IT, que es el nivel más bajo de CPU compatible con SE350, con cuatro núcleos físicos y 60 W TDP. Aunque el servidor no admite la sustitución de CPU, se puede pedir con una CPU más potente. La CPU más alta admitida es Intel Xeon D-2183IT con 16 núcleos, 100 W con 2,20 GHz. Esto aumenta considerablemente la capacidad computacional de la CPU. Mientras que la CPU no era un cuello de botella para ejecutar las cargas de trabajo de inferencia en sí, ayuda con el procesamiento de datos y otras tareas relacionadas con la inferencia. Actualmente, NVIDIA T4 es la única GPU disponible para casos de uso periféricos; por lo tanto, actualmente, no es posible actualizar o degradar el GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Almacenamiento compartido</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Para las pruebas y la validación, se utilizó el sistema AFF C190 de NetApp, que tiene una capacidad de almacenamiento máxima de 50,5 TB, una rendimiento de 4,4 GB/s para lecturas secuenciales y 230 000 IOPS para pequeñas lecturas aleatorias, con los fines de este documento y se ha demostrado ser apto para cargas de trabajo de inferencia periférica.</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">No obstante, si se requiere más capacidad de almacenamiento o velocidades de red más rápidas, deberá utilizar el o el sistema AFF A220 de NetApp<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> sistemas de almacenamiento. Además, el sistema EF280 de NetApp, que tiene una capacidad máxima de 1,5 PB, 10 Gbps de ancho de banda, también se utilizó para la validación de esta solución. Si prefiere más capacidad de almacenamiento con un mayor ancho de banda,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> puede utilizarse.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">En esta sección se resumen los resultados de la prueba de esta solución.</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">Anterior: Plan de pruebas.</block>
  <block id="6385fabeefcfa0be0a013cdd61625e31" category="paragraph"><block ref="6385fabeefcfa0be0a013cdd61625e31" category="inline-link-macro-rx"></block></block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">La tabla siguiente resume los resultados de todas las pruebas realizadas para esta solución.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Descripción de la prueba</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Resumen de resultados</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Formación de reconocimiento de imágenes: Varios trabajos simultáneos</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Rendimiento muy eficiente. Todos los trabajos se ejecutaron a toda velocidad incluso cuando se utilizaba al máximo el clúster. Los sistemas de almacenamiento de NetApp proporcionaron un rendimiento de formación comparable al almacenamiento SSD local a la vez que posibilitan un uso compartido sencillo de los datos entre servidores.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Formación para el reconocimiento de imágenes: Escalado horizontal</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Altamente eficiente para un máximo de cuatro nodos. En ese momento, la escalabilidad horizontal era menos eficiente pero todavía factible. El uso de una red computacional de mayor velocidad mejora la escalabilidad. El sistema de almacenamiento de NetApp proporcionó un rendimiento de formación comparable al almacenamiento en unidades de estado sólido locales a la vez que permitió compartir fácilmente los datos entre servidores.</block>
  <block id="09011e7c7cce04b0b96cec58ace75585" category="paragraph"><block ref="09011e7c7cce04b0b96cec58ace75585" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Para ejecutar un trabajo DE IA y ML de un solo nodo en su clúster de Kubernetes, realice las tareas que encontrará en esta página desde el host de inicio de la puesta en marcha.</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Para ejecutar una tarea DE IA y ML de un solo nodo en el clúster de Kubernetes, realice las siguientes tareas desde el host de puesta en marcha. Con Trident, puede crear de forma rápida y sencilla un volumen de datos, con potencialmente petabytes de datos al que se puede acceder una carga de trabajo de Kubernetes. Para que un volumen de datos de este tipo sea accesible desde un pod de Kubernetes, solo tiene que especificar una RVP en la definición del pod. Este paso es una operación nativa de Kubernetes, no se necesita experiencia en NetApp.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">En esta sección se supone que ya ha realizado un contenedor (en el formato de contenedor de Docker) con la carga de trabajo específica DE IA y ML que intenta ejecutar en su clúster de Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Sitio web de ImageNET</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Los siguientes comandos de ejemplo muestran la creación de un trabajo de Kubernetes para una carga de trabajo de prueba de ImageNET que utiliza el conjunto de datos de TensorFlow. Para obtener más información acerca del conjunto de datos ImageNET, consulte<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Este trabajo de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un solo nodo de trabajo de GPU con ocho o más GPU. Este trabajo de ejemplo se puede enviar en un clúster para el que no hay un nodo de trabajo con ocho o más GPU o esté ocupado actualmente con otra carga de trabajo. Si es así, el trabajo permanece en estado pendiente hasta que dicho nodo de trabajo esté disponible.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Además, para maximizar el ancho de banda de almacenamiento, el volumen que contiene los datos de entrenamiento necesarios se monta dos veces en el pod que crea este trabajo. Otro volumen también se monta en el pod. Este segundo volumen se utilizará para almacenar resultados y métricas. Estos volúmenes se hacen referencia en la definición de trabajo utilizando los nombres de las RVP. Para obtener más información sobre los trabajos de Kubernetes, consulte<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">An<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumen con un<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valor de<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> está montado en<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> en el pod que crea este trabajo de ejemplo. El tamaño predeterminado de<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> El volumen virtual que se crea automáticamente mediante el tiempo de ejecución del contenedor Docker puede en ocasiones ser insuficiente para las necesidades de TensorFlow. Montaje de un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumen como en el ejemplo siguiente proporciona un tamaño suficiente<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volumen virtual. Para obtener más información acerca de<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volúmenes, consulte<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">El contenedor único que se especifica en esta definición de trabajo de ejemplo se proporciona un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Este valor significa que el contenedor tiene acceso raíz en el host de forma efectiva. Esta anotación se utiliza en este caso porque la carga de trabajo específica que se está ejecutando requiere acceso raíz. Específicamente, una operación de caché clara que ejecuta la carga de trabajo requiere acceso raíz. Si esto o no<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> la anotación es necesaria depende de los requisitos de la carga de trabajo específica que se esté ejecutando.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Confirme que el trabajo que ha creado en el paso 1 se está ejecutando correctamente. El siguiente comando de ejemplo confirma que se creó un solo pod para el trabajo, tal como se especifica en la definición de trabajos, y que este pod se ejecuta actualmente en uno de los nodos de trabajo de la GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Confirme que el trabajo que ha creado en el paso 1 se ha completado correctamente. Los siguientes comandos de ejemplo confirman que el trabajo se ha completado correctamente.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Opcional:* limpiar artefactos de trabajo. Los siguientes comandos de ejemplo muestran la eliminación del objeto de trabajo creado en el paso 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Cuando se elimina el objeto de trabajo, Kubernetes elimina automáticamente todos los pods asociados.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">Siguiente: Ejecute una carga de trabajo de IA distribuida síncrona.</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">Siguiente: Requisitos de software</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">La siguiente figura ilustra la arquitectura del sistema de IA conversacional propuesta. Puede interactuar con el sistema con la señal de voz o con la entrada de texto. Si se detecta una entrada hablada, Jarvis AI-as-service (AIaaS) realiza ASR para producir texto para Dialog Manager. Dialog Manager recuerda los estados de la conversación, enruta el texto a los servicios correspondientes y pasa los comandos al motor de ejecución. El servicio Jarvis NLP toma texto, reconoce intentos y entidades, y envía esos intentos y ranuras de entidad de vuelta a Dialog Manager, que luego envía Acción al motor de cumplimiento. El motor de ejecución consta de API o bases de datos SQL de terceros que responden a las consultas de los usuarios. Después de recibir el resultado de Logística Engine, Dialog Manager enruta el texto a Jarvis TTS AIaaS para producir una respuesta de audio para el usuario final. Podemos archivar el historial de conversaciones, anotar frases con intentos y ranuras para la formación de Nemo, de forma que el servicio de NLP mejore a medida que más usuarios interactúan con el sistema.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">Requisitos de hardware</block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">Esta solución se validó con un sistema de almacenamiento DGX Station y uno AFF A220. Jarvis requiere una GPU T4 o V100 para realizar cálculos profundos de la red neuronal.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">GPU T4 O V100</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">Estación DGX de NVIDIA</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis Framework</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo:v0.10</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">Siguiente: Crear un asistente virtual usando Jarvis, Cloud Sync y Nemo Descripción general</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">Este whitepaper ofrece directrices para los clientes que crean soluciones de inteligencia artificial (IA) conversacionales que usan el marco NVIDIA Jarvis, IA y Cloud Sync ONTAP de NetApp para minoristas y otros casos de uso. Incluye información acerca de los flujos de trabajo de alto nivel utilizados en el desarrollo de modelos de procesamiento de lenguaje natural (NLP) para asistentes virtuales, casos de pruebas validados y resultados.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Esta sección describe el entorno de validación del diseño de la solución.</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">Anterior: Plan de pruebas y validación.</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">La siguiente tabla describe el entorno de validación del diseño de la solución.</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">Controlador Astra Trident CSI de NetApp</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kit de herramientas Data OPS de NetApp para Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">Siguiente: Procedimiento de prueba.</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="4adfb8f589471885ed2256c4719146a6" category="doc">TR-4815: AFF A800 de NetApp y Fujitsu Server PRIMERGY GX2570 M5 para cargas de trabajo de entrenamiento de modelos AI y ML</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette, NetApp Takashi Oishi, Fujitsu</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">Esta solución se centra en una arquitectura de escalado horizontal para poner en marcha sistemas de inteligencia artificial con sistemas de almacenamiento de NetApp y servidores Fujitsu. La solución se validó con las pruebas de rendimiento del modelo MLperf v0.6 mediante servidores Fujitsu GX2570 y un sistema de almacenamiento AFF A800 de NetApp.</block>
  <block id="d6f6c54736f64c202c28a1736214c268" category="paragraph"><block ref="d6f6c54736f64c202c28a1736214c268" category="inline-link-macro-rx"></block></block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">Anterior: Conclusión.</block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files.:</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Página de arquitectura de soluciones para Azure NetApp Files</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">Almacenamiento persistente de Trident para contenedores:</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files y Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">DASK y RAPIDS:</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">DASK</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Instalar el DASK</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">API DASK</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Aprendizaje automático DASK</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">DASK Distributed Diagnostics</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">Obtenga el código de GitHub</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">Ahora que el volumen de cloud de NetApp o el volumen de Trident de NetApp están disponibles para el clúster de Iguazio y el entorno de desarrolladores, puede comenzar a revisar la aplicación.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">Los usuarios tienen su propio espacio de trabajo (directorio). En cada notebook, la ruta al directorio de usuario es<block ref="60dfd72bb314eac7d0f73279723af059" prefix=" " category="inline-code"></block>. La plataforma Iguazio administra el directorio. Si sigue las instrucciones anteriores, el volumen de cloud de NetApp está disponible en<block ref="61bc18ea7642b598a1fcfad2e953599b" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Obtenga el código de GitHub con una terminal Juppyter.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">En el prompt de la terminal de Juppyter, clone el proyecto.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">Ahora debería ver la<block ref="fbeae7c8d4df4765206d2abb38069752" prefix=" " category="inline-code"></block> Carpeta en el árbol de archivos del espacio de trabajo Juppyter.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">Siguiente: Configure el entorno de trabajo</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configuración utilizada para la validación se puede ajustar para ajustarse a otros casos de uso.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Ajustes de arquitectura</block>
  <block id="747bf7dbe4329cb636a09e1a7e4b297b" category="inline-link-macro">Anterior: Procedimiento de prueba y resultados detallados.</block>
  <block id="61862ef71b0230e76d56381617d456b0" category="paragraph"><block ref="61862ef71b0230e76d56381617d456b0" category="inline-link-macro-rx"></block></block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configuración utilizada para esta validación se puede ajustar para ajustarse a otros casos prácticos.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Ajustes de CPU</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Utilizamos un procesador Intel Xeon Platinum 8360Y Skylake para esta validación, según lo recomendado por Lenovo. Esperamos que la CPU equivalente de Cascade Lake, un procesador Intel Xeon Gold 6330, proporcione un rendimiento similar porque esta carga de trabajo no está vinculada a la CPU.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Aumente la capacidad de almacenamiento</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">En función de sus necesidades de capacidad de almacenamiento, puede aumentar el espacio de almacenamiento compartido (volumen NFS) bajo demanda siempre que disponga de las bandejas de discos y los modelos de controladora adicionales. Puede hacerlo desde la CLI o desde la interfaz web de NetApp del controlador de almacenamiento como usuario administrador.</block>
  <block id="326221403d8b3298094c46f2012726ea" category="paragraph"><block ref="326221403d8b3298094c46f2012726ea" category="inline-link-macro-rx"></block></block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">Plazo de innovación más rápido. UsingRun:pool de recursos de IA, puesta en cola y mecanismos de priorización junto con el sistema de almacenamiento de NetApp, los investigadores se eliminan de las dificultades de la gestión de la infraestructura y pueden centrarse exclusivamente en la ciencia de datos. Ejecución:los clientes de NetApp y IA aumentan la productividad ejecutando tantas cargas de trabajo como necesiten sin cuellos de botella en la canalización de datos o en la computación.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">Aumento de la productividad del equipo. Ejecutar:los algoritmos de justicia de IA garantizan que todos los usuarios y equipos obtengan su participación en la feria de recursos. Es posible predefinir políticas sobre proyectos de prioridad y la plataforma permite la asignación dinámica de recursos de un equipo de usuario a otro, lo que ayuda a los usuarios a obtener un acceso puntual a los recursos de GPU codiciados.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">Uso de GPU mejorado. El planificador Run:AI permite a los usuarios utilizar fácilmente GPU fraccionarias, GPU enteros y varios nodos de GPU para llevar a cabo entrenamiento distribuido en Kubernetes. De esta forma, las cargas de trabajo de IA se ejecutan en función de las necesidades, no en función de la capacidad. Los equipos de ciencia de datos pueden realizar más experimentos de IA en la misma infraestructura.</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">Descripción general de casos de uso y declaración de problemas</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">Los conjuntos de datos y las versiones de conjuntos de datos normalmente se encuentran en un lago de datos, como el almacenamiento basado en objetos StorageGRID de NetApp, que ofrece un coste reducido y otras ventajas operativas. Los científicos de datos extraen estos conjuntos de datos y los ingenieros en varios pasos para prepararlos para el entrenamiento con un modelo específico, a menudo creando varias versiones en el proceso. Al siguiente paso, el científico de datos debe seleccionar recursos informáticos optimizados (GPU, instancias de CPU de gama alta, un clúster local, etc.) para ejecutar el modelo. En la siguiente figura, se muestra la falta de proximidad del conjunto de datos en un entorno de computación DE ML.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">Sin embargo, deben ejecutarse varios experimentos de entrenamiento en paralelo en distintos entornos informáticos, cada uno de los cuales requiere una descarga del conjunto de datos del lago de datos, lo cual es un proceso costoso y largo. No se garantiza la proximidad del conjunto de datos a entorno de computación (especialmente para un cloud híbrido). Además, otros miembros del equipo que llevan a cabo sus propios experimentos con el mismo conjunto de datos deben pasar por el mismo arduo proceso. Más allá del obvio y lento acceso a los datos, los retos incluyen las dificultades para seguir las versiones de los conjuntos de datos, compartir conjuntos de datos, colaboración y reproducibilidad.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">Requisitos del cliente</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">Los requisitos del cliente pueden variar para lograr una ejecución DE ML de alto rendimiento mientras se usan los recursos de forma eficiente. Por ejemplo, los clientes pueden requerir lo siguiente:</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">Acceso rápido a los conjuntos de datos desde cada instancia de computación que ejecuta el modelo de entrenamiento sin incurrir en costosas descargas y complejidades de acceso a los datos</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">El uso de cualquier instancia de computación (GPU o CPU) en el cloud o en las instalaciones, sin preocuparse de la ubicación de los conjuntos de datos</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">Aumenta la eficiencia y la productividad ejecutando múltiples experimentos de entrenamiento en paralelo con diferentes recursos informáticos en el mismo conjunto de datos sin retrasos innecesarios y latencia de los datos</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">Costes mínimos de instancias de computación</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">Reproducibilidad mejorada con herramientas para mantener registros de los conjuntos de datos, su linaje, versiones y otros detalles de metadatos</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">Colaboración y uso compartido mejorados para que cualquier miembro autorizado del equipo pueda acceder a los conjuntos de datos y realizar experimentos</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">Para implementar el almacenamiento de conjuntos de datos en caché con el software de gestión de datos ONTAP de NetApp, los clientes deben realizar las siguientes tareas:</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">Configure y establezca el almacenamiento NFS más cercano a los recursos de computación.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">Determinar qué conjunto de datos y versión almacenar en caché.</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">Supervise la memoria total comprometida con los conjuntos de datos almacenados en caché y cuánto almacenamiento NFS está disponible para las confirmaciones adicionales de la caché (por ejemplo, gestión de caché).</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">La caducidad de los conjuntos de datos de la caché si no se han utilizado en un momento determinado. El valor predeterminado es un día; hay otras opciones de configuración disponibles.</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">Siguiente: Descripción general de la solución</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">Creación de proyectos para equipos de ciencia de datos y asignación de GPU</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">Los investigadores pueden enviar cargas de trabajo a través de la CLI Run:AI, Kubeflow o procesos similares. Para agilizar la asignación de recursos y crear prioridades, Run:AI introduce el concepto de proyectos. Los proyectos son entidades de cuota que asocian un nombre de proyecto con la asignación y las preferencias de la GPU. Se trata de una forma sencilla y cómoda de gestionar varios equipos de ciencia de datos.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">Un investigador que presenta una carga de trabajo debe asociar un proyecto con una solicitud de carga de trabajo. El programador Run:AI compara la solicitud con las asignaciones actuales y el proyecto, y determina si la carga de trabajo puede asignarse recursos o si debe permanecer en estado pendiente.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">Como administrador del sistema, puede establecer los siguientes parámetros en la ficha Ejecutar:proyectos AI:</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">*Proyectos modelo.* establecer un proyecto por usuario, establecer un proyecto por equipo de usuarios y establecer un proyecto por proyecto de organización real.</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link">Utilización óptima del clúster gracias a la asignación de GPU por encima de una cuota</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* Cuotas del proyecto.* cada proyecto está asociado con una cuota de GPU que se pueden asignar para este proyecto al mismo tiempo. Se trata de una cuota garantizada en el sentido de que se garantiza que los investigadores que utilizan este proyecto obtengan este número de GPU, independientemente del estado del clúster. Por lo general, la suma de la asignación de proyectos debe ser igual al número de GPU del clúster. Más allá de eso, un usuario de este proyecto puede recibir un exceso de cuota. Mientras no se utilicen las GPU, un investigador que usa este proyecto puede obtener más GPU. Demostramos escenarios de prueba de exceso de cuota y consideraciones de equidad en<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, y.<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">Cree un proyecto nuevo, actualice un proyecto existente y elimine un proyecto existente.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">Ejecute:Documentación de IA</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">*Limite los trabajos para que se ejecuten en grupos de nodos específicos*. Puede asignar proyectos específicos para que se ejecuten solo en nodos específicos. Esto resulta útil cuando el equipo de proyecto necesita hardware especializado, por ejemplo, con suficiente memoria. Como alternativa, un equipo de proyecto podría ser el propietario de hardware específico que se adquirió con un presupuesto especializado o cuando sea necesario dirigir las cargas de trabajo de creación o interactivas para trabajar en hardware más débil y dirigir la formación de mayor duración o las cargas de trabajo sin supervisión a nodos más rápidos. Para ver los comandos para agrupar nodos y establecer la afinidad de un proyecto específico, consulte <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">*Limitar la duración de los trabajos interactivos*. Los investigadores se olvidan frecuentemente de cerrar trabajos interactivos. Esto podría conducir a una pérdida de recursos. Algunas organizaciones prefieren limitar la duración de los trabajos interactivos y cerrarlos automáticamente.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">La siguiente figura muestra la vista proyectos con cuatro equipos creados. A cada equipo se le asigna un número diferente de GPU para dar cuenta de diferentes cargas de trabajo, con un número total de GPU igual al de las GPU disponibles totales en un clúster que consta de dos DGX-1s.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">Siguiente: Envío de trabajos en la CLI de Run AI</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Utilice NVIDIA NGC Software - ejemplo de caso práctico - Trabajo de formación TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Ejemplo de caso práctico: Trabajo de formación de TensorFlow</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">Anterior: Configuración.</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">En esta sección se describen las tareas que se deben realizar para ejecutar una tarea de entrenamiento de TensorFlow dentro de un entorno NVIDIA AI Enterprise.</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">Antes de realizar los pasos descritos en esta sección, asumimos que ya ha creado una plantilla de equipo virtual invitado siguiendo las instrucciones que se describen en la <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> página.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Crear máquina virtual invitada a partir de la plantilla</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">En primer lugar, debe crear un nuevo equipo virtual invitado a partir de la plantilla que ha creado en la sección anterior. Para crear una máquina virtual invitada nueva desde la plantilla, inicie sesión en VMware vSphere, haga clic en el nombre de la plantilla, seleccione "New VM from this Template..." y, a continuación, siga el asistente.</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Cree y monte el volumen de datos</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">A continuación, debe crear un nuevo volumen de datos en el que almacenar el conjunto de datos de entrenamiento. Puede crear rápidamente un nuevo volumen de datos con el kit de herramientas de operaciones de datos de NetApp. El siguiente comando de ejemplo muestra la creación de un volumen llamado 'imagenet' con una capacidad de 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Antes de poder completar el volumen de datos con datos, debe montarlo en la máquina virtual invitada. Puede montar rápidamente un volumen de datos con el kit de herramientas Data OPS de NetApp. El comando de ejemplo siguiente muestra el bigote del volumen que se creó en el paso anterior.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Completar volumen de datos</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Una vez aprovisionado y montado el volumen nuevo, el conjunto de datos de entrenamiento puede recuperarse de la ubicación de origen y colocarse en el volumen nuevo. Normalmente, esto implica extraer los datos de un lago de datos de S3 o Hadoop y a veces contará con la ayuda de un ingeniero de datos.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Ejecutar la tarea de formación de TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Ahora, estará listo para ejecutar su trabajo de formación de TensorFlow. Para ejecutar el trabajo de entrenamiento de TensorFlow, realice las siguientes tareas.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Tire de la imagen del contenedor NVIDIA NGC para TensorFlow empresarial.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Inicie una instancia del contenedor NVIDIA NGC para TensorFlow empresarial. Utilice la opción '-v' para adjuntar el volumen de datos al contenedor.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Ejecute su programa de formación TensorFlow en el contenedor. El comando de ejemplo siguiente muestra la ejecución de un programa de entrenamiento ResNet-50 de ejemplo que se incluye en la imagen contenedora.</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">Siguiente: Dónde encontrar información adicional.</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise con NetApp y VMware - Utilice el software NVIDIA NGC - configuración</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">Anterior: Utilice el software NVIDIA NGC.</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">En esta sección se describen las tareas de configuración inicial que se deben realizar para utilizar el software empresarial NVIDIA NGC en un entorno de NVIDIA AI Enterprise.</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">Antes de realizar los pasos descritos en esta sección, asumimos que ya ha implementado el software host NVIDIA AI Entrprise siguiendo las instrucciones que se describen en la <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> página.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Cree una máquina virtual Ubuntu Guest con vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guía de puesta en marcha de NVIDIA AI Enterprise</block>
  <block id="1d7d5c692ef1d70e3217e93bb16af99e" category="paragraph">En primer lugar, debe crear una máquina virtual invitada Ubuntu 20.04 con vGPU. Para crear una VM huésped de Ubuntu 20.04 con vGPU, siga las instrucciones descritas en el <block ref="f5168fb76d8813fb2707289c4637d2ea" category="inline-link-macro-rx"></block>.</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Descargue e instale el software invitado de NVIDIA</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">A continuación, debe instalar el software invitado NVIDIA requerido en la máquina virtual invitada que creó en el paso anterior. Para descargar e instalar el software invitado NVIDIA necesario en el equipo virtual invitado, siga las instrucciones que se describen en las secciones 5.1-5.4 de la <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Al realizar las tareas de verificación descritas en la sección 5.4, es posible que necesite utilizar una etiqueta de versión de imagen de contenedor CUDA diferente ya que la imagen de contenedor CUDA se ha actualizado desde la escritura de la guía. En nuestra validación, utilizamos 'nvidia/cuda:11.0.3-base-ubuntu20.04'.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Descargue contenedores de marcos de análisis/IA</block>
  <block id="12a93794571377dc80b4be8c2f22349c" category="paragraph">A continuación, debe descargar las imágenes de contenedor de IA o marco de análisis necesarias de NVIDIA NGC para que estén disponibles en la máquina virtual invitada. Para descargar los contenedores de marco en el equipo virtual invitado, siga las instrucciones que se describen en <block ref="26bd3715eff2817a0154bee58d883e27" category="inline-link-macro-rx"></block>.</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Instalación y configuración del kit de herramientas de operaciones de datos de NetApp</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">A continuación, debe instalar el kit de herramientas DataOPS de NetApp para entornos tradicionales en el equipo virtual invitado. El kit de herramientas DataOPS de NetApp se puede usar para gestionar los volúmenes de datos de escalado horizontal en su sistema ONTAP directamente desde el terminal dentro del equipo virtual «guest». Para instalar el kit de herramientas DataOPS de NetApp en el equipo virtual invitado, realice las siguientes tareas.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Instalar la tubería.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Cierre la sesión en el terminal de la máquina virtual invitada y vuelva a iniciarla.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configurar el kit de herramientas de operaciones de datos de NetApp. Para completar este paso, necesitará detalles de acceso a la API para su sistema ONTAP. Es posible que tenga que obtenerlos del administrador de almacenamiento.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Cree una plantilla de máquina virtual invitada</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Por último, debe crear una plantilla de equipo virtual basada en el equipo virtual «guest». Podrá utilizar esta plantilla para crear rápidamente equipos virtuales invitados con el software NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Si desea crear una plantilla de máquina virtual basada en su equipo virtual invitado, inicie sesión en VMware vSphere, haga clic con el botón derecho en el nombre de la máquina virtual invitada, seleccione 'Clonar', elija 'Clonar en plantilla...' y, a continuación, siga el asistente.</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">Siguiente: Caso práctico de ejemplo: Trabajo de formación de TensorFlow.</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise es una suite integral nativa en el cloud de software de análisis de datos e IA optimizada para que todas las organizaciones puedan tener éxito con la IA.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise con NetApp y VMware</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Para los arquitectos y administradores DE TECNOLOGÍA, las herramientas de IA pueden ser complicadas y no conocidas. Además, muchas plataformas de IA no están listas para las empresas. NVIDIA AI Enterprise, con la tecnología de NetApp y VMware, se ha creado para proporcionar una arquitectura de IA optimizada para la gran empresa.</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise es una suite integral y nativa en el cloud de software de IA y análisis de datos optimizado, certificado y compatible con NVIDIA para ejecutarse en VMware vSphere con sistemas certificados por NVIDIA. Este software facilita la puesta en marcha, la gestión y el escalado simples y rápidos de las cargas de trabajo de IA en el entorno de cloud híbrido moderno. NVIDIA AI Enterprise, con la tecnología de NetApp y VMware, ofrece una excelente carga de trabajo de IA y gestión de datos en un paquete simplificado y conocido.</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">Siguiente: Visión general de la tecnología.</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">En esta sección se describen los resultados detallados del procedimiento de prueba.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procedimiento de prueba y resultados detallados</block>
  <block id="5a05f12c2c7f8b9ff569496691352e05" category="paragraph"><block ref="5a05f12c2c7f8b9ff569496691352e05" category="inline-link-macro-rx"></block></block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">El entrenamiento de reconocimiento de imágenes mediante ResNet en ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Ejecutamos la prueba de rendimiento ResNet50 con uno y dos servidores SR670 V2. Esta prueba utilizó el contenedor MXNet 22.04-py3 NGC para realizar el entrenamiento.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Hemos utilizado el siguiente procedimiento de prueba en esta validación:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Se borró la caché del host antes de ejecutar el script para garantizar que los datos no se almacenaban en caché:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Ejecutamos el script de pruebas de rendimiento con el conjunto de datos ImageNET en el almacenamiento de servidores (almacenamiento SSD local) y en el sistema de almacenamiento AFF de NetApp.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Validamos el rendimiento del almacenamiento local y en red con el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Para la ejecución de un solo nodo, utilizamos el siguiente comando:</block>
  <block id="014e128029d9142b6957ca4f1b291090" category="list-text">Para las ejecuciones distribuidas, utilizamos el modelo de paralelización del servidor de parámetros. Se utilizaron dos servidores de parámetros por nodo y se establece el número de épocas igual que para la ejecución de un único nodo. Lo hicimos porque el entrenamiento distribuido a menudo toma más épocas debido a la sincronización imperfecta entre procesos. El número diferente de épocas puede sesgar comparaciones entre casos de un solo nodo y distribuidos.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Velocidad de lectura de los datos: Local frente a almacenamiento en red</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La velocidad de lectura se probó con el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Comando en uno de los archivos para el conjunto de datos ImageNET. Específicamente, ejecutamos los siguientes comandos para datos locales y de red:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Ambos valores son similares, lo que demuestra que el almacenamiento en red puede ofrecer datos a un ritmo similar al del almacenamiento local.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Caso de uso compartido: Trabajos múltiples, independientes y simultáneos</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Esta prueba simuló el caso de uso esperado para esta solución: Formación de IA para varios trabajos y varios usuarios. Cada nodo ejecutó su propia formación mientras utiliza el almacenamiento de red compartida. Los resultados se muestran en la siguiente figura, que muestra que el caso de la solución proporcionó un rendimiento excelente con todos los trabajos que se ejecutan básicamente a la misma velocidad que los trabajos individuales. El rendimiento total se escaló de forma lineal con el número de nodos.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">En esta figura se muestran las imágenes agregadas por segundo.</block>
  <block id="5224aacbc4b8472eb40ead3ee8856b90" category="paragraph"><block ref="5224aacbc4b8472eb40ead3ee8856b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Esta figura muestra el tiempo de ejecución en minutos.</block>
  <block id="8255e8c790967568129f1f898048f1c5" category="paragraph"><block ref="8255e8c790967568129f1f898048f1c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Estos gráficos presentan el tiempo de ejecución en minutos y las imágenes agregadas por segundo para los nodos de computación que utilizaron ocho GPU de cada servidor en una red de cliente de 100 GbE, combinando tanto el modelo de entrenamiento simultáneo como el único modelo de entrenamiento. El tiempo de ejecución medio del modelo de entrenamiento fue de 35 minutos y 9 segundos. Los tiempos de ejecución individuales fueron de 34 minutos y 32 segundos, 36 minutos y 21 segundos, 34 minutos y 37 segundos, 35 minutos y 25 segundos, y 34 minutos y 31 segundos. El promedio de imágenes por segundo para el modelo de entrenamiento fue de 22,573, y las imágenes individuales por segundo fueron de 21,764; 23,438; 22,556; 22,564; y 22,547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Según nuestra validación, un modelo de entrenamiento independiente con tiempo de ejecución de datos de NetApp fue de 34 minutos y 54 segundos con 22,231 imágenes/s. Un modelo de entrenamiento independiente con un tiempo de ejecución de datos locales (DAS) era de 34 minutos y 21 segundos con 22,102 imágenes/s. Durante estas operaciones, el uso medio de la GPU era del 96 %, como se observó en nvidia-smi. Tenga en cuenta que esta media incluye la fase de prueba, durante la cual no se utilizaron las GPU, mientras que el uso de CPU fue del 40 % medido por mpstat. Esto demuestra que la tasa de entrega de datos es suficiente en cada caso.</block>
  <block id="f63534f8e2150e0624ee2af349f77999" category="inline-link-macro">Siguiente: Ajustes de arquitectura.</block>
  <block id="92a7087794ac4c23f482ff2db8cf1742" category="paragraph"><block ref="92a7087794ac4c23f482ff2db8cf1742" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">Esta página describe las tareas que debe completar para poner en marcha un clúster de Kubernetes en el que desea implementar la solución NetApp AI Control Plane. Si ya tiene un clúster de Kubernetes, puede omitir esta sección siempre que ejecute una versión de Kubernetes compatible con Kubeflow y NetApp Trident.</block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Puesta en marcha de Kubernetes</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">En esta sección se describen las tareas que debe completar para poner en marcha un clúster de Kubernetes en el que desea implementar la solución de plano de control de IA de NetApp. Si ya tiene un clúster de Kubernetes, puede omitir esta sección siempre que ejecute una versión de Kubernetes compatible con Kubeflow y NetApp Trident. Si desea ver una lista de las versiones de Kubernetes compatibles con ubeflow, consulte la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Si desea ver una lista de las versiones de Kubernetes compatibles con Trident, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">En el caso de puestas en marcha de Kubernetes en las instalaciones que incorporan nodos de reconstrucción completa con GPU de NVIDIA, NetApp recomienda usar la herramienta de puesta en marcha de Kubernetes DeepOps de NVIDIA. En esta sección, se describe la puesta en marcha de un clúster de Kubernetes con DeepOps.</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">Ya ha configurado todos los nodos Kubernetes con configuración básica (por ejemplo, un sistema NVIDIA DGX que forma parte de un pod ONTAP AI), de acuerdo con instrucciones de configuración estándar.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">Sitio DeepOps GitHub</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">Ha instalado un sistema operativo compatible en todos los nodos maestro y de trabajo de Kubernetes y en un host de salto de implementación. Para obtener una lista de los sistemas operativos compatibles con DeepOps, consulte<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">Utilice NVIDIA DeepOps para instalar y configurar Kubernetes</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">Para poner en marcha y configurar su clúster de Kubernetes con NVIDIA DeepOPS, realice las siguientes tareas desde un host de salto de implementación:</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">Página de Inicio</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">Descargue NVIDIA DeepOps siguiendo las instrucciones de<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Página de la Guía de implementación de Kubernetes</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">Implemente Kubernetes en su clúster siguiendo las instrucciones que se indican en<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">Siguiente: Información general sobre la implementación y la configuración de Trident de NetApp.</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp y cnvrg.io se han asociado para ofrecer a los clientes una solución completa de gestión de datos para el desarrollo de software ML y DL. ONTAP AI proporciona almacenamiento y computación de alto rendimiento para cualquier escala de operación y el software cnvrg.io optimiza los flujos de trabajo de ciencia de datos y mejora la utilización de recursos.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">Siguiente: Reconocimientos</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">Enviar trabajos en ejecución:AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">En esta sección se ofrecen detalles sobre los comandos básicos Run:AI que puede utilizar para ejecutar cualquier trabajo con Kubernetes. Se divide en tres partes según el tipo de carga de trabajo. Las cargas de trabajo de IA/ML/AP se pueden dividir en dos tipos genéricos:</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">*Sesiones de formación desatendida*. Con estos tipos de cargas de trabajo, el científico de datos prepara una carga de trabajo de ejecución automática y la envía para su ejecución. Durante la ejecución, el cliente puede examinar los resultados. Este tipo de carga de trabajo se utiliza a menudo en la producción o cuando el desarrollo de modelos se encuentra en una etapa en la que no se requiere intervención humana.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">*Sesiones interactivas de construcción*. Con este tipo de cargas de trabajo, el científico de datos abre una sesión interactiva con Bash, Juppyter Notebook, PyCharm remoto o IDE similares y accede directamente a los recursos de la GPU. Incluimos un tercer escenario para ejecutar cargas de trabajo interactivas con puertos conectados a fin de revelar un puerto interno al usuario del contenedor.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">Cargas de trabajo de formación desatendida</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">Después de configurar los proyectos y asignar GPU, puede ejecutar cualquier carga de trabajo de Kubernetes usando el siguiente comando en la línea de comandos:</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">Este comando inicia un trabajo de entrenamiento desatendido para el equipo a con una asignación de una única GPU. El trabajo se basa en una imagen de docker de muestra,<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block>. Nosotros nombramos el trabajo<block ref="b10f762d9445989813486accc082c6f1" prefix=" " category="inline-code"></block>. A continuación, puede supervisar el progreso del trabajo ejecutando el siguiente comando:</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">En la siguiente figura se muestra el resultado del<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> comando. Los Estados típicos que puede ver incluyen los siguientes:</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text"><block ref="8627ca3ad23f4fb9adc6ba05047004c6" prefix="" category="inline-code"></block>. El contenedor docker se está descargando del repositorio en la nube.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text"><block ref="2d13df6f8b5e4c5af9f87e0dc39df69d" prefix="" category="inline-code"></block>. El trabajo está a la espera de ser programado.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text"><block ref="5bda814c4aedb126839228f1a3d92f09" prefix="" category="inline-code"></block>. El trabajo se está ejecutando.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">Para obtener un estado adicional en su trabajo, ejecute el siguiente comando:</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">Para ver los registros del trabajo, ejecute el<block ref="13be9f2fcfc2532531562b1e0c6dd431" prefix=" " category="inline-code"></block> comando:</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">En este ejemplo, debería ver el registro de una sesión DL en ejecución, incluyendo la época de entrenamiento actual, ETA, valor de la función de pérdida, precisión y tiempo transcurrido para cada paso.</block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">Puede ver el estado del clúster en la interfaz de usuario Run:AI en<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. En Paneles &gt; Descripción general, puede supervisar el uso de la GPU.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">Para detener esta carga de trabajo, ejecute el siguiente comando:</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">iniciar cargas de trabajo de formación sin supervisión</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">Este comando detiene la carga de trabajo de entrenamiento. Puede verificar esta acción ejecutando<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> de nuevo. Para obtener información detallada, consulte<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">Cargas de trabajo de compilación interactiva</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">Después de configurar proyectos y asignar GPU, puede ejecutar una carga de trabajo de compilación interactiva utilizando el siguiente comando en la línea de comandos:</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">El trabajo se basa en un pitón de imagen de Docker de muestra. Nombramos el edificio de trabajo 1.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">La<block ref="1f21ac5e64afff9d56d5047ace21ffd8" prefix=" " category="inline-code"></block> indicador significa que el trabajo no tiene inicio ni fin Es responsabilidad del investigador cerrar el trabajo. El administrador puede definir un límite de tiempo para los trabajos interactivos después de que el sistema los termine.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">La<block ref="41edd6984c1a14599f6d54cd297a423e" prefix=" " category="inline-code"></block> El indicador asigna una única GPU a este trabajo. El comando y el argumento proporcionados son<block ref="f18e9c054b4fccbc27cd764cb472a213" prefix=" " category="inline-code"></block>. Debe proporcionar un comando o el contenedor se inicia y, a continuación, sale inmediatamente.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">Los siguientes comandos funcionan de forma similar a los comandos descritos en <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text"><block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix="" category="inline-code"></block>: Muestra el nombre, el estado, la edad, el nodo, la imagen, Proyecto, usuario y GPU para trabajos.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text"><block ref="1051ced5efff9d2868a1edd38f951e6e" prefix="" category="inline-code"></block>: Muestra el estado adicional en la generación de trabajos 1.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text"><block ref="624c1f4b1937b32c12cfa1346cb037f9" prefix="" category="inline-code"></block>: Detiene la carga de trabajo interactiva build1.para obtener un shell bash en el contenedor, el siguiente comando:</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">Esto proporciona un shell directo en el equipo. A continuación, los científicos de datos pueden desarrollar o afinar sus modelos dentro del contenedor.</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">iniciar y utilizar cargas de trabajo de compilación interactivas</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">Puede ver el estado del clúster en la interfaz de usuario Run:AI en<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. Para obtener información detallada, consulte<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">Cargas de trabajo interactivas con puertos conectados</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">Entrada</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Como extensión de las cargas de trabajo de compilación interactiva, puede revelar puertos internos al usuario del contenedor al iniciar un contenedor con la CLI Run:AI. Esto resulta útil para entornos cloud, trabajar con Juppyter Notebooks o conectarse a otros microservicios.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Permite el acceso a los servicios de Kubernetes desde fuera del clúster de Kubernetes. Puede configurar el acceso mediante la creación de una colección de reglas que definan qué conexiones entrantes llegan a qué servicios.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">Para mejorar la gestión del acceso externo a los servicios de un clúster, sugerimos que instalen los administradores de clúster<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Y configurar LoadBalancer.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">Para utilizar Ingress como tipo de servicio, ejecute el siguiente comando para establecer el tipo de método y los puertos al enviar la carga de trabajo:</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">Una vez que el contenedor se haya iniciado correctamente, ejecute<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> para ver la<block ref="8d6518907bf83f7ae243a42bc2d2daba" prefix=" " category="inline-code"></block> Con el que acceder al Cuaderno de Jupyter. La dirección URL está compuesta por el punto final de entrada, el nombre del trabajo y el puerto. Por ejemplo, consulte<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">iniciar una carga de trabajo de compilación interactiva con puertos conectados</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">Para obtener información detallada, consulte<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">Siguiente: Lograr un uso elevado del cluster</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Esta solución de NetApp y Lenovo es una arquitectura flexible de escalado horizontal ideal para introducir la IA en una empresa de gama media. El almacenamiento de NetApp proporciona el mismo rendimiento o superior que el almacenamiento SSD local y ofrece las siguientes ventajas a los científicos de datos, ingenieros de datos y responsables de la toma DE decisiones TECNOLÓGICAS.</block>
  <block id="632d8fd87d5999301cfd5bd0c0f29b5f" category="inline-link-macro">Anterior: Ajustes de arquitectura.</block>
  <block id="b145bbef70e5528880cc5abbbe8575cd" category="paragraph"><block ref="b145bbef70e5528880cc5abbbe8575cd" category="inline-link-macro-rx"></block></block>
  <block id="aa91666790d55bdaa993592c884df440" category="paragraph">La solución de NetApp y Lenovo validada aquí es una arquitectura flexible de escalado horizontal ideal para IA empresarial de gama media. El almacenamiento de NetApp proporciona el mismo rendimiento o mejor que el almacenamiento SSD local y ofrece las siguientes ventajas a los científicos de datos, ingenieros de datos y responsables de la toma DE decisiones TECNOLÓGICAS:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Almacenamiento y cálculo escalables independientemente para minimizar los costes y mejorar la utilización de recursos.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Flujos de trabajo de desarrollo y puesta en marcha optimizados que utilizan copias Snapshot y clones integrados para espacios de trabajo de usuario instantáneos con gestión eficiente del espacio, control de versiones integrado y puesta en marcha automatizada.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protección de datos de clase empresarial para recuperación ante desastres y continuidad empresarial.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, Ingeniero Técnico de Marketing de NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, Admin, AI Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Página de producto de cabinas all-flash de NetApp</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Página AFF A400 de NetApp</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Página de producto del software de gestión de datos ONTAP de NetApp</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Prueba de rendimiento de TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">SMI de NVIDIA (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="cf2dfa7ef96d78d1f3ec76316e1481d0" category="cell">Febrero de 2020</block>
  <block id="54858f2e7ecb57a17b7c0be2dedfcd7b" category="cell">Versión inicial. Validación para SR670 y AFF A220 con TensorFlow.</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Versión 2.0</block>
  <block id="abb14d21829ba186172f6e1d0b64b55b" category="cell">Enero de 2023</block>
  <block id="c04468d92a14823a475df983d69e5f9f" category="cell">Versión actualizada. Validación para SR 670 V2 y AFF A400 con MXNet.</block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Ejemplo de flujos de trabajo de flujo de aire de Apache</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">La<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Se puede utilizar junto con el flujo de aire. El uso del kit de herramientas para la ciencia de datos de NetApp con flujo de aire le permite incorporar operaciones de gestión de datos de NetApp en flujos de trabajo automatizados orquestados por flujo de aire.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Ejemplos de flujo de aire</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">Consulte la<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> Sección dentro del repositorio de Data Science Toolkit de NetApp, GitHub para obtener información sobre el uso del kit de herramientas con flujo de aire.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">Siguiente: Ejemplo de operaciones de Trident.</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">Esta página proporciona una descripción general de la tecnología utilizada en esta solución.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft y NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">Desde mayo de 2019, Microsoft ha ofrecido un servicio de portales nativo de Azure para servicios de archivos NFS y SMB empresariales basados en la tecnología ONTAP de NetApp. Este desarrollo está impulsado por una asociación estratégica entre Microsoft y NetApp, y amplía aún más el alcance de los servicios de datos de ONTAP de primera calidad para Azure.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">El servicio de Azure NetApp Files es un servicio de almacenamiento de ficheros de alto rendimiento y medida para empresas. Azure NetApp Files es compatible con cualquier tipo de carga de trabajo y está altamente disponible de manera predeterminada. Puede seleccionar los niveles de servicio y rendimiento, y configurar copias Snapshot a través del servicio. Azure NetApp Files es un servicio de primera parte de Azure para migrar y ejecutar las cargas de trabajo de archivo empresarial más exigentes en el cloud, incluidas bases de datos, SAP y aplicaciones de computación de alto rendimiento sin necesidad de modificar el código.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">Esta arquitectura de referencia proporciona a las organizaciones DE TI las siguientes ventajas:</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">Ofrece una gama de niveles de almacenamiento para distintos niveles de rendimiento y coste</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Información general sobre DASK y NVIDIA RAPIDS</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">DASK es una herramienta de computación paralela de código abierto que escala bibliotecas Python en varias máquinas y permite un procesamiento más rápido de grandes cantidades de datos. Proporciona una API similar a las bibliotecas de Python convencionales de un solo subproceso, como Pandas, numpy y scikit-Learn. Como resultado, los usuarios nativos de Python no se ven obligados a cambiar mucho su código existente para utilizar recursos en el clúster.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS es un paquete de bibliotecas de código abierto que permite ejecutar flujos de trabajo completos de APRENDIZAJE AUTOMÁTICO y análisis de datos en GPU. Junto con DASK, puede escalar con facilidad desde una estación de trabajo con GPU (escalado vertical) a clústeres de varios nodos y varias GPU (escalado horizontal).</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">Para poner en marcha DASK en un clúster, podría utilizar Kubernetes para la orquestación de recursos. También podría escalar verticalmente o reducir los nodos de trabajo según los requisitos del proceso, lo cual, a su vez, puede ayudarle a optimizar el consumo de recursos de clúster, como se muestra en la siguiente figura.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">Siguiente: Requisitos de software.</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785: Puesta en marcha de IA con E-Series de NetApp y BeeGFS</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju, Daniel Landas, Nathan Swartz, Amine Bennani, NetApp</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">Las aplicaciones de inteligencia artificial (IA), aprendizaje automático (ML, por sus siglas en inglés) y aprendizaje profundo (DL, por sus siglas en inglés) implican conjuntos de datos de gran tamaño y cálculos elevados. Para ejecutar estas cargas de trabajo con éxito, necesita una infraestructura ágil que le permita escalar horizontalmente tanto los nodos de almacenamiento como los de computación sin problemas. Este informe incluye los pasos para poner en marcha un modelo de entrenamiento de IA en un modo distribuido, que permite un escalado horizontal fluido de los nodos de computación y almacenamiento. El informe también incluye varios indicadores de rendimiento para mostrar cómo una solución, que combina el almacenamiento E-Series de NetApp con el sistema de archivos en paralelo BeeGFS, proporciona una solución flexible, rentable y sencilla para cargas de trabajo de IA.</block>
  <block id="2ca630161d7251bb59a9e458ddef241c" category="paragraph"><block ref="2ca630161d7251bb59a9e458ddef241c" category="inline-link-macro-rx"></block></block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">Detalles de validación y puesta en marcha de la solución</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">En las siguientes secciones se tratan los detalles de la validación y puesta en marcha de la solución.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">Siguiente: Puesta en marcha de IA de ONTAP</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">Puede personalizar los Estados y flujos de Dialog Manager para sus casos de uso específicos. En nuestro ejemplo de venta al por menor, tenemos los siguientes cuatro archivos yaml para dirigir la conversación según diferentes intentos.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">S la siguiente lista de nombres de archivo y descripción de cada archivo:</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text"><block ref="ef7c28f5093b59a07761555c8914df26" prefix="" category="inline-code"></block>: Define los principales flujos y estados de conversación y dirige el flujo a los otros tres archivos yaml cuando sea necesario.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text"><block ref="dfc9a806326d590aa4ccf49aa6909cda" prefix="" category="inline-code"></block>: Contiene estados relacionados con preguntas sobre puntos de interés o minoristas. El sistema proporciona la información de la tienda más cercana o el precio de un artículo determinado.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text"><block ref="6e08d9d65c68d5f447f4fd239052c12e" prefix="" category="inline-code"></block>: Contiene estados relacionados con las preguntas sobre el clima. Si no se puede determinar la ubicación, el sistema hace una pregunta de seguimiento para aclarar.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text"><block ref="b7dc1d2ced2caa9352158983c5ffeda1" prefix="" category="inline-code"></block>: Trata los casos en los que las intenciones del usuario no entran en los tres archivos yaml anteriores. Después de mostrar un mensaje de error, el sistema vuelve a enruta para aceptar preguntas de usuario.las siguientes secciones contienen las definiciones detalladas de estos archivos yaml.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail_flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">weather_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">error_flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">Siguiente: Conéctese a las API de terceros como motor logístico</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">La combinación de NetApp e Iguazio aúna estas tecnologías como servicios gestionados para acelerar la adopción de tecnologías y mejorar los plazos de comercialización de las nuevas aplicaciones DE IA/ML.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">Esta solución sigue el ciclo de vida de una aplicación de IA/ML. Empezamos con la labor de los científicos de datos para definir los diferentes pasos necesarios para preparar datos y entrenar modelos. Al aprovechar RAPIDS on Dink, realizamos formación distribuida en el clúster de Azure Kubernetes Service (AKS) para reducir drásticamente el tiempo de entrenamiento en comparación con el método convencional de aprendizaje del kit de ciencias de Python. Para completar el ciclo completo, integramos la canalización con Azure NetApp Files.</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904: Formación distribuida en Azure - predicción de frecuencias mediante clic</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">El trabajo de un científico de datos debe centrarse en el entrenamiento y el ajuste de los modelos de aprendizaje automático y de inteligencia artificial (IA). Sin embargo, según una investigación de Google, los científicos de datos dedican aproximadamente el 80 % de su tiempo a averiguar cómo hacer que sus modelos funcionen con aplicaciones empresariales y se ejecuten a escala.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">Para gestionar proyectos de IA y ML integrales, se necesita una comprensión más amplia de los componentes empresariales. Aunque DevOps ha retomado la definición, la integración y la puesta en marcha, estos tipos de componentes, LAS operaciones ML siguen un flujo similar que incluye proyectos de IA/ML. Para hacerse una idea de lo que puede tocar una canalización de IA/ML integral en la empresa, consulte la siguiente lista de componentes requeridos:</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">Oracle</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">Sistemas de ficheros</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">Integración continua y canalización de puesta en marcha continua (CI/CD)</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">Entorno de desarrollo integrado (IDE)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">Seguridad</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">Políticas de acceso a los datos</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">Conjuntos de herramientas y bibliotecas de ciencia de datos</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">El mundo de la ciencia de datos tiene múltiples disciplinas DE TECNOLOGÍA y negocio:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">El científico de datos necesita la flexibilidad para poder usar las herramientas y las bibliotecas de elección.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">El ingeniero de datos necesita saber cómo fluyen los datos y dónde residen.</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">Un ingeniero de DevOps necesita herramientas para integrar nuevas aplicaciones de IA/ML en sus canalizaciones de CI/CD.</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">Los administradores de cloud y arquitectos tienen que poder configurar y gestionar recursos de Azure.</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">Los usuarios empresariales quieren tener acceso a aplicaciones de IA/ML.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">En este informe técnico describimos cómo Azure NetApp Files, RAPIDS AI, Dink y Azure ayudan a cada uno de estos roles a aportar valor empresarial.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="section-title">Descripción general de la solución</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files ofrece varios niveles de rendimiento. Los clientes pueden comenzar con un nivel estándar y escalar horizontalmente y verticalmente a un nivel de alto rendimiento de forma no disruptiva y sin necesidad de mover datos. Esta funcionalidad permite a los científicos de datos entrenar modelos a escala sin problemas de rendimiento y evitar silos de datos en el clúster, como se muestra en la siguiente figura.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">Implementación de la aplicación</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">En las siguientes secciones se describe cómo instalar e implementar la aplicación.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">Siguiente: Obtenga el código de GitHub</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">En esta validación, realizamos el entrenamiento de reconocimiento de imágenes según lo especificado por MLPerf v2.0. En concreto, se formó el modelo ResNet v2.0 con el conjunto de datos ImageNET. La métrica principal es el tiempo para alcanzar la precisión deseada. También reportamos formación de ancho de banda en imágenes por segundo para valorar mejor la eficiencia del escalado horizontal.</block>
  <block id="813c7764ec170fb5498e50560d32a97f" category="paragraph"><block ref="813c7764ec170fb5498e50560d32a97f" category="inline-link-macro-rx"></block></block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">En esta validación, realizamos el entrenamiento de reconocimiento de imágenes según lo especificado por MLPerf v2.0. Específicamente, entrenamos el modelo ResNet v2.0 con el conjunto de datos ImageNET hasta que alcanza una precisión del 76.1 %. La métrica principal es el tiempo para alcanzar la precisión deseada. También reportamos formación de ancho de banda en imágenes por segundo para valorar mejor la eficiencia del escalado horizontal.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">El caso de prueba principal evaluó la ejecución simultánea de varios procesos de entrenamiento independientes (uno por nodo). Simula el caso práctico principal, un sistema compartido utilizado por varios científicos de datos. En el segundo caso de prueba se evaluó la eficiencia del escalado horizontal.</block>
  <block id="e34017da9a1a8d672a4859eb7c75947a" category="paragraph"><block ref="e34017da9a1a8d672a4859eb7c75947a" category="inline-link-macro-rx"></block></block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">Esta sección contiene detalles de la prueba para la sección <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">Enviar trabajos en el siguiente orden:</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">La carga de trabajo Team-b/c se pone en pausa y se mueve a.<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">Las cargas de trabajo de otros equipos (b/c) se pausan y pasan a.<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">Consulte la sección <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> para un debate sobre el escenario de pruebas en curso.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">Siguiente: Detalles de las pruebas para la sección 4.10</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">Plano de control de IA de NetApp:</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">Informe técnico sobre el plano de control de IA de NetApp</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow: Un marco de aprendizaje automático de código abierto para todos<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Plataforma de Ciencia de datos de Iguazio</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Documentación de la Plataforma de Ciencias de datos de Iguazio</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nuclio función sin servidor</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">Marco de orquestación de canalización de código abierto MLRun</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">Sistemas DGX-1 de NVIDIA</block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">GPU de núcleo tensor NVIDIA Tesla V100</block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">GPU Cloud de NVIDIA</block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">Ventaja de NetApp Flash para AFF</block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Cisco Networking</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">Guía de puesta en marcha de ONTAP AI con DGX-1 y Cisco Networking</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Mellanox Networking</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">Redes de IA de ONTAP</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Switches de la serie Cisco Nexus 3232C</block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Serie de switches Ethernet de escalabilidad horizontal Mellanox SN2000</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">Esta página describe los pasos necesarios para configurar el clúster de AKS.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">Instalar y configurar el clúster AKS</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">Anterior: Resumen de casos de uso de predicción de velocidad de clic.</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">Para instalar y configurar el clúster AKS, consulte la página web<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> y, a continuación, realice los siguientes pasos:</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">Al seleccionar el tipo de nodo (nodos System [CPU] o worker [GPU]), seleccione lo siguiente:</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">Los nodos del sistema principal deben ser DS2v2 estándar <block ref="917718fb2e3dcf94043ea14d44580bc2" prefix="(" category="inline-code"></block> tres nodos predeterminados).</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">A continuación, agregue el pool Standard_NC66s_v3 del nodo de trabajo (tres nodos como mínimo) para el grupo de usuarios (para nodos GPU) denominado<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block>.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">La puesta en marcha tarda entre 5 y 10 minutos. Una vez finalizado, haga clic en Connect to Cluster.</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">Para conectarse al clúster AKS recién creado, instale lo siguiente desde su entorno local (portátil/pc):</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">Instrucciones proporcionadas para su SO específico</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">La herramienta de línea de comandos de Kubernetes que utiliza<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Instale la CLI de Azure</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">El CLI de Azure tal como se describe en el documento,<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">Para acceder al clúster AKS desde el terminal, introduzca<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> e introduzca las credenciales.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Introduzca<block ref="33ba05f3df928c75694839078d97b2e4" prefix=" " category="inline-code"></block>.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">Si los seis nodos están en funcionamiento, como se muestra en el siguiente ejemplo, su clúster AKS estará listo y conectado a su entorno local</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">Siguiente: Cree una subred delegada para Azure NetApp Files.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">Requisitos de software y hardware</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">Configuración de red</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">A continuación, se muestra el requisito de configuración de red para configurar en el cloud:</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">El clúster de Iguazio y los volúmenes cloud de NetApp deben estar en el mismo cloud privado virtual.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">El administrador de la nube debe tener acceso al puerto 6443 en los nodos de la aplicación Iguazio.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">Utilizamos Amazon Web Services en este informe técnico. Sin embargo, los usuarios tienen la opción de poner en marcha la solución en cualquier proveedor de cloud.para las pruebas en las instalaciones en IA de ONTAP con NVIDIA DGX-1, hemos utilizado el servicio DNS alojado en Iguazio para mayor comodidad.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">Los clientes deben poder acceder a los dominios DNS creados de forma dinámica. Los clientes pueden utilizar su propio DNS si lo desean.</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">Puede instalar Iguazio en sus instalaciones en su propio clúster. Hemos verificado la solución en ONTAP AI de NetApp con un sistema NVIDIA DGX-1. La siguiente tabla enumera el hardware utilizado para probar esta solución.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">Sistema AFF A800 de NetApp</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1 pareja de alta disponibilidad (ha), incluye 2 controladoras y 48 SSD NVMe (3,8 TB o superior)</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Switches de red Cisco Nexus 3232C</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">En la siguiente tabla se enumeran los componentes de software necesarios para las pruebas in situ:</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 - Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">Versión del contenedor</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tf1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">Marco de aprendizaje automático</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">Iguazio</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">La versión es 2.8 o posterior</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">Servidor ESX</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">Esta solución se ha probado totalmente con Iguazio versión 2.5 y NetApp Cloud Volumes ONTAP para AWS. El clúster de Iguazio y el software de NetApp se ejecutan en AWS.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">Versión o tipo</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">Nodo de aplicación</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xgrande</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">Nodo de datos</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.4xgrande</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">Siguiente: Resumen de casos de uso de predicción de fallos de dispositivo de red</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Puesta en marcha de escala de espectro de IBM con almacenamiento E-Series de NetApp: Instalación y validación</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859 describe el proceso de implementación de una solución de sistema de archivos en paralelo completa basada en la pila de software Spectrum Scale de IBM. TR-4859 está diseñado para proporcionar detalles sobre cómo instalar Spectrum Scale, validar la infraestructura y gestionar la configuración.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp y Run:AI se han asociado en este informe técnico para mostrar las exclusivas funcionalidades de la solución ONTAP AI de NetApp junto con la plataforma Run:AI para simplificar la orquestación de las cargas de trabajo de IA. Los pasos anteriores proporcionan una arquitectura de referencia para optimizar el proceso de canalizaciones de datos y orquestación de cargas de trabajo para el aprendizaje profundo. Animamos a los clientes que deseen poner en marcha estas soluciones a NetApp y a Run:AI para obtener más información.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">Siguiente: Detalles de las pruebas para la sección 4.8</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">Puesta en marcha de IA de ONTAP</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-PUESTA en MARCHA: ONTAP AI de NetApp, con tecnología NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">La puesta en marcha de ONTAP AI requiere la instalación y configuración de hardware de almacenamiento, computación y redes. Este documento no cubre las instrucciones específicas para la puesta en marcha de la infraestructura de IA de ONTAP. Para obtener información detallada sobre la implementación, consulte<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">Para esta validación de soluciones, se creó y montó un solo volumen en el sistema DGX-1. A continuación, ese punto de montaje se montó en los contenedores para que los datos sean accesibles para el entrenamiento. Para puestas en marcha a gran escala, Trident de NetApp automatiza la creación y el montaje de volúmenes para eliminar la sobrecarga administrativa y permitir la gestión de recursos por parte del usuario final.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">Siguiente: Puesta en marcha de Kubernetes</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">Un auténtico sistema de IA conversacional se involucra en un diálogo similar al humano, comprende el contexto y proporciona respuestas inteligentes. Estos modelos de IA a menudo son enormes y muy complejos. Con las GPU de NVIDIA y el almacenamiento de NetApp, se pueden formar y optimizar modelos masivos de lenguaje de última generación para ejecutar inferencia rápidamente. Se trata de una importante medida para poner fin a la compensación entre un modelo de IA que es rápido frente a uno que es grande y complejo. Los modelos de comprensión del lenguaje optimizados para GPU se pueden integrar en las aplicaciones de IA en sectores como el sanitario, el minorista y los servicios financieros. Esto hace posible que asistentes de voz digitales avanzados en altavoces inteligentes y líneas de servicio al cliente. Estos sistemas de IA conversacionales de alta calidad permiten a las empresas de sectores verticales proporcionar servicios personalizados que antes eran impensables al tratar con los clientes.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis permite el despliegue de casos de uso como asistentes virtuales, avatares digitales, sensor multimodal Fusion (CV con fusible ASR/NLP/TTS) o cualquier caso de uso independiente ASR/NLP/TTS/CV, como la transcripción. Hemos creado un asistente de venta al por menor virtual que puede responder a preguntas relacionadas con el tiempo, los puntos de interés y los precios del inventario. También hemos demostrado cómo mejorar el lenguaje natural comprender las funcionalidades del sistema de IA conversacional archivando el historial de conversaciones con Cloud Sync y formando modelos Nemo en nuevos datos.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">Resumen</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Varios supuestos de aplicaciones emergentes, como los sistemas avanzados de asistencia al conductor (ADAS), el sector 4.0, las ciudades inteligentes y el Internet de las cosas (IoT), requieren el procesamiento de flujos de datos continuos con una latencia cercana a cero. Este documento describe una arquitectura de computación y almacenamiento para poner en marcha la inferencia de inteligencia artificial (IA) basada en GPU en controladoras de almacenamiento de NetApp y servidores Lenovo ThinkSystem en un entorno perimetral que satisface estos requisitos. Este documento también proporciona datos de rendimiento para las pruebas de rendimiento de inferencia MLPerf estándares del sector, por lo que evalúa diversas tareas de inferencia en servidores periféricos equipados con GPU T4 de NVIDIA. Investigamos el rendimiento de escenarios de inferencia multisecuencia, sin conexión y con múltiples flujos, y mostramos que la arquitectura con un sistema de almacenamiento en red compartido rentable tiene un alto rendimiento y proporciona un punto central para la gestión de modelos y datos en servidores periféricos múltiples.</block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">El crecimiento exponencial de los datos y el crecimiento exponencial del aprendizaje automático y la inteligencia artificial (IA) han convergido para crear una nueva economía con retos de desarrollo e implementación únicos. Normalmente, se almacenan cantidades masivas de datos en un lago de datos de bajo coste, en el que los recursos informáticos de IA de alto rendimiento, como las GPU, no pueden acceder a ellos de forma eficiente. En este informe presentamos una nueva solución en la que los profesionales de la ciencia de datos implementan un concentrador de datos y, con un solo clic, crean una caché de conjuntos de datos cerca de sus recursos informáticos, independientemente de dónde estén ubicados. Como resultado, los profesionales de la IA pueden realizar la formación de modelos de alto rendimiento con mayor facilidad gracias a la colaboración mejorada que permite un nuevo concentrador de versiones de conjuntos de datos.</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">En esta sección se revisa una canalización de ciencia de datos convencional y sus inconvenientes. También presenta la arquitectura de la solución de almacenamiento en caché del conjunto de datos propuesta.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">Canalización convencional de ciencia de datos e inconvenientes</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">Una secuencia típica de desarrollo e implementación de modelos ML implica pasos iterativos que incluyen lo siguiente:</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">Ingestión de datos</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">Procesamiento previo de los datos (crear varias versiones de los conjuntos de datos)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">Ejecución de múltiples experimentos que implican la optimización de hiperparámetros, diferentes modelos, etc.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="list-text">Puesta en marcha</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io ha desarrollado una plataforma completa para automatizar todas las tareas, desde la investigación hasta la implementación. En la siguiente figura se muestra una pequeña muestra de capturas de pantalla del panel relativas a la canalización.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">Es muy común tener múltiples conjuntos de datos en juego desde los repositorios públicos y los datos privados. Además, es probable que cada conjunto de datos tenga varias versiones como resultado de la limpieza del conjunto de datos o la ingeniería de funciones. Se necesita un panel que proporcione un concentrador de conjuntos de datos y un concentrador de versiones para garantizar que las herramientas de colaboración y consistencia estén disponibles para el equipo, como se puede ver en la siguiente figura.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">El siguiente paso de la canalización es el entrenamiento, que requiere varias instancias paralelas de modelos de entrenamiento, cada uno asociado con un conjunto de datos y una determinada instancia de computación. La vinculación de un conjunto de datos con un cierto experimento con una determinada instancia informática es un reto, ya que es posible que algunos experimentos se realicen mediante instancias de GPU de Amazon Web Services (AWS), mientras que otras instancias de DGX-1 o DGX-2 se llevan a cabo en las instalaciones. Es posible que se ejecuten otros experimentos en servidores de CPU en GCP, mientras que la ubicación del conjunto de datos no está muy cerca de los recursos informáticos que realizan el entrenamiento. Una proximidad razonable tendría conectividad de 10 GbE completa o más baja latencia desde el almacenamiento del conjunto de datos a la instancia de computación.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">Es una práctica común que los científicos de datos descarguen el conjunto de datos a la instancia de computación que realice el entrenamiento y ejecute el experimento. Sin embargo, este enfoque presenta varios problemas posibles:</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">Cuando el científico de datos descarga el conjunto de datos en una instancia informática, no hay garantías de que el almacenamiento informático integrado tenga un alto rendimiento (un ejemplo de un sistema de alto rendimiento sería la solución NVMe A800 de ONTAP AFF).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">Cuando el conjunto de datos descargado reside en un nodo de computación, el almacenamiento puede convertirse en un cuello de botella cuando se ejecutan los modelos distribuidos en varios nodos (a diferencia del almacenamiento distribuido de alto rendimiento de ONTAP de NetApp).</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">La siguiente iteración del experimento de entrenamiento podría realizarse en una instancia de computación diferente debido a conflictos de cola o prioridades, creando de nuevo una distancia significativa de la red desde el conjunto de datos hasta la ubicación de computación.</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">Otros miembros del equipo que ejecutan experimentos de entrenamiento en el mismo clúster informático no pueden compartir este conjunto de datos; cada uno realiza la descarga (costosa) del conjunto de datos desde una ubicación arbitraria.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">Si se necesitan otros conjuntos de datos o versiones del mismo conjunto de datos para las siguientes tareas de entrenamiento, los científicos de datos deben volver a realizar la descarga (costosa) del conjunto de datos en la instancia informática que realiza la versión training.NetApp y cnvrg.io han creado una nueva solución de almacenamiento en caché de conjuntos de datos que elimina estos obstáculos. Esta solución crea una ejecución acelerada de la canalización DE ML mediante el almacenamiento en caché de conjuntos de datos activos en el sistema de almacenamiento de alto rendimiento de ONTAP. Con NFS de ONTAP, los conjuntos de datos se almacenan en caché una vez (y solo una) en una estructura de datos con tecnología de NetApp (como AFF A800), que se encuentra junto con el sistema informático. Dado que el almacenamiento de alta velocidad NFS de ONTAP de NetApp puede dar servicio a nodos de computación DE varios ML, el rendimiento de los modelos de entrenamiento se optimiza, lo que permite ahorrar costes, productividad y eficiencia operativa a la organización.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Arquitectura de la solución</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">Esta solución de NetApp y cnvrg.io proporciona almacenamiento en caché de conjuntos de datos, como se muestra en la siguiente figura. El almacenamiento en caché de conjuntos de datos permite a los científicos de datos elegir la versión deseada de conjuntos de datos o conjuntos de datos y moverlos a la caché NFS de ONTAP, que se encuentra cerca del clúster de computación DE ML. Ahora, el científico de datos puede realizar varios experimentos sin incurrir en retrasos ni descargas. Además, todos los ingenieros de colaboración pueden utilizar el mismo conjunto de datos con el clúster de computación conectado (con la libertad de elegir cualquier nodo) sin descargar adicionales del lago de datos. A los científicos de datos se les ofrece un panel que realiza un seguimiento y supervisa todos los conjuntos de datos y versiones y ofrece una vista de los conjuntos de datos que se almacenan en caché.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">La plataforma cnvrg.io detecta automáticamente conjuntos de datos antiguos que no se han utilizado durante un cierto tiempo y los desaloja de la caché, por lo que mantiene un espacio libre de la caché NFS para conjuntos de datos utilizados con mayor frecuencia. Es importante tener en cuenta que el almacenamiento en caché del conjunto de datos con ONTAP funciona en el cloud y en las instalaciones, por lo que proporciona la máxima flexibilidad.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">Siguiente: Conceptos y componentes</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Ejemplo de operaciones de Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">En esta sección se incluyen ejemplos de diversas operaciones que quizás desee realizar con Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importe un volumen existente</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Si hay volúmenes existentes en su sistema/plataforma de almacenamiento de NetApp que desea montar en contenedores dentro de su clúster de Kubernetes, pero que no están ligados a las RVP en el clúster, debe importar estos volúmenes. Es posible usar la funcionalidad de importación de volúmenes de Trident para importar estos volúmenes.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">Los comandos de ejemplo siguientes muestran la importación del mismo volumen, denominado<block ref="716577bd9ec46fd219326b2aa7404103" prefix=" " category="inline-code"></block> Dos veces, una para cada backend de Trident que se creó en el ejemplo de la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 1. Importar el mismo volumen dos veces de esta manera le permite montar el volumen (un volumen FlexGroup existente) varias veces en diferentes LIF, como se describe en la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 1. Para obtener más información acerca de las EVs, consulte<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. Para obtener más información sobre la funcionalidad de importación de volúmenes, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> Se especifica en los archivos de especificaciones de PVC de ejemplo. Para obtener más información acerca de<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> consulte<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">Los nombres de backend especificados en los siguientes comandos de importación de ejemplo corresponden a las backends que se crearon en el ejemplo de la sección <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, paso 1. Los nombres de StorageClass especificados en el siguiente ejemplo de archivos de definición PVC corresponden a las clases de almacenamiento que se crearon en el ejemplo de la sección <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, paso 1.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Aprovisione un nuevo volumen</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Puede usar Trident para aprovisionar un nuevo volumen en su plataforma o sistema de almacenamiento de NetApp. Los siguientes comandos de ejemplo muestran el aprovisionamiento de un volumen FlexVol nuevo. En este ejemplo, se aprovisiona el volumen con el tipo de almacenamiento que se creó en el ejemplo de la sección <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, paso 2.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> Se especifica en el siguiente archivo de definición de PVC de ejemplo. Para obtener más información acerca de<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> consulte<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">Siguiente: Ejemplo de trabajos de alto rendimiento para puestas en marcha de IA en ONTAP Información general.</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">En esta sección se presentan con mayor detalle los principales componentes de esta solución.</block>
  <block id="56cdae354d8e4efeaa936d576b919c49" category="paragraph"><block ref="56cdae354d8e4efeaa936d576b919c49" category="inline-link-macro-rx"></block></block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Los sistemas de almacenamiento AFF de NetApp permiten a las empresas cumplir sus requisitos de almacenamiento con un rendimiento líder del sector, una flexibilidad superior, integración con el cloud y la mejor gestión de datos. Los sistemas AFF han sido diseñados específicamente para flash y ayudan a acelerar, gestionar y proteger los datos esenciales para la empresa.</block>
  <block id="bd06e3e9a11cc16a8f389477f9ed6a95" category="paragraph">AFF A400 de NetApp es un sistema de almacenamiento flash NVMe de gama media basado en hardware FAS2650 y medios flash SSD.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Este gráfico muestra el frente de la controladora de almacenamiento AFF A400 de NetApp.</block>
  <block id="55f69aa150e5e2d9b4339594dbb70471" category="paragraph"><block ref="55f69aa150e5e2d9b4339594dbb70471" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Este gráfico muestra la parte posterior de la controladora de almacenamiento AFF A400 de NetApp.</block>
  <block id="e83035ebe127e618e86974c913d42589" category="paragraph"><block ref="e83035ebe127e618e86974c913d42589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5062a65c6ae4cbe0c015396c4011a811" category="paragraph">Las funciones del sistema de almacenamiento de gama media AFF A400 de NetApp incluyen las siguientes:</block>
  <block id="722f61060a76e673835749dd7040109c" category="list-text">Capacidad efectiva máxima: 702,7 PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Escalado horizontal máximo: 2-24 nodos (12 parejas de alta disponibilidad)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Compatibilidad con host de FC de 25 GbE y 16 GB</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Conectividad RDMA over Converged Ethernet (roce) de 100 GbE con bandejas de almacenamiento de ampliación NVMe</block>
  <block id="2f5979909b8c4a0d58f13de4881feaf1" category="list-text">Los puertos roce de 100 GbE se pueden utilizar para la conexión adjunta de red de host si no se conectan las bandejas NVMe</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Bandejas de ampliación de almacenamiento con conectividad SAS completa de 12 Gbps</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponible en dos configuraciones:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 puertos Ethernet de 25 GB (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Fibre Channel: 4 puertos FC de 16 GB (SFP+)</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100 % lectura aleatoria de 8 KB @,4 ms 400 k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Las funciones AFF A250 de NetApp para puestas en marcha DE IA/ML de gama básica incluyen lo siguiente:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacidad efectiva máxima: 35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Escalado horizontal máximo: 2-24 nodos (12 parejas de alta disponibilidad)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basado en la última versión de ONTAP de NetApp, ONTAP 9.8 o posterior</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Dos puertos Ethernet de 25 GB para alta disponibilidad e interconexión de clúster</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp también ofrece otros sistemas de almacenamiento, como A800 y AFF A700 de AFF, que proporcionan un mayor rendimiento y escalabilidad para puestas en marcha de IA/ML a gran escala.</block>
  <block id="b2c0ed3ea756cb47f24ee9aef32e0f01" category="paragraph">ONTAP 9, la última generación del software de gestión del almacenamiento de NetApp, permite a las empresas modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. ONTAP ofrece las mejores capacidades de gestión de datos y permite la gestión y protección de los datos con un solo conjunto de herramientas, sin importar dónde residan. Los datos también pueden trasladarse libremente allí donde sea necesario: El perímetro, el núcleo o el cloud. ONTAP 9 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen los datos esenciales y preparan su infraestructura para el futuro con arquitecturas de cloud híbrido.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Calidad de servicio (QoS) mínima, máxima y adaptativa.* los controles granulares de QoS ayudan a mantener los niveles de rendimiento para aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">*ONTAP FabricPool*. Esta función organiza automáticamente en niveles los datos fríos en opciones de almacenamiento en cloud público y privado, incluido el almacenamiento de objetos Amazon Web Services (AWS), Azure y StorageGRID de NetApp.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Rendimiento y menor latencia.* ONTAP ofrece el rendimiento más alto posible con la menor latencia posible.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">*Cifrado de volumen de NetApp.* ONTAP ofrece cifrado nativo a nivel de volumen con compatibilidad para la gestión de claves incorporada y externa.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 ayuda a satisfacer las exigentes y siempre cambiantes necesidades de su empresa:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Escalado sencillo y operaciones no disruptivas.* ONTAP admite la adición sin interrupciones de capacidad a las controladoras existentes y a los clústeres de escalado horizontal. Los clientes pueden empezar a utilizar tecnologías punteras como NVMe y FC 32 GB, sin necesidad de realizar costosas migraciones de datos y sin cortes.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integración con aplicaciones emergentes.* ONTAP ofrece servicios de datos de clase empresarial para plataformas y aplicaciones de próxima generación como OpenStack, Hadoop y MongoDB usando la misma infraestructura que soporta las aplicaciones empresariales existentes.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">FlexGroup Volumes de NetApp</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Los conjuntos de datos de entrenamiento suelen ser una colección de potencialmente miles de millones de archivos. Pueden ser archivos de texto, de audio, de vídeo o cualquier otra forma de datos no estructurados que deban almacenarse y procesarse para su lectura en paralelo. El sistema de almacenamiento debe almacenar muchos archivos pequeños y debe leerlos en paralelo, con una entrada y salida secuencial o aleatoria</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volumen FlexGroup (figura a continuación) es un espacio de nombres único compuesto por múltiples volúmenes constituyentes que se gestiona y actúa como un volumen FlexVol de NetApp entre los administradores de almacenamiento. Los archivos de un volumen de FlexGroup se asignan a volúmenes miembro individuales y no están repartidos en volúmenes o nodos. Ofrecen las siguientes capacidades:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Hasta 20 petabytes de capacidad y baja latencia predecible para cargas de trabajo con una gran cantidad de metadatos</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Hasta 400 000 millones de archivos en un mismo espacio de nombres</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Operaciones en paralelo para cargas de trabajo NAS entre varias CPU, nodos, agregados y volúmenes FlexVol constituyentes</block>
  <block id="19adba666d12642fc956c8a4c4607a66" category="inline-image-macro">"Esta imagen muestra un par de controladoras de almacenamiento de alta disponibilidad que contiene muchos volúmenes con archivos principales dentro de una FlexGroup.</block>
  <block id="67243c21916276b166b8cad21f937c57" category="paragraph"><block ref="3998ac0cd0b54d5528002049c9fb6e1f" category="inline-image-macro-rx" type="image"></block>"</block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Gama Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Entre las ventajas clave de la implementación de servidores Lenovo ThinkSystem se incluyen las siguientes:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Diseños modulares y de gran escalabilidad que crecen con el negocio</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">En el ámbito de la IA, Lenovo está adoptando un enfoque práctico para ayudar a las empresas a comprender y adoptar las ventajas DEL APRENDIZAJE AUTOMÁTICO y la IA para sus cargas de trabajo. Los clientes de Lenovo pueden explorar y evaluar las ofertas de IA de Lenovo en los centros de innovación de IA de Lenovo para comprender por completo el valor de su caso de uso en particular. Con el fin de mejorar la rentabilidad de la inversión, este enfoque centrado en el cliente ofrece a los clientes pruebas de concepto para plataformas de desarrollo de soluciones listas para usar y optimizadas para la IA.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">El servidor en rack Lenovo ThinkSystem SR670 V2 ofrece un rendimiento óptimo para una IA acelerada y una informática de alto rendimiento (HPC). Con soporte para hasta ocho GPU, la SR670 V2 es adecuada para los requisitos de cargas de trabajo informáticas intensivas DE ML, DL e inferencia.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Esta imagen muestra tres configuraciones SR670. La primera muestra cuatro GPU SXM con ocho unidades HS de 2.5 pulgadas y 2 ranuras I/o PCIe. El segundo muestra cuatro ranuras GPU de ancho doble u ocho de ancho único y dos ranuras PCIe de I/o con ocho unidades HS de 2.5 o cuatro de 3.5 pulgadas. El tercero muestra ocho ranuras GPU de doble anchura con seis unidades EDSFF HS y dos ranuras PCIe I/O.</block>
  <block id="f3ebf0cd9319acd4d10b09be0d9220c2" category="paragraph"><block ref="f3ebf0cd9319acd4d10b09be0d9220c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Con las CPU Intel Xeon más recientes y escalables que admiten GPU de gama alta (incluida la GPU 8x PCIe NVIDIA A100 de 80 GB), ThinkSystem SR670 V2 ofrece un rendimiento optimizado y acelerado para cargas de trabajo de IA y computación de alto rendimiento.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Puesto que en más cargas de trabajo se utiliza el rendimiento de los aceleradores, ha aumentado la demanda de densidad de GPU. Sectores como el comercio minorista, los servicios financieros, la energía y la sanidad utilizan GPU para obtener una mayor información e impulsar la innovación con APRENDIZAJE AUTOMÁTICO, DL y técnicas de inferencia.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 es una solución empresarial optimizada para poner en marcha cargas de trabajo aceleradas de HPC e IA en la producción, maximizando el rendimiento del sistema a la vez que mantiene la densidad del centro de datos para los clústeres de supercomputación con plataformas de última generación.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Entre otras funciones se incluyen las siguientes:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Compatibilidad con I/o RDMA directa de GPU en la que los adaptadores de red de alta velocidad están conectados directamente a las GPU para maximizar el rendimiento de I/O.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Compatibilidad con almacenamiento directo de GPU en el que las unidades NVMe están conectadas directamente a las GPU para maximizar el rendimiento del almacenamiento.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf es el conjunto de pruebas de rendimiento líder del sector para evaluar el rendimiento de la IA. En esta validación, utilizamos su punto de referencia de clasificación de imágenes con MXNet, uno de los marcos de IA más populares. El script de formación MXNet_Benchmark se utilizó para impulsar la formación de IA. El script contiene implementaciones de varios modelos convencionales populares y está diseñado para ser lo más rápido posible. Puede ejecutarse en una sola máquina o ejecutarse en modo distribuido entre varios hosts.</block>
  <block id="a29118c3c40b6309f6b6354a52631e91" category="paragraph"><block ref="a29118c3c40b6309f6b6354a52631e91" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">Empresas y organizaciones de todos los tamaños y sectores se están decantando por la inteligencia artificial (IA), el aprendizaje automático (ML) y el aprendizaje profundo (DL) para solucionar problemas del mundo real, ofrecer productos y servicios innovadores y obtener una ventaja en un mercado cada vez más competitivo. A medida que las organizaciones aumentan el uso de la IA, EL ML y el AP, deben hacer frente a numerosos retos, como la escalabilidad de la carga de trabajo y la disponibilidad de los datos. Estos desafíos se pueden abordar mediante el uso de la solución de plano de control de IA de NetApp.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">Esta solución le permite clonar rápidamente un espacio de nombres de los datos. Además, le permite definir e implementar flujos de trabajo de entrenamiento de IA, ML y DL que incorporan la creación casi instantánea de bases de datos y modelos para su trazabilidad y versionado. Con esta solución, puede rastrear cada entrenamiento de modelo único que se ejecuta en los conjuntos de datos exactos con los que se ha entrenado el modelo y/o validado. Por último, esta solución le permite aprovisionar rápidamente espacios de trabajo de los portátiles Juppyter con acceso a conjuntos de datos masivos.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">Dado que esta solución está dirigida a científicos e ingenieros de datos, se requiere una experiencia mínima en NetApp o ONTAP de NetApp. Con esta solución, las funciones de gestión de datos se pueden ejecutar utilizando interfaces y herramientas sencillas y conocidas. Además, esta solución utiliza componentes totalmente de código abierto y libres. Por lo tanto, si ya dispone de almacenamiento de NetApp en su entorno, puede implantar esta solución hoy mismo. Si desea probar esta solución pero no dispone de almacenamiento de NetApp, visite<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>Y puede tener una solución de almacenamiento de NetApp basada en cloud en un instante.</block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">Ejecutar:Paneles de IA y vistas</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Después de instalar Run:AI en su clúster de Kubernetes y configurar los contenedores correctamente, verá las siguientes consolas y vistas en<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> en su navegador, como se muestra en la siguiente figura.</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">Hay 16 GPU en total en el clúster proporcionados por dos nodos DGX-1. Puede ver el número de nodos, el total de GPU disponibles, las GPU asignadas con cargas de trabajo, el número total de trabajos en ejecución, los trabajos pendientes y las GPU asignadas inactivas. En el lado derecho, el diagrama de barras muestra las GPU por proyecto, que resume cómo usan los distintos equipos el recurso de clúster. En el medio se encuentra la lista de trabajos actualmente en ejecución con detalles de trabajo, incluidos el nombre del trabajo, el proyecto, el usuario, el tipo de trabajo, El nodo en el que se ejecuta cada trabajo, el número de GPU asignados para ese trabajo, el tiempo de ejecución actual del trabajo, el progreso del trabajo en porcentaje y el uso de la GPU para ese trabajo. Tenga en cuenta que el clúster está infrautilizado (uso de la GPU al 23%) porque solo hay tres trabajos en ejecución enviados por un único equipo <block ref="9320270de4ff6824ae7a21f729fb7d44" prefix="(" category="inline-code"></block>).</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">En la siguiente sección, mostramos cómo crear varios equipos en la pestaña proyectos y asignar GPU para cada equipo con el fin de maximizar el uso del clúster y gestionar los recursos cuando hay muchos usuarios por clúster. Los escenarios de prueba imitan entornos empresariales en los que los recursos de memoria y GPU se comparten entre cargas de trabajo de entrenamiento, inferencia e interactivas.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">Siguiente: Creación de proyectos para equipos de ciencia de datos y asignación de GPU</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">En esta sección se tratan los requisitos tecnológicos de la solución de IA de ONTAP.</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">Sitio web de IA de ONTAP</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">Aunque los requisitos de hardware dependen de cargas de trabajo específicas de los clientes, es posible poner en marcha IA de ONTAP a cualquier escala para la ingeniería de datos, el entrenamiento de modelos y la inferencia de producción desde una única GPU hasta configuraciones a escala de rack para operaciones DE APRENDIZAJE AUTOMÁTICO o aprendizaje profundo a gran escala. Si quiere más información sobre ONTAP AI, consulte<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">Esta solución se validó utilizando un sistema DGX-1 para computación, un sistema de almacenamiento AFF A800 de NetApp y Cisco Nexus 3232C para conectividad de red. El AFF A800 utilizado en esta validación puede admitir hasta 10 sistemas DGX-1 para la mayoría de cargas de trabajo DE ML/DL. En la siguiente figura se muestra la topología ONTAP AI utilizada para entrenar el modelo en esta validación.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">Para ampliar esta solución a un cloud público, Cloud Volumes ONTAP puede ponerse en marcha junto con los recursos informáticos de la GPU del cloud e integrarse en un tejido de datos del cloud híbrido que permita a los clientes utilizar los recursos que sean apropiados para una carga de trabajo en concreto.</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">En la siguiente tabla se muestran las versiones de software específicas que se utilizan en la validación de esta solución.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">Para esta validación de soluciones, se puso en marcha Kubernetes como un clúster de un solo nodo en el sistema DGX-1. Para las puestas en marcha a gran escala, se deben poner en marcha nodos maestros de Kubernetes independientes para proporcionar una alta disponibilidad de los servicios de gestión y reservar valiosos recursos DGX para las cargas de trabajo DE APRENDIZAJE AUTOMÁTICO y aprendizaje profundo.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">Siguiente: Detalles de implementación y validación de la solución</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">Los autores agradecen las contribuciones que nuestros estimados colegas de NVIDIA han realizado a este documento técnico: Davide Onofrío, Alex Qi, Sicong Ji, Marty Jain y Robert Sohigian. Los autores también desean reconocer las contribuciones de miembros clave del equipo de NetApp: Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare, Erik Mulder, y Mike McNamara.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">Nuestro más sincero agradecimiento a todos aquellos que nos ofrecieron sus valiosos comentarios y su experiencia para la creación de este informe.</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">En esta sección se describen las tareas que debe completar para poner en marcha el flujo de aire en el clúster de Kubernetes.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Distribución del flujo de aire de Apache</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">NetApp recomienda ejecutar el flujo de aire de Apache sobre Kubernetes. En esta sección se describen las tareas que debe completar para poner en marcha el flujo de aire en el clúster de Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Es posible poner en marcha un flujo de aire en plataformas distintas a Kubernetes. Esta solución no cubre la posibilidad de poner en marcha un flujo de aire en plataformas distintas a Kubernetes.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Ya tiene un clúster de Kubernetes en funcionamiento.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">Ya ha instalado y configurado NetApp Trident en su clúster de Kubernetes como se indica en la sección “NetApp Trident Deployment and Configuration”.</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Instale el Helm</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">El flujo de aire se pone en marcha con Helm, un conocido administrador de paquetes para Kubernetes. Antes de implementar el flujo de aire, debe instalar Helm en el host de salto de la implementación. Para instalar Helm en el host de salto de despliegue, siga la<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> En la documentación oficial de Helm.</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">Antes de implementar el flujo de aire, debe designar un tipo de almacenamiento predeterminado en el clúster de Kubernetes. El proceso de implementación de flujo de aire intenta aprovisionar nuevos volúmenes persistentes mediante el tipo de almacenamiento predeterminado. Si no se designa StorageClass como clase de almacenamiento predeterminado, la implementación falla. Para designar un tipo de almacenamiento predeterminado en el clúster, siga las instrucciones que se describen en la sección <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. Si ya ha designado un tipo de almacenamiento predeterminado en el clúster, puede omitir este paso.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Utilice Helm para desplegar el flujo de aire</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Para poner en marcha el flujo de aire en su clúster de Kubernetes con Helm, realice las siguientes tareas desde el host de salto de implementación:</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Despliegue el flujo de aire con Helm siguiendo la<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Para el diagrama de flujo de aire oficial en el Hub de artefactos. Los comandos de ejemplo siguientes muestran la implementación del flujo de aire con Helm. Modifique, agregue o elimine valores en la<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> fichero según sea necesario en función de su entorno y de la configuración deseada.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Confirme que todos los pods de flujo de aire estén activos y en funcionamiento. Puede tardar varios minutos en comenzar todos los pods.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Obtenga la URL del servicio web de flujo de aire siguiendo las instrucciones que se imprimieron en la consola cuando implementó el flujo de aire con Helm en el paso 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Confirme que puede acceder al servicio web de flujo de aire.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">Siguiente: Ejemplo de flujos de trabajo de flujo de aire de Apache.</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">Artículo técnico WP-7328: La IA conversacional de NetApp con NVIDIA Jarvis</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-han Lin, NetApp Davide Onofrío, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">La familia de sistemas NVIDIA DGX está compuesta por los primeros sistemas basados en inteligencia artificial (IA) integrados del mundo, creados expresamente para la IA empresarial. Los sistemas de almacenamiento AFF de NetApp proporcionan un rendimiento extremo y funcionalidades de gestión de datos de cloud híbrido líderes en el sector. NetApp y NVIDIA se han asociado para crear la arquitectura de referencia de IA ONTAP de NetApp, una solución lista para usar para cargas de trabajo de IA y aprendizaje automático (ML) que ofrece rendimiento, fiabilidad y soporte de clase empresarial.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">Este whitepaper proporciona instrucciones direccionales a los clientes para crear sistemas de IA conversacionales que respaldan diferentes casos de uso en diversos sectores verticales. Incluye información sobre la implementación del sistema mediante NVIDIA Jarvis. Las pruebas se llevaron a cabo con una estación DGX de NVIDIA y un sistema de almacenamiento AFF A220 de NetApp.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos de IA y software para casos de uso de IA conversacionales como un asistente de ventas al por menor virtual</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">Científicos de datos que buscan formas eficientes de lograr los objetivos de desarrollo del modelado del lenguaje</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">Ingenieros de datos encargados de mantener y procesar datos de texto, como preguntas de clientes y transcripciones de diálogo</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">Responsables de la toma de decisiones tecnológicas y ejecutivas y líderes de negocio interesados en transformar la experiencia de IA conversacional y lograr el plazo de comercialización más rápido de iniciativas de IA</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">La solución propuesta en este informe técnico ha quedado demostrada para respaldar la prestación de estas experiencias excepcionales a los clientes, y el reto consiste ahora en garantizar que las empresas tomen acciones para modernizar su infraestructura de IA y sus flujos de trabajo.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Anterior: Vídeos y demostraciones.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">A medida que se considera cada vez más la experiencia de los clientes como un campo de batalla competitivo clave, un centro de soporte global aumentado por IA se convierte en un componente fundamental que las empresas de casi todos los sectores no pueden permitirse el lujo de descuidar. La solución propuesta en este informe técnico ha quedado demostrada para respaldar la prestación de estas experiencias excepcionales a los clientes, y el reto consiste ahora en garantizar que las empresas tomen acciones para modernizar su infraestructura de IA y sus flujos de trabajo.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">Las mejores implementaciones de IA en servicio al cliente no consisten en sustituir a los agentes humanos. Más bien, la IA puede empoderarlos para crear experiencias de cliente excepcionales mediante análisis de sensibilidad en tiempo real, escalado de disputas y computación afectiva multimodal para detectar señales verbales, no verbales y faciales con las que los modelos de IA integrales pueden hacer recomendaciones a escala y complementar lo que podría carecer un agente humano individual. Asimismo, la IA puede proporcionar una mejor unión entre un cliente concreto con los agentes disponibles actualmente. Gracias a la IA, las empresas pueden extraer un valioso sentimiento de los clientes en cuanto a sus pensamientos e impresiones sobre los productos, servicios y la imagen de la Marca del proveedor.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">La solución también se puede usar para construir datos de series temporales para que los agentes de soporte sirvan como métrica de evaluación del rendimiento objetivo. Las encuestas convencionales de satisfacción de clientes a menudo no tienen respuestas suficientes. Al recopilar la opinión de los empleados y los clientes a largo plazo, los empleadores pueden tomar decisiones informadas con respecto al desempeño de los agentes de apoyo.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">La combinación de NetApp, SFL Scientific, marcos de orquestación de código abierto y NVIDIA reúne las tecnologías más recientes como servicios gestionados con una gran flexibilidad para acelerar la adopción de tecnología y mejorar el plazo de comercialización de las nuevas aplicaciones de IA/ML. Estos servicios avanzados se ofrecen en las instalaciones que se pueden transportar fácilmente para entornos nativos del cloud así como arquitecturas de puesta en marcha híbrida.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">Descargue NVIDIA DeepOps siguiendo las instrucciones de<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Guía de puesta en marcha de Kubernetes</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">Implemente Kubernetes en su clúster siguiendo las instrucciones que se indican en<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> En el sitio de NVIDIA DeepOps GitHub.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">Para que la puesta en marcha de DeepOps Kubernetes funcione, debe haber el mismo usuario en todos los nodos maestro y de trabajador de Kubernetes.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">Si la implementación falla, cambie el valor de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> a falso in<block ref="399db550c3eadd49b7f0681bf65049a0" prefix=" " category="inline-code"></block> y repita el paso 2. La<block ref="3d9043b4bfb5ecceda4eaf60e73c2655" prefix=" " category="inline-code"></block> tarea, que sólo se ejecuta cuando el valor de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> Es cierto que se basa en el módulo Fetch Ansible, que tiene problemas conocidos con el uso de memoria. Estos problemas de uso de la memoria a veces pueden provocar un error en la tarea. Si la tarea falla debido a un problema de memoria, el resto de la operación de implementación no se completa correctamente.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">Si la implementación se completa correctamente después de cambiar el valor de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> para<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block>, a continuación, debe copiar manualmente la<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> Desde un nodo maestro de Kubernetes a un host de salto de implementación. Puede encontrar la ubicación del<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> en un nodo maestro específico ejecutando el<block ref="c768a64827ad16455d7c655ea5ae91ff" prefix=" " category="inline-code"></block> comando directamente en ese nodo.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">Siguiente: Puesta en marcha de Cnvrg.io</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858: Solución de orquestación de NetApp con Run:AI</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-han Lin, NetApp Yaron Goldberg, Run:AI</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">Los sistemas de almacenamiento AFF de NetApp proporcionan un rendimiento extremo y funcionalidades de gestión de datos de cloud híbrido líderes en el sector. NetApp y Run:AI se han asociado para demostrar las funcionalidades únicas de la solución de IA ONTAP de NetApp para cargas de trabajo de inteligencia artificial (IA) y aprendizaje automático (ML) que ofrecen rendimiento, fiabilidad y soporte de clase empresarial. Ejecutar:la orquestación de la IA de las cargas de trabajo de IA añade una programación basada en Kubernetes y una plataforma de uso de recursos para ayudar a los investigadores a gestionar y optimizar la utilización de la GPU. Junto con los sistemas DGX de NVIDIA, la solución combinada de NetApp, NVIDIA y Run:AI proporciona una pila de infraestructura diseñada específicamente para cargas de trabajo de IA empresariales. Este informe técnico proporciona instrucciones direccionales a los clientes que crean sistemas de IA conversacionales que respaldan diversos casos prácticos y mercados verticales del sector. Incluye información sobre la puesta en marcha de Run:AI y un sistema de almacenamiento AFF A800 de NetApp y sirve como arquitectura de referencia para obtener el método más sencillo de poner en marcha con éxito iniciativas de IA de forma rápida.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">Los arquitectos empresariales que diseñan soluciones para el desarrollo de modelos de IA y software para casos prácticos basados en Kubernetes, como microservicios en contenedores</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">Los científicos de datos que buscan formas eficientes de alcanzar objetivos de desarrollo de modelos eficientes en un entorno de clúster con varios equipos y proyectos</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">Ingenieros de datos a cargo del mantenimiento y la ejecución de modelos de producción</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">Responsables de la toma de decisiones de TECNOLOGÍA y ejecutivos y líderes empresariales que desean crear la experiencia óptima de utilización de recursos de clúster de Kubernetes y lograr el plazo de comercialización más rápido posible gracias a las iniciativas de IA</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="7054aac0ed39fa340a2d8034700f7366" category="doc">Diseño de la arquitectura NVA-1151: Guía de diseño de sistemas ONTAP AI de NetApp con NVIDIA DGX A100</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">EL DISEÑO NVA-1151 describe una arquitectura verificada de NetApp para cargas de trabajo de aprendizaje automático y inteligencia artificial que utilizan sistemas de almacenamiento AFF A800 de NetApp, sistemas NVIDIA DGX A100 y switches de red NVIDIA Mellanox. También se incluyen los resultados de las pruebas de rendimiento de la arquitectura tal y como se han implementado.</block>
  <block id="c3e7dfc3691f26701d35cccf4caf7151" category="paragraph"><block ref="c3e7dfc3691f26701d35cccf4caf7151" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">Esta página resume las ventajas de Azure NetApp Files en formación distribuida o a gran escala.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">Resumen de casos de uso de predicción de velocidad mediante clic</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Anterior: Requisitos de recursos del cloud.</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">Terabyte haga clic en registros</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Laboratorio Criteo AI</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">Este caso de uso se basa en el público disponible<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> conjunto de datos de<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. Con los recientes avances en las plataformas Y aplicaciones DE ML, ahora se presta mucha atención al aprendizaje a escala. La tasa de clics (CTR) se define como el número medio de clics-throughs por cien impresiones de anuncios en línea (expresado como porcentaje). Se ha adoptado ampliamente como métrica clave en diversos mercados verticales del sector y casos de uso, incluidos el marketing digital, el comercio minorista, el comercio electrónico y los proveedores de servicios. Algunos ejemplos de uso de CTR como una métrica importante para el tráfico potencial de clientes son los siguientes:</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google Analytics</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">Clasificación de anuncios</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">*Marketing digital:* in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR se puede usar para medir cómo se están realizando las palabras clave, los anuncios y los listados libres de un anunciante o comerciante. Un CTR alto es una buena indicación de que los usuarios encuentran sus anuncios y listados útiles y relevantes. CTR también contribuye a la CTR esperada de su palabra clave, que es un componente de<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">*Comercio electrónico:* además de apalancar<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>, hay por lo menos algunas estadísticas de visitantes en un fondo de comercio electrónico. Aunque estas estadísticas pueden no parecer útiles a primera vista, suelen ser fáciles de leer y pueden ser más precisas que otras informaciones. Los conjuntos de datos de primera parte compuestos por estas estadísticas son de propiedad y, por lo tanto, los más relevantes para los vendedores, compradores y plataformas de comercio electrónico. Estos conjuntos de datos se pueden utilizar para establecer pruebas de rendimiento, comparar los resultados con el año pasado y el pasado construyendo una serie temporal para un análisis más profundo.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">*Retail:* los minoristas tradicionales pueden correlacionar el número de visitantes y el número de clientes con el CTR. El número de clientes se puede ver desde su historial de puntos de venta. El CTR de los sitios web de los minoristas o del tráfico de anuncios puede resultar en las ventas mencionadas. Los programas de fidelidad son otro caso de uso, ya que los clientes redirigidos de anuncios en línea u otros sitios web podrían unirse para obtener recompensas. Los minoristas pueden conseguir clientes a través de programas de fidelidad y comportamientos récord de historias de ventas para crear un sistema de recomendaciones que no solo predice las conductas de compra de los consumidores en diferentes categorías, sino que también personaliza las cupones y reduce la pérdida de clientes.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">*Proveedores de servicios:* las empresas de telecomunicaciones y los proveedores de servicios de Internet tienen una abundancia de datos de telemetría de usuarios de primera parte para casos de uso de IA, ML y analítica perspicaz. Por ejemplo, las telecomunicaciones pueden aprovechar los registros diarios de historial de dominios de navegación web de sus suscriptores móviles para ajustar los modelos existentes y producir una segmentación de público actualizada, predecir el comportamiento de los clientes y colaborar con los anunciantes para colocar anuncios en tiempo real para una mejor experiencia en línea. En este flujo de trabajo de marketing basado en datos, CTR es una métrica importante para reflejar las conversiones.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Criteo Terabyte haga clic en registros</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">En el contexto del marketing digital,<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> Son ahora el conjunto de datos de referencia a la hora de evaluar la escalabilidad de las plataformas Y algoritmos ML. Al predecir la tarifa de clic, un anunciante puede seleccionar a los visitantes que tienen más probabilidades de responder a los anuncios, analizar su historial de navegación y mostrar los anuncios más relevantes basados en los intereses del usuario.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">La solución proporcionada en este informe técnico destaca las siguientes ventajas:</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Las ventajas de Azure NetApp Files en formación distribuida o a gran escala</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RÁPIDO procesamiento de datos habilitado para CUDA (cuDF, cúpula, etc.) y algoritmos ML (cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">El marco informático paralelo de DASK para la formación distribuida</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Un flujo de trabajo integral basado en RAPIDS AI y Azure NetApp Files demuestra la drástica mejora del tiempo de entrenamiento de los modelos de bosques aleatorios en dos órdenes de magnitud. Esta mejora es significativa en comparación con el enfoque convencional de pandas al tratar los registros de clic del mundo real con 45GB de datos tabulares estructurados (en promedio) cada día. Esto equivale a un DataFrame que contiene aproximadamente veinte mil millones de filas. Demostraremos la configuración del entorno de clúster, la instalación de marcos y bibliotecas, la carga y el procesamiento de datos, la formación convencional frente a la distribuida, la visualización y supervisión, y compararemos los resultados fundamentales de tiempo de ejecución completo en este informe técnico.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">Siguiente: Instale y configure el cluster robles.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">En esta sección se describen las tareas necesarias para completar la validación.</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Para ejecutar las tareas descritas en esta sección, debe tener acceso a un host Linux o MacOS con las siguientes herramientas instaladas y configuradas:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (se configura para acceder a un clúster de Kubernetes existente)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Se pueden encontrar instrucciones de instalación y configuración<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>.</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Se pueden encontrar instrucciones de instalación<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>.</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Escenario 1 – inferencia bajo demanda en JuppyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Cree un espacio de nombres de Kubernetes para las cargas de trabajo de inferencia de IA/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Utilice el kit de herramientas DataOPS de NetApp para aprovisionar un volumen persistente para almacenar los datos en los que realizará la inferencia.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Use el kit de herramientas DataOPS de NetApp para crear un nuevo espacio de trabajo JuppyterLab. Monte el volumen persistente que se creó en el paso anterior mediante el<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> opción. Asigne las GPU de NVIDIA al espacio de trabajo según sea necesario mediante el<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> opción.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">En el siguiente ejemplo, el volumen persistente<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> Está montado en el contenedor de espacio de trabajo JJupyterLab en<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>. Cuando utilice las imágenes del contenedor de Jupyter del proyecto oficial,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> Se presenta como el directorio de nivel superior dentro de la interfaz Web JuppyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Acceda al espacio de trabajo JupyterLab utilizando la dirección URL especificada en la salida del<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> comando. El directorio de datos representa el volumen persistente que se montó en el espacio de trabajo.</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Abra el<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> directory y cargue los archivos en los que se va a realizar la inferencia. Cuando se cargan archivos en el directorio de datos, se almacenan automáticamente en el volumen persistente que se montó en el espacio de trabajo. Para cargar archivos, haga clic en el icono cargar archivos, como se muestra en la siguiente imagen.</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Vuelva al directorio de nivel superior y cree un nuevo portátil.</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Agregue el código de inferencia al cuaderno. En el siguiente ejemplo, se muestra el código de inferencia para un caso de uso de detección de imagen.</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Agregue la ofuscación Protopia al código de inferencia. Protopia trabaja directamente con los clientes para proporcionar documentación específica para casos de uso y está fuera del alcance de este informe técnico. En el siguiente ejemplo se muestra el código de inferencia para un caso de uso de detección de imágenes con ofuscación Protopía agregada.</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Escenario 2: Inferencia por lotes en Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Rellene el nuevo volumen persistente con los datos en los que realizará la inferencia.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Funcionalidades de NetApp DataOPS Toolkit S3 Data mover</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">Existen varios métodos para cargar datos en un PVC. Si actualmente sus datos están almacenados en una plataforma de almacenamiento de objetos compatible con S3, como StorageGRID de NetApp o Amazon S3, podrá utilizar<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>. Otro método simple es crear un espacio de trabajo JJupyterLab y cargar archivos a continuación a través de la interfaz web JJupyterLab, como se indica en los pasos 3 a 5 de la sección “<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>.”</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Cree un trabajo de Kubernetes para la tarea de inferencia de lotes. El siguiente ejemplo muestra un trabajo de inferencia en lote para un caso de uso de detección de imagen. Este trabajo realiza la inferencia en cada imagen de un conjunto de imágenes y escribe métricas de precisión de inferencia para su colocación.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Confirme que el trabajo de inferencia se completó correctamente.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Agregue la ofuscación de Protopia a su trabajo de inferencia. Puede encontrar instrucciones específicas para casos de uso para agregar la ofuscación Protopia directamente desde Protopia, que está fuera del alcance de este informe técnico. El ejemplo siguiente muestra un trabajo de inferencia por lotes para un caso de uso de detección de cara con ofuscación Protopía agregada mediante un valor ALFA de 0.8. Este trabajo aplica la ofuscación Protopia antes de realizar la inferencia para cada imagen en un conjunto de imágenes y luego escribe las métricas de precisión de inferencia para el stdout.</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">“Comparación de precisión de inferencia.”</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">Hemos repetido este paso para los valores ALFA 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9 y 0.95. Puede ver los resultados en <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Escenario 3: Servidor de inferencia NVIDIA Triton</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilice el kit de herramientas DataOPS de NetApp para aprovisionar un volumen persistente y usarlo como repositorio de modelo para el servidor de inferencia NVIDIA Triton.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">formato</block>
  <block id="97be18cb741b4fd763ebe22e034705fa" category="list-text">Almacene su modelo en el nuevo volumen persistente en un<block ref="bfcdc35d352d3deff6efdd3b8b2ac7ac" category="inline-link-rx"></block> Reconocida por el servidor de inferencia NVIDIA Triton.</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">Existen varios métodos para cargar datos en un PVC. Un método simple es crear un espacio de trabajo JupyterLab y luego cargar archivos a través de la interfaz web JupyterLab, como se describe en los pasos 3 a 5 en “<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. ”</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilice el kit de herramientas DataOPS de NetApp para poner en marcha una nueva instancia del servidor de inferencia NVIDIA Triton.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilice el SDK del cliente Triton para realizar una tarea de inferencia. El siguiente extracto de código de Python utiliza el SDK del cliente de Triton Python para realizar una tarea de inferencia para un caso de uso de detección facial. En este ejemplo se llama a la API de Triton y se pasa una imagen para la inferencia. A continuación, el servidor de inferencia Triton recibe la solicitud, invoca el modelo y devuelve la salida de inferencia como parte de los resultados de la API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Agregue la ofuscación Protopia al código de inferencia. Puede encontrar instrucciones específicas para casos de uso para agregar la ofuscación Protopia directamente desde Protopia; sin embargo, este proceso está fuera del alcance de este informe técnico. El ejemplo siguiente muestra el mismo código Python que se muestra en el paso anterior 5, pero con la ofuscación de Protopia agregada.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Tenga en cuenta que la confusión Protopia se aplica a la imagen antes de pasarla a la API de Triton. Así, la imagen no ofuscada nunca sale de la máquina local. Sólo la imagen oculta se pasa a través de la red. Este flujo de trabajo es aplicable para casos de uso en los que los datos se recopilan en una zona de confianza, pero luego debe pasarse fuera de esa zona de confianza para la inferencia. Sin la ocultación de Protopia, no es posible implementar este tipo de flujo de trabajo sin que haya datos confidenciales que salgan de la zona de confianza.</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">Siguiente: Comparación de precisión de inferencia.</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">Sistemas DGX de NVIDIA</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">Sistema DGX-1 de NVIDIA<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">GPU de núcleo tensor NVIDIA V100<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">Ejecute:solución de orquestación de contenedores de IA</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">Ejecución: Introducción de producto de IA<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">Ejecución:documentación de instalación de IA<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Enviar trabajos en Ejecutar:AI CLI<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">Asignar fracciones de GPU en la CLI de Run:AI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">Informe técnico<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">Demostración en formato breve<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">Repositorio de GitHub<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">Especificaciones técnicas de AFF a-Series de NetApp<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">Ventaja de NetApp Flash para All Flash FAS<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">Biblioteca de información de ONTAP 9<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">Informe técnico de NetApp ONTAP FlexGroup Volumes<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Cisco Networking<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">Guía de puesta en marcha de ONTAP AI con DGX-1 y Cisco Networking<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Mellanox Networking<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">Guía de diseño de ONTAP AI con DGX-2<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">Puesta en marcha de cnvrg.io</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Ponga en marcha EL NÚCLEO cnvrg mediante Helm</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Timón es la forma más sencilla de poner en marcha cnvrg rápidamente mediante cualquier clúster, en las instalaciones, MiniClube o en cualquier clúster de cloud (como AKS, EKS y GKE). En esta sección se describe cómo se instaló cnvrg en una instancia de las instalaciones (DGX-1) con Kubernetes instalado.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">Antes de completar la instalación, debe instalar y preparar las siguientes dependencias en su equipo local:</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Timón 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Clúster de Kubernetes 1.15 o posterior</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Despliegue mediante Helm</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">Para descargar los gráficos cnvrg del timón más actualizados, ejecute el siguiente comando:</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">Antes de poner en marcha cnvrg, necesita la dirección IP externa del clúster y el nombre del nodo en el que se va a implementar cnvrg. Para poner en marcha cnvrg en un clúster de Kubernetes en las instalaciones, ejecute el siguiente comando:</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">Ejecute el<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> comando. Todos los servicios y sistemas se instalan automáticamente en el clúster. El proceso puede tardar hasta 15 minutos.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">La<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> command puede tardar hasta 10 minutos. Cuando finalice la implementación, vaya a la dirección URL de su cnvrg recién implementado o agregue el nuevo clúster como un recurso dentro de su organización. La<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> Command le informa de la URL correcta.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">Cuando el estado de todos los contenedores se ejecuta o se completa, cnvrg se ha implementado correctamente. Debería ser similar a la siguiente salida de ejemplo:</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">Formación de modelos de visión computarizada con ResNet50 y el conjunto de datos de rayos X torácicos</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">Sitio de descarga de NIH</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">Cnvrg.io AI OS se puso en marcha en una configuración de Kubernetes en una arquitectura de IA ONTAP de NetApp basada en el sistema NVIDIA DGX. Para la validación, se utilizó el conjunto de datos de radiografía de tórax de los NIH que consistía en imágenes desidentificadas de radiografías de tórax. Las imágenes estaban en formato PNG. Los datos fueron proporcionados por el Centro clínico de los NIH y están disponibles a través del<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. Utilizamos una muestra de 250 GB de los datos con 627, 615 imágenes en 15 clases.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">El conjunto de datos se cargó en la plataforma cnvrg y se almacenó en caché en una exportación NFS desde el sistema de almacenamiento AFF A800 de NetApp.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">Configure los recursos de computación</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">La arquitectura cnvrg y la funcionalidad de programación de metadatos permiten que los ingenieros y profesionales DE TECNOLOGÍA adjunte diferentes recursos informáticos a una única plataforma. En nuestra configuración, utilizamos el mismo cnvrg de clúster que se puso en marcha para ejecutar cargas de trabajo de aprendizaje profundo. Si necesita conectar clústeres adicionales, utilice la GUI, tal como se muestra en la siguiente captura de pantalla.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">Cargar datos</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">Para cargar datos en la plataforma cnvrg, puede utilizar la interfaz gráfica de usuario o la interfaz de línea de comandos cnvrg. En el caso de conjuntos de datos de gran tamaño, NetApp recomienda el uso de la CLI porque es una herramienta sólida, escalable y fiable capaz de gestionar un gran número de archivos.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">Para cargar datos, realice los siguientes pasos:</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">CLI de cnvrg</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">Descargue el<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">desplácese hasta el directorio de rayos x.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">Inicialice el conjunto de datos en la plataforma con el<block ref="93683f43f0985082ca58f41ff93ff85f" prefix=" " category="inline-code"></block> comando.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">Cargue todo el contenido del directorio en el lago de datos central con el<block ref="3e18d74143663f7fae3446eb44229f0f" prefix=" " category="inline-code"></block> Command.una vez que los datos se cargan en el almacén de objetos central (StorageGRID, S3 u otros), puede navegar por la GUI. La siguiente figura muestra un archivo PNG cargado de imagen de fibrosis torácica. Además, cnvrg introduce los datos de modo que cualquier modelo que cree pueda reproducirse en la versión de los datos.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Datos de Cach</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">Para realizar el entrenamiento con más rapidez y evitar la descarga de más de 600 000 archivos para cada entrenamiento y experimento, utilizamos la función de almacenamiento en caché de datos después de cargar los datos inicialmente en el almacén de objetos del lago de datos central.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">Después de que los usuarios hagan clic en caché, cnvrg descarga los datos de su registro específico del almacén de objetos remoto y los almacena en caché en el volumen NFS de ONTAP. Una vez que finalice, los datos estarán disponibles para el entrenamiento instantáneo. Además, si los datos no se utilizan durante unos días (para el entrenamiento de modelos o la exploración, por ejemplo), cnvrg borra automáticamente la memoria caché.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">Cree un ML de canalización con datos en caché</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">Cnvrg fluye le permite construir fácilmente tuberías ML de producción. Los flujos son flexibles, pueden funcionar para cualquier tipo de caso de uso DE ML y pueden crearse a través de la GUI o el código. Cada componente de un flujo puede ejecutarse en un recurso de computación diferente con una imagen de Docker diferente, por lo que es posible crear canalizaciones de APRENDIZAJE AUTOMÁTICO optimizadas y de cloud híbrido.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">Cómo construir el flujo de la radiografía de tórax: Ajuste de los datos</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">Hemos añadido nuestro conjunto de datos a un flujo recién creado. Al agregar el conjunto de datos, puede seleccionar la versión específica (Commit) e indicar si desea la versión en caché. En este ejemplo, hemos seleccionado la confirmación almacenada en caché.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">Cómo construir el flujo de rayos X del tórax: Ajuste del modelo de entrenamiento: ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">En la canalización, puede agregar cualquier tipo de código personalizado que desee. En cnvrg, también existe la biblioteca de IA, una colección de componentes DE ML reutilizables. En la biblioteca de IA existen algoritmos, scripts, orígenes de datos y otras soluciones que se pueden usar en cualquier flujo DE APRENDIZAJE profundo o DE ML. En este ejemplo, hemos seleccionado el módulo ResNet50 premontado. Se utilizaron parámetros predeterminados como batch_size:128, épocas:10 y más. Estos parámetros pueden verse en los documentos de la Biblioteca de IA. La siguiente captura de pantalla muestra el nuevo flujo con el conjunto de datos de rayos X conectado a ResNet50.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">Defina el recurso de computación para ResNet50</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">Cada algoritmo o componente en flujos cnvrg puede ejecutarse en una instancia de computación diferente, con una imagen de Docker diferente. En nuestra configuración, queríamos ejecutar el algoritmo de entrenamiento en los sistemas DGX de NVIDIA con la arquitectura de IA ONTAP de NetApp. En la siguiente figura, hemos seleccionado<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block>, que es una plantilla de cálculo y una especificación para nuestro clúster local. También creamos una cola de plantillas y seleccionamos varias plantillas. De esta manera, si el<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block> no se puede asignar el recurso (si, por ejemplo, otros científicos de datos lo están utilizando), puede habilitar la explosión automática en el cloud añadiendo una plantilla de proveedor de cloud. La siguiente captura de pantalla muestra el uso de gpu-real como nodo de computación para ResNet50.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">Seguimiento y seguimiento de resultados</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">Después de ejecutar un flujo, cnvrg activa el motor de seguimiento y supervisión. Cada ejecución de un flujo se documenta y actualiza automáticamente en tiempo real. Hiperparámetros, métricas, uso de recursos (utilización de GPU, etc.), versión de código, artefactos, registros Y así sucesivamente están automáticamente disponibles en la sección experimentos, como se muestra en las dos capturas de pantalla siguientes.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">Las soluciones de inteligencia artificial de NetApp son un conjunto de soluciones estratégicas y técnicas que demuestran las funcionalidades del almacenamiento de NetApp en el espacio DE IA/ML.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">Soluciones de inteligencia artificial de NetApp</block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">La automatización impulsada por IA y la informática perimetral es un enfoque líder que ayuda a las organizaciones empresariales a lograr la transformación digital y maximizar la eficiencia y la seguridad operativas. En el caso de los entornos periféricos, los datos se procesan con mayor rapidez, porque no tienen que desplazarse hacia y desde un centro de datos. Por lo tanto, el coste asociado al envío de datos a los centros de datos o al cloud se ve disminuido.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">Anterior: Opciones de ajuste de tamaño de arquitectura.</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">La automatización impulsada por IA y la informática perimetral es un enfoque líder que ayuda a las organizaciones empresariales a lograr la transformación digital y maximizar la eficiencia y la seguridad operativas. En el caso de los entornos periféricos, los datos se procesan con mayor rapidez, porque no tienen que desplazarse hacia y desde un centro de datos. Por lo tanto, el coste asociado al envío de datos a los centros de datos o al cloud se ve disminuido. La reducción de la latencia y el aumento de la velocidad pueden ser beneficiosas cuando las empresas deben tomar decisiones casi en tiempo real mediante modelos de inferencia de IA implementados en el perímetro.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">Los sistemas de almacenamiento de NetApp ofrecen el mismo rendimiento o mejor que el almacenamiento SSD local y ofrecen las siguientes ventajas a los científicos de datos, ingenieros de datos, desarrolladores de IA/ML y responsables de la toma de decisiones EMPRESARIALES o TECNOLÓGICAS:</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Protección de datos de clase empresarial para la recuperación ante desastres y la continuidad del negocio. La solución de NetApp y Lenovo presentada en este documento es una arquitectura flexible y de escalado horizontal ideal para puestas en marcha de inferencia de IA en el perímetro.</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger, Sr. Director de Soluciones HPC e IA de Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, ingeniero técnico de marketing, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, responsable técnico de soluciones de IA de E-Series de NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, ingeniero de control de calidad, NetApp</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Página de producto de las cabinas AFF a-Series de NetApp</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Software de gestión de datos ONTAP de NetApp: Biblioteca de información de ONTAP 9</block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Introducción a EF-Series de NetApp</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Especificaciones técnicas del software SANtricity para E-Series de NetApp</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Almacenamiento persistente de NetApp para contenedores: Trident de NetApp</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Sistema de almacenamiento flash unificado Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">Marzo de 2021</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Versión inicial</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Octubre de 2021</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">Actualizado con EF y MLPerf inferencias v1.1</block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">Diseño de NVA-1150: Quantum StorNext con la guía de diseño de sistemas E-Series de NetApp</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Este documento proporciona información detallada sobre cómo diseñar una solución de sistema de archivos paralelo StorNext con los sistemas de almacenamiento E-Series de NetApp. Esta solución abarca la cabina all-flash EF280 de NetApp, la cabina NVMe all-flash EF300 de NetApp, la cabina NVMe all-flash EF600 y el sistema híbrido E5760 de NetApp. Ofrece una caracterización del rendimiento basada en las pruebas comparativas de Frametest, una herramienta que se utiliza ampliamente para realizar pruebas en el sector del entretenimiento y los medios de comunicación.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="doc">RESNET-50 con resumen de la prueba de rendimiento de conjunto de datos ImageNET</block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">Validamos el funcionamiento y el rendimiento de este sistema mediante herramientas estándar del sector para pruebas de rendimiento TensorFlow. El conjunto de datos ImageNET se utilizó para entrenar ResNet-50, que es un famoso modelo de red neuronal convolucional (CNN) DL para la clasificación de imágenes. RESNET-50 ofrece un resultado de formación preciso con un tiempo de procesamiento más rápido que nos permite atender una demanda suficiente sobre el almacenamiento.</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">En este apartado se describen las configuraciones probadas, la infraestructura de red, el servidor SE350 y los detalles de aprovisionamiento de almacenamiento.</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La figura siguiente muestra la configuración de prueba. Utilizamos el sistema de almacenamiento AFF C190 de NetApp y dos servidores Lenovo ThinkSystem SE350 (cada uno con un acelerador NVIDIA T4). Estos componentes se conectan a través de un switch de red de 10 GbE. El almacenamiento en red contiene conjuntos de datos de validación y pruebas y modelos preentrenados. Los servidores proporcionan una funcionalidad computacional y se accede al almacenamiento mediante un protocolo NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">En este apartado se describen las configuraciones probadas, la infraestructura de red, el servidor SE350 y los detalles de aprovisionamiento de almacenamiento. En la siguiente tabla se enumeran los componentes básicos para la arquitectura de la solución.</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 servidores SE350 con una tarjeta GPU NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Cada servidor contiene una CPU Intel Xeon D-2123IT con cuatro núcleos físicos que funcionan a 2,20 GHz y 128 GB de RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Sistema de almacenamiento AFF de gama básica de NetApp (par de alta disponibilidad)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Software ONTAP 9 de NetApp</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un grupo de interfaces por controladora, con cuatro direcciones IP lógicas para puntos de montaje</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">La siguiente tabla enumera la configuración del almacenamiento: AFF C190 con 2 ranuras de 24 unidades 2RU.</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Agregatesize</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumen</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Punto de montaje del sistema operativo</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/Netaptenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8,42 TIB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">La carpeta /netappLenovo_AI_fg contiene los conjuntos de datos utilizados para la validación del modelo.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La siguiente figura muestra la configuración de prueba. Utilizamos el sistema de almacenamiento EF280 de NetApp y dos servidores Lenovo ThinkSystem SE350 (cada uno con un acelerador NVIDIA T4). Estos componentes se conectan a través de un switch de red de 10 GbE. El almacenamiento en red contiene conjuntos de datos de validación y pruebas y modelos preentrenados. Los servidores proporcionan una funcionalidad computacional y se accede al almacenamiento mediante un protocolo NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">La siguiente tabla enumera la configuración de almacenamiento para EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Grupo de volúmenes</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volumen</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">Tamaño DDPsize</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Método de conexión</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volumen 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 a iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volumen 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 a iSCSI LUN 1</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Este documento describe una solución de diseño validada en tres situaciones diferentes, con y sin la confusión de imágenes relevante para preservar la privacidad y poner en marcha una solución de IA responsable.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: IA responsable e inferencia confidencial - NetApp AI con Protopía Image y transformación de datos</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Las interpretaciones visuales se han convertido en parte integral de la comunicación con la aparición de la captura de imágenes y el procesamiento de imágenes. La inteligencia artificial (IA) en el procesamiento de imágenes digitales brinda nuevas oportunidades de negocio, como en el campo médico para la identificación del cáncer y otras enfermedades, en el análisis visual geoespacial para estudiar peligros ambientales, en el reconocimiento de patrones, en el procesamiento de vídeos para combatir la delincuencia, etc. Sin embargo, esta oportunidad también viene con responsabilidades extraordinarias.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Cuantas más decisiones las organizaciones se pongan en manos de la IA, más aceptan riesgos relacionados con la privacidad y la seguridad de los datos, así como con cuestiones legales, éticas y reguladoras. La IA responsable permite aplicar una práctica que permite a las empresas y organizaciones gubernamentales crear confianza y gobernanza, algo crucial para la IA a escala en grandes empresas. Este documento describe una solución de inferencia de IA validada por NetApp en tres situaciones diferentes utilizando las tecnologías de gestión de datos de NetApp con el software de ofuscación de datos de Protopía con el fin de privatizar datos confidenciales y reducir riesgos y preocupaciones éticas.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Cada día, los consumidores y entidades de negocio generan millones de imágenes con diversos dispositivos digitales. La consiguiente explosión masiva de datos y cargas de trabajo informáticas hace que las empresas recurren a plataformas de cloud computing para obtener escalado y eficiencia. Mientras tanto, la preocupación por la privacidad de la información confidencial que contienen los datos de imágenes surge como consecuencia de la transferencia a un cloud público. La falta de garantías de seguridad y privacidad se convierte en la principal barrera para el despliegue de sistemas de IA que procesan imágenes.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">derecho a borrar</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Ley de Privacidad</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Además, está el<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> Según el RGPD, el derecho de una persona a solicitar que una organización borre todos sus datos personales. También está la<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>, que establece un código de prácticas de información justas. Las imágenes digitales, como las fotografías, pueden constituir datos personales en virtud del RGPD, que rige la forma en que deben recopilarse, procesarse y borrarse los datos. El no hacerlo es un incumplimiento del RGPD, que puede conllevar multas cuantiosas por incumplimiento de las normativas que pueden resultar seriamente perjudiciales para las organizaciones. Los principios de privacidad son uno de los pilares de la implementación de IA responsable que garantice la justicia en las predicciones de modelos de aprendizaje automático y aprendizaje profundo (DL) y reduce los riesgos asociados con la infracción de privacidad o el cumplimiento de normativas.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Este documento describe una solución de diseño validada en tres situaciones diferentes, con y sin la confusión de imágenes relevante para preservar la privacidad y poner en marcha una solución de IA responsable:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Escenario 1.* inferencia a petición dentro del cuaderno Juppyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Escenario 2.* inferencia por lotes en Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Escenario 3.* servidor de inferencia NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Para esta solución, utilizamos el conjunto de datos y el punto de referencia de detección facial (FDDB), un conjunto de datos de regiones faciales diseñado para estudiar el problema de la detección facial sin restricciones, combinado con el marco de aprendizaje de máquinas PyTorch para la implementación de FaceBox. Este conjunto de datos contiene las anotaciones para 5171 caras en un conjunto de 2845 imágenes de varias resoluciones. Además, este informe técnico presenta algunas áreas de soluciones y casos de uso relevantes recopilados por clientes de NetApp e ingenieros de campo en situaciones en las que sea aplicable esta solución.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Este informe técnico está dirigido a los siguientes destinatarios:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Líderes empresariales y arquitectos empresariales que desean diseñar y poner en marcha una IA responsable y abordar cuestiones de protección y privacidad de datos relacionadas con el procesamiento de imágenes faciales en espacios públicos.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Científicos de datos, ingenieros de datos, investigadores DE IA/aprendizaje automático (ML) y desarrolladores de sistemas de IA/ML que pretenden proteger y preservar la privacidad.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Arquitectos empresariales que diseñan soluciones de confusión de datos para modelos y aplicaciones de IA/ML que cumplen con las normativas tales como RGPD, CCPA o las organizaciones gubernamentales (Ley de privacidad del Departamento de Defensa) y la Ley de privacidad del Departamento de Defensa (DoD).</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Científicos e ingenieros de IA buscan formas eficientes de poner en marcha el aprendizaje profundo (DL) y modelos de inferencia de IA/ML/DL que protegen la información confidencial.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Los administradores de dispositivos periféricos y los administradores de servidor perimetral son responsables de la puesta en marcha y la gestión de modelos de inferencia perimetrales.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Esta solución está diseñada para gestionar cargas de trabajo de IA de inferencia en lote y en tiempo real en grandes conjuntos de datos utilizando la potencia de procesamiento de las GPU junto con las CPU tradicionales. Esta validación demuestra la inferencia privacidad de ML y la gestión de datos óptima que necesitan las organizaciones que buscan una puesta en marcha de IA responsable. Esta solución proporciona una arquitectura adecuada para una plataforma Kubernetes de uno o varios nodos para el perímetro y el cloud computing interconectados con ONTAP AI de NetApp en el núcleo de las instalaciones, el kit de herramientas DataOPS de NetApp y el software de ofuscación por medio de las interfaces CLI y de Juppyter Lab. En la siguiente figura se muestra información general sobre la arquitectura lógica del Data Fabric con la tecnología de NetApp con el kit de herramientas de operaciones de datos y Protopía.</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">El software de ofuscación de Protopía se ejecuta sin problemas sobre el kit de herramientas DataOPS de NetApp y transforma los datos antes de salir del servidor de almacenamiento.</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">Siguiente: Áreas de soluciones.</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">Tal como se ha mencionado en la sección anterior, los errores se propagan por la canalización siempre que haya dos o más modelos de aprendizaje automático ejecutándose de forma secuencial. Para esta solución, el sentimiento de la frase es el factor más importante a la hora de medir el nivel de riesgo de las acciones de la empresa. El modelo de voz a texto, aunque esencial para la canalización, sirve como unidad de preprocesamiento antes de que se puedan predecir los sentimientos.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">Resultados de validación</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">Anterior: Puesta en marcha del análisis de opinión del centro de soporte.</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">Tal como se ha mencionado en la sección anterior, los errores se propagan por la canalización siempre que haya dos o más modelos de aprendizaje automático ejecutándose de forma secuencial. Para esta solución, el sentimiento de la frase es el factor más importante a la hora de medir el nivel de riesgo de las acciones de la empresa. El modelo de voz a texto, aunque esencial para la canalización, sirve como unidad de preprocesamiento antes de que se puedan predecir los sentimientos. Lo que realmente importa es la diferencia en el sentimiento entre las frases de la verdad en el terreno y las oraciones predichas. Esto sirve como proxy para la velocidad de error de la palabra (WER). La precisión de voz a texto es importante, pero el WER no se utiliza directamente en la métrica de canalización final.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">Estas métricas de sentimiento se pueden calcular para la puntuación F1, la recuperación y la precisión de cada frase. Los resultados se pueden agregar y mostrar dentro de una matriz de confusión, junto con los intervalos de confianza de cada métrica.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">La ventaja de usar el aprendizaje de transferencia es un aumento en el rendimiento de los modelos por una fracción de los requisitos de datos, el tiempo de entrenamiento y el coste. Los modelos ajustados también deben compararse con sus versiones de referencia para garantizar que el aprendizaje de la transferencia mejore el rendimiento en lugar de deteriorarlo. En otras palabras, el modelo ajustado debería tener un mejor rendimiento en los datos del centro de soporte que el modelo preentrenado.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">Evaluación de la canalización</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">Caso de prueba</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">Número de prueba</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">Métrica de sentimiento de canalización</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">Probar los requisitos previos</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">Modelos ajustados para modelos de análisis de voz a texto y de sentimiento</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">Resultado esperado</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">La métrica de sentimiento del modelo ajustado funciona mejor que el modelo preentrenado original.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">Calcule la métrica de sentimiento para el modelo de referencia.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">Calcule la métrica de sentimiento para el modelo ajustado.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">Calcular la diferencia entre estas métricas.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">Calcule la media de las diferencias entre todas las frases.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">Siguiente: Vídeos y demos.</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">Puesta en marcha de una infraestructura virtual de VMware en NetApp HCI con NDE (puesta en marcha automatizada)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">Requisitos previos de puesta en marcha de NDE</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">Lista de verificación de requisitos previos de NetApp HCI</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">Consulte la<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> Para consultar los requisitos y las recomendaciones para NetApp HCI antes de la implementación.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">Requisitos y configuración de switch y red</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">Preparar los identificadores de VLAN necesarios</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">Configuración de switches</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">Requisitos de dirección IP para NetApp HCI y VMware</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">Requisitos de DNS y de mantenimiento del tiempo</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">Preparaciones finales</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">Ejecución de NDE</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">Antes de ejecutar el NDE, debe completar el rack y la pila de todos los componentes, la configuración de los switches de red y la verificación de todos los requisitos previos. Puede ejecutar NDE conectando a la dirección de gestión de un solo nodo de almacenamiento si tiene pensado permitir que NDE configure automáticamente todas las direcciones.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">Nde realiza las siguientes tareas para poner un sistema HCI en línea:</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">Instala el nodo de almacenamiento (software NetApp Element) en un mínimo de dos nodos de almacenamiento.</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">Instala el hipervisor de VMware en dos nodos de computación como mínimo.</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">Instala VMware vCenter para gestionar toda la pila de NetApp HCI.</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">Instala y configura el nodo de gestión de almacenamiento de NetApp (mNode) y el agente de supervisión de NetApp.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">Esta validación utiliza NDE para configurar automáticamente todas las direcciones. También puede configurar DHCP en el entorno o asignar manualmente direcciones IP para cada nodo de almacenamiento y nodo de computación. Estos pasos no se describen en esta guía.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">Como se mencionó anteriormente, esta validación utiliza una configuración de dos cables para los nodos de computación.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">Los pasos detallados para el NDE no se tratan en este documento.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">Guía de puesta en marcha</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">Si desea obtener una guía paso a paso para completar la puesta en marcha de la plataforma NetApp HCI básica, consulte<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">Una vez que NDE haya terminado, inicie sesión en vCenter y cree un grupo de puertos distribuido<block ref="b792ce2538db0b838bb1f2cd727d3417" prefix=" " category="inline-code"></block> Para que ONTAP Select y la aplicación utilicen la red NFS.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">Siguiente: Configuración de H615c de NetApp (implantación manual)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">Asignación de GPU fraccionaria para las cargas de trabajo menos exigentes o interactivas</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">Cuando investigadores y desarrolladores trabajan en sus modelos, ya sea en las etapas de desarrollo, ajuste de hiperparámetros o depuración, estas cargas de trabajo suelen requerir menos recursos computacionales. Por lo tanto, es más eficiente aprovisionar GPU y memoria fraccionarias de modo que la misma GPU se pueda asignar simultáneamente a otras cargas de trabajo. Ejecutar:la solución de orquestación de IA proporciona un sistema de uso compartido de GPU fraccionario para las cargas de trabajo en contenedores en Kubernetes. El sistema admite cargas de trabajo que ejecutan programas CUDA y se adapta especialmente a tareas de IA ligeras como la inferencia y la creación de modelos. El sistema de GPU fraccionaria proporciona a los equipos de ciencia de datos e ingeniería de IA la capacidad de ejecutar varias cargas de trabajo simultáneamente en una única GPU. De este modo, las empresas pueden ejecutar más cargas de trabajo, como visión informática, reconocimiento de voz y procesamiento de lenguaje natural en el mismo hardware, con lo que se reducen los costes.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">Ejecutar:el sistema de GPU fraccionaria de IA crea de manera efectiva GPU lógicas virtualizadas con su propia memoria y espacio de computación que los contenedores pueden utilizar y acceder como si fueran procesadores independientes. De este modo, es posible ejecutar varias cargas de trabajo en contenedores en paralelo y en la misma GPU sin interferir entre sí. La solución es transparente, sencilla y portátil y no requiere ningún cambio en los contenedores en sí.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">Una usecasa típica podría ver dos a ocho trabajos ejecutándose en la misma GPU, lo que significa que podría trabajar ocho veces más con el mismo hardware.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">Para el trabajo<block ref="9ee74d566135099889c5305d14349d44" prefix=" " category="inline-code"></block> perteneciente al proyecto<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> En la siguiente figura podemos comprobar que el número de GPU asignadas era de 0.50. Esto es verificado por el<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Comando, que muestra que la memoria de la GPU disponible para el contenedor era de 16,255 MB: La mitad de las 32 GB por GPU V100 en el nodo DGX-1.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">Siguiente: Lograr un uso elevado del clúster con asignación de GPU que sobrecupo</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">La arquitectura de esta solución de centro de soporte se basa en las herramientas prediseñadas de NVIDIA y el kit de herramientas Data OPS de NetApp. Las herramientas de NVIDIA se utilizan para poner en marcha rápidamente soluciones de IA de alto rendimiento utilizando modelos y canalizaciones prediseñados. El kit de herramientas DataOPS de NetApp simplifica diversas tareas de gestión de datos para acelerar el desarrollo.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Arquitectura</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">Anterior: Casos de uso.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">Tecnología de soluciones</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> Es un SDK acelerado por GPU para crear aplicaciones de IA conversacionales multimodales que ofrecen rendimiento en tiempo real en las GPU. El kit de herramientas NVIDIA Train, Adapt y Optimize (TAO) proporciona un método más rápido y sencillo para acelerar la formación y crear rápidamente modelos de IA específicos para dominios con un alto rendimiento y precisión.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">El kit de herramientas NetApp DataOPS es una biblioteca Python que facilita a los desarrolladores, científicos de datos, ingenieros de DevOps e ingenieros de datos la tarea de realizar varias tareas de gestión de datos. Esto incluye el aprovisionamiento casi instantáneo de un nuevo volumen de datos o espacio de trabajo JupyterLab, el clonado casi instantáneo de un volumen de datos o un espacio de trabajo JupyterLab y la creación casi instantánea de copias Snapshot de un volumen de datos o de un espacio de trabajo JupyterLab para su seguimiento y línea de base.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">Diagrama arquitectónico</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">El siguiente diagrama muestra la arquitectura de la solución. Existen tres categorías de entorno principales: El cloud, el núcleo y el perímetro. Cada una de las categorías puede estar geográficamente dispersa. Por ejemplo, el cloud contiene almacenes de objetos con archivos de audio en buckets en diferentes regiones, mientras que el núcleo puede contener centros de datos vinculados a través de una red de alta velocidad o Cloud Sync de NetApp. Los nodos EDGE denotan las plataformas de trabajo diario del agente humano individual, en las que hay disponibles micrófonos y herramientas de panel interactivas para visualizar la opinión y recopilar datos de audio de conversaciones con los clientes.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">Diseño del almacenamiento</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">RIVA</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Kit de herramientas Tao</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">En los centros de datos acelerados por GPU, las empresas pueden utilizar NVIDIA<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> Marco para crear aplicaciones de IA conversacionales, con las que el<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Se conecta para la finetunización de modelos y el reciclaje mediante técnicas de aprendizaje en L de transferencia. Estas aplicaciones y flujos de trabajo de computación funcionan con la<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Activación de las mejores capacidades de administración de datos que ONTAP tiene para ofrecer. El kit de herramientas permite a los equipos de datos corporativos realizar rápidamente prototipos de sus modelos con datos estructurados y no estructurados asociados a través de copias Snapshot y clones para llevar a cabo seguimientos, crear versiones, realizar pruebas A/B, proporcionando así seguridad, gobernabilidad, y cumplimiento de las normativas. Consulte la sección <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">Esta solución muestra los pasos detallados del procesamiento de archivos de audio, el entrenamiento de modelos NLP, el aprendizaje de transferencias y la administración de datos. La canalización integral resultante genera un resumen de sentimiento que se muestra en tiempo real en los paneles de control de los agentes de apoyo humano.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Requisitos de hardware</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">En la siguiente tabla se enumeran los componentes de hardware necesarios para implementar la solución. Los componentes de hardware que se usan en cualquier implementación particular de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">Pruebas de latencia de respuesta</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">Tiempo (milisegundos)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">Procesamiento de datos</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">Inferencia</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">Estas pruebas de tiempo de respuesta se realizaron en más de 50,000 archivos de audio en 560 conversaciones. Cada archivo de audio tenía un tamaño de ~100 KB como MP3 y de ~1 MB cuando se convirtió a WAV. El paso de procesamiento de datos convierte MP3s en archivos WAV. Los pasos de inferencia convierten los archivos de audio en texto y extraen un sentimiento del texto. Estos pasos son todos independientes entre sí y pueden ser paralelizados para acelerar el proceso.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">Teniendo en cuenta la latencia de transferencia de datos entre almacenes, los administradores deben poder ver actualizaciones del análisis de opinión en tiempo real en un segundo del final de la frase.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">Hardware NVIDIA RIVA</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">Requisitos</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">SO</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">Memoria GPU (ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">Modelos de streaming: Aprox. 5600 MB modelos sin secuencias: Aprox. 3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">Memoria GPU (NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">~500 MB por modelo BERT</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">Hardware del kit de herramientas TAO de NVIDIA</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">RAM del sistema</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">RAM DE GPU</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 núcleos</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA (A100, V100 y RTX 30x0)</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100 GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">Sistema de almacenamiento flash</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ONTAP 9.9, la última generación del software de gestión del almacenamiento de NetApp, permite a las empresas modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. ONTAP ofrece las mejores capacidades de gestión de datos y permite la gestión y protección de los datos con un solo conjunto de herramientas, sin importar dónde residan. También puede mover los datos libremente a donde sea necesario: El perímetro, el núcleo o el cloud. ONTAP 9.9 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen los datos esenciales y permiten disfrutar de funcionalidades de infraestructura de nueva generación en arquitecturas de cloud híbrido.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Es un servicio de NetApp que ofrece una sincronización de datos rápida y segura que permite transferir archivos entre recursos compartidos de archivos NFS o SMB en las instalaciones a cualquiera de los siguientes destinos:</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="list-text">StorageGRID de NetApp</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">ONTAP S3 de NetApp</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">Cloud Volumes Service de NetApp</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Simple Storage Service (Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Sistema de archivos Elastic de Amazon (Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google Cloud Storage</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">Almacenamiento de objetos en cloud de IBM</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync mueve los archivos donde los necesite de una forma rápida y segura. Una vez transferidos los datos, estarán completamente disponibles para su uso tanto en el origen como en el destino. Cloud Sync sincroniza continuamente los datos, en función de su programación predefinida, moviendo solo los deltas, de modo que se minimiza el tiempo y el dinero invertidos en la replicación de datos. Cloud Sync es una herramienta de software como servicio (SaaS) fácil de configurar y usar. Las transferencias de datos que Cloud Sync activa son llevadas a cabo por agentes de datos. Puede poner en marcha agentes de datos de Cloud Sync en AWS, Azure, Google Cloud Platform o en las instalaciones.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">La suite de almacenamiento de objetos definida por software StorageGRID admite una amplia gama de casos de uso en entornos multicloud públicos, privados e híbridos sin problemas. Con innovaciones líderes del sector, StorageGRID de NetApp almacena, protege y preserva datos no estructurados para usos múltiples, incluida la gestión automatizada del ciclo de vida durante largos periodos de tiempo. Para obtener más información, consulte<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> sitio.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">En la siguiente tabla se enumeran los componentes de software necesarios para implementar esta solución. Los componentes que se usan en cualquier implementación particular de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">Máquina host</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">RIVA (anteriormente JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">TAO Toolkit (antes Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">SO DGX</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DOTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">Software NVIDIA RIVA</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02 (con nvidia-docker instalado)&gt;=19.03 si no se utiliza DGX</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">Controlador NVIDIA</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">Más de 465.19.01 418.40+, 440.33+, 450.51+ y 460.27+ para las GPU del centro de datos</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">So del contenedor</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">CuBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">CuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Servidor de inferencia Triton</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">Software NVIDIA TAO Toolkit</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Sistema operativo Ubuntu 18.04 LTS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;=3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">docker-ce</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">&gt;19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">docker-API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">kit de herramientas de nvidia-container</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-container-runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">controlador nvidia</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">Última versión</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">Detalles de casos de uso</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Esta solución se aplica a los siguientes casos de uso:</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">El caso práctico de voz a texto comienza ingiriendo archivos de audio para los centros de soporte. Este audio se procesa entonces para ajustarse a la estructura requerida por RIVA. Si los archivos de audio aún no se han dividido en sus unidades de análisis, esto se debe hacer antes de pasar el audio a RIVA. Una vez procesado el archivo de audio, se pasa al servidor RIVA como una llamada API. El servidor emplea uno de los muchos modelos que aloja y devuelve una respuesta. Este mensaje de voz a texto (parte del reconocimiento automático de voz) devuelve una representación de texto del audio. A partir de ahí, la canalización pasa a la parte del análisis de confianza.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">Para el análisis de confianza, la salida de texto del reconocimiento automático de voz sirve como entrada a la clasificación de texto. Text Classification es el componente NVIDIA para clasificar el texto en cualquier número de categorías. Las categorías de sentimiento varían de positivo a negativo para las conversaciones del centro de apoyo. El rendimiento de los modelos se puede evaluar utilizando un conjunto de holdout para determinar el éxito del paso de ajuste fino.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">Catálogo de NVIDIA NGC</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">Una canalización similar se utiliza tanto para el análisis de voz a texto como para el análisis de sentimiento dentro del TAO Toolkit. La principal diferencia es el uso de etiquetas que se requieren para la afinación de los modelos. La canalización del kit de herramientas TAO comienza con el procesamiento de los archivos de datos. A continuación, los modelos preformados (procedentes de<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>) se ajustan con precisión mediante los datos del centro de soporte. Los modelos ajustados con precisión se evalúan en función de sus mediciones de rendimiento correspondientes y, si tienen un rendimiento superior al de los modelos preformados, se implementan en EL servidor RIVA.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">Siguiente: Consideraciones de diseño.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">En esta sección se describe la carga de Criteo Click Logs Day 15 en Pandas y el entrenamiento de un modelo de bosque aleatorio scikit-Learn. En este ejemplo, realizamos la carga de DataFrame con DASK cuDF y entrenamos un modelo de bosque aleatorio en DASK cuML.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Cargar día 15 en DASK y entrenar un modelo de bosque aleatorio DASK cuML</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">Anterior: Cargar Criteo Click Logs Day 15 en Pandas y entrenar un cikit-aprender modelo de bosque aleatorio.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">“Comparación del tiempo de formación”.</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">De una manera similar a la sección anterior, cargue Criteo Click Logs Day 15 en Pandas y entrena un cikit-aprende el modelo de bosque aleatorio. En este ejemplo, realizamos la carga de DataFrame con DASK cuDF y entrenamos un modelo de bosque aleatorio en DASK cuML. Hemos comparado las diferencias en el tiempo de formación y el escalado en la sección <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dask_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">Este portátil importa<block ref="2ea9510c37f7f89e4941ff75f62f21cb" prefix=" " category="inline-code"></block>,<block ref="7bdff0c624ecc34cd492f58859b5a599" prefix=" " category="inline-code"></block>, y lo necesario<block ref="b2015e522a418c3350d3af1da8790aeb" prefix=" " category="inline-code"></block> bibliotecas, como se muestra en el siguiente ejemplo:</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Inicie cliente DASK().</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">Si su clúster está configurado correctamente, puede ver el estado de los nodos de trabajo.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">En nuestro clúster AKS, se muestra el siguiente estado:</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Tenga en cuenta que DASK emplea el paradigma de ejecución lenta: En lugar de ejecutar el código de procesamiento al instante, DASK crea en su lugar un gráfico cíclico dirigido (DAG) de ejecución. DAG contiene un conjunto de tareas y sus interacciones que cada trabajador necesita ejecutar. Este diseño significa que las tareas no se ejecutan hasta que el usuario le indique a DASK que las ejecute de una forma u otra. Con DASK tiene tres opciones principales:</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">*Call comput() en un DataFrame.* esta llamada procesa todas las particiones y, a continuación, devuelve los resultados al planificador para la agregación final y conversión a cuDF DataFrame. Esta opción debe usarse con moderación y sólo en resultados muy reducidos a menos que el nodo del programador se quede sin memoria.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">*Call persistent() en un DataFrame.* esta llamada ejecuta el gráfico, pero, en lugar de devolver los resultados al nodo del planificador, los mantiene en la memoria a través del clúster para que el usuario pueda reutilizar estos resultados intermedios en la canalización sin necesidad de volver a ejecutar el mismo procesamiento.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">*Call head() en un DataFrame.* al igual que con cuDF, esta llamada devuelve 10 registros al nodo del planificador. Esta opción se puede utilizar para comprobar rápidamente si el DataFrame contiene el formato de salida deseado o si los propios registros tienen sentido, en función del procesamiento y cálculo.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">Por lo tanto, a menos que el usuario llama a cualquiera de estas acciones, los trabajadores se sientan inactivos esperando que el programador inicie el procesamiento. Este paradigma de ejecución perezosa es común en marcos informáticos modernos en paralelo y distribuidos como Apache Spark.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">En el siguiente párrafo se entrena un modelo de bosque aleatorio mediante el uso de DASK cuML para computación acelerada por GPU distribuida y se calcula la precisión de predicción del modelo.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">Siguiente: Supervisión de tarea mediante el panel de control de flujos de tareas nativo.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Este documento describe una arquitectura de computación y almacenamiento para poner en marcha la inferencia de inteligencia artificial (IA) basada en GPU en controladoras de almacenamiento de NetApp y servidores Lenovo ThinkSystem en un entorno perimetral que satisface los nuevos escenarios de aplicaciones.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Inferencia de IA en el Edge - NetApp con Lenovo ThinkSystem - Diseño de la solución</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Las empresas están generando cada vez más volúmenes masivos de datos en el extremo de la red. Con el fin de obtener el máximo valor a partir de sensores inteligentes y datos del Internet de las cosas, las organizaciones buscan una solución de transmisión de eventos en tiempo real que permita el uso de la informática perimetral. Así, pues, cada vez se realizan más tareas informáticas exigentes fuera del perímetro y fuera de los centros de datos. La inferencia de IA es uno de los motores de esta tendencia. Los servidores periféricos proporcionan suficiente potencia computacional para estas cargas de trabajo, sobre todo cuando se utilizan aceleradores, pero el almacenamiento limitado suele ser un problema, especialmente en entornos con varios servidores. En este documento mostramos cómo puede poner en marcha un sistema de almacenamiento compartido en un entorno perimetral y cómo beneficia a las cargas de trabajo de inferencia de IA sin perjudicar el rendimiento.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Este documento describe una arquitectura de referencia para la inferencia de IA en el perímetro. Combina múltiples servidores Lenovo ThinkSystem Edge con un sistema de almacenamiento de NetApp para crear una solución fácil de poner en marcha y gestionar. Está previsto ser una guía de referencia para implementaciones prácticas en diversas situaciones, como la planta de fábrica con múltiples cámaras y sensores industriales, sistemas de punto de venta (POS) en transacciones de venta al por menor o sistemas de autoconducción completa (FSD) que identifican anomalías visuales en vehículos autónomos.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Este documento recoge las pruebas y validación de una configuración de computación y almacenamiento que consta de Lenovo ThinkSystem SE350 Edge Server y un sistema de almacenamiento AFF y EF-Series de NetApp de gama básica. Las arquitecturas de referencia proporcionan una solución eficiente y rentable para puestas en marcha de IA, a la vez que proporcionan servicios de datos completos, protección de datos integrada, escalabilidad fluida y almacenamiento de datos conectado al cloud con ONTAP de NetApp y el software para la gestión de datos SANtricity de NetApp.</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Líderes de negocio y arquitectos empresariales que quieren aprovechar la IA en el perímetro.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Científicos de datos, ingenieros de datos, investigadores DE IA/aprendizaje automático y desarrolladores de sistemas de IA.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos y aplicaciones de IA/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Científicos e ingenieros de IA que buscan formas eficientes de poner en marcha modelos DE aprendizaje profundo (DL) Y ML.</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Este servidor Lenovo ThinkSystem y la solución de almacenamiento ONTAP o SANtricity de NetApp están diseñados para gestionar la inferencia de IA en grandes conjuntos de datos mediante la potencia de procesamiento de GPU junto con CPU tradicionales. Esta validación demuestra un alto rendimiento y una gestión de datos óptima con una arquitectura que utiliza uno o varios servidores de borde Lenovo SR350 interconectados con un único sistema de almacenamiento AFF de NetApp, como se muestra en las siguientes dos figuras.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">La descripción general de la arquitectura lógica de la siguiente figura muestra las funciones de los elementos de computación y almacenamiento de esta arquitectura. Específicamente, muestra lo siguiente:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Dispositivos de computación periféricos que realizan inferencia en los datos que recibe de cámaras, sensores, etc.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Un elemento de almacenamiento compartido que ofrece diversos objetivos:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Ofrece una ubicación central para los modelos de inferencia y otros datos que necesitan para realizar la inferencia. Los servidores informáticos acceden al almacenamiento directamente y utilizan los modelos de inferencia en toda la red sin necesidad de copiarlos de forma local.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Los modelos actualizados se empujan aquí.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archiva los datos de entrada que los servidores perimetrales reciben para analizarlos posteriormente. Por ejemplo, si los dispositivos periféricos están conectados a las cámaras, el elemento de almacenamiento mantiene los vídeos capturados por las cámaras.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rojo</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">azul</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Sistema de computación Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Sistema de almacenamiento AFF de NetApp</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Dispositivos periféricos que realizan inferencia en las entradas de cámaras, sensores, etc.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Almacenamiento compartido que mantiene los modelos de inferencia y los datos de los dispositivos periféricos para su posterior análisis.</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">GPU acelera la computación en el extremo.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Implementación de varios servidores periféricos, respaldados y gestionado desde un almacenamiento compartido.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protección de datos sólida para cumplir con los objetivos de punto de recuperación (RPO) y los objetivos de tiempo de recuperación (RTO) bajos sin pérdida de datos.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestión de datos optimizada con copias Snapshot y clones de NetApp para optimizar los flujos de trabajo de desarrollo.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Cómo utilizar esta arquitectura</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Este documento valida el diseño y el rendimiento de la arquitectura propuesta. Sin embargo, no hemos probado ciertas piezas a nivel de software, como la gestión y sincronización de datos de contenedores, cargas de trabajo o modelos con cloud o centros de datos en las instalaciones, ya que son específicas de un escenario de puesta en marcha. Aquí existen varias opciones.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">En el nivel de gestión de contenedores, la gestión de contenedores de Kubernetes es una buena opción y es compatible con una versión totalmente ascendente (Canonical) o con una versión modificada adecuada para implementaciones empresariales (Red Hat). La <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> Que utiliza Trident de NetApp y los recientemente añadidos<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> Proporciona trazabilidad, funciones de gestión de datos, interfaces y herramientas integradas para que los científicos e ingenieros de datos se integren con el sistema de almacenamiento de NetApp. Kubeflow, el kit DE herramientas ML para Kubernetes, proporciona funcionalidades de IA adicionales junto con compatibilidad para el control de versiones de modelos y KFServing en varias plataformas como TensorFlow Serving o NVIDIA Triton inferpensado Server. Otra opción es la plataforma NVIDIA EGX, que proporciona gestión de las cargas de trabajo junto con acceso a un catálogo de contenedores de inferencia de IA habilitados para GPU. Sin embargo, es posible que estas opciones requieran gran esfuerzo y experiencia para ponerlas en producción y es posible que requieran la ayuda de un proveedor de software independiente (ISV) o un asesor de terceros.</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">La ventaja clave de la inferencia de IA y la computación perimetral es la capacidad de que los dispositivos calculen, procesen y analicen datos con un alto nivel de calidad sin latencia. Hay demasiados ejemplos de casos de uso de computación perimetral que describir en este documento, pero aquí hay algunos ejemplos destacados:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automóviles: Vehículos autónomos</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">La ilustración clásica de la informática avanzada se encuentra en los sistemas avanzados de asistencia al conductor (ADAS) en vehículos autónomos (AV). La IA en vehículos sin conductor debe procesar rápidamente una gran cantidad de datos procedentes de cámaras y sensores para garantizar su seguridad. Tomar demasiado tiempo para interpretar entre un objeto y un humano puede significar la vida o la muerte, por lo tanto poder procesar los datos lo más cerca posible del vehículo es crucial. En este caso, uno o varios servidores de computación periféricos se encarga de las entradas de cámaras, RADAR, LiDAR y otros sensores, mientras que el almacenamiento compartido contiene modelos de inferencia y almacena datos de entrada de los sensores.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Atención sanitaria: Monitorización de pacientes</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">Uno de los mayores impactos de la IA y la informática perimetral es su capacidad para mejorar la supervisión continua de pacientes para enfermedades crónicas, tanto en las unidades de cuidados intensivos como en las unidades de cuidados intensivos (UCI). Los datos de los dispositivos periféricos que supervisan los niveles de insulina, la respiración, la actividad neurológica, el ritmo cardíaco y las funciones gastrointestinales requieren un análisis instantáneo de los datos que deben ser objeto de acciones inmediatas porque hay poco tiempo para actuar y salvar la vida de alguien.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Venta al por menor: Pago sin cajero</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">La computación perimetral puede ayudar a los minoristas a reducir el tiempo de salida y aumentar el tráfico de pies. Los sistemas sin cajero admiten varios componentes, como los siguientes:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Autenticación y acceso. Conectar el comprador físico a una cuenta validada y permitir el acceso al espacio de venta al por menor.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Supervisión de inventario. Utilizar sensores, etiquetas RFID y sistemas de visión computarizada para confirmar la selección o deselección de artículos por parte de los compradores.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Aquí, cada uno de los servidores perimetrales gestiona cada contador de retirada y el sistema de almacenamiento compartido sirve como punto de sincronización central.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Servicios financieros: Seguridad humana en quioscos y prevención del fraude</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Las organizaciones bancarias utilizan la IA y la informática perimetral para innovar y crear experiencias bancarias personalizadas. Los quioscos interactivos, mediante el análisis de datos en tiempo real y la inferencia de IA, permiten ahora a los cajeros automáticos no sólo ayudar a los clientes a retirar el dinero, sino también supervisar de forma proactiva los quioscos a través de las imágenes capturadas con las cámaras para identificar el riesgo para la seguridad humana o el comportamiento fraudulento. En este escenario, los servidores periféricos informáticos y los sistemas de almacenamiento compartido se conectan a quioscos y cámaras interactivos para ayudar a los bancos a recopilar y procesar datos con modelos de inferencia de IA.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Fabricación: Industria 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">La cuarta revolución industrial (Industry 4.0) ha comenzado, junto con tendencias emergentes como Smart Factory e impresión 3D. Con el fin de prepararse para un futuro impulsado por los datos, la comunicación y el Internet de las cosas (M2M) a gran escala están integrados para una mayor automatización sin necesidad de intervención humana. La fabricación ya está altamente automatizada y añadir características de IA es una continuación natural de la tendencia a largo plazo. La IA permite automatizar operaciones que se pueden automatizar con la ayuda de la visión computarizada y otras funcionalidades de IA. Puede automatizar el control de calidad o las tareas que se basan en la visión humana o en la toma de decisiones para realizar análisis más rápidos de materiales en líneas de ensamblaje en plantas de fabricación para ayudar a las plantas de fabricación a cumplir con los estándares ISO requeridos de gestión de la seguridad y la calidad. Aquí, cada servidor perimetral informático está conectado a una matriz de sensores que supervisan el proceso de fabricación, y cuando es necesario, los modelos de inferencia actualizados se ven empujados al almacenamiento compartido.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telecomunicaciones: Detección de óxido, inspección de torre y optimización de la red</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">La industria de las telecomunicaciones utiliza técnicas de IA y visión informática para procesar imágenes que detectan automáticamente el óxido e identifican las torres celulares que contienen corrosión y, por lo tanto, requieren una inspección adicional. El uso de imágenes con drones y modelos de IA para identificar regiones distintas de una torre para analizar la oxidación, las grietas superficiales y la corrosión ha aumentado en los últimos años. La demanda continúa creciendo para tecnologías de IA que permiten inspeccionar eficientemente la infraestructura de telecomunicaciones y las torres de células, evaluar periódicamente la degradación y reparar rápidamente cuando sea necesario.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">Además, otro caso de uso emergente en las telecomunicaciones es el uso de algoritmos de IA y ML para predecir patrones de tráfico de datos, detectar dispositivos compatibles con 5G y automatizar y aumentar la gestión energética de múltiples entradas y salidas múltiples (MIMO). El hardware de MIMO se utiliza en las torres de radio para aumentar la capacidad de la red; sin embargo, esto viene con costos de energía adicionales. Los modelos ML para “modo de suspensión MIMO” implementados en las zonas de células pueden predecir el uso eficiente de las radios y ayudar a reducir los costes de consumo de energía para los operadores de redes móviles (MNO). Las soluciones de computación avanzada y de inferencia de IA ayudan a las MNO a reducir la cantidad de datos transmitidos hacia los centros de datos, reducir su TCO, optimizar las operaciones de red y mejorar el rendimiento general de los usuarios finales.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">En esta sección, ampliamos el escenario en el que varios equipos envían cargas de trabajo y superan su cuota. De esta manera, mostramos cómo el algoritmo de equidad de Run:AI asigna recursos de clúster según la proporción de cuotas predefinidas.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">Objetivos de este escenario de prueba:</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">Muestra el mecanismo de cola cuando varios equipos solicitan GPU a través de su cuota.</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">Muestre cómo distribuye el sistema una cuota del clúster entre varios equipos que se encuentran por encima de su cuota en función de la proporción entre sus cuotas, de modo que el equipo con la cuota mayor obtenga una parte mayor de la capacidad de reserva.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">Al final de <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, hay dos cargas de trabajo en cola: una para<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y uno para<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>. En esta sección, ponemos en cola las cargas de trabajo adicionales.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">Detalles de la prueba para la sección 4.10</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">Para obtener información detallada, incluidos los envíos de trabajos, las imágenes contenedoras utilizadas y las secuencias de comandos ejecutadas, consulte <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">Cuando todos los trabajos se someten según la sección <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>, el panel del sistema muestra eso<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, y.<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Todos tienen más GPU que su cuota predefinida.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Ocupa cuatro GPU más que su cuota de software predefinida (cuatro), mientras que<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Cada uno ocupa dos GPU más que su cuota blanda (dos). La proporción de GPU asignadas por encima de una cuota es igual a la de su cuota predefinida. Esto se debe a que el sistema utilizó la cuota preconfigurada como referencia de prioridad y se aprovisionó de manera acorde cuando varios equipos soliciten más GPU, por lo que superó su cuota. Este equilibrio de carga automático proporciona justicia y priorización cuando los equipos de ciencia de datos empresariales están involucrados activamente en el desarrollo y la producción de modelos de IA.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">Los resultados de este escenario de prueba muestran lo siguiente:</block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">El sistema empieza a deponer las cargas de trabajo de otros equipos en cola.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">El orden de la depuesta en cola se decide de acuerdo a los algoritmos de justicia, tal que<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Obtenga la misma cantidad de GPU de cuota superior (ya que tienen una cuota similar) y.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Obtiene una cantidad doble de GPU, ya que su cuota es dos veces superior a la de<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">Toda la asignación se realiza automáticamente.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">Por lo tanto, el sistema debe estabilizarse en los siguientes estados:</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU asignadas</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">Cuatro GPU a lo largo de la cuota. Cola vacía.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4/2</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">Dos GPU por encima de la cuota. Una carga de trabajo en cola.</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">No utiliza GPU en absoluto, sin cargas de trabajo en cola.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">La siguiente figura muestra la asignación de GPU por proyecto a lo largo del tiempo en el panel Run:AI Analytics de las secciones <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, y. <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. Cada línea de la figura indica el número de GPU aprovisionadas para un equipo de ciencias de datos en cualquier momento. Podemos observar que el sistema asigna dinámicamente las GPU de acuerdo con las cargas de trabajo enviadas. Esto permite a los equipos revisar las cuotas cuando hay GPU disponibles en el clúster y, después, adelantarse a los trabajos según sea necesario, antes de alcanzar, por fin, un estado estable para los cuatro equipos.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">Siguiente: Guardar datos en un volumen persistente aprovisionado por Trident</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">Este informe le muestra cómo clonar rápidamente un espacio de nombres de datos. Demuestra cómo definir e implementar flujos de trabajo de entrenamiento de IA que incorporan la creación casi instantánea de bases de datos y modelos para la trazabilidad y el control de versiones. También muestra cómo replicar datos sin problemas a través de sitios y regiones y aprovisionar rápidamente espacios de trabajo de los portátiles Juppyter con acceso a conjuntos de datos masivos.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798: Plano de control de IA de NetApp</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">Empresas y organizaciones de todos los tamaños y sectores se están decantando por la inteligencia artificial (IA), el aprendizaje automático (ML) y el aprendizaje profundo (DL) para resolver problemas reales, ofrecer productos y servicios innovadores y obtener una ventaja en un mercado cada vez más competitivo. A medida que las organizaciones aumentan el uso de la IA, EL ML y el AP, deben hacer frente a numerosos retos, como la escalabilidad de la carga de trabajo y la disponibilidad de los datos. En este documento se demuestra cómo puede hacer frente a estos retos usando el plano de control de IA de NetApp, una solución que empareja las funcionalidades de gestión de datos de NetApp con marcos y herramientas de código abierto más populares.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">Este informe le muestra cómo clonar rápidamente un espacio de nombres de datos. También le muestra cómo replicar datos sin problemas en sitios y regiones para crear una canalización de datos coherente y unificada de IA/ML/DL. Además, le guía por la definición e implementación de flujos de trabajo de formación de IA, ML y DL que incorporan la creación casi instantánea de datos y líneas de base de modelos para su trazabilidad y versionado. Con esta solución, puede rastrear cada entrenamiento de modelo que se ejecuta en el conjunto de datos exacto que se utilizó para entrenar o validar el modelo. Por último, este documento le muestra cómo aprovisionar rápidamente espacios de trabajo de Juppyter Notebook con acceso a conjuntos de datos masivos.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">Solución de sistema de archivos en paralelo totalmente compatible de NetApp BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">Nota: Para entrenamiento distribuido al estilo HPC a escala que implique un gran número de servidores GPU que requieran acceso compartido al mismo conjunto de datos o, si necesita o prefiere un sistema de archivos paralelo, consulte el documento <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. En este informe técnico se describe cómo incluir <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> Como parte del plano de control de IA de NetApp. Esta solución está diseñada para escalar a partir de un puñado de sistemas NVIDIA DGX A100, hasta un SuperPOD de 140 nodos completo.</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">El plano de control de IA de NetApp se dirige a los científicos e ingenieros de datos y, por lo tanto, se necesita experiencia mínima en NetApp o en ONTAP® de NetApp. Con esta solución, las funciones de gestión de datos se pueden ejecutar utilizando interfaces y herramientas sencillas y conocidas. Si ya dispone de almacenamiento de NetApp en su entorno, puede probar el plano de control de IA de NetApp hoy mismo. Si desea probar la solución pero no dispone de almacenamiento de NetApp, visite<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>Y puede volver a tener una solución de almacenamiento de NetApp basada en cloud en cuestión de minutos. La siguiente figura ofrece una visualización de la solución.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">Siguiente: Conceptos y componentes.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">En esta arquitectura, lo primordial es la parte de cálculo más intensivo del proceso de formación distribuida de detección de carriles POR inteligencia artificial o aprendizaje automático (ML).</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">En esta arquitectura, lo primordial es la parte de cálculo más intensivo del proceso de formación distribuida de detección de carriles POR inteligencia artificial o aprendizaje automático (ML). La detección de carriles es una de las tareas más importantes en la conducción autónoma, que ayuda a guiar los vehículos por la localización de las marcas de carril. Los componentes estáticos, como las marcas de carril, guían al vehículo a conducir por la carretera de forma interactiva y segura.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">Los enfoques basados en la red neuronal convolucional (CNN) han empujado la comprensión y segmentación de la escena a un nuevo nivel. Aunque no funciona bien para objetos con estructuras largas y regiones que podrían ser ocluidas (por ejemplo, postes, sombra en el carril, etc.). La Red neuronal convolucional Espacial (SCNN) generaliza la CNN a un rico nivel espacial. Permite la propagación de información entre neuronas en la misma capa, lo que lo hace más adecuado para objetos estructurados como carriles, polos o camiones con oclusiones. Esta compatibilidad se debe a que la información espacial se puede reforzar y conserva la suavidad y la continuidad.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">Es necesario inyectar miles de imágenes de escenas en el sistema para permitir que el modelo aprenda y distinga los diversos componentes del conjunto de datos. Estas imágenes incluyen el tiempo, día o noche, carreteras de varios carriles y otras condiciones de tráfico.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">Para la formación, es necesario disponer de buena calidad y cantidad de datos. Una única GPU o varias GPU pueden tardar entre días y semanas para completar el entrenamiento. El entrenamiento con distribución de datos puede acelerar el proceso mediante varias GPU de varios nodos. Horovod es uno de esos marcos que concede entrenamiento distribuido pero la lectura de datos en clústeres de GPU puede ser un obstáculo. Azure NetApp Files proporciona un rendimiento elevado y una latencia baja constante ultrarrápida que proporciona funcionalidades de escalado horizontal y escalado vertical, de tal modo que se utilicen las GPU en la mejor capacidad computacional. Nuestros experimentos verificaron que todas las GPU del clúster se utilizan de media más del 96 % para entrenar la detección de carriles con SCNN.</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">La ciencia de datos incorpora varias disciplinas EN TECNOLOGÍA y negocio, por lo que múltiples personas forman parte de nuestro público objetivo:</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">Los científicos de datos necesitan la flexibilidad necesaria para utilizar las herramientas y las bibliotecas que prefieran.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">Los ingenieros de datos necesitan saber cómo fluyen los datos y dónde residen.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">Expertos en casos de uso de conducción autónoma.</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">Administradores de cloud y arquitectos para configurar y gestionar recursos de cloud (Azure).</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">Un ingeniero de DevOps necesita herramientas para integrar nuevas aplicaciones de IA/ML en sus canalizaciones de integración continua y de puesta en marcha continua (CI/CD).</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">En este documento, describimos cómo Azure NetApp Files, EJECUTA: IA y Microsoft Azure ayudan a cada uno de estos roles a aportar valor empresarial.</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">Esta sección abarca los requisitos tecnológicos del caso práctico de detección de carriles al implementar una solución de formación distribuida a escala que se ejecuta completamente en el cloud de Azure. La siguiente figura muestra información general sobre la arquitectura de la solución.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">Los elementos utilizados en esta solución son:</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes Service (AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">SKU de Azure Compute con GPU de NVIDIA</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">EJECUCIÓN: IA</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">Los vínculos a todos los elementos mencionados aquí se enumeran en el <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> sección.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">Requisitos de servicios y recursos cloud</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">En la siguiente tabla se enumeran los componentes de hardware necesarios para implementar la solución. Los componentes cloud que se usan en cualquier implementación de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">Un mínimo de tres nodos de sistema y tres nodos de trabajo de GPU</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">Nodos del sistema de SKU de máquinas virtuales (VM)</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Tres Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">Nodos de trabajo de GPU de VM SKU</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">Tres Standard_NC63_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">Nivel estándar de 4 TB</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">En la siguiente tabla se enumeran los componentes de software necesarios para implementar la solución. Los componentes de software que se usan en cualquier implementación de la solución pueden variar en función de las necesidades del cliente.</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">Versión u otra información</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - versión Kubernetes</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">EJECUCIÓN: CLI DE IA</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">EJECUTAR:versión del operador de Kubernetes de orquestación de IA</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">Demostraciones interactivas en 3D</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">Conecte directamente con un especialista en IA de NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">Descripción de la solución NVDIA base Command Platform con NetApp</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">NetApp para IA 10: Infografía buenas razones</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">IA en la sanidad: Aprendizaje profundo para identificar las lesiones del COVID-19 en exploraciones pulmonares TC</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">AI en la atención sanitaria: Monitorización del uso de la máscara facial en entornos sanitarios documento técnico</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">IA en la sanidad: Informe técnico de imágenes de diagnóstico</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">IA para minoristas: Inteligencia artificial de NetApp conversacional con NVIDIA RIVA</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">Resumen de la solución ONTAP AI de NetApp</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">Resumen de la solución del kit de herramientas de operaciones de datos de NetApp</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">Resumen de la solución del plano de control de IA de NetApp</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">Libro electrónico "transformando el sector con los datos impulsan la IA"</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">Resumen de la solución de IA EF-Series de NetApp</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">Resumen de la solución de NetApp AI y Lenovo ThinkSystem para la inferencia de IA</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">Resumen de la solución NetApp AI y Lenovo ThinkSystem para IA empresarial Y ML</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp y NVIDIA: Redefiniendo lo que es posible con el vídeo de IA</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">ONTAP AI de NetApp con NVIDIA</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">Descripción general de las soluciones de infraestructura convergente de ONTAP AI de NetApp y NVIDIA.</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">ONTAP AI de NetApp con sistemas NVIDIA DGX A100</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">ONTAP AI de NetApp con sistemas NVIDIA DGX A100 y switches Mellanox Spectrum Ethernet</block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="c95fe91ba2d256285401bdabdd666ca7" category="doc">NVA-1151-PUESTA en MARCHA: ONTAP AI de NetApp con sistemas NVIDIA DGX A100</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-DEPLOY incluye instrucciones de puesta en marcha del sistema de almacenamiento para cargas de trabajo de arquitectura verificada de NetApp (NVA) para aprendizaje automático (ML) y inteligencia artificial (AI) con sistemas de almacenamiento AFF A800 de NetApp, sistemas NVIDIA DGX A100 y switches de red NVIDIA Mellanox. También incluye instrucciones para ejecutar pruebas de prueba de rendimiento de validación una vez completada la implementación.</block>
  <block id="3f8a5951b902f50dcbc39690406ade15" category="paragraph"><block ref="3f8a5951b902f50dcbc39690406ade15" category="inline-link-macro-rx"></block></block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, GPU V100, GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">Estación DGX de NVIDIA<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">GPU de núcleo tensor NVIDIA V100<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">Acceso temprano a NVIDIA Jarvis<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">Guía para desarrolladores<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">Especificaciones técnicas de AFF a-Series de NetApp<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">Ventaja de NetApp Flash para All Flash FAS<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">Biblioteca de información de ONTAP 9<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">Informe técnico de NetApp ONTAP FlexGroup Volumes<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Cisco Networking<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">Guía de puesta en marcha de ONTAP AI con DGX-1 y Cisco Networking<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">Guía de diseño de ONTAP AI con DGX-1 y Mellanox Networking<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">Guía de diseño de ONTAP AI con DGX-2<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">Conceptos y componentes</block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">En esta sección se tratan conceptos y componentes asociados al almacenamiento en caché de datos en un flujo DE trabajo DE ML.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">Aprendizaje automático</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">LA ML se está convirtiendo rápidamente en un factor esencial para muchas empresas y organizaciones de todo el mundo. Por lo tanto, los equipos DE TECNOLOGÍA y DevOps se enfrentan ahora al reto de estandarizar cargas de trabajo DE ML y aprovisionar cloud, recursos informáticos en las instalaciones y recursos informáticos híbridos que dan soporte a los flujos de trabajo dinámicos e intensivos que requieren las tareas de ML y las canalizaciones.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">Aprendizaje automático basado en contenedores y Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">Los contenedores son instancias aisladas del espacio de usuario que se ejecutan sobre un kernel de sistema operativo host compartido. La adopción de contenedores está aumentando rápidamente. Los contenedores ofrecen muchos de los mismos beneficios de uso de pruebas de espacio que las máquinas virtuales (VM). Sin embargo, debido a que se eliminan las capas de hipervisor y de sistema operativo «guest» de las que dependen las máquinas virtuales, los contenedores son mucho más ligeros.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Sitio web de Docker</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">Los contenedores también permiten el empaquetado eficiente de dependencias de aplicaciones, tiempos de ejecución, etc. directamente en una aplicación. El formato de embalaje de contenedor más utilizado es el contenedor Docker. Una aplicación que se haya contenedor en el formato de contenedor Docker se puede ejecutar en cualquier máquina que pueda ejecutar contenedores Docker. Esto es cierto incluso si las dependencias de la aplicación no están presentes en la máquina, porque todas las dependencias están empaquetadas en el propio contenedor. Para obtener más información, visite la<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Sitio web de Kubernetes</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">Kubernetes, el popular orquestador de contenedores, permite a los científicos de datos lanzar trabajos y canalizaciones flexibles basados en contenedores. También permite a los equipos de infraestructura gestionar y supervisar cargas de trabajo DE ML en un único entorno gestionado y nativo del cloud. Para obtener más información, visite la<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">Cnvrg.io es un sistema operativo de IA que transforma la forma en la que las empresas gestionan, escalan y aceleran la IA y el desarrollo científico de datos de la investigación a la producción. La plataforma de código primero está desarrollada por científicos de datos para científicos de datos y ofrece flexibilidad para ejecutarse en las instalaciones o en el cloud. Gracias a la gestión de modelos, MLOPS y soluciones continuas DE ML, cnvrg.io aporta una tecnología de primera línea a los equipos de ciencia de datos para que puedan dedicar menos tiempo a DevOps y centrarse en la auténtica magia, gracias a los algoritmos. Desde que utiliza cnvrg.io, los equipos de distintos sectores han obtenido más modelos de producción, lo que da como resultado un aumento del valor empresarial.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">Cnvrg.io Meta-Scheduler</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg. i/o tiene una arquitectura única que permite A LOS DEPARTAMENTOS DE TECNOLOGÍA e ingenieros conectar distintos recursos informáticos al mismo plano de control y que cnvrg.io gestiona tareas DE ML en todos los recursos. Esto significa que puede conectar varios clústeres de Kubernetes en las instalaciones, servidores de VM y cuentas de cloud, y ejecutar cargas de trabajo DE ML en todos los recursos, como se muestra en la siguiente figura.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">Cnvrg.io almacenamiento en caché de datos</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">cnvrg.io permite a los científicos de datos definir versiones de conjuntos de datos calientes y fríos con su tecnología de almacenamiento en caché de datos. De forma predeterminada, los conjuntos de datos se almacenan en una base de datos de almacenamiento de objetos centralizada. A continuación, los científicos de datos pueden almacenar en caché una versión de datos específica en el recurso de computación seleccionado para ahorrar tiempo en la descarga y, por tanto, aumentar EL desarrollo DE ML y la productividad. Los conjuntos de datos que se almacenan en la caché y no se utilizan durante unos días se borran automáticamente del NFS seleccionado. El almacenamiento en caché y el borrado de la caché se pueden realizar con un solo clic; no se requiere codificación, NI trabajo de DevOps.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">Cnvrg.io fluye y canalizaciones ML</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">Cnvrg.io fluye es una herramienta para construir tuberías DE PRODUCCIÓN ML. Cada componente de un flujo es un script/código que se ejecuta en una computación seleccionada con una imagen de Docker base. Este diseño permite a los científicos e ingenieros de datos crear una única canalización que puede ejecutar tanto en las instalaciones como en el cloud. cnvrg.io garantiza que los datos, los parámetros y los artefactos se mueven entre los diferentes componentes. Además, se supervisa y se sigue cada flujo para obtener ciencia de datos reproducibles al 100%.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">NÚCLEO cnvrg.io</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">El NÚCLEO cnvrg.io es una plataforma gratuita para que la comunidad de ciencia de datos pueda ayudar a los científicos de datos a centrarse más en la ciencia de datos y menos en DevOps. La infraestructura flexible DE CORE aporta a los científicos de datos el control de usar cualquier idioma, marco de IA o entorno informático, ya sea en las instalaciones o en el cloud, para poder hacer lo que mejor hacen o crear algoritmos. El NÚCLEO cnvrg.io se puede instalar fácilmente con un único comando en cualquier clúster de Kubernetes.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI es una arquitectura de referencia de centro de datos para cargas de trabajo DE APRENDIZAJE profundo (DL) y ML que utiliza sistemas de almacenamiento AFF de NetApp y sistemas DGX de NVIDIA con GPU Tesla V100. ONTAP AI se basa en el protocolo de archivos NFS estándar del sector en Ethernet de 100 GB y proporciona a los clientes una infraestructura DE APRENDIZAJE PROFUNDO DE alto rendimiento QUE utiliza tecnologías estándar para el centro de datos para reducir los gastos generales de implementación y administración. Con una red y protocolos estandarizados, ONTAP AI se integra en entornos de cloud híbrido a la vez que mantiene la coherencia y la simplicidad operativas. Como solución de infraestructura prevalidada, ONTAP AI reduce el tiempo y el riesgo de la puesta en marcha y la sobrecarga de la administración de forma significativa, lo que permite a los clientes lograr una rentabilidad de la inversión más rápida.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">Sitio web DeepOps</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps es un proyecto de código abierto de NVIDIA que, con Ansible, automatiza la puesta en marcha de clústeres de servidores de GPU de acuerdo con las prácticas recomendadas. DeepOps es modular y se puede utilizar para realizar varias tareas de puesta en marcha. En este documento y en el ejercicio de validación descrito, DeepOps se utiliza para poner en marcha un clúster de Kubernetes que consta de nodos de trabajo de servidor GPU. Para obtener más información, visite la<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Sitio web de Trident</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident es un orquestador de almacenamiento de código abierto desarrollado y mantenido por NetApp que simplifica en gran medida la creación, la gestión y el consumo de almacenamiento persistente para cargas de trabajo de Kubernetes. Trident, en sí misma, una aplicación nativa de Kubernetes, se ejecuta directamente en un clúster de Kubernetes. Con Trident, los usuarios de Kubernetes (desarrolladores, científicos de datos, administradores de Kubernetes, etc.) pueden crear, gestionar e interactuar con volúmenes de almacenamiento persistente en el formato Kubernetes estándar, con el que ya están familiarizados. Al mismo tiempo, pueden aprovechar las funciones avanzadas de gestión de datos de NetApp y un Data Fabric con tecnología de NetApp. Trident elimina las complejidades del almacenamiento persistente y facilita el consumo. Para obtener más información, visite la<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">StorageGRID de NetApp es una plataforma de almacenamiento de objetos definida por software diseñada para satisfacer estas necesidades proporcionando un almacenamiento sencillo y similar al cloud a el que los usuarios pueden acceder mediante el protocolo S3. StorageGRID es un sistema de escalado horizontal diseñado para admitir varios nodos en sitios conectados a Internet, independientemente de la distancia. Con el motor de políticas inteligente de StorageGRID, los usuarios pueden elegir objetos de codificación de borrado en todos los sitios para lograr resiliencia geográfica o replicación de objetos entre sitios remotos para minimizar la latencia de acceso WAN. StorageGRID proporciona un excelente lago de datos de almacenamiento de objetos primarios de cloud privado en esta solución.</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">Cloud Volumes ONTAP de NetApp</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">El software de gestión de datos Cloud Volumes ONTAP de NetApp proporciona control, protección y eficiencia para los datos de usuarios con la flexibilidad de proveedores de cloud público como AWS, Google Cloud Platform y Microsoft Azure. Cloud Volumes ONTAP es un software para la gestión de datos nativo del cloud, integrado en el software de almacenamiento ONTAP de NetApp, que proporciona a los usuarios una plataforma de almacenamiento universal superior que cubre sus necesidades de datos en el cloud. Disponer de un mismo software de almacenamiento en el cloud y en las instalaciones proporciona a los usuarios el valor de una estructura de datos sin necesidad de formar al personal INFORMÁTICO en todos los métodos nuevos para gestionar los datos.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">Para los clientes interesados en modelos de puesta en marcha de cloud híbrido, Cloud Volumes ONTAP puede proporcionar las mismas funcionalidades y un rendimiento líder en la mayoría de clouds públicos para proporcionar una experiencia de usuario fluida y coherente en cualquier entorno.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">Siguiente: Requisitos de hardware y software</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">Dónde encontrar información adicional, reconocimientos e historial de versiones</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">Almacenamiento persistente de NetApp para contenedores: Astra Trident de NetApp</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopía AI: Inferencia confidencial</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentación de NVIDIA Triton inferencias Server</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxes en PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, Director de producto, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, ingeniero técnico de marketing, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, director técnico y profesor de Protopía AI</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">Historial de versiones del documento</block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">Mayo de 2022</block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">El kit de herramientas DataOPS de NetApp para Kubernetes abstrae los recursos de almacenamiento y las cargas de trabajo de Kubernetes hasta el nivel de espacio de trabajo de ciencia de datos. Estas funciones se presentan en una interfaz sencilla y fácil de usar diseñada para científicos e ingenieros de datos.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">Creación de versiones de conjuntos de datos y modelos con el kit de herramientas de operaciones de datos de NetApp</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">Anterior: Monitor de Dink y RAPIDS con Prometheus y Grafana.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">El kit de herramientas DataOPS de NetApp para Kubernetes abstrae los recursos de almacenamiento y las cargas de trabajo de Kubernetes hasta el nivel de espacio de trabajo de ciencia de datos. Estas funciones se presentan en una interfaz sencilla y fácil de usar diseñada para científicos e ingenieros de datos. Utilizando la forma familiar de un programa de Python, el kit de herramientas permite a científicos e ingenieros de datos aprovisionar y destruir espacios de trabajo de JuppyterLab en cuestión de segundos. Estas áreas de trabajo pueden contener terabytes o incluso petabytes de capacidad de almacenamiento, lo que permite a los científicos de datos almacenar todos sus conjuntos de datos de entrenamiento directamente en sus espacios de trabajo de proyectos. Han pasado los días de gestionar los espacios de trabajo y los volúmenes de datos por separado.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">Repositorio de GitHub</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">Para obtener más información, visite el Kit de herramientas<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">Configuración de NetApp</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">Siguiente:Descripción general</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">Este informe técnico proporciona directrices de diseño para que los clientes realicen análisis de opinión en un centro de soporte global de nivel empresarial usando las tecnologías de gestión de datos de NetApp con un marco de software de NVIDIA mediante la transferencia de aprendizaje e IA conversacional.</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910: Análisis de sentimiento en las comunicaciones de los clientes con IA de NetApp</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Sathish Thyagarajan, y David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">Este informe técnico proporciona directrices de diseño para que los clientes realicen análisis de opinión en un centro de soporte global de nivel empresarial usando las tecnologías de gestión de datos de NetApp con un marco de software de NVIDIA mediante la transferencia de aprendizaje e IA conversacional. Esta solución es aplicable a cualquier sector que desee obtener información de los clientes a partir de archivos de voz o texto grabados que representen registros de chat, correos electrónicos y otras comunicaciones de texto o audio. Hemos implementado una canalización integral para demostrar el reconocimiento automático de voz, el análisis de sensibilidad en tiempo real y el modelo de procesamiento de lenguaje natural y aprendizaje profundo: Funcionalidades de nueva formación en un clúster informático acelerado por GPU con almacenamiento all-flash conectado al cloud de NetApp. Se pueden formar y optimizar modelos lingüísticos masivos de vanguardia para realizar inferencia rápidamente con el centro de soporte global y crear una experiencia de cliente excepcional y evaluaciones de rendimiento de empleados objetivas y a largo plazo.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">El análisis del sentimiento es un campo de estudio dentro del procesamiento del lenguaje natural (NLP) por el cual se extraen sentimientos positivos, negativos o neutrales del texto. Los sistemas de IA conversacionales han aumentado hasta alcanzar un nivel de integración casi global a medida que cada vez más personas acuden para interactuar con ellos. El análisis de confianza tiene una variedad de casos de uso, desde determinar el rendimiento de los empleados del centro de soporte en conversaciones con los llamantes y proporcionar respuestas automatizadas adecuadas al bot conversacional para predecir el precio de las acciones de una empresa basándose en las interacciones entre representantes de la empresa y la audiencia en llamadas trimestrales a ganancias. Además, el análisis de confianza puede utilizarse para determinar la visión del cliente sobre los productos, servicios o asistencia proporcionados por la Marca.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">Esta solución integral utiliza modelos NLP para realizar un análisis de confianza de alto nivel que permita marcos analíticos del centro de soporte. Las grabaciones de audio se procesan en texto escrito y el sentimiento se extrae de cada frase de la conversación. Los resultados, agregados en un panel, se pueden elaborar para analizar los sentimientos de la conversación, tanto históricos como en tiempo real. Esta solución se puede generalizar a otras soluciones con modalidades de datos y necesidades de producción similares. Con los datos adecuados se pueden llevar a cabo otros casos de uso. Por ejemplo, las llamadas de beneficios de la empresa se pueden analizar para determinar la opinión utilizando la misma canalización de extremo a extremo. Otras formas de análisis de NLP, como el modelado de temas y el reconocimiento de entidades con nombre (TNM), también son posibles debido a la naturaleza flexible del ducto.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">Estas implementaciones de IA fueron posibles gracias a NVIDIA RIVA, el kit de herramientas TAO de NVIDIA y el kit de herramientas DataOPS de NetApp trabajando juntos. Las herramientas de NVIDIA se utilizan para poner en marcha rápidamente soluciones de IA de gran rendimiento utilizando modelos y canalizaciones prediseñados. El kit de herramientas DataOPS de NetApp simplifica diversas tareas de gestión de datos para acelerar el desarrollo.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">Valor para el cliente</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">Las empresas ven el valor de una herramienta de evaluación de empleados y de reacción del cliente para la conversación de texto, audio y vídeo para el análisis de opiniones. Los gerentes se benefician de la información presentada en el panel, permitiendo una evaluación de los empleados y la satisfacción del cliente basada en ambos lados de la conversación.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">Además, el kit de herramientas DataOps de NetApp gestiona el versionado y la asignación de datos dentro de la infraestructura del cliente. Esto lleva a frecuentes actualizaciones de los análisis presentados en el panel de control sin crear costes rígidos de almacenamiento de datos.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">Siguiente: Casos de uso.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">Detalles de las pruebas para la sección 4.8</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">Esta sección contiene los detalles de las pruebas de la sección <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">Imagen</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">NetApp</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">Ejecución: IA</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">Usando toda su cuota</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">GPU fraccionaria</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">Dos sobre cuota</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">Uno sobre cuotas</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">Utilizando la mitad de su cuota</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">Estructura de comandos:</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">Secuencia de comandos real utilizada en la prueba:</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 (cuota suave/asignación real)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Mayor uso de clúster con la asignación de GPU over-uota</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">Consulte la sección <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> para discusiones sobre el escenario de pruebas en curso.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">Siguiente: Detalles de las pruebas para la sección 4.9</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">En esta sección y en las secciones <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, y. <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, Hemos diseñado escenarios de pruebas avanzados para demostrar las capacidades de orquestación Run:AI para la administración de cargas de trabajo complejas, la programación preventiva automática y el aprovisionamiento de GPU con exceso de cuota. Hemos hecho esto para lograr un uso elevado de los recursos de clúster y optimizar la productividad de los equipos científicos de datos a nivel empresarial en un entorno de IA de ONTAP.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">Para estas tres secciones, defina los siguientes proyectos y cuotas:</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">Cuota</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">Además, utilizamos los siguientes contenedores para estas tres secciones:</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Portátil Jupyter:<block ref="71f36d3504ef6b5a0ba9f34fe1143008" prefix=" " category="inline-code"></block></block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Ejecutar:AI Quickstart:<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block></block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">Definimos los siguientes objetivos para este escenario de prueba:</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">Muestre la simplicidad del aprovisionamiento de recursos y cómo los recursos se abstraen de los usuarios</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">Mostrar cómo los usuarios pueden aprovisionar fácilmente fracciones de una GPU y un número entero de GPU</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">Muestre cómo el sistema elimina los cuellos de botella de computación al permitir que equipos o usuarios hagan uso de su cuota de recursos si hay GPU libres en el clúster</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">Muestre cómo se eliminan los cuellos de botella en la canalización de datos utilizando la solución de NetApp cuando se ejecutan tareas con un gran procesamiento como el contenedor de NetApp</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">Muestra cómo se ejecutan los diversos tipos de contenedores mediante el sistema</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Portátil Jupyter</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">Ejecute:contenedor de IA</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">Muestra una alta utilización cuando el clúster está lleno</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">Para obtener información detallada sobre la secuencia de comandos real ejecutada durante la prueba, consulte <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">Cuando se envían las 13 cargas de trabajo, puede ver una lista con los nombres de los contenedores y las GPU asignadas, como se muestra en la siguiente figura. Contamos con siete cursos de formación y seis trabajos interactivos, que simulan cuatro equipos de ciencia de datos, cada uno con sus propios modelos en ejecución o en desarrollo. Para trabajos interactivos, los desarrolladores individuales están utilizando Jupyter Notebooks para escribir o depurar su código. Por lo tanto, es adecuado aprovisionar fracciones de GPU sin usar demasiados recursos de clúster.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">El clúster debe estar lleno: Se utilizan 16/16 GPU.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">Uso elevado de clúster.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">Más experimentos que las GPU debido a la asignación fraccionaria.</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text"><block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix="" category="inline-code"></block> no está utilizando toda su cuota; por lo tanto,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> y..<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Puede utilizar más GPU para sus experimentos, lo que acelera el plazo de innovación.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">Siguiente: Equidad en la asignación de recursos básicos</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">Es posible cambiar el nivel de servicio de un volumen existente si se mueve el volumen a otro pool de capacidad que utiliza el nivel de servicio que se desea para el volumen. Esta solución permite a los clientes comenzar con un conjunto de datos pequeño y un número reducido de GPU en el nivel estándar y escalar horizontalmente o verticalmente hasta el nivel Premium a medida que aumenta la cantidad de datos y las GPU.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Niveles de rendimiento de Azure NetApp Files</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">Anterior: Configuración de Dask con la implementación DE RAPIDS en AKS con Helm.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">Es posible cambiar el nivel de servicio de un volumen existente si se mueve el volumen a otro pool de capacidad que utiliza el nivel de servicio que se desea para el volumen. Esta solución permite a los clientes comenzar con un conjunto de datos pequeño y un número reducido de GPU en el nivel estándar y escalar horizontalmente o verticalmente hasta el nivel Premium a medida que aumenta la cantidad de datos y las GPU. El nivel Premium ofrece cuatro veces el rendimiento por terabyte como nivel estándar, así como la escalabilidad vertical se realiza sin tener que mover datos para cambiar el nivel de servicio de un volumen.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">Para cambiar de forma dinámica el nivel de servicio de un volumen, complete los pasos siguientes:</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">En la ventana Cambiar pool, seleccione el pool de capacidad al que desea mover el volumen.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Haga clic en Aceptar.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">Automatice el cambio en el nivel de rendimiento</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">Existen las siguientes opciones para automatizar los cambios en el nivel de rendimiento:</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">El cambio de nivel de servicio dinámico sigue en la vista previa pública en este momento y no está activado de forma predeterminada. Para habilitar esta función en la suscripción a Azure, consulte esta documentación sobre cómo<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">documentación de cambio de pool de volúmenes</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Se proporcionan comandos de cambio de pool de volúmenes de la interfaz de línea de comandos de Azure en<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> y en el ejemplo siguiente:</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Set-AzNetAppFilesVolumePool</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell: El<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Cambia el pool de un volumen Azure NetApp Files y se muestra en el ejemplo siguiente:</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">Siguiente: Bibliotecas para el procesamiento de datos y el entrenamiento de modelos.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">Anterior: Par AKS vnet y Azure NetApp Files vnet.</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Para instalar Trident con Helm, lleve a cabo los siguientes pasos:</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">origen</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Instale Helm (para obtener instrucciones de instalación, visite<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>).</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Descargue y extraiga el instalador de Trident 20.01.1.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">Copiar<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> a un directorio del sistema<block ref="b6aef5812b57b2270b8146870910b1d3" prefix=" " category="inline-code"></block>.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Instale Trident en el clúster Kubernetes (K8s) con Helm (<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>):</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">Cambie el directorio a<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Comprobar el estado de los pods de Trident.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">Si todos los pods están ya en funcionamiento, se instala Trident y se puede avanzar.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">Configurar el back-end de Azure NetApp Files y la clase de almacenamiento para AKS.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Cree un principio de Azure Service.</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">El principal del servicio es cómo Trident se comunica con Azure para manipular sus recursos de Azure NetApp Files.</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Cree un archivo del back-end json de Trident, nombre de ejemplo<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block>.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">Con el editor de texto preferido, complete los siguientes campos dentro del<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> archivo:</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">Sustituya los siguientes campos:</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text"><block ref="8c443e170595ba0feac007ffb92cb49a" prefix="" category="inline-code"></block>. Su ID de suscripción de Azure.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text"><block ref="bc54592d6183695b841c6d1880ec0bf8" prefix="" category="inline-code"></block>. Su ID de inquilino de Azure de la salida de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> en el paso anterior.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text"><block ref="93c5bebdea9c94a0740fe6fd9bb250f0" prefix="" category="inline-code"></block>. Su AppID desde la salida de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> en el paso anterior.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text"><block ref="2b53761249254ce6b502f521e5cc0683" prefix="" category="inline-code"></block>. Su contraseña de la salida de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> en el paso anterior.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">Indique a Trident que cree el back-end de Azure NetApp Files en la<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> espacio de nombres con<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> como archivo de configuración:</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">Cree una clase de almacenamiento. Los usuarios de Kubernetes aprovisionan volúmenes con RVP que especifican una clase de almacenamiento por nombre. Indique a K8S que cree una clase de almacenamiento<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Que hace referencia al back-end de Trident creado en el paso anterior.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">Cree una AYLMA <block ref="330e60441e96769dd29fd0a282d4f84a" prefix="(" category="inline-code"></block>) archivo para la clase de almacenamiento y copiar.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">Compruebe que la clase de almacenamiento se ha creado.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">Siguiente: Configurar Dask con la implementación DE RAPIDS en AKS con Helm.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow es capaz de suministrar rápidamente nuevos servidores Jupyter Notebook para actuar como espacios de trabajo de científicos de datos. Para suministrar un nuevo servidor Juppyter Notebook con Kubeflow, realice las tareas enumeradas en esta página.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Aprovisione un espacio de trabajo para portátiles Juppyter para uso científico de datos o desarrollador</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow es capaz de suministrar rápidamente nuevos servidores Jupyter Notebook para actuar como espacios de trabajo de científicos de datos. Para aprovisionar un nuevo servidor Juppyter Notebook con Kubeflow, realice las siguientes tareas. Para obtener más información acerca de Jupyter Notebooks dentro del contexto de Kubeflow, consulte<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Desde el panel central de Kubeflow, haga clic en Notebook Servers en el menú principal para acceder a la página de administración del servidor Jupyter Notebook.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">Haga clic en Nuevo servidor para aprovisionar un nuevo servidor Juppyter Notebook.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">Asigne un nombre a su nuevo servidor, elija la imagen de Docker en la que desea que se base su servidor y especifique la cantidad de CPU y RAM que debe reservar su servidor. Si el campo espacio de nombres está en blanco, utilice el menú Seleccionar espacio de nombres en el encabezado de la página para elegir un espacio de nombres. El campo de espacio de nombres se rellena automáticamente con el espacio de nombres elegido.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">En el siguiente ejemplo, la<block ref="aec502449511a35e8b040af72693bf5c" prefix=" " category="inline-code"></block> se elige espacio de nombres. Además, se aceptan los valores predeterminados de imagen Docker, CPU y RAM.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">Especifique los detalles del volumen del área de trabajo. Si decide crear un nuevo volumen, ese volumen o RVP se aprovisionan con el tipo de almacenamiento predeterminado. Dado que se designó un clase de almacenamiento con Trident como el clase de almacenamiento predeterminado de la sección <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, El volumen o PVC se aprovisiona con Trident. Este volumen se monta automáticamente como espacio de trabajo predeterminado dentro del contenedor servidor del portátil Jupyter. Los portátiles que cree un usuario en el servidor que no se guarden en un volumen de datos independiente se guardarán automáticamente en este volumen de área de trabajo. Por lo tanto, los portátiles se conservan entre reinicios.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">Añadir volúmenes de datos. En el siguiente ejemplo, se especifica un RVP existente llamado 'pb-fg-All' y acepta el punto de montaje predeterminado.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">*Opcional:* Solicite que se asigne el número deseado de GPU al servidor de su portátil. En el siguiente ejemplo, se solicita una GPU.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">Haga clic en Iniciar para aprovisionar su nuevo servidor de notebook.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">Espere a que el servidor de su portátil esté completamente aprovisionado. Esto puede tardar varios minutos si nunca ha aprovisionado un servidor con la imagen Docker que ha especificado porque es necesario descargar la imagen. Una vez que el servidor ha sido completamente aprovisionado, verá una Marca de verificación verde en la columna Estado de la página de administración del servidor Jupyter Notebook.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">Haga clic en conectar para conectarse a la nueva interfaz web del servidor.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">Confirme que el volumen del conjunto de datos especificado en el paso 6 está montado en el servidor. Tenga en cuenta que este volumen se monta en el espacio de trabajo predeterminado de forma predeterminada. Desde la perspectiva del usuario, ésta es sólo otra carpeta dentro del área de trabajo. El usuario, que es probable que un científico de datos y no sea un experto en infraestructura, no necesita tener experiencia en almacenamiento para utilizar este volumen.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">Abra un terminal y, suponiendo que se haya solicitado un nuevo volumen en el paso 5, ejecute<block ref="109faa0d3af468439c8966d496020840" prefix=" " category="inline-code"></block> Para confirmar que un nuevo volumen persistente aprovisionado por Trident se monta como espacio de trabajo predeterminado.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">El directorio de área de trabajo predeterminado es el directorio base con el que se presenta cuando se accede por primera vez a la interfaz web del servidor. Por lo tanto, cualquier artefacto que cree mediante la interfaz web se almacena en este volumen persistente aprovisionado por Trident.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">Con el terminal, ejecute<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Para confirmar que se ha asignado el número correcto de GPU al servidor del portátil. En el siguiente ejemplo, se ha asignado una GPU al servidor de portátiles como se solicitó en el paso 7.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">Siguiente: Ejemplos de cuadernos y tuberías.</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841: Sistema operativo de IA para el cloud híbrido con almacenamiento en caché de datos</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">El crecimiento exponencial de los datos y el crecimiento exponencial DE LOS ML y la IA se han convergido para crear una economía de zettabytes con retos exclusivos de desarrollo e implementación.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">A pesar de que los modelos DE ML consumen gran cantidad de datos y requieren un almacenamiento de datos de alto rendimiento cerca de los recursos informáticos, en la práctica no es tan sencillo implementar este modelo, especialmente con instancias de cloud híbrido y computación elástica. Normalmente, se almacenan cantidades masivas de datos en lagos de datos de bajo coste, en los que los recursos informáticos de IA de alto rendimiento, como las GPU, no pueden acceder a ellos de forma eficiente. Este problema se agrava en una infraestructura de cloud híbrido, en la que algunas cargas de trabajo funcionan en el cloud y otras están ubicadas en las instalaciones o en un entorno diferente de informática de alto rendimiento.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">En este documento, presentamos una nueva solución que permite a los profesionales DE TECNOLOGÍA y a los ingenieros de datos crear una verdadera plataforma de IA de cloud híbrido con un concentrador de datos con topología que permite a los científicos de datos crear de forma instantánea y automática una caché de sus conjuntos de datos cerca de sus recursos informáticos, dondequiera que se encuentren. Como resultado, no solo se puede realizar el entrenamiento con modelos de alto rendimiento, sino que se obtienen ventajas adicionales, como la colaboración de varios profesionales de la IA, que tienen acceso inmediato a las cachés de los conjuntos de datos, las versiones y los linajes dentro de un concentrador de versiones del conjunto de datos.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">Siguiente: Descripción general de casos de uso y declaración del problema</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">En esta sección se ofrece información general sobre los tres escenarios validados en esta solución.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Plan de pruebas y validación</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Para este diseño de solución, se validaron los tres siguientes supuestos:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Una tarea de inferencia, con y sin Protopía ofuscación, dentro de un espacio de trabajo JupyterLab que fue orquestada mediante el kit de herramientas DataOPS de NetApp para Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Una tarea de inferencia por lotes, con y sin ofuscación de Protopía, en Kubernetes con un volumen de datos orquestado mediante el kit de herramientas DataOps de NetApp para Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Una tarea de inferencia mediante una instancia del servidor de inferencia de NVIDIA Triton orquestada mediante el kit de herramientas NetApp DataOPS para Kubernetes. Aplicamos la confusión Protopia a la imagen antes de llamar a la API de inferencia Triton para simular el requisito común de que cualquier dato que se transmita a través de la red debe ser ocultado. Este flujo de trabajo es aplicable para casos en los que los datos se recopilan en una zona de confianza, pero debe pasarse fuera de esa zona de confianza para la inferencia. Sin la ocultación de Protopia, no es posible implementar este tipo de flujo de trabajo sin que los datos confidenciales salgan de la zona de confianza.</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">Esta página incluye información sobre cómo NetApp puede avanzar en los proyectos de IA, como información sobre contenedores, Kubernetes, NetApp Trident, etc.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Inteligencia artificial</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">La IA es una disciplina informática en la que las computadoras están entrenadas para imitar las funciones cognitivas de la mente humana. Los desarrolladores de IA entrenan computadoras para aprender y resolver problemas de una manera similar, o incluso superior a, humanos. El aprendizaje profundo y el aprendizaje automático son subcampos de la IA. Las organizaciones adoptan cada vez más IA, ML y DL para dar soporte a sus necesidades empresariales cruciales. Algunos ejemplos son los siguientes:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analizar grandes cantidades de datos para desconocer información empresarial anteriormente desconocida</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interacción directa con los clientes mediante el procesamiento de lenguaje natural</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatización de diversos procesos y funciones empresariales</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">La formación de IA moderna y las cargas de trabajo de inferencia requieren de funcionalidades de computación en paralelo masivas. Por lo tanto, se están utilizando cada vez más GPU para ejecutar operaciones de IA, ya que las capacidades de procesamiento paralelo de las GPU son muy superiores a las de las CPU de uso general.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Los contenedores son instancias aisladas del espacio de usuario que se ejecutan sobre un kernel de sistema operativo host compartido. La adopción de contenedores aumenta rápidamente. Los contenedores ofrecen muchos de los mismos beneficios de uso de pruebas de espacio que las máquinas virtuales (VM). Sin embargo, debido a que se eliminan las capas de hipervisor y de sistema operativo «guest» de las que dependen las máquinas virtuales, los contenedores son mucho más ligeros. En la siguiente figura, se muestra una visualización de las máquinas virtuales en comparación con los contenedores.</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">Los contenedores también permiten el paquete eficiente de dependencias de aplicaciones, tiempos de ejecución, etc., directamente con una aplicación. El formato de embalaje de contenedor más utilizado es el contenedor Docker. Una aplicación que se haya contenedor en el formato de contenedor Docker se puede ejecutar en cualquier máquina que pueda ejecutar contenedores Docker. Esto es cierto incluso si las dependencias de la aplicación no están presentes en la máquina porque todas las dependencias están empaquetadas en el propio contenedor. Para obtener más información, visite la<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes es una plataforma de orquestación de contenedores distribuida de código abierto que originalmente diseñada por Google y que ahora se mantiene mediante Cloud Native Computing Foundation (CNCF). Kubernetes permite automatizar las funciones de puesta en marcha, gestión y escalado para aplicaciones en contenedores. En los últimos años, Kubernetes se ha convertido en la plataforma de orquestación de contenedores dominante. Aunque son compatibles con otros formatos de empaquetado y tiempos de ejecución, Kubernetes se utiliza con más frecuencia como un sistema de orquestación para contenedores Docker. Para obtener más información, visite la<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident es un orquestador de almacenamiento de código abierto desarrollado y mantenido por NetApp que simplifica en gran medida la creación, la gestión y el consumo de almacenamiento persistente para cargas de trabajo de Kubernetes. Trident, en sí misma una aplicación nativa de Kubernetes, se ejecuta directamente en un clúster de Kubernetes. Con Trident, los usuarios de Kubernetes (desarrolladores, científicos de datos, administradores de Kubernetes, etc.) pueden crear, gestionar e interactuar con volúmenes de almacenamiento persistente en el formato Kubernetes estándar, con el que ya están familiarizados. Al mismo tiempo, pueden aprovechar las funciones avanzadas de gestión de datos de NetApp y un Data Fabric con tecnología de NetApp. Trident elimina las complejidades del almacenamiento persistente y facilita el consumo. Para obtener más información, visite la<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Sitio web de Kubeflow</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow es un kit de herramientas DE IA Y ML de código abierto para Kubernetes que fue desarrollado originalmente por Google. El proyecto Kubeflow hace que la puesta en marcha de flujos de trabajo de IA y ML en Kubernetes sea sencilla, portátil y escalable. ―Kubeflow elimina las complejidades de Kubernetes, lo que permite a los científicos de datos centrarse en lo que saben más ciencia de datos. Consulte la siguiente figura para ver una visualización. Kubeflow ha ido ganando terreno a medida que los departamentos DE TI de las empresas se han estandarizado cada vez más en Kubernetes. Para obtener más información, visite la<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Tuberías de Kubeflow</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Los oleoductos de Kubeflow son un componente clave de Kubeflow. Las canalizaciones de Kubeflow son una plataforma y un estándar para definir y poner en marcha flujos de trabajo DE IA Y ML escalables y portátiles. Para obtener más información, consulte<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Sitio Web de Juppyter</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Un servidor Juppyter Notebook es una aplicación web de código abierto que permite a los científicos de datos crear documentos similares a wiki llamados portátiles Juppyter que contienen código en vivo así como pruebas descriptivas. Los portátiles Juppyter se utilizan ampliamente en la comunidad de AI Y ML como medio para documentar, almacenar y compartir proyectos de IA y ML. Kubeflow simplifica el aprovisionamiento y la puesta en marcha de servidores para portátiles Juppyter en Kubernetes. Para obtener más información sobre los Cuadernos Jupyter, visite<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Para obtener más información acerca de Jupyter Notebooks en el contexto de Kubeflow, consulte<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>.</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow es una plataforma de gestión de flujos de trabajo de código abierto que permite la creación, programación y supervisión de programas para flujos de trabajo empresariales complejos. A menudo se utiliza para automatizar los flujos de trabajo de ETL y de canalización de datos, pero estos tipos de flujos de trabajo no se limitan a ellos. El proyecto de flujo de aire fue iniciado por Airbnb, pero desde entonces se ha vuelto muy popular en la industria y ahora está bajo los auspicios de la Apache Software Foundation. El flujo de aire se escribe en Python, los flujos de trabajo del flujo de aire se crean a través de scripts Python y el flujo de aire está diseñado según el principio de "configuración como código". Muchos usuarios de flujo de aire empresarial ahora ejecutan el flujo de aire sobre Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Gráficos de Acíclicos dirigidos (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">En el flujo de aire, los flujos de trabajo se denominan gráficos Acíclicos dirigidos (DAG). Los DAG se componen de tareas que se ejecutan en secuencia, en paralelo o en una combinación de las dos, dependiendo de la definición DAG. El programador de flujo de aire ejecuta tareas individuales en una matriz de trabajadores y cumple con las dependencias a nivel de tarea especificadas en la definición DAG. Los DAG se definen y crean a través de scripts Python.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">ONTAP 9 de NetApp es la última generación del software de gestión del almacenamiento de NetApp y permite a empresas como la suya modernizar su infraestructura y realizar la transición a un centro de datos preparado para el cloud. Gracias a las capacidades de gestión de datos líderes del sector, ONTAP le permite gestionar y proteger sus datos con un solo conjunto de herramientas sin importar dónde residan. También puede mover los datos libremente a donde necesite: El extremo, el núcleo o el cloud. ONTAP 9 incluye numerosas funciones que simplifican la gestión de datos, aceleran y protegen sus datos esenciales y preparan su infraestructura para el futuro con arquitecturas de cloud híbrido.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">Simplifique la gestión de los datos</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">La gestión de datos es vital para las operaciones TECNOLÓGICAS de su empresa, de modo que pueda usar los recursos adecuados para sus aplicaciones y conjuntos de datos. ONTAP incluye las siguientes funciones para facilitar y simplificar las operaciones, y reducir el coste total de funcionamiento:</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">*Compactación de datos inline y deduplicación expandida.* la compactación de datos reduce el espacio perdido dentro de los bloques de almacenamiento, y la deduplicación aumenta significativamente la capacidad efectiva.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">*ONTAP FabricPool.* esta función ofrece una organización automática en niveles de datos inactivos para opciones de almacenamiento en cloud público y privado, incluidos Amazon Web Services (AWS), Azure y almacenamiento basado en objetos StorageGRID de NetApp.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">Acelere y proteja sus datos</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP no solo ofrece niveles de rendimiento y protección de datos superiores, sino que amplía estas funcionalidades con las siguientes funciones:</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">*Alto rendimiento y baja latencia.* ONTAP ofrece el rendimiento más alto posible con la menor latencia posible.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">*La tecnología ONTAP FlexGroup de NetApp.* Un volumen FlexGroup es un contenedor de datos de alto rendimiento que se puede escalar linealmente hasta 20 PB y 400 000 millones de archivos, lo que proporciona un espacio de nombres único que simplifica la gestión de datos.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">Infraestructura preparada para futuros retos</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 le ayuda a satisfacer las exigentes y siempre cambiantes necesidades de su empresa:</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">*Escalado sencillo y operaciones no disruptivas.* ONTAP admite la adición sin interrupciones de capacidad a las controladoras existentes y a los clústeres de escalado horizontal. Puede empezar a utilizar tecnologías punteras como NVMe y FC 32 GB, sin necesidad de realizar costosas migraciones de datos y sin cortes.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">*Conexión al cloud.* ONTAP es uno de los programas de gestión del almacenamiento con mejor conexión al cloud e incluye opciones de almacenamiento definido por software (ONTAP Select) e instancias nativas del cloud (Cloud Volumes Service de NetApp) en todos los clouds públicos.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">*Integración con aplicaciones emergentes.* al utilizar la misma infraestructura que soporta las aplicaciones empresariales existentes, ONTAP ofrece servicios de datos de clase empresarial para plataformas y aplicaciones de próxima generación como OpenStack, Hadoop y MongoDB.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copias Snapshot de NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Una copia Snapshot de NetApp es una imagen puntual de solo lectura de un volumen. La imagen consume un espacio de almacenamiento mínimo y tiene una sobrecarga del rendimiento mínima, ya que solo registra los cambios que se han realizado en los archivos creados desde que se realizó la última copia Snapshot, como se muestra en la siguiente figura.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Las copias Snapshot deben su eficiencia a la tecnología de virtualización del almacenamiento central de ONTAP, el sistema de archivos de escritura en cualquier lugar (WAFL). Al igual que una base de datos, WAFL utiliza metadatos para apuntar a los bloques de datos reales en el disco. Sin embargo, a diferencia de una base de datos, WAFL no sobrescribe los bloques existentes. Escribe los datos actualizados en un bloque nuevo y cambia los metadatos. Porque ONTAP hace referencia a los metadatos cuando crea una copia Snapshot, en lugar de copiar bloques de datos, es tan eficiente que las copias Snapshot. Al hacerlo, se elimina el tiempo de búsqueda que otros sistemas incurren en la localización de los bloques a copiar, así como el costo de hacer la copia misma.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Puede utilizar una copia Snapshot para recuperar archivos o LUN individuales o para restaurar el contenido completo de un volumen. ONTAP compara la información de punteros de la copia Snapshot con los datos del disco para reconstruir el objeto faltante o dañado, sin tiempo de inactividad ni un coste de rendimiento significativo.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Tecnología FlexClone de NetApp</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La tecnología FlexClone de NetApp hace referencia a los metadatos de Snapshot para crear copias puntuales editables de un volumen. Las copias comparten bloques de datos con sus padres, sin consumir almacenamiento excepto lo que se necesita para los metadatos hasta que se escriben los cambios en la copia, como se muestra en la siguiente figura. Cuando se pueden crear copias tradicionales en minutos o incluso horas, el software FlexClone le permite copiar incluso los conjuntos de datos más grandes de forma casi instantánea. Esto lo convierte en la opción ideal para las situaciones en las que necesita varias copias de conjuntos de datos idénticos (un espacio de trabajo de desarrollo, por ejemplo) o copias temporales de un conjunto de datos (probar una aplicación contra un conjunto de datos de producción).</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Tecnología de replicación de datos de SnapMirror de NetApp</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">El software SnapMirror de NetApp es una solución de replicación unificada rentable y fácil de usar para todo Data Fabric. Replica datos a altas velocidades mediante LAN o WAN. Le proporciona una alta disponibilidad de datos y una rápida replicación de datos para todo tipo de aplicaciones, incluidas aplicaciones vitales para el negocio en entornos tanto virtuales como tradicionales. Al replicar datos en uno o varios sistemas de almacenamiento de NetApp y actualizar continuamente los datos secundarios, estos están siempre al día y disponibles cuando los necesite. No se requieren servidores de replicación externos. Consulte la figura siguiente para ver un ejemplo de una arquitectura que aprovecha la tecnología SnapMirror.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">El software SnapMirror aprovecha las eficiencias del almacenamiento de ONTAP de NetApp y envía únicamente los bloques cambiados a través de la red. El software SnapMirror también usa la compresión de red incorporada para acelerar las transferencias de datos y reducir la utilización de ancho de banda hasta un 70 %. Con la tecnología SnapMirror, puede aprovechar un flujo de datos de thin replication para crear un único almacén que mantenga los reflejos activos y las copias de momentos específicos anteriores, lo que reduce el tráfico de red hasta un 50 %.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync es un servicio de NetApp que ofrece una sincronización de datos rápida y segura. Ya tenga que transferir archivos entre unidades de archivos NFS o SMB en las instalaciones, StorageGRID de NetApp, ONTAP S3 de NetApp, Cloud Volumes Service de NetApp, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, Cloud Sync mueve los archivos donde los necesite de forma rápida y segura.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">Una vez transferidos los datos, estarán completamente disponibles para su uso tanto en origen como en destino. Cloud Sync puede sincronizar datos bajo demanda cuando se activa una actualización o sincronizar datos de forma continua en función de una programación predefinida. Sin embargo, Cloud Sync solo mueve los deltas, por lo que se minimiza el tiempo y el dinero invertidos en la replicación de datos.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync es una herramienta de software como servicio (SaaS) extremadamente fácil de configurar y utilizar. Las transferencias de datos que Cloud Sync activa son llevadas a cabo por agentes de datos. Los agentes de datos de Cloud Sync pueden ponerse en marcha en AWS, Azure, Google Cloud Platform o en las instalaciones.</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">XCP de NetApp es el software basado en cliente para migraciones de datos y análisis del sistema de archivos entre NetApp y NetApp. XCP se ha diseñado para escalar y lograr el máximo rendimiento utilizando todos los recursos del sistema disponibles para gestionar conjuntos de datos de gran volumen y migraciones de alto rendimiento. XCP le ayuda a obtener una visibilidad completa del sistema de archivos con la opción de generar informes.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">XCP de NetApp está disponible en un único paquete compatible con los protocolos NFS y SMB. XCP incluye un binario de Linux para conjuntos de datos NFS y un ejecutable de Windows para conjuntos de datos SMB.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">XCP File Analytics de NetApp es un software basado en host que detecta recursos compartidos de archivos, ejecuta análisis en el sistema de archivos y proporciona una consola para el análisis de archivos. XCP File Analytics es compatible con los sistemas NetApp y de otros proveedores, y se ejecuta en hosts Linux o Windows para proporcionar análisis en sistemas de archivos NFS y exportados SMB.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">ONTAP FlexGroup Volumes de NetApp</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un conjunto de datos de entrenamiento puede ser una colección con hasta miles de millones de archivos. Pueden ser archivos de texto, de audio, de vídeo o cualquier otra forma de datos no estructurados que deban almacenarse y procesarse para su lectura en paralelo. El sistema de almacenamiento debe almacenar un gran número de archivos pequeños y debe leerlos en paralelo, con una entrada y salida secuencial o aleatoria</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volumen FlexGroup es un espacio de nombres único que comprende varios volúmenes miembro constituyentes, tal y como se muestra en la siguiente figura. Desde el punto de vista de un administrador de almacenamiento, un volumen FlexGroup se gestiona y actúa como un volumen FlexVol de NetApp. Los archivos de un volumen de FlexGroup se asignan a volúmenes miembro individuales y no están repartidos en volúmenes o nodos. Ofrecen las siguientes capacidades:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">Los volúmenes FlexGroup proporcionan varios petabytes de capacidad y una baja latencia predecible para cargas de trabajo con una gran cantidad de metadatos.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Permiten un máximo de 400 000 millones de archivos en un mismo espacio de nombres.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Admiten operaciones en paralelo para cargas de trabajo NAS entre varias CPU, nodos, agregados y volúmenes FlexVol constituyentes.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">Siguiente: Requisitos de hardware y software.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Antes de poder usar Trident para aprovisionar recursos de almacenamiento de forma dinámica dentro de su clúster de Kubernetes, debe crear uno o varios Back-ends de Trident. Los ejemplos de esta página representan diferentes tipos de backends que puede crear si va a implementar la solución de plano de control de IA de NetApp en un pod ONTAP AI.</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Antes de poder usar Trident para aprovisionar recursos de almacenamiento de forma dinámica dentro de su clúster de Kubernetes, debe crear uno o varios Back-ends de Trident. Los siguientes ejemplos representan diferentes tipos de backends que puede crear si va a implementar la solución de plano de control de IA de NetApp en un pod ONTAP AI. Para obtener más información acerca de backends, consulte<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp recomienda crear un Back-end de Trident habilitado para FlexGroup para cada LIF de datos (interfaz de red lógica que proporciona acceso a los datos) que desee utilizar en su sistema AFF de NetApp. Esto le permitirá equilibrar los montajes de volumen entre LIF</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">Los siguientes comandos de ejemplo muestran la creación de dos Back-ends de Trident habilitados para FlexGroup para dos LIF de datos diferentes asociadas con la misma máquina virtual de almacenamiento (SVM) de ONTAP. Estas backends utilizan la<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> controlador de almacenamiento. ONTAP admite dos tipos de volúmenes de datos principales: FlexVol y FlexGroup. Los volúmenes FlexVol tienen un tamaño limitado (a partir de la escritura, el tamaño máximo depende de la implementación específica). Por otro lado, los volúmenes FlexGroup se pueden escalar de forma lineal hasta 20 PB y 400 000 millones de archivos y, además, ofrecen un espacio de nombres único que simplifica enormemente la gestión de los datos. Por lo tanto, los volúmenes FlexGroup son óptimos para cargas de trabajo de IA y ML que dependen de grandes cantidades de datos.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Si está trabajando con una pequeña cantidad de datos y desea usar volúmenes de FlexVol en lugar de volúmenes de FlexGroup, puede crear Back-ends de Trident que utilizan<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> controlador de almacenamiento en lugar de<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> controlador de almacenamiento.</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">NetApp también recomienda crear uno o varios Back-ends de Trident habilitados para FlexVol. Si se utilizan FlexGroup Volumes para el entrenamiento del almacenamiento de conjuntos de datos, es posible que se desee usar volúmenes de FlexVol para almacenar resultados, resultados, información de depuración, etc. Si se desean usar volúmenes de FlexVol, se deben crear uno o varios Back-ends de Trident habilitados para FlexVol. Los siguientes comandos de ejemplo muestran la creación de una única estructura de fondo Trident habilitada para FlexVol que utiliza una sola LIF de datos.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">Siguiente: Ejemplo de una historia de Kubernetes para las puestas en marcha de IA de ONTAP.</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834: NetApp e Iguazio para el suministro de MLRun</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">Este documento contiene los detalles de la canalización MLRun usando NetApp ONTAP AI, el plano de control de IA de NetApp, el software Cloud Volumes de NetApp y la plataforma de ciencia de datos de Iguazio. Utilizamos la función Nuclio serverless, volúmenes persistentes de Kubernetes, volúmenes Cloud de NetApp, copias Snapshot de NetApp, consola Grafana, Y otros servicios en la plataforma Iguazio para crear una canalización de datos de extremo a extremo para la simulación de la detección de fallos de red. Hemos integrado las tecnologías de Iguazio y NetApp para permitir una rápida puesta en marcha de modelos, replicación de datos y supervisión de la producción tanto en las instalaciones como en el cloud.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">El trabajo de un científico de datos debe centrarse en el entrenamiento y el ajuste de los modelos de aprendizaje automático y de inteligencia artificial (IA). Sin embargo, según una investigación realizada por Google, los científicos de datos gastan aproximadamente un 80 % de su tiempo en averiguar cómo hacer que sus modelos funcionen con aplicaciones empresariales y se ejecutan a escala, como se muestra en la siguiente imagen, en la que se ilustra el desarrollo de modelos en el flujo de trabajo de IA/ML.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">Para gestionar proyectos de IA y ML integrales, se necesita una comprensión más amplia de los componentes empresariales. Aunque DevOps ha retomado la definición, la integración y la puesta en marcha de estos tipos de componentes, las operaciones de aprendizaje automático siguen un flujo similar que incluye proyectos de IA/ML. Para hacerse una idea de lo que puede tocar una canalización de IA/ML integral en la empresa, consulte la siguiente lista de componentes requeridos:</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">Entorno de desarrollo integrado (IDE)</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">En este artículo mostramos cómo la asociación entre NetApp y Iguazio simplifica drásticamente el desarrollo de una canalización completa de IA/ML. Esta simplificación acelera el plazo de comercialización de todas sus aplicaciones de IA/ML.</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">El mundo de la ciencia de datos tiene múltiples disciplinas de tecnología de la información y negocio.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">Los usuarios empresariales quieren tener acceso a aplicaciones de IA/ML. Describimos cómo NetApp y Iguazio ayudan a cada una de estas funciones a aportar valor empresarial con nuestras plataformas.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">Esta solución sigue el ciclo de vida de una aplicación de IA/ML. Empezamos con la labor de los científicos de datos para definir los diferentes pasos necesarios para preparar datos y entrenar y poner en marcha modelos. Seguimos con el trabajo necesario para crear una canalización completa con la capacidad de realizar un seguimiento de los artefactos, experimentar con la ejecución y desplegar en Kubeflow. Para completar el ciclo completo, integramos la canalización con NetApp Cloud Volumes para permitir el versionado de datos, tal y como se puede ver en la siguiente imagen.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">Siguiente: Visión general de la tecnología</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">Se obtiene un uso elevado del clúster</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">En esta sección, emulamos un escenario realista en el que cuatro equipos de ciencia de datos envían sus propias cargas de trabajo para demostrar la solución de orquestación Run:AI que logra un uso elevado del clúster mientras mantiene la priorización y el equilibrio de los recursos de la GPU. Empezamos utilizando la prueba de rendimiento ResNet-50 descrita en el apartado <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">Ejecutamos la misma prueba de rendimiento ResNet-50 como en la<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. Usamos la bandera<block ref="f4fdcbb99cb8e39e4706115c80cb3968" prefix=" " category="inline-code"></block> para contenedores que no residen en el repositorio de docker público. Montamos los directorios<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> y..<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> En el nodo DGX-1 del host a.<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> y..<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> al contenedor, respectivamente. El conjunto de datos se encuentra en NetApp AFFA800 con el<block ref="a64503025c7495ecf42633d117f8b536" prefix=" " category="inline-code"></block> argumento que apunta al directorio. Ambas<block ref="96dbae4bbcb6841c17bc66f858d93982" prefix=" " category="inline-code"></block> y..<block ref="a78db0f035a543e24e7b038d359b5e74" prefix=" " category="inline-code"></block> Significa que asignamos una GPU para este trabajo. El primero es un argumento para el<block ref="6e38f16215ae91c11fc5c54b74c66d54" prefix=" " category="inline-code"></block> script, mientras que el último es un indicador para el<block ref="7897d57a96444dff260ef2bf8a0589b1" prefix=" " category="inline-code"></block> comando.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">La siguiente figura muestra un panel de información general del sistema con un uso del 97 % de la GPU y las dieciséis GPU disponibles asignadas. Puede ver fácilmente cuántas GPU se asignan a cada equipo en el gráfico de barras GPU/proyecto. El panel trabajos en ejecución muestra los nombres de los trabajos en ejecución actuales, el proyecto, el usuario, el tipo, el nodo, Las GPU consumidas, tiempo de ejecución, progreso y detalles de uso. Se muestra una lista de las cargas de trabajo que están en cola con el tiempo de espera en trabajos pendientes. Finalmente, el recuadro Nodes ofrece cifras de GPU y utilización de nodos DGX-1 individuales en el clúster.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">Siguiente: Asignación de GPU fraccionaria para cargas de trabajo menos exigentes o interactivas</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="716c8038f7ef1bc60bc3fe6c036e2d3b" category="doc">TR-4807: Arquitectura de referencia de IA de ONTAP de NetApp para cargas de trabajo de servicios financieros - Diseño de la solución</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam, Sung-han Lin, NetApp Jacci Cenci, NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">Esta arquitectura de referencia ofrece directrices a los clientes que crean una infraestructura de inteligencia artificial con los sistemas NVIDIA DGX-1 y el almacenamiento AFF de NetApp para casos de uso con sectores financieros. Por ejemplo, incluye información sobre los flujos de trabajo de alto nivel utilizados en el desarrollo de modelos de aprendizaje profundo para los casos de pruebas y los resultados de servicios financieros. También incluye recomendaciones para el dimensionamiento de las puestas en marcha de los clientes.</block>
  <block id="96ac76dbb46fec3f4db7ec194dc52d2a" category="paragraph"><block ref="96ac76dbb46fec3f4db7ec194dc52d2a" category="inline-link-macro-rx"></block></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">Casos de uso</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">Aunque todas las aplicaciones actuales no están impulsadas por la IA, están evolucionando capacidades que les permiten acceder a los inmensos beneficios de la IA. Para respaldar la adopción de la IA, las aplicaciones necesitan una infraestructura que les proporcione los recursos necesarios para funcionar a un nivel óptimo y para respaldar su continua evolución.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">Para las aplicaciones condicionadas por la IA, las ubicaciones perimetrales funcionan como una fuente de datos importante. Los datos disponibles se pueden usar para el entrenamiento cuando se recogen de varias ubicaciones perimetrales a lo largo de un periodo de tiempo para formar un conjunto de datos de entrenamiento. A continuación, el modelo entrenado se puede volver a poner en marcha en las ubicaciones perimetrales en las que se recogieron los datos, lo que permite una inferencia más rápida sin la necesidad de transferir repetidamente datos de producción a una plataforma de inferencia dedicada.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">La solución de inferencia de IA de NetApp HCI, impulsada por los nodos de computación H615c de NetApp con GPU NVIDIA T4 y los sistemas de almacenamiento conectados al cloud de NetApp, ha sido desarrollada y verificada por NetApp y NVIDIA. NetApp HCI simplifica la puesta en marcha de soluciones de inferencia de IA en centros de datos periféricos abordando las áreas de ambigüedad, eliminando complejidades en el diseño y acabar con las conjeturas. Esta solución proporciona a las organizaciones DE TI una arquitectura prescriptiva que:</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">Permite la inferencia de IA en centros de datos periféricos</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">Optimiza el consumo de recursos de GPU</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Proporciona una plataforma de inferencia basada en Kubernetes para conseguir flexibilidad y escalabilidad</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">Los centros de datos del perímetro gestionan y procesan los datos en ubicaciones que están muy cerca del punto de generación. Esta proximidad aumenta la eficiencia y reduce la latencia involucrada en la gestión de datos. Muchos mercados verticales se han dado cuenta de las ventajas de un centro de datos perimetral y están adoptando en gran medida este enfoque distribuido del procesamiento de datos.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">En la siguiente tabla se enumeran las aplicaciones y verticales de bordes.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">Vertical</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">Más grandes</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">Médica</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">El diagnóstico asistido por ordenador ayuda al personal médico en la detección temprana de enfermedades</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">Petróleo y gas</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">Inspección autónoma de instalaciones de producción remotas, vídeo y análisis de imágenes</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">Aviación</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">Asistencia para el control del tráfico aéreo y análisis de alimentación de vídeo en tiempo real</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">Medios y entretenimiento</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">Filtrado de contenidos de audio y vídeo para ofrecer contenido familiar</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">Análisis empresarial</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">Reconocimiento de Marca para analizar la apariencia de la Marca en eventos televisados en directo</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">Comercio electrónico</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">La agrupación inteligente de ofertas de proveedores para encontrar combinaciones ideales de comercios y almacenes</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">Comercio minorista</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">Pago automático para reconocer los artículos que un cliente ha colocado en el carrito y facilitar el pago digital</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">Ciudad inteligente</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">Mejore el flujo de tráfico, optimice el estacionamiento y mejore la seguridad de peatones y ciclistas</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">Fabricación</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">Control de calidad, control de línea de montaje e identificación de defectos</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">Atención al cliente</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">Automatización del servicio al cliente para analizar y clasificar consultas (teléfono, correo electrónico y redes sociales)</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">Agricultura</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">Funcionamiento de granja inteligente y planificación de actividades, para optimizar la aplicación de fertilizantes y herbicidas</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">Científicos de datos</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">Arquitectos de TECNOLOGÍA</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">Consultores de campo</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">Servicios profesionales</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">Responsables de TECNOLOGÍA</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">Cualquiera que necesite una infraestructura que ofrezca innovación TECNOLÓGICA y servicios de aplicaciones y datos sólidos en las ubicaciones perimetrales</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">Siguiente: Arquitectura</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">En esta sección se enumeran los Cuadernos Jupyter y otros recursos útiles para esta solución.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">Vídeos y demostraciones</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Anterior: Resultados de validación.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">“Support-Center-sentimiento-Analysis-Pipeline.ipynb”</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">“Support-Center-Model-Transfer-Learning-and-Fine-Tuning.ipynb”</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">Existen dos portátiles que contienen la canalización de análisis de confianza:<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> y.. <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. Juntos, estos portátiles muestran cómo desarrollar una canalización para la incorporación de datos de centro de soporte y extraer sentimientos de cada frase mediante modelos de aprendizaje profundo de última generación ajustados a los datos del usuario.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">Centro de apoyo - Análisis de confianza Pipeline.ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">Este cuaderno contiene la canalización RIVA de inferencia para la incorporación de audio, la conversión a texto y la extracción de sentimientos para su uso en un panel externo. El conjunto de datos se descarga y procesa automáticamente si aún no se ha hecho. La primera sección del bloc de notas es la voz a texto que controla la conversión de archivos de audio a texto. A continuación se muestra la sección Análisis de sentimientos que extrae sentimientos para cada frase de texto y muestra dichos resultados en un formato similar al panel propuesto.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">Este portátil debe ejecutarse antes del entrenamiento del modelo y del ajuste preciso porque el conjunto de datos MP3 debe descargarse y convertirse al formato correcto.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Centro de soporte - formación de modelos y afinación.ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">El entorno virtual del kit de herramientas de TAO debe configurarse antes de ejecutar el cuaderno (consulte la sección del kit de herramientas de TAO en la descripción general de comandos para obtener instrucciones de instalación).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">Este cuaderno confía en el kit de herramientas TAO para ajustar los modelos de aprendizaje profundo en los datos de los clientes. Al igual que en el cuaderno anterior, este se separa en dos secciones para los componentes de análisis de opinión y voz. Cada sección abarca el procesamiento de datos, la formación de modelos y el ajuste preciso, la evaluación de los resultados y la exportación de modelos. Por último, existe una sección final para implementar tanto sus modelos ajustados para su uso en RIVA.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Arquitectura</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">Anterior: Visión general de la tecnología.</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Esta solución se basa en una arquitectura probada y familiar que incluye NetApp, VMware y sistemas con certificación NVIDIA. Consulte la siguiente tabla para obtener más información.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Software de IA y análisis de datos</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise para VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Plataforma de virtualización</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Plataforma informática</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Sistemas con certificación NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Plataforma de gestión de datos</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">Siguiente: Configuración inicial.</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">Esta página describe cómo utilizamos Pandas y DASK DataFrames para cargar datos Click Logs del conjunto de datos Criteo Terabyte. El caso de uso es relevante en la publicidad digital para intercambios de anuncios para crear perfiles de usuarios al predecir si se hará clic en anuncios o si el intercambio no está utilizando un modelo exacto en una canalización automatizada.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Cargue Criteo haga clic en el día 15 de los registros en pandas y entrena un cikit-aprende el modelo de bosque aleatorio</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Anterior: Bibliotecas para procesamiento de datos y entrenamiento de modelos.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">En esta sección se describe cómo utilizamos Pandas y DASK DataFrames para cargar datos Click Logs del conjunto de datos Criteo Terabyte. El caso de uso es relevante en la publicidad digital para intercambios de anuncios para crear perfiles de usuarios al predecir si se hará clic en anuncios o si el intercambio no está utilizando un modelo exacto en una canalización automatizada.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Se cargaron los datos del día 15 desde el conjunto de datos Click Logs, sumando 45 GB. Ejecutar la siguiente celda en el portátil Jupyter<block ref="687d69c323eb8500d21df9bfb49c3b55" prefix=" " category="inline-code"></block> Crea un DataFrame de pandas que contiene los primeros 50 millones de filas y genera un modelo de bosque aleatorio cikit-aprender.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">documentación oficial de scikit-aprender</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">Para realizar la predicción utilizando un modelo de bosque aleatorio entrenado, ejecute el siguiente párrafo en este cuaderno. Tomamos las últimas filas de un millón del día 15 como conjunto de pruebas para evitar cualquier duplicación. La celda también calcula la precisión de la predicción, definida como el porcentaje de ocurrencias que el modelo predice con precisión si un usuario hace clic o no en un anuncio. Para revisar cualquier componente desconocido en este cuaderno, consulte<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">Siguiente: Cargar día 15 en DASK y entrenar un modelo de bosque aleatorio cuML de DASK.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">&lt;Solution Name&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">Autores: &lt;name&gt;, &lt;title&gt;, &lt;company&gt;</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="section-title">Específico</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">Esta solución aborda los siguientes casos prácticos:</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">&lt;use case 1&gt;</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">&lt;use case 2&gt; ...</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">&lt;use case n&gt;</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Destinatarios</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">Esta solución está dirigida a los &lt;role&gt; interesados en &lt;goal&gt;.</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">O.</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">Esta solución está pensada para:</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">&lt;role&gt;, que está interesado en &lt;goal&gt;,</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">&lt;role&gt;, que está interesado en &lt;goal&gt;.</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">Entorno de prueba de la solución / validación</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">Las pruebas y la validación de esta solución se llevaron a cabo en un laboratorio que puede o no coincidir con el entorno de puesta en marcha final. Para obtener más información, consulte las siguientes secciones.</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">Diagrama de la arquitectura de la solución</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="example-title">Componentes de hardware/software</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">&lt;hardware name&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">&lt;model / version&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">Más información</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">&lt;software name&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">&lt;version&gt;</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="example-title">Notas adicionales</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">Nota 1</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">Nota 2 ...</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">Nota n</block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">Puesta en marcha de la solución</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">La implementación de esta solución se puede completar:</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">De forma manual siguiendo las instrucciones detalladas completas con capturas de pantalla,</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">De forma manual, siga los vídeos que muestran los pasos que se deben ejecutar, o.</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">Seguir automáticamente las instrucciones proporcionadas en la sección de automatización.</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">Instrucciones detalladas</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">Paso 1: &amp;Lt;nombre y gt de paso descriptivo;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">Tarea 1</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">Tarea 2 ...</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">Tarea n</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">Paso 2: &amp;Lt;nombre y gt de paso descriptivo;</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">Paso n: &amp;Lt;nombre y gt de paso descriptivo;</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">Demostración de vídeo</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">&lt;Include the video(s) details here&gt;</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">Puesta en marcha automatizada</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">&lt;include the automated steps/process/videos here&gt;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">Otras opciones de puesta en marcha</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">&amp;Lt;Descripción de la opción 1&amp;gt;</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">&lt;enter the details of the option here&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">&amp;Lt;Descripción de la opción 2&amp;gt;</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">&amp;Lt;Descripción de la opción n&amp;gt;</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Información adicional</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">Descripción del documento</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">Descripción de otro documento</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Serie de vídeos y demostraciones donde se analizan las características de muchas de las soluciones de NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Soluciones de NetApp: Vídeos y demostraciones</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Descripción general de los vídeos y demostraciones en los que se destacan características específicas de muchas de las soluciones de NetApp.</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">Inteligencia artificial (IA) y análisis de datos moderno</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">Soluciones de IA de NetApp</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOPS</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">Aplicaciones y bases de datos empresariales</block>
  <block id="031004dd1775e5fd9d35b534e33217ea" category="paragraph">[Underline]#*Vídeos para bases de datos de código abierto*#</block>
  <block id="5b70a7f45ddd32cacfe28af238662d3d" category="video-title">Puesta en marcha automatizada de PostgreSQL, configuración de replicación de alta disponibilidad/recuperación ante desastres, conmutación por error y resincronización</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[Underline]#*Vídeos para la modernización de Oracle con el cloud híbrido en AWS y FSX*#</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">Parte 1: Caso práctico y arquitectura de la solución</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">Parte 2a: Migración de bases de datos desde las instalaciones a AWS mediante reubicación automatizada de PDB con la máxima disponibilidad</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">Parte 2b: Migración de bases de datos desde las instalaciones a AWS mediante la consola BlueXP mediante SnapMirror</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">Parte 3: Configuración automatizada de replicación de alta disponibilidad/recuperación ante desastres de bases de datos, conmutación por error y resincronización</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">Parte 4a: Clonado de bases de datos para desarrollo/pruebas con interfaz de usuario de SnapCenter desde copia replicada en espera</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">Part 4b: Backup, restauración y clonado de bases de datos con la interfaz de usuario de SnapCenter</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">Parte 4c: Backup de bases de datos, restauración con backup y recuperación de aplicaciones SaaS BlueXP</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">Cluster de alta disponibilidad SQL en Azure NetApp Files</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">Clon de base de datos multi-tenant conectable de Oracle con snapshots de almacenamiento</block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Puesta en marcha automatizada de Oracle 19c RAC en FlexPod con Ansible</block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*Estudio de caso*</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">SAP en Azure NetApp Files</block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="example-title">Multicloud híbrido (HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[Underline]#*Vídeos para AWS/VMC*#</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="video-title">Almacenamiento conectado como invitado de Windows con FSX ONTAP mediante iSCSI</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="video-title">Almacenamiento conectado invitado de Linux con FSX ONTAP mediante NFS</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="video-title">VMware Cloud en un almacén de datos complementario con Amazon FSX para ONTAP de NetApp</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="video-title">Ahorro de VMware Cloud en AWS TCO con Amazon FSX para ONTAP de NetApp</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">Instalación y configuración de VMware HCX para VMC</block>
  <block id="c6434a9743fb403cd78cd2d3a42d9683" category="video-title">Demostración de VMotion con VMware HCX para VMC y FSxN</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">Demostración de migración en frío con VMware HCX para VMC y FSxN</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[Underline]#*Vídeos para Azure/AVS*#</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="video-title">Descripción general adicional del almacén de datos de la solución para VMware Azure con Azure NetApp Files</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="video-title">Recuperación ante desastres de la solución VMware para Azure con Cloud Volumes ONTAP, SnapCenter y JetStream</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">Demostración de migración en frío con VMware HCX para AVS y ANF</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">Demostración de VMotion con VMware HCX para AVS y ANF</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">Demostración de migración masiva con VMware HCX para AVS y ANF</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">Colección de vídeos de VMware</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">Contenedores/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">Vídeos de NetApp con Google Anthos</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">Vídeos de NetApp con VMware Tanzu</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">Vídeos de NetApp para DevOps</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">Vídeos de NetApp con Red Hat OpenShift</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="example-title">Automatización de soluciones</block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">Registro de cambios recientes en el material complementario de soluciones de NetApp</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">Registro de cambios de soluciones de NetApp</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">Cambios recientes en el material complementario de las soluciones de NetApp. Los cambios más recientes se enumeran primero.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">Todos los cambios</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">*Fecha*</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* Área de solución*</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">*Descripción del cambio*</block>
  <block id="b46d6d6e100776ecf2985ff50a451beb" category="cell">02/07/2023</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="cell">Cloud híbrido</block>
  <block id="6e6d4a2ed2ec59b98f8da1da20e890bb" category="cell">Blog añadido: Anuncio de la disponibilidad general de la compatibilidad del almacén de datos de Cloud Volumes Service de NetApp con Google Cloud VMware Engine</block>
  <block id="7240c168839eaf56e1bc86326fb29d5b" category="cell">Incorporación de TR-4955: Recuperación ante desastres con FSX para ONTAP y VMC (AWS VMware Cloud)</block>
  <block id="61c8e892dd7e1908020eb0a312fd4bbb" category="cell">02/15/2023</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">Base de datos</block>
  <block id="2ee6a0567aa163f6ace02183cb041cbd" category="cell">Se ha agregado la puesta en marcha de alta disponibilidad y la recuperación ante desastres de PostgreSQL en AWS FSX/EC2</block>
  <block id="2eded16d414f6935c27c95495a25eb53" category="cell">01/24/2023</block>
  <block id="d75c9f4acb46fbd1cc7aeecbd376940e" category="cell">Añadido TR-4954: Puesta en marcha y protección de bases de datos de Oracle en Azure NetApp Files</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">01/12/2023</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">Añadido del blog: Proteja sus cargas de trabajo de SQL Server mediante SnapCenter de NetApp con Amazon FSX para ONTAP de NetApp</block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">12/15/2022</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">Se ha añadido TR-4923: SQL Server en AWS EC2 mediante Amazon FSX para ONTAP de NetApp</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">12/06/2022</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">Se han agregado 7 vídeos para la modernización de las bases de datos de Oracle en el cloud híbrido con almacenamiento Amazon FSX</block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">10/25/2022</block>
  <block id="80d05b7bca341d02b41c7f6cb32ad23b" category="cell">Se ha añadido un enlace a la docencia de VMware para FSX ONTAP como almacén de datos NFS</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">Se ha añadido una referencia al blog para configurar el cloud híbrido con FSX ONTAP y VMC en AWS SDDC mediante VMware HCX</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">09/30/2022</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">Se ha agregado la solución para migrar cargas de trabajo al almacén de datos FSxN mediante VMware HCX</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">09/29/2022</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">Se ha agregado una solución para migrar cargas de trabajo al almacén de datos ANF mediante VMware HCX</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">09/14/2022</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">Adición de enlaces a calculadoras y simuladores de TCO para FxN / VMC y ANF / AVS</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">Se ha añadido la opción complementaria de almacén de datos NFS para AWS/VMC</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">08/25/2022</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">Añadido blog: Modernice su base de datos Oracle en el cloud híbrido con el almacenamiento Amazon FSX</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">IA</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">Nueva solución: NVIDIA AI Enterprise con NetApp y VMware</block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">08/23/2022</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">Se ha actualizado la disponibilidad de región más reciente para todas las opciones complementarias de almacén de datos NFS</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">08/05/2022</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">Se añadió la información "Reiniciar requiere" para los ajustes ESXi y ONTAP recomendados</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">07/28/2022</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">Nueva solución de recuperación ante desastres con SnapCenter y Veeam para AWS/VMC (almacenamiento conectado «guest»).</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">07/21/2022</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">Ha añadido una solución de recuperación ante desastres con CVO y JetStream para AVS (almacenamiento conectado de invitado).</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">06/29/2022</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">Incorporación de WP-7357: Implementación de bases de datos Oracle en prácticas recomendadas de EC2/FSX</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">06/16/2022</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">Se ha añadido NVIDIA DGX SuperPOD con la guía de diseño de NetApp</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">06/10/2022</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">Se ha añadido AVS con información general sobre el almacén de datos nativo ANF y DR con JetStream</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">06/07/2022</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">Compatibilidad actualizada con la región de AVS para coincidir con el anuncio/soporte de vista previa pública</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">Análisis de datos</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Ha añadido un enlace a EF600 de NetApp con la solución Splunk Enterprise</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">06/02/2022</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">Ha añadido una lista de disponibilidad de región para los almacenes de datos NFS para el multicloud híbrido de NetApp con VMware</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">05/20/2022</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">Nuevas guías de diseño e implementación de BeeGFS para SuperPOD</block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">04/01/2022</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">Contenido organizado del multicloud híbrido con soluciones de VMware: Páginas de destino para cada proveedor a hiperescala e inclusión de contenido de solución disponible (caso de uso)</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">03/29/2022</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">Se ha añadido un nuevo TR: DevOps con NetApp Astra</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">03/08/2022</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">Ha añadido un nuevo vídeo de demostración: Acelere el desarrollo de software con Astra Control y la tecnología FlexClone de NetApp</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">03/01/2022</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">Se han añadido nuevas secciones a NVA-1160: Instalación de Astra Control Center a través de OperatorHub y Ansible</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">Generales</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">Ha creado páginas de destino para organizar mejor el contenido para la IA y los análisis de datos modernos</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">01/22/2022</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">Añadido TR: Movimiento de datos con E-Series y BeeGFS para flujos de trabajo de análisis e IA</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">12/21/2021</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">Ha creado páginas de destino para organizar mejor el contenido para la virtualización y el multicloud híbrido con VMware</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">Se ha añadido una nueva demostración en vídeo: Aproveche Astra Control de NetApp para realizar un análisis post mortem y restaurar su aplicación en NVA-1160</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/06/2021</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">Creación de multicloud híbrido con contenido de VMware para entornos de virtualización y opciones de almacenamiento conectado a invitado</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">11/15/2021</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">Se ha añadido un nuevo vídeo de demostración: Protección de datos en canalización de CI/CD con Astra Control y NVA-1160</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">Análisis de datos moderno</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">Nuevo contenido: Mejores prácticas para Confluent Kafka</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">11/02/2021</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">Automatización</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">10/29/2021</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">Nuevo contenido: TR-4657 - Soluciones de datos en el cloud híbrido de NetApp: Spark y Hadoop</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Protección de datos automatizada para bases de datos de Oracle</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">10/26/2021</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">Se ha añadido la sección de blog para aplicaciones empresariales y bases de datos al icono de soluciones de NetApp. Se han agregado dos blogs a los blogs de la base de datos.</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">10/18/2021</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - Soluciones de bases de datos para el cloud híbrido con SnapCenter</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">10/14/2021</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">Se han añadido las partes 1-4 de NetApp con la serie de blogs VCF de VMware</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">10/04/2021</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">Se ha añadido una nueva demostración en vídeo: Migración de cargas de trabajo con Astra Control Center a NVA-1160</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">09/23/2021</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">Migración de datos</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">Nuevo contenido: Mejores prácticas de NetApp para NetApp XCP</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">09/21/2021</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">Nuevo contenido o ONTAP para administradores de VMware vSphere, automatización de VMware vSphere</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">09/09/2021</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">Se ha añadido la integración DEL equilibrador DE carga BIG-IP de F5 con OpenShift a NVA-1160</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">08/05/2021</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Se ha añadido una nueva integración tecnológica a NVA-1160: NetApp Astra Control Center en Red Hat OpenShift</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">07/21/2021</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">Puesta en marcha automatizada de Oracle19c para ONTAP en NFS</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 - SQL Server en Azure NetApp Files: Vista real de la puesta en marcha</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">06/16/2021</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">Se ha añadido una nueva demostración en vídeo, instalando OpenShift Virtualization: Red Hat OpenShift con NetApp</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">Se ha añadido una nueva demostración en vídeo de implementación de una máquina virtual con OpenShift Virtualization: Red Hat OpenShift con NetAppp</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">06/14/2021</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Solución adicional: Microsoft SQL Server en Azure NetApp Files</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">06/11/2021</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">Se ha añadido una nueva demostración en vídeo: Migración de cargas de trabajo con Astra Trident y SnapMirror a NVA-1160</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">06/09/2021</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">Se ha añadido un nuevo caso de uso a NVA-1160 - Advanced Cluster Management para Kubernetes en Red Hat OpenShift con NetApp</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">05/28/2021</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">Se ha añadido un nuevo caso de uso a NVA-1160 - OpenShift Virtualization con ONTAP de NetApp</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">05/27/2021</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">Se ha añadido un nuevo caso de uso a NVA-1160- Multitenancy en OpenShift con NetApp ONTAP</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">05/26/2021</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">Se ha añadido NVA-1160: Red Hat OpenShift con NetApp</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">05/25/2021</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">Blog añadido: Instalación de NetApp Trident en Red Hat OpenShift: Cómo resolver el problema del Docker «toomanyRequests».</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">05/19/2021</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">Vínculo añadido a las soluciones FlexPod</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">Se ha convertido la solución AI Control Plane de PDF a HTML</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">05/17/2021</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">Se ha agregado el mosaico de comentarios de soluciones a la página principal</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">05/11/2021</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">Incorporación de la puesta en marcha automatizada de Oracle 19c para ONTAP en NFS</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">05/10/2021</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">Nuevo vídeo: Cómo usar vVols con NetApp y VMware Tanzu Basic, parte 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">05/06/2021</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Base de datos Oracle</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">Vínculo añadido a las bases de datos RAC Oracle 19c en el centro de datos de FlexPod con Cisco UCS y AFF A800 de NetApp sobre FC</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">05/05/2021</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">Se han añadido FlexPod los vídeos de NetApp, NetApp, Oracle NVA (1155) y Automation</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">05/03/2021</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">Virtualización de escritorios</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">Vínculo agregado a las soluciones de virtualización de puestos de trabajo de FlexPod</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">04/30/2021</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">Vídeo: Cómo usar vVols con NetApp y VMware Tanzu Basic, parte 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">04/26/2021</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">Añadió el blog: Uso de VMware Tanzania con ONTAP para acelerar su viaje hacia Kubernetes</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">04/06/2021</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">Se añadió "Acerca de este repositorio"</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">03/31/2021</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Se ha añadido TR-4886 - inferencia de IA en el perímetro: ONTAP de NetApp con el diseño de la solución de sistema de ThinkSystem de Lenovo</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">03/29/2021</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">Se ha añadido NVA-1157: Carga de trabajo de Apache Spark con la solución de almacenamiento de NetApp</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">03/23/2021</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">Vídeo: Cómo usar vVols con NetApp y VMware Tanzu Basic, parte 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">03/09/2021</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">Contenido de E-Series añadido; contenido de IA clasificado</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">03/04/2021</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">Nuevo contenido: Introducción a la automatización de soluciones de NetApp</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">02/18/2021</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">Se ha añadido TR-4597 - VMware vSphere para ONTAP</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">02/16/2021</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">Se han agregado pasos de puesta en marcha automatizados para la inferencia de IA Edge</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">02/03/2021</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">Ha añadido una página de inicio para todo el contenido de SAP y SAP HANA</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">02/01/2021</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">VDI con VDS de NetApp, se añade contenido para los nodos de GPU</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">01/06/2021</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">Nueva solución: ONTAP AI de NetApp con sistemas NVIDIA DGX A100 y switches Ethernet Mellanox Spectrum (diseño y puesta en marcha)</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">12/22/2020</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">El lanzamiento inicial del repositorio de soluciones de NetApp</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">IA/Análisis de datos</block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">Multicloud híbrido</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">Aplicaciones y bases de datos empresariales</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">Almacén de soluciones SAP</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">Si quiere más información sobre las actualizaciones de SAP y SAP HANA, consulte el contenido "Historial de actualizaciones" presente para cada una de las soluciones del <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">Protección y migración de datos</block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">VDS de NetApp puede ponerse en marcha en Microsoft Azure mediante una aplicación de configuración disponible en función de la base de código necesaria.</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">VDS de NetApp puede ponerse en marcha en Microsoft Azure mediante una aplicación de configuración disponible en función de la base de código necesaria. La versión actual está disponible<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> y el lanzamiento de vista previa del próximo producto está disponible<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">este vídeo</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">Consulte<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> para obtener instrucciones de puesta en funcionamiento.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">Siguiente: Entorno de cloud híbrido</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">VDS de NetApp utiliza Azure Active Directory para la autenticación de identidades y Azure Active Directory Domain Services para la autenticación NTLM/Kerberos. La herramienta ADConnect se puede utilizar para sincronizar un dominio de Active Directory en las instalaciones con Azure Active Directory.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">Gestión de usuarios</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">Es posible añadir nuevos usuarios desde el portal o habilitar espacios de trabajo cloud para los usuarios existentes. Los permisos para los espacios de trabajo y los servicios de aplicaciones pueden ser controlados por usuarios individuales o por grupos. Desde el portal de gestión, los usuarios administrativos pueden definirse para controlar los permisos del portal, los espacios de trabajo, etc.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">La siguiente figura muestra la gestión de usuarios en VDS de NetApp.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">Cada espacio de trabajo reside en su propia unidad organizativa (OU) de Active Directory bajo la unidad organizativa de Cloud Workspace como se muestra en la siguiente figura.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">Para obtener más información, consulte<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> Sobre los permisos de usuario y la gestión de usuarios en NetApp VDS.</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">Cuando un grupo de Active Directory se define como un grupo CRAUserGroup mediante una llamada API para el centro de datos, todos los usuarios de ese grupo se importan en CloudWorkspace para la administración mediante la interfaz de usuario. Cuando el espacio de trabajo en la nube está habilitado para el usuario, VDS crea carpetas de inicio de usuario, permisos de configuración, actualizaciones de propiedades de usuario, etc.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">Si se activa el usuario de VDI activado, VDS crea un equipo RDS de una sola sesión dedicado a ese usuario. Solicita la plantilla y el almacén de datos que se deben aprovisionar.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">Siguiente: Gestión de espacios de trabajo</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">Con VDS de NetApp, los administradores pueden delegar tareas a otras. Pueden conectarse a servidores implementados para solucionar problemas, ver registros y ejecutar informes de auditoría. Mientras ayuda a los clientes, al servicio de asistencia técnica o a los técnicos de nivel 3, puede remedar sesiones de usuarios, ver listas de procesos y matar procesos si es necesario.</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Prueba de carga de servidor único con Login VSI</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">Virtual Desktop Service de NetApp utiliza el protocolo de Microsoft Remote Desktop para acceder a aplicaciones y sesiones de puestos de trabajo virtuales, y la herramienta Login VSI determina el número máximo de usuarios que pueden alojarse en un modelo de servidor específico. Login VSI simula el inicio de sesión de usuario a intervalos específicos y realiza operaciones de usuario como abrir documentos, leer y redactar correos electrónicos, trabajar con Excel y PowerPoint, imprimir documentos, comprimir archivos y efectuar pausas aleatorias. Luego mide los tiempos de respuesta. El tiempo de respuesta del usuario es bajo cuando el uso del servidor es bajo y aumenta cuando se añaden más sesiones de usuario. Login VSI determina la línea de base en función de las sesiones iniciales de inicio de sesión de usuario e informa de la sesión de usuario máxima cuando la respuesta del usuario supera los 2 segundos de la línea de base.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">El servicio de puestos de trabajo virtuales de NetApp utiliza el protocolo de Microsoft Remote Desktop para acceder a las aplicaciones y sesiones de puestos de trabajo virtuales. Para determinar el número máximo de usuarios que se pueden alojar en un modelo de servidor específico, utilizamos la herramienta Login VSI. Login VSI simula el inicio de sesión de usuario a intervalos específicos y realiza operaciones de usuario como abrir documentos, leer y redactar correos electrónicos, trabajar con Excel y PowerPoint, imprimir documentos, comprimir archivos, tomar pausas aleatorias, etc. También mide los tiempos de respuesta. El tiempo de respuesta del usuario es bajo cuando el uso del servidor es bajo y aumenta cuando se añaden más sesiones de usuario. Login VSI determina la línea de base en función de las sesiones iniciales de inicio de sesión de usuario e informa de la cantidad máxima de sesiones de usuario cuando la respuesta del usuario supera los 2 segundos de la línea de base.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">La siguiente tabla contiene el hardware utilizado para esta validación.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">Cuente</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">Tres de un clúster para lanzadores, AD, DHCP, etc. Un servidor para la prueba de carga.</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2 x Intel Xeon Gold 24C 6282 a 2,1 GHz. 1,5 TB DE RAM.</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">La siguiente tabla contiene el software utilizado para esta validación.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">producto</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">VDS 5.4 de NetApp</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">Coordinación</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">Ventanas de plantilla de equipo virtual 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">Sistema operativo del servidor PARA RDSH</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 Update 3</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">Hipervisor</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3f</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">Herramienta de gestión de VMware</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Los resultados de la prueba Login VSI son los siguientes:</block>
  <block id="17126aef3e415713552604218f448967" category="cell">Configuración de las máquinas virtuales</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Línea de base de inicio de sesión VSI</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Inicio de sesión VSI Max</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">8 vCPU, 48 GB de RAM, disco de 75 GB, perfil de vGPU 8Q</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">12 vCPU, 128 GB de RAM, 75 GB de disco</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">Teniendo en cuenta los límites e hiperprocesos de NUMA, los ocho equipos virtuales elegidos para la prueba y la configuración de equipos virtuales dependen de los núcleos disponibles en el host.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">Utilizamos 10 equipos virtuales de inicio en H610C, la cual utilizó el protocolo RDP para conectarse a la sesión de usuario. En la siguiente figura se muestra la información de conexión de Login VSI.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">En la siguiente figura, se muestra el tiempo de respuesta de Login VSI frente a las sesiones activas para H610C.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">En la siguiente figura, se muestra el tiempo de respuesta de Login VSI con las sesiones activas para H615C.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">En la siguiente figura, se muestran las métricas de rendimiento de Cloud Insights durante la prueba de H615C Login VSI al host de vSphere y las máquinas virtuales.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">Siguiente: Portal de gestión</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">Los trabajadores de tareas pueden iniciar rápidamente una aplicación desde la lista de aplicaciones que se les han puesto a su disposición. Los servicios de aplicaciones publican aplicaciones desde los hosts de sesión de Remote Desktop Services. Con WVD, los grupos de aplicaciones proporcionan una funcionalidad similar a la de los grupos de host de Windows 10 con varias sesiones.</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">Soluciones tecnológicas para el usuario final (EUC)/Infraestructura de puestos de trabajo virtuales (VDI)</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">Tanto si pone en marcha puestos de trabajo virtuales en las instalaciones como en el cloud, NetApp cuenta con una gran variedad de soluciones de EUC/VDI para responder a sus necesidades.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">Servicios de puestos de trabajo virtuales (VDS) de NetApp</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">El servicio de escritorios virtuales (VDS) de NetApp organiza los servicios de escritorios remotos (RDS) en los principales clouds públicos y en clouds privados.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">Soluciones disponibles para VDS:</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">Infraestructura de puestos de trabajo virtuales de cloud híbrido con Virtual Desktop Service de NetApp</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">Computación de usuario final con VMware Horizon</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp ha verificado las arquitecturas para VMware Horizon que abarcan varias configuraciones de computación. Entre las soluciones disponibles se incluyen:</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">Computación de usuario final con VMware (guía de diseño)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">Computación de usuario final con VMware y GPU NVIDIA (guía de diseño)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">Computación de usuario final con VMware y GPU NVIDIA (guía de puesta en marcha)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">Computación de usuario final con VMware para gráficos 3D</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">Un espacio de trabajo consta de un entorno de puestos de trabajo, que puede compartirse sesiones de puestos de trabajo remotos alojadas en el entorno local o en cualquier entorno cloud de soporte. Con Microsoft Azure, el entorno de puestos de trabajo puede ser persistente con puestos de trabajo virtuales de Windows. Cada área de trabajo está asociada a una organización o cliente específico.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">Gestión de espacios de trabajo</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">Un espacio de trabajo consta de un entorno de puestos de trabajo; se pueden compartir sesiones de puestos de trabajo remotos alojadas en las instalaciones o en cualquier entorno cloud compatible. Con Microsoft Azure, el entorno de puestos de trabajo puede ser persistente con puestos de trabajo virtuales de Windows. Cada área de trabajo está asociada a una organización o cliente específico. Las opciones disponibles al crear un espacio de trabajo nuevo se pueden ver en la siguiente figura.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">Cada área de trabajo está asociada con una implementación específica.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">Los espacios de trabajo contienen aplicaciones y servicios de aplicaciones asociados, carpetas de datos compartidos, servidores y una instancia de WVD. Cada espacio de trabajo puede controlar las opciones de seguridad, como la aplicación de la complejidad de las contraseñas, la autenticación multifactorial, las auditorías de archivos, etc.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">Los espacios de trabajo pueden controlar la programación de la carga de trabajo para encender servidores adicionales, limitar el número de usuarios por servidor o establecer la programación de los recursos disponibles para un determinado período (siempre activos/apagados). Los recursos también se pueden configurar para activarse a petición.</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="inline-link">vídeo</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">Si es necesario, el espacio de trabajo puede anular los valores predeterminados de los recursos del equipo virtual de implementación. Para WVD, los pools de hosts WVD (que contienen hosts de sesiones y grupos de aplicaciones) y los espacios de trabajo WVD también se pueden gestionar desde el portal del paquete de gestión de espacios de trabajo en la nube. Para obtener más información sobre el grupo de hosts de WVD, consulte este<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">Siguiente: Gestión de aplicaciones</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">Gestión de aplicaciones</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">Para que los trabajadores de la oficina puedan suministrar las aplicaciones que necesiten mediante una placa de servicio manualmente, o bien se pueden aprovisionar automáticamente con la función de eventos programados de VDS de NetApp.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">Página de autorización de aplicaciones de NetApp</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">Para obtener más información, consulte<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">Siguiente: Funciones de ONTAP para el servicio de escritorios virtuales</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">El servicio de puestos de trabajo virtuales de NetApp se puede ampliar a las instalaciones cuando existe conectividad entre los recursos en las instalaciones y los recursos cloud. Las empresas pueden establecer el vínculo a Microsoft Azure mediante Express Route o una conexión VPN IPsec de sitio a sitio. También puede crear vínculos a otras nubes de forma similar mediante un enlace dedicado o con un túnel VPN IPsec.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">Entorno de cloud híbrido</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">Para la validación de soluciones, utilizamos el entorno descrito en la siguiente figura.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">En las instalaciones, teníamos varias VLAN para gestión, hosts de sesiones de puesto de trabajo remoto, etc. Se encontraban en la subred 172.21.146-150.0/24 y se enrutaron a la red corporativa mediante el Servicio de acceso de enrutamiento remoto de Microsoft. También realizamos las siguientes tareas:</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Notamos la IP pública del servidor de enrutamiento y acceso remoto de Microsoft (RRAS; identificado con IPchicken.com).</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Creamos un recurso de Virtual Network Gateway (VPN basado en rutas) en la suscripción a Azure.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Creamos la conexión que proporciona la dirección de pasarela de red local para la IP pública del servidor RRAS de Microsoft.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">Hemos completado la configuración de VPN en RRAS para crear una interfaz virtual mediante la autenticación precompartida que se proporcionó al crear la puerta de enlace VPN. Si se configura correctamente, la VPN debe estar en el estado conectado. En lugar de RRAS de Microsoft, también puede utilizar pfSense u otras herramientas relevantes para crear el túnel VPN IPsec de sitio a sitio. Dado que se basa en rutas, el túnel redirige el tráfico en función de las subredes específicas configuradas.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory proporciona autenticación de identidad basada en oAuth. Las autenticaciones de cliente empresarial normalmente requieren autenticación basada en NTLM o Kerberos. Microsoft Azure Active Directory Domain Services realiza una sincronización hash de contraseña entre Azure Active Directory y los controladores de dominio en las instalaciones mediante ADConnect.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">Para esta validación de la solución VDS híbrida, inicialmente implementamos Microsoft Azure y añadimos un sitio adicional con vSphere. La ventaja de este método es que los servicios de plataforma se pusieron en marcha en Microsoft Azure y se incluyeron después en un backup fácilmente mediante el portal. A continuación, se puede acceder fácilmente a los servicios desde cualquier lugar, incluso si el enlace VPN del sitio no está disponible.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">Para agregar otro sitio, utilizamos una herramienta llamada DCConfig. El acceso directo a esa aplicación está disponible en el escritorio del equipo virtual del administrador de espacio de trabajo en la nube (CWMgr). Una vez que se haya iniciado esta aplicación, desplácese a la ficha Sitios de centro de datos, agregue el nuevo sitio del centro de datos y rellene la información necesaria como se muestra a continuación. La URL apunta a la IP de vCenter. Asegúrese de que el equipo virtual de CWMgr pueda comunicarse con vCenter antes de agregar la configuración.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">Asegúrese de que está instalado vSphere PowerCLI 5.1 en CloudWorkspace Manager para habilitar la comunicación con el entorno de VMware vSphere.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">La siguiente figura muestra la configuración del sitio del centro de datos local.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">Tenga en cuenta que existen opciones de filtrado disponibles para los recursos de computación en función del clúster específico, el nombre de host o el espacio de RAM libre. Las opciones de filtrado para recursos de almacenamiento incluyen el espacio libre mínimo en los almacenes de datos o la cantidad máxima de máquinas virtuales por almacén de datos. Los almacenes de datos se pueden excluir con expresiones regulares. Haga clic en el botón Guardar para guardar la configuración.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">Para validar la configuración, haga clic en el botón Test, o bien haga clic en Load Hypervisor y compruebe cualquier lista desplegable en la sección vSphere. Debe rellenarse con los valores adecuados. Se recomienda mantener el hipervisor principal establecido en yes para el sitio de aprovisionamiento predeterminado.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">Las plantillas de máquinas virtuales creadas en VMware vSphere se consumen como colecciones de aprovisionamiento en VDS. Las colecciones para aprovisionamiento se presentan de dos formas: Compartidas e infraestructuras de puestos de trabajo virtuales. El tipo de colección de aprovisionamiento compartido se utiliza para los servicios de escritorio remoto para los que se aplica una única política de recursos a todos los servidores. El tipo de VDI se utiliza para las instancias de WVD para las que se asigna la política de recursos de forma individual. Los servidores de una colección de aprovisionamiento pueden asignarse una de las siguientes tres funciones:</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA.* combinación de Servicios de Terminal Server y función de servidor de datos.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*Servicios de terminal TS.* (Host de sesión).</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">*DATA.* servidor de archivos o servidor de bases de datos. Al definir el rol de servidor, debe seleccionar la plantilla y el almacenamiento (almacén de datos) de la máquina virtual. El almacén de datos elegido puede restringirse a un almacén de datos específico o puede usar la opción menos utilizada en la que se elige el almacén de datos en función del uso de los datos.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">Cada implementación tiene valores predeterminados de recursos de equipo virtual para la asignación de recursos de cloud en función de usuarios activos, fijos, carga de servidor o recuento de usuarios.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">Siguiente: Prueba de carga de un solo servidor con Login VSI</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp ofrece muchos servicios cloud, como el aprovisionamiento rápido de puestos de trabajo virtuales con WVD o aplicaciones remotas, incluida la rápida integración con Azure NetApp Files.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">Descripción general de Virtual Desktop Service de NetApp</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp ofrece muchos servicios cloud, como el aprovisionamiento rápido de puestos de trabajo virtuales con WVD o aplicaciones remotas, y la rápida integración con Azure NetApp Files.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">Tradicionalmente, se necesitan semanas para aprovisionar y prestar servicios de escritorios remotos a los clientes. Además del aprovisionamiento, puede resultar difícil gestionar aplicaciones, perfiles de usuario, datos compartidos y objetos de normativa de grupo para aplicar normativas. Las reglas de firewall pueden aumentar la complejidad y requerir habilidades y herramientas separadas.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Con el servicio de escritorio virtual de Microsoft Azure Windows, Microsoft se ocupa del mantenimiento de los componentes de Servicios de Escritorio remoto, lo que permite a los clientes centrarse en aprovisionar espacios de trabajo en el cloud. Los clientes deben aprovisionar y gestionar toda la pila, lo cual requiere habilidades especiales para gestionar entornos de VDI.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">Con VDS de NetApp, los clientes pueden poner en marcha rápidamente puestos de trabajo virtuales sin tener que preocuparse de dónde instalar los componentes de arquitectura como intermediarios, puertas de enlace, agentes, etc. Los clientes que necesiten un control completo de su entorno pueden trabajar con un equipo de servicios profesionales para lograr sus objetivos. Los clientes consumen VDS como servicio y, por lo tanto, pueden centrarse en sus desafíos empresariales clave.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">VDS de NetApp es una oferta de software como servicio para gestionar de forma centralizada varias puestas en marcha en entornos de AWS, Azure, GCP o de cloud privado. Microsoft Windows Virtual Desktop solo está disponible en Microsoft Azure. VDS de NetApp orquesta servicios de Microsoft Remote Desktop en otros entornos</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft ofrece varias sesiones en Windows 10 exclusivamente para entornos de escritorio virtual de Windows en Azure. La autenticación e identidad se gestionan mediante la tecnología de puestos de trabajo virtuales; WVD requiere que Azure Active Directory se sincroniza (con AD Connect) con Active Directory y que las máquinas virtuales de sesión se unen a Active Directory. RDS requiere Active Directory para la identidad de usuario, la autenticación y la unión y la gestión del dominio de VM.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">En la siguiente figura se muestra un ejemplo de topología de puesta en marcha.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">Cada implementación está asociada a un dominio de directorio activo y proporciona a los clientes un punto de entrada de acceso para áreas de trabajo y aplicaciones. Normalmente, un proveedor de servicios o empresa que tiene varios dominios de Active Directory tiene más puestas en marcha. Un único dominio de Active Directory que abarca varias regiones normalmente tiene una única implementación con varios sitios.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Para WVD en Azure, Microsoft proporciona una plataforma como servicio que VDS de NetApp consume. En otros entornos, VDS de NetApp coordina la implementación y la configuración de Microsoft Remote Desktop Services. VDS de NetApp es compatible con WVD Classic y WVD ARM, y también se puede utilizar para actualizar las versiones existentes.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">Cada puesta en marcha tiene sus propios servicios de plataforma, que consisten en Cloud Workspace Manager (extremo de la API DE REST), una puerta de enlace HTML 5 (conexión a equipos virtuales desde un portal de gestión VDS), puertas de enlace RDS (punto de acceso para clientes) y un controlador de dominio. La siguiente figura muestra la arquitectura VDS Control Plane para la implementación RDS.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">Para implementaciones RDS, se puede acceder fácilmente a VDS de NetApp desde Windows y navegadores con un software de cliente que puede personalizarse para incluir imágenes y el logotipo del cliente. Basándose en las credenciales de usuario, proporciona acceso de los usuarios a los espacios de trabajo y aplicaciones aprobados. No es necesario configurar los detalles de la puerta de enlace.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">La siguiente figura muestra el cliente VDS de NetApp.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">En la implementación de Azure WVD, Microsoft gestiona el punto de entrada de acceso de los clientes y puede ser consumido por un cliente WVD de Microsoft disponible de forma nativa para varios SO. También se puede acceder a él desde un portal web. La configuración del software cliente debe ser gestionada por el objeto de directiva de grupo (GPO) o de otras formas preferidas por los clientes.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">En la siguiente figura se muestra la arquitectura VDS Control Plane para implementaciones de Azure WVD.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">Además de la instalación y configuración de los componentes necesarios, NetApp VDS también gestiona la gestión de usuarios, la gestión de aplicaciones, el escalado de recursos y la optimización.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">VDS de NetApp puede crear usuarios o conceder acceso a cuentas de usuario existentes al espacio de trabajo del cloud o a los servicios de la aplicación. El portal también se puede utilizar para restablecer contraseñas y para la delegación de administrar un subconjunto de componentes. Los administradores del servicio de asistencia técnica o los técnicos de nivel 3 pueden remedar sesiones de usuario para solucionar problemas o conectarse a servidores desde el portal.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">VDS de NetApp puede utilizar las plantillas de imagen que crea o puede usar las existentes del mercado para el aprovisionamiento basado en cloud. Para reducir el número de imágenes que se deben gestionar, puede utilizar una imagen base y aprovisionar cualquier aplicación adicional que necesite utilizando el marco proporcionado para incluir cualquier herramienta de línea de comandos como Chocolatey, conexión de aplicaciones MSIX, PowerShell, etc. Incluso los scripts personalizados pueden utilizarse como parte de los eventos de ciclo de vida de la máquina.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">Siguiente: Descripción general de NetApp HCI</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">En esta página se describen la herramienta DCConfig, las herramientas de TestVdc y los archivos de registro.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">Herramientas y registros</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">Herramienta DCConfig</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">La herramienta DCCconfig admite las siguientes opciones de hipervisor para agregar un sitio:</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">La asignación de letras de unidades específicas del espacio de trabajo para datos compartidos se puede gestionar mediante GPO. Los Servicios profesionales o el equipo de soporte pueden utilizar la ficha Avanzadas para personalizar configuraciones como nombres de OU de Active Directory, la opción para activar o desactivar la implementación de FSLogix, varios valores de tiempo de espera, etc.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Centro de comandos (anteriormente conocido como Herramientas de TestVdc)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Descripción general del Centro de comandos</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Para iniciar Command Center y el rol necesario, consulte <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">Es posible realizar las siguientes operaciones:</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">Cambiar la ruta del bloque de mensajes del servidor de un espacio de trabajo.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">Cambie el sitio para la colección de abastecimiento.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">Archivos de registro</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">registros de automatización</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>Comprobar <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> para obtener más información.</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">Cloud de NetApp</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">Documentación de producto VDS de NetApp</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">Conecte su red local a Azure con VPN Gateway</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Portal de Azure</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Escritorio virtual de Microsoft Windows</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Registro de Azure NetApp Files</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">El portal VDS Cloud Workspace Management Suite de NetApp permite la gestión centralizada de diversas implementaciones de VDS, incluida una con sitios definidos para los usuarios locales, los administradores, el catálogo de aplicaciones y los eventos programados. El portal también lo utilizan los usuarios administrativos para el aprovisionamiento manual de aplicaciones si es necesario y para conectarse a cualquier equipo para la solución de problemas.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">Portal de gestión</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">El portal VDS Cloud Workspace Management Suite de NetApp está disponible<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> y la próxima versión está disponible<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">El portal permite la administración centralizada de varias implementaciones de VDS, incluida una que tiene sitios definidos para los usuarios locales, administrativos, el catálogo de aplicaciones y eventos con secuencias de comandos. El portal también lo utilizan los usuarios administrativos para el aprovisionamiento manual de aplicaciones si es necesario y para conectarse a cualquier equipo para la solución de problemas.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">Los proveedores de servicios pueden utilizar este portal para agregar sus propios socios de canal y permitirles gestionar sus propios clientes.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">Siguiente: Gestión de usuarios</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">El servicio de escritorios virtuales de NetApp ofrece un entorno de aplicaciones y puestos de trabajo virtuales fácil de usar, prestando especial atención a los desafíos empresariales. Al ampliar VDS con NetApp HCI, es posible utilizar potentes funciones de NetApp en un entorno de VDS, incluidos la deduplicación en línea, la compactación, el thin provisioning y la compresión.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">El servicio de escritorios virtuales de NetApp ofrece un entorno de aplicaciones y puestos de trabajo virtuales fácil de usar, prestando especial atención a los desafíos empresariales. Al ampliar VDS con el entorno ONTAP en las instalaciones, es posible utilizar potentes funciones de NetApp en un entorno VDS, que incluyen un clonado rápido, deduplicación en línea, compactación, thin provisioning, y compresión. Estas funciones ahorran en costes de almacenamiento y mejoran el rendimiento con el almacenamiento all-flash. Con el hipervisor VMware vSphere, que minimiza el tiempo de aprovisionamiento del servidor mediante Virtual Volumes y la API de vSphere para la integración de cabina. Con el cloud híbrido, los clientes pueden elegir el entorno adecuado para sus cargas de trabajo exigentes y ahorrar dinero. La sesión de escritorio que se ejecuta en las instalaciones puede acceder a los recursos cloud en función de políticas.</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">Gestión de operaciones</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">Solución de problemas de la página de acciones de VDA fallidas</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">Para obtener información acerca de los archivos de registro de VDS, consulte<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">Página componentes y permisos de VDA</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">Para obtener más información sobre los permisos mínimos necesarios, consulte<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">Página Cloning Virtual Machines</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">Si desea clonar manualmente un servidor, consulte<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">Página de características aumento automático del espacio en disco</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">Para aumentar automáticamente el tamaño del disco de la máquina virtual, consulte<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">Requisitos del usuario final</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">Para identificar la dirección de puerta de enlace para configurar manualmente el cliente, consulte<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">Cloud Insights de NetApp es una herramienta de supervisión basada en Web que le ofrece una visibilidad completa de la infraestructura y las aplicaciones que se ejecutan en NetApp y otros componentes de infraestructura de terceros. Cloud Insights admite tanto clouds privados como públicos para supervisar, solucionar problemas y optimizar recursos.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">Sólo la unidad de adquisición VM (puede ser Windows o Linux) debe estar instalada en una nube privada para recopilar métricas de recopiladores de datos sin necesidad de agentes. Los recopiladores de datos basados en agentes le permiten extraer métricas personalizadas del Monitor de rendimiento de Windows o de cualquier agente de entrada compatible con Telegraf.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">La siguiente figura muestra el panel de VDS de Cloud Insights.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">Para obtener más información sobre Cloud Insights de NetApp, consulte<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">Siguiente: Herramientas y registros</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">El servicio de escritorios virtuales (VDS) de NetApp organiza los servicios de escritorios remotos (RDS) en los principales clouds públicos y en clouds privados. VDS es compatible con Windows Virtual Desktop (WVD) en Microsoft Azure. VDS automatiza muchas tareas que se deben realizar después de la implementación de WVD o RDS, incluida la configuración de recursos compartidos de archivos SMB (para perfiles de usuario, datos compartidos y la unidad de inicio del usuario), habilitar funciones de Windows, instalación de aplicaciones y agentes, firewall y políticas, etc.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861: VDI de cloud híbrido con servicio de puestos de trabajo virtuales</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">Suresh Thoppay, NetApp</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">Los usuarios consumen VDS para escritorios dedicados, escritorios compartidos y aplicaciones remotas. VDS proporciona eventos con secuencias de comandos para automatizar la administración de aplicaciones en los escritorios y reduce el número de imágenes que se van a gestionar.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS proporciona un único portal de gestión para gestionar las puestas en marcha de entornos de cloud público y privado.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">Valor para el cliente</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">La explosión de personal remoto en 2020 ha cambiado los requisitos de continuidad del negocio. Los departamentos DE TECNOLOGÍA deben hacer frente a nuevos retos para aprovisionar con rapidez puestos de trabajo virtuales y, por tanto, requerir agilidad de aprovisionamiento, gestión remota y las ventajas del TCO de un cloud híbrido que facilita el aprovisionamiento de recursos en las instalaciones y en el cloud. Necesitan una solución de cloud híbrido que:</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">Aborda la realidad del espacio de trabajo post-COVID para hacer posibles modelos de trabajo flexibles con dinámica global</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">Permite el trabajo en turnos simplificando y acelerando la implementación de entornos de trabajo para todos los empleados, desde trabajadores de tareas hasta usuarios avanzados</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">Moviliza a su personal proporcionando recursos de infraestructura de puestos de trabajo virtuales seguros y enriquecidos independientemente de la ubicación física</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">Simplifica la puesta en marcha del cloud híbrido</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">Automatiza y simplifica la gestión de la reducción de riesgos</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">Siguiente: Casos de uso</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">Cuando se utiliza H610C o H615C, la licencia de la GPU debe obtenerse de los partners de NVIDIA autorizados a revender las licencias.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">Gestión de licencias de NVIDIA</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">localizador de partners</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">Cuando se utiliza H610C o H615C, la licencia de la GPU debe obtenerse de los partners de NVIDIA autorizados a revender las licencias. Puede encontrar partners de NVIDIA con el<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. Busque competencias como GPU virtual (vGPU) o Tesla.</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">El software NVIDIA vGPU está disponible en cuatro ediciones:</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">PC virtual DE GRID de NVIDIA (GRID VPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">Aplicaciones virtuales DE GRID de NVIDIA (VAPPS DE GRID)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">Estación de trabajo de centro de datos virtual Quadro (Quadro VDWS) NVIDIA</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">Virtual ComputeServer de NVIDIA (vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">PC virtual DE GRID</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">Este producto es ideal para usuarios que desean un escritorio virtual que proporcione una gran experiencia de usuario para aplicaciones de Microsoft Windows, exploradores, vídeo de alta definición y soporte para varios monitores. El PC virtual GRID de NVIDIA ofrece una experiencia nativa en un entorno virtual, lo que le permite ejecutar todas las aplicaciones de su PC a pleno rendimiento.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">Aplicaciones virtuales GRID</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">LAS vApps DE GRID se utilizan para organizaciones que implementan un host de sesión de Escritorio remoto (RDSH) u otras soluciones basadas en sesiones o en streaming de aplicaciones. Diseñado para ofrecer aplicaciones de Microsoft Windows a todo rendimiento, los escritorios RDSH alojados en Windows Server también son compatibles con GRID vApps.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Estación de trabajo Quadro Virtual Data Center</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">Esta edición es ideal para diseñadores generales y de gama alta que utilizan potentes herramientas de creación de contenido en 3D como Dassault CATIA, SOLIDWORKS, 3Dexsite, Siemens NX, PTC Creo, Schlumberger Petrel o Autodesk Maya. NVIDIA Quadro VDWS permite a los usuarios acceder a sus aplicaciones gráficas profesionales con todas las características y el rendimiento en cualquier lugar de cualquier dispositivo.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">Virtual ComputeServer de NVIDIA</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">Muchas organizaciones ejecutan cargas de trabajo de servidores con un uso intensivo de la computación, como la inteligencia artificial (IA), el aprendizaje profundo (DL) y la ciencia de los datos. Para estos casos de uso, el software NVIDIA vComputeServer virtualiza la GPU NVIDIA, lo que acelera las cargas de trabajo de servidores con un uso intensivo de recursos informáticos con características como el código de corrección de errores, la retirada de páginas, la paridad a punto en NVLink y multi-vGPU.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Una licencia Quadro VDWS permite utilizar GRID VPC y NVIDIA vComputeServer.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">Siguiente: Implementación</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">Las estaciones de trabajo gráficas suelen utilizarse en sectores como la fabricación, la sanidad, la energía, los medios de comunicación y el entretenimiento, la educación, y así sucesivamente. La movilidad suele ser limitada a aplicaciones que hacen un uso intensivo de los gráficos.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">Soluciones para el sector</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">Para abordar el problema de la movilidad, Virtual Desktop Services proporciona un entorno de escritorio para todo tipo de trabajadores, desde trabajadores de tareas a usuarios expertos, utilizando recursos de hardware en el cloud o con NetApp HCI, incluidas opciones para configuraciones de GPU flexibles. VDS permite a los usuarios acceder a su entorno de trabajo desde cualquier lugar con portátiles, tablets y otros dispositivos móviles.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">Para ejecutar cargas de trabajo de fabricación con software como ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3ds Max, Dassault Systèmes SOLIDWORKS, Dassault Systèmes CATIA, PTC Creo, Siemens PLM NX, etc. En la siguiente tabla figuran las GPU disponibles en varios clouds (a fecha de enero de 2021).</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">Modelo GPU</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute (GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services (AWS)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">En las instalaciones (NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">P100 DE NVIDIA</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">También están disponibles sesiones de escritorio compartidas con otros usuarios y escritorios personales dedicados. Los escritorios virtuales pueden tener de una a cuatro GPU o pueden utilizar GPU parciales con NetApp HCI. NVIDIA T4 es una tarjeta GPU versátil que puede hacer frente a las demandas de una amplia gama de cargas de trabajo de usuarios. Cada tarjeta GPU de NetApp HCI H615C tiene 16 GB de memoria de búfer de trama y tres tarjetas por servidor. El número de usuarios que se puede alojar en un único servidor H615C depende de la carga de trabajo del usuario.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">Usuarios/servidor</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">Luz (4 GB)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">Medio (8 GB)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">Pesado (16 GB)</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">Para determinar el tipo de usuario, ejecute la herramienta de perfilador de GPU mientras los usuarios trabajan con aplicaciones que realizan tareas típicas. El perfilador de GPU captura las demandas de memoria, el número de pantallas y la resolución que los usuarios necesitan. A continuación, puede elegir el perfil vGPU que satisfaga sus necesidades.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">Los puestos de trabajo virtuales con GPU pueden admitir una resolución de visualización de hasta 8K y la utilidad nView puede dividir un único monitor en regiones para trabajar con diferentes conjuntos de datos.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">Con el almacenamiento de archivos de ONTAP, puede obtener las siguientes ventajas:</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">Un espacio de nombres único que puede aumentar hasta 20 PB de almacenamiento con 400 000 millones de archivos sin necesidad de mucha intervención administrativa</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">Un espacio de nombres que puede extenderse por todo el mundo con una caché global de archivos</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">Multi-tenancy seguro con almacenamiento gestionado de NetApp</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">La migración de datos inactivos a almacenes de objetos con FabricPool de NetApp</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">Rápida estadística de archivos con análisis del sistema de archivos</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">Escalar un clúster de almacenamiento hasta 24 nodos aumentando la capacidad y el rendimiento</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">La capacidad de controlar el espacio de almacenamiento usando cuotas y un rendimiento garantizado con límites de calidad de servicio</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">Proteja los datos mediante el cifrado</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">Cumplimiento de una amplia gama de requisitos de protección de datos y cumplimiento de normativas</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">Ofrecer opciones flexibles de continuidad empresarial</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">Como parte de la implementación, puede elegir el método de servicios de archivos para alojar el perfil de usuario, los datos compartidos y la carpeta de la unidad principal. Las opciones disponibles son File Server, Azure Files o Azure NetApp Files. Sin embargo, después de la implementación, puede modificar esta opción con la herramienta Command Center para que apunte a cualquier recurso compartido de SMB. El alojamiento tiene varias ventajas con ONTAP de NetApp.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">Gestión de datos</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">El alojamiento tiene varias ventajas con ONTAP de NetApp</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">Cambiar la capa de datos</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">Como parte de la implementación, puede elegir el método de servicios de archivos para alojar el perfil de usuario, los datos compartidos y la carpeta de la unidad principal. Las opciones disponibles son File Server, Azure Files o Azure NetApp Files. Sin embargo, después de la implementación, puede modificar esta opción con la herramienta Command Center para que apunte a cualquier recurso compartido de SMB. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. Para saber cómo cambiar el recurso compartido de SMB, consulte<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">Caché de archivos global</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">Cuando los usuarios se distribuyen entre varios sitios dentro de un espacio de nombre global, la caché de archivos global puede ayudar a reducir la latencia de los datos a los que se accede con frecuencia. La implementación de caché global de archivos se puede automatizar mediante una recopilación de datos y eventos programados. La caché de archivos global gestiona las cachés de lectura y escritura localmente y mantiene los bloqueos de archivos entre ubicaciones. La caché de archivos global puede funcionar con cualquier servidor de archivos SMB, incluido Azure NetApp Files.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">La caché global de archivos requiere lo siguiente:</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">Servidor de gestión (servidor de gestión de licencias)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">Núcleo</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">Extremo con suficiente capacidad de disco para almacenar en caché los datos</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">Documentación GFC</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">Para descargar el software y calcular la capacidad de la caché en disco de Edge, consulte<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">Para nuestra validación, implementamos los recursos principales y de gestión en la misma máquina virtual en Azure y recursos periféricos en NetApp HCI. Tenga en cuenta que el núcleo es donde se requiere acceso a datos de gran volumen y el perímetro es un subconjunto del núcleo. Después de instalar el software, debe activar la licencia antes de utilizarla. Para ello, lleve a cabo los siguientes pasos:</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">En la sección Configuración de licencia, utilice el enlace haga clic aquí para completar la activación de la licencia. A continuación, registre el núcleo.</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">Proporcione la cuenta de servicio que se utilizará para la caché de archivos global. Para conocer los permisos necesarios para esta cuenta, consulte<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">Agregue un nuevo servidor de archivos back-end y proporcione el nombre o la IP del servidor de archivos.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">En el borde, la unidad de caché debe tener la letra de unidad D. Si no lo hace, utilice diskpart.exe para seleccionar el volumen y cambiar la letra de la unidad. Regístrese en el servidor de licencias como EDGE.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">Si la configuración automática de núcleo está habilitada, la información principal se recupera automáticamente del servidor de administración de licencias.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">Desde cualquier equipo cliente, los administradores que solían acceder al recurso compartido en el servidor de archivos pueden acceder a él con GFC Edge mediante UNC Path<block ref="4fe16e12c05517e32740fd6ba0c0691f" prefix=" " category="inline-code"></block>. Los administradores pueden incluir esta ruta de acceso en el script de inicio de sesión de usuario o GPO para la asignación de unidades de usuarios en la ubicación perimetral.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">Para proporcionar acceso transparente a los usuarios de todo el mundo, un administrador puede configurar Microsoft Distributed Filesystem (DFS) con enlaces que apuntan a recursos compartidos de servidores de archivos y a ubicaciones perimetrales.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">Cuando los usuarios inician sesión con credenciales de Active Directory basadas en las subredes asociadas al sitio, el cliente DFS utiliza el vínculo apropiado para tener acceso a los datos.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">Los iconos de archivo cambian dependiendo de si un archivo está almacenado en caché; los archivos que no están almacenados en caché tienen una X gris en la esquina inferior izquierda del icono. Cuando un usuario de una ubicación perimetral accede a un archivo, dicho archivo se almacena en caché y el icono cambia.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">Cuando un archivo está abierto y otro usuario intenta abrir el mismo archivo desde una ubicación de borde, se le solicita al usuario la siguiente selección:</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">Si el usuario selecciona la opción de recibir una notificación cuando la copia original está disponible, se notifica al usuario de la siguiente manera:</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Vídeo sobre implementación de Talon y Azure NetApp Files</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">Para obtener más información, consulte este tema<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">Backup de SaaS</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">VDS de NetApp proporciona protección de datos para Salesforce y Microsoft Office 365, incluidos Exchange, SharePoint y Microsoft OneDrive. La figura siguiente muestra cómo VDS de NetApp proporciona SaaS Backup para estos servicios de datos.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Para ver una demostración de la protección de datos de Microsoft Office 365, consulte<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Para ver una demostración de la protección de datos de Salesforce, consulte<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">Siguiente: Gestión de operaciones</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">Normalmente, las GPU se utilizan para la visualización gráfica (renderización) mediante cálculos aritméticos repetitivos. Esta funcionalidad de computación repetitiva se utiliza a menudo para casos de uso de IA y aprendizaje profundo.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">Consideraciones sobre la GPU</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">Para aplicaciones con un uso intensivo de gráficos, Microsoft Azure ofrece la serie NV basada en la tarjeta NVIDIA Tesla M60 con una a cuatro GPU por máquina virtual. Cada tarjeta NVIDIA Tesla M60 incluye dos GPU basadas en Maxwell, cada una con 8 GB de memoria GDDR5 para un total de 16 GB.</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">Se incluye una licencia de NVIDIA con la serie NV.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">Con NetApp HCI, la GPU H615C contiene tres tarjetas NVIDIA Tesla T4. Cada tarjeta NVIDIA Tesla T4 dispone de una GPU basada en Touring con 16 GB de memoria GDDR6. Si se utiliza en un entorno VMware vSphere, los equipos virtuales pueden compartir la GPU y cada equipo virtual tiene una memoria de búfer de trama dedicada. El seguimiento de rayos está disponible con las GPU en la NetApp HCI H615C para generar imágenes realistas, incluidos reflejos de luz. Tenga en cuenta que debe tener un servidor de licencias de NVIDIA con una licencia para las funciones de GPU.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">Para utilizar la GPU, debe instalar el controlador apropiado, que puede descargarse desde el portal de licencias de NVIDIA. En un entorno de Azure, el controlador NVIDIA está disponible como extensión del controlador GPU. A continuación, las políticas de grupo de la siguiente captura de pantalla deben actualizarse para utilizar hardware GPU para sesiones de servicio de escritorio remoto. Debe priorizar el modo de gráficos H.264 y activar la funcionalidad de codificador.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">Valide la supervisión del rendimiento de la GPU con el Administrador de tareas o utilizando la interfaz de línea de comandos nvidia-smi cuando ejecute muestras WebGL. Asegúrese de que se están consumiendo recursos de GPU, memoria y codificador.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">Para asegurarse de que la máquina virtual se despliegue en NetApp HCI H615C con Virtual Desktop Service, defina un sitio con el recurso de clúster de vCenter que tenga hosts H615C. La plantilla de VM debe tener conectado el perfil vGPU requerido.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">En los entornos de varias sesiones compartidos, considere la posibilidad de asignar varios perfiles homogéneos de vGPU. Sin embargo, en el caso de aplicaciones gráficas profesionales de gama alta, es mejor hacer que cada equipo virtual esté dedicado a un usuario para mantener las máquinas virtuales aisladas.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">El procesador de GPU puede controlarse mediante una política de calidad de servicio, y cada perfil de vGPU puede tener búferes de trama dedicados. Sin embargo, el codificador y el decodificador son compartidos para cada tarjeta. La ubicación de un perfil vGPU en una tarjeta de GPU está controlada por la política de asignación de GPU del host de vSphere, que puede hacer hincapié en el rendimiento (propagación de VM) o la consolidación (grupo de VM).</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">Siguiente: Soluciones para el sector.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">La infraestructura de puestos de trabajo virtuales híbrida con VDS de NetApp permite a los proveedores de servicios y a los administradores de puestos de trabajo virtuales empresariales ampliar fácilmente los recursos a otro entorno de cloud sin que ello afecte a los usuarios. Al disponer de recursos en las instalaciones en NetApp HCI, se obtiene un mejor control de los recursos de GPU y se pueden ampliar los nodos de computación o de almacenamiento según se requiera.</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">La infraestructura de puestos de trabajo virtuales híbrida con VDS de NetApp permite a los proveedores de servicios y a los administradores de puestos de trabajo virtuales empresariales ampliar fácilmente los recursos a otro entorno de cloud sin que ello afecte a los usuarios. Contar con recursos en las instalaciones proporciona un mejor control de los recursos y ofrece una amplia selección de opciones (computación, GPU, almacenamiento y red) para satisfacer la demanda.</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">Desbordamiento del cloud por el aumento en la demanda de aplicaciones y puestos de trabajo remotos</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">Reducir el TCO en aplicaciones y puestos de trabajo remotos de larga duración alojándolos en las instalaciones con almacenamiento flash y recursos GPU</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">Facilidad de gestión de puestos de trabajo y aplicaciones remotos en todos los entornos cloud</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">Disfrute de aplicaciones y puestos de trabajo remotos usando un modelo de software como servicio con recursos en las instalaciones</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">Arquitectos de EUC/VDI que quieren comprender los requisitos de una instancia de VDS híbrida</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">Los partners de NetApp que desean ayudar a sus clientes con sus necesidades de aplicaciones y puesto de trabajo remoto</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">Clientes de NetApp HCI existentes que desean atender las demandas de las aplicaciones y los puestos de trabajo remotos</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">Siguiente: Descripción general del servicio de puestos de trabajo virtuales de NetApp</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">Funciones de ONTAP para el servicio de escritorios virtuales.</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">Funciones de ONTAP para el servicio de escritorios virtuales</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">Las siguientes funciones de ONTAP hacen que resulte atractiva la elección para su uso con un servicio de escritorios virtuales.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">*Sistema de archivos de escalado horizontal.* los volúmenes ONTAP FlexGroup pueden crecer hasta más de 20 PB de tamaño y pueden contener más de 400 mil millones de archivos dentro de un solo espacio de nombres. El clúster puede contener hasta 24 nodos de almacenamiento, cada uno con un número flexible de tarjetas de interfaz de red en función del modelo utilizado.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">Los escritorios virtuales del usuario, las carpetas principales, los contenedores de perfiles de usuario, los datos compartidos, etc. pueden crecer en función de la demanda sin preocuparse por las limitaciones del sistema de archivos.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">*Análisis del sistema de archivos.* puede utilizar la herramienta XCP para obtener información detallada sobre los datos compartidos. Con ONTAP 9.8 o ActiveIQ Unified Manager, puede consultar y recuperar fácilmente la información de metadatos de archivos e identificar los datos inactivos.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">*Organización en niveles en el cloud.* puede realizar la migración de datos inactivos a un almacén de objetos en la nube o a cualquier almacenamiento compatible con S3 del centro de datos.</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">*Versiones de archivo.* los usuarios pueden recuperar archivos protegidos por copias Snapshot de ONTAP de NetApp. Las copias Snapshot de ONTAP ocupan muy poco espacio, ya que solo registran los bloques cambiados.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">*Espacio de nombre global.* la tecnología ONTAP FlexCache permite almacenar en caché de forma remota el almacenamiento de archivos, lo que facilita la administración de datos compartidos entre ubicaciones que contienen sistemas de almacenamiento ONTAP.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">*Soporte multi-tenancy seguro.* Un único clúster de almacenamiento físico puede presentarse como múltiples matrices de almacenamiento virtual cada una con sus propios volúmenes, protocolos de almacenamiento, interfaces de red lógicas, dominio de identidad y autenticación, usuarios de administración, etc. Por lo tanto, es posible compartir la cabina de almacenamiento en varias unidades de negocio o entornos, como pruebas, desarrollo y producción.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">Para garantizar el rendimiento, puede utilizar la calidad de servicio adaptativa para establecer niveles de rendimiento que se basan en el espacio utilizado o asignado y puede controlar la capacidad de almacenamiento mediante cuotas.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">*Integración de VMware.* Herramientas de ONTAP para VMware vSphere proporciona un complemento de vCenter para aprovisionar almacenes de datos, implementar prácticas recomendadas de host de vSphere y supervisar recursos de ONTAP.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP admite API de vStorage para la integración de cabinas (VAAI) para descargar las operaciones SCSI/archivo en la cabina de almacenamiento. ONTAP también admite API de vStorage para compatibilidad con Storage Awareness (VASA) y Virtual Volumes para protocolos de bloques y archivos.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">El plugin de SnapCenter para VMware vSphere ofrece un método sencillo de realizar backups y restaurar máquinas virtuales con la función Snapshot en una cabina de almacenamiento.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager proporciona visibilidad completa de la red de almacenamiento en un entorno de vSphere. Los administradores pueden identificar fácilmente cualquier problema de latencia que pueda producirse en entornos de puestos de trabajo virtuales alojados en ONTAP.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">*Conformidad de seguridad.* con ActiveIQ Unified Manager, puede supervisar múltiples sistemas ONTAP con alertas por cualquier infracción de directivas.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">*Compatibilidad multiprotocolo.* ONTAP admite bloques (iSCSI, FC, FCoE y NVMe/FC), archivos (NFSv3, NFSv4.1, SMB2.x y SMB3.x) y protocolos de almacenamiento de objetos (S3).</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">*Compatibilidad con automatización.* ONTAP proporciona módulos API REST, Ansible y PowerShell para automatizar tareas con el portal de administración VDS.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">Siguiente: Gestión de datos</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI es una infraestructura de cloud híbrido que consta de una combinación de nodos de almacenamiento y nodos de computación. Está disponible en función del modelo, como unidad de dos racks o de un solo rack. La instalación y configuración necesarias para poner en marcha máquinas virtuales se automatizan con el motor de puesta en marcha de NetApp (NDE). Los clústeres de computación se gestionan con VMware vCenter y los clústeres de almacenamiento se gestionan con el plugin de vCenter puesto en marcha con NDE.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">Información general de NetApp HCI</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI es una infraestructura de cloud híbrido que consta de una combinación de nodos de almacenamiento y nodos de computación. Está disponible en función del modelo, como unidad de dos racks o de un solo rack. La instalación y configuración necesarias para poner en marcha máquinas virtuales se automatizan con el motor de puesta en marcha de NetApp (NDE). Los clústeres de computación se gestionan con VMware vCenter y los clústeres de almacenamiento se gestionan con el plugin de vCenter puesto en marcha con NDE. Como parte de NDE, se pone en marcha una máquina virtual de gestión, denominada mNode.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI gestiona las siguientes funciones:</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">Actualizaciones de versiones</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">Llevar eventos a vCenter</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">Gestión del complemento de vCenter</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">Un túnel VPN para soporte</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">El recopilador Active IQ de NetApp</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">La extensión de los servicios cloud de NetApp a las instalaciones, lo cual permite una infraestructura de cloud híbrido. En la siguiente figura, se muestran los componentes HCI.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">Nodos de almacenamiento</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">Los nodos de almacenamiento están disponibles en una unidad de rack de media anchura o de anchura completa. En primer lugar se requiere un mínimo de cuatro nodos de almacenamiento y un clúster se puede ampliar hasta 40 nodos. Un clúster de almacenamiento se puede compartir entre varios clústeres de computación. Todos los nodos de almacenamiento contienen una controladora de caché para mejorar el rendimiento de escritura. Un único nodo proporciona 50 000 o 100 000 IOPS a un tamaño de bloque de 4 KB.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">Los nodos de almacenamiento de NetApp HCI ejecutan el software NetApp Element, que proporciona límites de calidad de servicio mínimos, máximos y de ráfaga. El clúster de almacenamiento admite una combinación de nodos de almacenamiento, aunque un nodo de almacenamiento no puede superar un tercio de la capacidad total.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">Nodos de computación</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">Guía de compatibilidad de VMware</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp admite su almacenamiento conectado a cualquier servidor informático que figure en el<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">Los nodos de computación están disponibles en tamaño de media anchura, de anchura completa y de dos unidades de rack. El NetApp HCI H410C y H610C están basados en procesadores escalables de Intel Skylake. El sistema H615C se basa en los procesadores Intel Cascade Lake escalables de segunda generación. Hay dos modelos de computación que contienen GPU: La H610C contiene dos tarjetas NVIDIA M10 y la H615C contiene tres tarjetas NVIDIA T4.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">El NVIDIA T4 cuenta con 40 núcleos RT que proporcionan la potencia de computación necesaria para ofrecer un seguimiento de rayos en tiempo real. El mismo modelo de servidor utilizado por diseñadores e ingenieros ahora también puede ser utilizado por los artistas para crear imágenes fotorrealistas que presenta un rebote ligero de las superficies como lo haría en la vida real. Esta GPU compatible con RTX produce un rendimiento de rastreo de rayos en tiempo real de hasta cinco rayos Giga por segundo. La NVIDIA T4, al combinarse con el software Quadro Virtual Data Center Workstation (Quadro VDWS), permite a los artistas crear diseños fotorrealistas con sombras, reflejos y refracciones precisas en cualquier dispositivo desde cualquier ubicación.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Los núcleos tensores permiten ejecutar cargas de trabajo de inferencia de aprendizaje profundo. Cuando se ejecutan estas cargas de trabajo, una NVIDIA T4 con Quadro VDWS puede funcionar hasta 25 veces más rápido que un equipo virtual basado en un servidor solo de CPU. Un NetApp H615C con tres tarjetas NVIDIA T4 en una unidad de rack es una solución ideal para cargas de trabajo con un uso intensivo de gráficos y de computación.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">La siguiente figura enumera las tarjetas GPU NVIDIA y compara sus características.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">La GPU M10 sigue siendo la mejor solución de TCO para casos de uso de trabajadores formados. Sin embargo, la T4 es una excelente alternativa cuando quiere estandarizar en una GPU que se puede utilizar en múltiples casos de uso, como estaciones de trabajo virtuales, rendimiento gráfico, renderizado interactivo en tiempo real e inferencia. Con T4, SE pueden beneficiar de los mismos recursos de GPU para ejecutar cargas de trabajo mixtas―por ejemplo, ejecutar VDI durante el día y reasignar los recursos para ejecutar cargas de trabajo informáticas nocturnas.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">El nodo de computación H610C es dos unidades de rack, el tamaño de H615C es una unidad de rack y consume menos energía. H615C admite codificación H.264 y H.265 (codificación de vídeo de alta eficiencia [HEVC]) 4:4:4 y decodificación. También soporta el cada vez más integrado VP9 descodificador; incluso el paquete contenedor WebM que ofrece YouTube utiliza el códec VP9 para vídeo.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">La cantidad de nodos de un clúster de computación está dictada por VMware; actualmente, es 96 con VMware vSphere 7.0 Update 1. Se admite la mezcla de diferentes modelos de nodos de computación en un clúster cuando se habilita la función Enhanced vMotion Compatibility (EVC).</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">Siguiente: NVIDIA Licensing</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">Vídeos y demostraciones: Red Hat OpenShift con NetApp</block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">En el siguiente vídeo se muestran algunas de las funciones documentadas en este documento:</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">Vídeo: Acelere el desarrollo de software con Astra Control y la tecnología FlexClone de NetApp</block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">Vídeo: Aproveche Astra Control de NetApp para realizar análisis y restauración de su aplicación tras una mortem</block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="list-text"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">Vídeo: Protección de datos en canalización CI/CD con Astra Control</block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="list-text"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">Vídeo: Migración de cargas de trabajo con Astra Control Center - Red Hat OpenShift con NetApp</block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="list-text"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">Vídeo: Migración de cargas de trabajo con Astra Trident y SnapMirror: Red Hat OpenShift con NetApp</block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="list-text"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">Vídeo: Instalación de OpenShift Virtualization - Red Hat OpenShift con NetApp</block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="list-text"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">Vídeo: Implementación de una máquina virtual con OpenShift Virtualization - Red Hat OpenShift con NetApp</block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="list-text"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">Vídeo: NetApp HCI para Red Hat OpenShift en implementación de virtualización de Red Hat</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">Siguiente: Información adicional: Red Hat OpenShift con NetApp.</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform proporciona una base integrada para crear, implementar y escalar una nube segura y fiable de OpenStack privada.</block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="doc">OpenShift en Red Hat OpenStack Platform</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP es un cloud de infraestructura como servicio (IaaS) implementado por una colección de servicios de control que gestionan los recursos de computación, almacenamiento y redes. El entorno se gestiona mediante una interfaz web que permite a los administradores y usuarios controlar, aprovisionar y automatizar los recursos de OpenStack. Además, la infraestructura de OpenStack se consigue gracias a una amplia interfaz de línea de comandos y API que ofrece funcionalidades de automatización completas para administradores y usuarios finales.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">El proyecto OpenStack es un proyecto comunitario de rápido desarrollo que proporciona lanzamientos actualizados cada seis meses. Inicialmente, Red Hat OpenStack Platform se mantuvo al ritmo de este ciclo de lanzamiento al publicar una nueva versión junto con cada versión anterior y proporcionar soporte a largo plazo para cada tercera versión. Recientemente, con la versión OSP 16.0 (basada en OpenStack Train), Red Hat ha optado por no mantenerse al ritmo de los números de versión, sino por incorporar nuevas funciones a las subversiones. La versión más reciente es Red Hat OpenStack Platform 16.1, que incluye funciones avanzadas con puerto de las versiones anteriores de Ussuri y Victoria.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Sitio web de Red Hat OpenStack Platform</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">Para obtener más información sobre OSP, consulte<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">Servicios OpenStack</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">Los servicios de la plataforma OpenStack se ponen en marcha como contenedores, lo cual aísla los servicios entre sí y permite una fácil actualización. La plataforma OpenStack utiliza un conjunto de contenedores integrados y gestionados con Kolla. La implementación de los servicios se realiza extrayendo imágenes de contenedor del Portal personalizado de Red Hat. Estos contenedores de servicios se gestionan mediante el comando Podman y se implementan, configuran y mantienen con Red Hat OpenStack Director.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">Servicio</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">Nombre del proyecto</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">Consola</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">Horizonte</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">Consola basada en navegador web que utiliza para gestionar los servicios de OpenStack.</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">Identidad</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">Servicio centralizado para autenticación y autorización de servicios de OpenStack y para gestionar usuarios, proyectos y funciones.</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">Redes OpenStack</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">Neutrones</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">Proporciona conectividad entre las interfaces de servicios de OpenStack.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">Almacenamiento en bloques</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">Gestiona volúmenes de almacenamiento en bloques persistentes para máquinas virtuales (VM).</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="cell">Informática</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">Nova</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">Gestiona y aprovisiona máquinas virtuales que se ejecutan en nodos de computación.</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">De un vistazo</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">Servicio de registro que se utiliza para almacenar recursos como imágenes de equipo virtual y snapshots de volúmenes.</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">Almacenamiento de objetos</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Swift</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">Permite a los usuarios almacenar y recuperar archivos y datos arbitrarios.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">Telemetría</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometer</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">Proporciona mediciones de uso de recursos cloud.</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">Calor</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">Motor de orquestación basado en plantillas que admite la creación automática de pilas de recursos.</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Diseño de red</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">La solución Red Hat OpenShift con NetApp utiliza dos switches de datos para proporcionar conectividad de datos principal a 25 Gbps. También usa dos switches de gestión adicionales que proporcionan conectividad a 1 Gbps para la gestión en banda de los nodos de almacenamiento y la gestión fuera de banda para la funcionalidad de IPMI.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director requiere la funcionalidad de IPMI para poner en marcha Red Hat OpenStack Platform usando el irónico servicio de aprovisionamiento completo.</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">Requisitos de VLAN</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">Red Hat OpenShift con NetApp se ha diseñado para separar de forma lógica el tráfico de red para distintos fines mediante redes de área local virtual (VLAN). Esta configuración se puede ampliar para satisfacer las demandas del cliente o para proporcionar un aislamiento adicional para servicios de red específicos. La siguiente tabla enumera las VLAN necesarias para implementar la solución mientras valida la solución en NetApp.</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">ID DE VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">Red de gestión fuera de banda</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">La red que se usa para la gestión de nodos físicos y el servicio IPMI para irónica.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">De almacenamiento de datos</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Red que se usa para los nodos de las controladoras de manera que se puedan asignar volúmenes directamente para admitir servicios de infraestructura como Swift.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">Almacenamiento Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">Red que se utiliza para asignar y asociar los volúmenes de bloques directamente a las instancias virtuales implementadas en el entorno.</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">API interna</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">Red utilizada para la comunicación entre los servicios de OpenStack mediante la comunicación API, los mensajes RPC y la comunicación de bases de datos.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">Inquilino</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron proporciona a cada cliente sus propias redes a través de túneles a través de VXLAN. El tráfico de red se aísla dentro de cada red de inquilino. Cada red de arrendatarios tiene asociada una subred IP, y los espacios de nombres de red significan que varias redes de arrendatario pueden utilizar el mismo rango de direcciones sin causar conflictos.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">Gestión del almacenamiento</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage (Swift) utiliza esta red para sincronizar objetos de datos entre nodos de réplica participantes. El servicio proxy actúa como la interfaz intermedia entre las solicitudes del usuario y la capa de almacenamiento subyacente. El proxy recibe solicitudes entrantes y localiza la réplica necesaria para recuperar los datos solicitados.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director proporciona el arranque PXE como parte del irónico servicio de aprovisionamiento de «bare metal» para orquestar la instalación del OSP Overcloud.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">Externa</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">Red disponible públicamente, que aloja OpenStack Dashboard (Horizon) para la gestión gráfica y permite llamadas de API públicas para gestionar los servicios de OpenStack.</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">Red de gestión en banda</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">Proporciona acceso a funciones de administración del sistema, como acceso SSH, tráfico DNS y tráfico del protocolo de tiempo de redes (NTP). Esta red también actúa como puerta de enlace para los nodos que no pertenecen a la controladora.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">Recursos de soporte de infraestructura de red</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">Debe existir la siguiente infraestructura antes de la implementación de OpenShift Container Platform:</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">Al menos un servidor DNS que proporciona una resolución completa de nombres de host.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">Al menos tres servidores NTP que pueden mantener la sincronización temporal de los servidores de la solución.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(Opcional) conectividad saliente a Internet para el entorno OpenShift.</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">Mejores prácticas para las instalaciones de producción</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">Esta sección enumera varias prácticas recomendadas que una organización debe tener en cuenta antes de implementar esta solución en la producción.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">Implemente OpenShift en un cloud privado de OSP con al menos tres nodos de computación</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">La arquitectura verificada que se describe en este documento presenta la puesta en marcha mínima de hardware adecuada para las operaciones de alta disponibilidad al poner en marcha tres nodos de controladora OSP y dos nodos de computación OSP. Esta arquitectura garantiza una configuración tolerante a fallos en la que los dos nodos de computación puedan iniciar instancias virtuales y los equipos virtuales puestos en marcha puedan migrar entre los dos hipervisores.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Puesto que Red Hat OpenShift se implementa inicialmente con tres nodos maestros, una configuración de dos nodos podría provocar que al menos dos maestros ocuparan el mismo nodo, lo que puede provocar una posible interrupción en OpenShift si ese nodo específico deja de estar disponible. Por lo tanto, es una práctica recomendada de Red Hat implementar al menos tres nodos de computación OSP para que los maestros de OpenShift se puedan distribuir uniformemente y la solución reciba un grado añadido de tolerancia a fallos.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">Configurar la afinidad del host/equipo virtual</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">La distribución de los maestros de OpenShift a través de varios nodos de hipervisor se puede lograr habilitando la afinidad de VM/host.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">La afinidad es una forma de definir reglas para un conjunto de VM y/o hosts que determinan si los VM se ejecutan en el mismo host o hosts del grupo o en hosts diferentes. Se aplica a los equipos virtuales mediante la creación de grupos de afinidad que constan de equipos virtuales y/o hosts con un conjunto de parámetros y condiciones idénticos. En función de si los equipos virtuales de un grupo de afinidad se ejecutan en el mismo host o hosts del grupo o por separado en hosts diferentes, los parámetros del grupo de afinidad pueden definir afinidad positiva o afinidad negativa. En Red Hat OpenStack Platform, se pueden crear e implementar reglas de afinidad y afinidad de host creando grupos de servidores y configurando filtros para que las instancias implementadas por Nova en un grupo de servidores se implementen en diferentes nodos informáticos.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">Un grupo de servidores tiene un máximo predeterminado de 10 instancias virtuales para las que puede administrar la colocación. Esto se puede modificar actualizando las cuotas predeterminadas para Nova.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">Existe un límite de afinidad/afinidad específica para los grupos de servidores OSP; si no hay suficientes recursos para implementar en nodos separados o no hay suficientes recursos para permitir el uso compartido de nodos, el equipo virtual no arranca.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">¿Cómo puedo configurar Affinity y Anti-Affinity para las instancias de OpenStack?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">Para configurar grupos de afinidad, consulte<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">Utilice un archivo de instalación personalizado para la implementación de OpenShift</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI facilita la implementación de los clústeres de OpenShift a través del asistente interactivo que se ha tratado anteriormente en este documento. Sin embargo, es posible que deba cambiar algunos valores predeterminados como parte de una implementación de clúster.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift instalación de un clúster en OpenStack con personalizaciones</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">En estos casos, puede ejecutar y ejecutar el asistente sin poner en marcha inmediatamente un clúster; en su lugar, crea un archivo de configuración a partir del cual el clúster puede ponerse en marcha posteriormente. Esto resulta muy útil si necesita cambiar cualquier valor predeterminado de IPI o si desea implementar varios clústeres idénticos en su entorno para otros usos como multi-tenancy. Para obtener más información acerca de cómo crear una configuración de instalación personalizada para OpenShift, consulte<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">Siguiente: Información general sobre el almacenamiento de NetApp.</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">Clone la aplicación para el análisis post mortem y restaure su aplicación en la canalización de CI/CD con Astra Control Center</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">Aproveche Astra Control de NetApp para realizar un análisis post-mortem y restaurar su aplicación</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">Siguiente: Información adicional: Red Hat OpenShift con NetApp</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">Validación de soluciones y casos prácticos: Red Hat OpenShift con NetApp</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">Los ejemplos proporcionados en esta página son validaciones de soluciones y casos de uso para Red Hat OpenShift con NetApp.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">Ponga en marcha una canalización CI/CD de Jenkins con almacenamiento persistente</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">Configuración de Multitenancy en Red Hat OpenShift con NetApp</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">OpenShift Virtualization de Red Hat con ONTAP de NetApp</block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="inline-link-macro">Advanced Cluster Management para Kubernetes en Red Hat OpenShift con NetApp</block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">Siguiente: Vídeos y demostraciones.</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="40ef898131b1ea0532620ff9cb12840c" category="summary">Esta página contiene un enlace a una demostración en vídeo de cómo utilizar Astra Trident para aprovisionar almacenamiento persistente en VMware Tanzu.</block>
  <block id="e0d2648924bbf778345db6153fddf464" category="doc">Utilice Astra Trident para aprovisionar almacenamiento persistente en VMware Tanzu</block>
  <block id="db70f2aaf062f269f45b2fe61ad31160" category="admonition">Esta demostración se grabó como una vista previa técnica utilizando la versión 1.3.1 de TKG y la versión 21.12 de Astra Control Center. Consulte la matriz de soporte para conocer las versiones oficiales compatibles.</block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">Siguiente: Información adicional: VMware Tanzania con NetApp.</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzania es una cartera de productos que permite a las empresas modernizar sus aplicaciones y la infraestructura en la que se ejecutan. La pila completa de funcionalidades de VMware Tanzu unifica los equipos de desarrollo y operaciones TECNOLÓGICAS en una única plataforma para adoptar la modernización tanto de sus aplicaciones como de su infraestructura de forma consistente en los entornos locales y de cloud híbrido para ofrecer continuamente mejor software en la producción.</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">Descripción general de VMware Tanzu</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">Cartera de VMware Tanzania</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Para conocer más sobre las distintas ofertas y sus capacidades en la cartera de tanzu, visite la documentación <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">En cuanto al catálogo de operaciones con Kubernetes de Tanzania, VMware cuenta con una amplia gama de implementaciones para Tanzania Kubernetes Grid, que aprovisiona y gestiona el ciclo de vida de los clústeres de Tanzania Kubernetes en una gran variedad de plataformas. Un clúster de Kubernetes tanzu es una distribución de Kubernetes completa creada y respaldada por VMware.</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp ha probado y validado la implementación y la interoperabilidad de los siguientes productos de la cartera Tanzania de VMware en sus laboratorios:</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="inline-link-macro">Grid de Kubernetes de VMware Tanzu (TKG)</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="inline-link-macro">Servicio Grid de VMware Tanzu Kubernetes (TKGS)</block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated (TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphere con Tanzu (pods de vSphere)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">Siguiente: Información general sobre los sistemas de almacenamiento de NetApp.</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">Visión general de VMware Tanzu Kubernetes Grid (TKG)</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">VMware Tanzu Kubernetes Grid, también conocido como TKG, le permite implementar clústeres de Kubernetes tanzu en entornos de cloud híbrido o de cloud público. TKG se instala como un clúster de gestión, que es el propio clúster de Kubernetes, que pone en marcha y opera los clústeres de Kubernetes de Tanzania. Estos clústeres de Kubernetes tanzu son los clústeres de Kubernetes de carga de trabajo en los que se implementa la carga de trabajo real.</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid se basa en algunos de los proyectos de la comunidad de prospección y extracción, y ofrece una plataforma de Kubernetes desarrollada, comercializada y con soporte de VMware. Además de la distribución de Kubernetes, Tanzu Kubernetes Grid proporciona complementos adicionales, que son servicios esenciales para el nivel de producción, como registro, balanceo de carga, autenticación, etc. VMware TKG con clúster de gestión se utiliza ampliamente en entornos vSphere 6.7 y, aunque es compatible, no se recomienda la puesta en marcha en entornos vSphere 7, debido a que TKGS tiene funcionalidades de integración nativas con vSphere 7.</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">VMware Tanzania Kubernetes Grid con clúster de gestión</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Si quiere más información sobre la cuadrícula de Tanzania Kubernetes, consulte la documentación <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>.</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">Según si la cuadrícula de Kubernetes tanzu se está instalando en las instalaciones en el clúster de vSphere o en entornos cloud, prepare e implemente Tanzu Kubernetes Grid siguiendo la guía de instalación <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>.</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Después de instalar el clúster de gestión para Tanzu Kubernetes Grid, despliegue los clústeres de usuarios o los clústeres de cargas de trabajo según sea necesario siguiendo la documentación <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>. El clúster de gestión VMware TKG requiere que se proporcione una clave SSH para la instalación y el funcionamiento de clústeres Tanzania Kubernetes. Esta clave se puede usar para iniciar sesión en los nodos del clúster mediante el<block ref="5ef871b8f1f696f9bb22de1dff45a81c" prefix=" " category="inline-code"></block> usuario.</block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">Para habilitar la integración de Trident con el sistema de almacenamiento ONTAP de NetApp, debe crear un back-end que permita la comunicación con el sistema de almacenamiento.</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">Configuración NFS de ONTAP de NetApp</block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">Para habilitar la integración de Trident con el sistema de almacenamiento ONTAP de NetApp mediante NFS, debe crear un back-end que permita la comunicación con el sistema de almacenamiento. Configuramos un back-end básico en esta solución, pero si busca opciones más personalizadas, visite la documentación <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>.</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">Cree una SVM en ONTAP</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">Inicie sesión en el Administrador del sistema de ONTAP, desplácese hasta almacenamiento &gt; Storage VMs y haga clic en Add.</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">Introduzca un nombre para la SVM, habilite el protocolo NFS, active la casilla de comprobación allow NFS Client Access y añada las subredes en las reglas de política de exportación para permitir el montaje de los volúmenes como VP en los clústeres de carga de trabajo.</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">Creación de SVM con NFS</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">Si está utilizando NAT'ed despliegues de clústeres de usuarios o clústeres de cargas de trabajo con NSX-T, debe agregar la subred Egress (en el caso de TKGS0 o la subred Floating IP (en el caso de TKGI) a las reglas de la política de exportación.</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">Proporcione los detalles de las LIF de datos y los detalles de la cuenta de administración de SVM y, a continuación, haga clic en Save.</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">LIF de datos de SVM y administración de SVM</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">Asigne los agregados a una SVM. Desplácese hasta almacenamiento &gt; Storage VMs, haga clic en los tres puntos junto a la SVM recién creada y, a continuación, haga clic en Edit. Active la casilla de comprobación Limit Volume Creation to Preferred local Tiers y adjunte los agregados necesarios.</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">Asignación del agregado de SVM</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">En caso de implementaciones en NAT de clústeres de usuarios o cargas de trabajo en los que se instale Trident, la solicitud de montaje del almacenamiento puede llegar desde un puerto no estándar debido a SNAT. De forma predeterminada, ONTAP solo permite las solicitudes de montaje del volumen cuando se origina desde el puerto raíz. Por lo tanto, inicie sesión en la CLI de ONTAP y modifique la configuración para permitir las solicitudes de montaje de puertos no estándares.</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">Cree back-ends y StorageClass</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">Para los sistemas ONTAP de NetApp que sirven NFS, cree un archivo de configuración de back-end en el host con backendName, managementLIF, dataLIF, svm, username, contraseña y otros detalles.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">Se recomienda definir el valor de backendName personalizado como una combinación de storageDriverName y DataLIF que sirve NFS para una identificación sencilla.</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">Ejecute el siguiente comando para crear el back-end de Trident.</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">Con el back-end creado, debe crear después una clase de almacenamiento. La siguiente definición de clase de almacenamiento de ejemplo resalta los campos necesarios y básicos. El parámetro<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Debe reflejar el controlador de almacenamiento desde el back-end de Trident recién creado.</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">Cree la clase de almacenamiento con el comando kubectl.</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">Con la clase de almacenamiento creada, debe crear la primera reclamación de volumen persistente (RVP). A continuación se proporciona una definición de PVC de muestra. Compruebe que la<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> el campo coincide con el nombre de la clase de almacenamiento que se acaba de crear. La definición de PVC se puede personalizar aún más según sea necesario, en función de la carga de trabajo que se vaya a aprovisionar.</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">Cree la RVP emitiendo el comando kubectl. La creación puede tardar un poco de tiempo, según el tamaño del volumen de backup que se esté creando, para que pueda ver el proceso a medida que finalice.</block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">Siguiente: Vídeos y demostraciones: VMware Tanzu con NetApp.</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Una vez que Astra Control Center gestiona las cargas de trabajo de las aplicaciones, puede configurar los ajustes de protección para esas cargas de trabajo.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">Proteja sus aplicaciones</block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">Crear una instantánea de aplicación</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">Una copia Snapshot de una aplicación crea una copia Snapshot de ONTAP y una copia de los metadatos de la aplicación que se pueden usar para restaurar o clonar la aplicación en un momento específico según esa copia Snapshot.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">Para tomar una instantánea de la aplicación, desplácese a la ficha aplicaciones &gt; gestionado y haga clic en la aplicación de la que desea realizar una copia snapshot. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en Snapshot.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="image-alt">Botón de instantánea de Astra Control Center</block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">Introduzca los detalles de la snapshot, haga clic en Siguiente y luego en Snapshot. La creación de la snapshot tarda aproximadamente un minuto y el estado cambia a disponible después de que se cree correctamente la snapshot.</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="image-alt">Astra Control Center crea una instantánea</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">Crear un backup de aplicación</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">Un backup de una aplicación captura el estado activo de la aplicación y la configuración de sus recursos de TI, los coloca en archivos y los almacena en un bloque de almacenamiento de objetos remotos.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="list-text">Para realizar la copia de seguridad y la restauración de las aplicaciones gestionadas en el Centro de control de Astra, debe configurar los ajustes de superusuario para los sistemas ONTAP de respaldo como requisito previo. Para ello, introduzca los comandos siguientes.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Para crear una copia de seguridad de la aplicación gestionada en Astra Control Center, desplácese a la ficha aplicaciones &gt; administradas y haga clic en la aplicación de la que desea realizar una copia de seguridad. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en copia de seguridad.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="image-alt">Botón de copia de seguridad de Astra Control Center</block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">Introduzca los detalles de la copia de seguridad, seleccione el bloque de almacenamiento de objetos donde se retengan los archivos de copia de seguridad, haga clic en Siguiente y, tras revisar los detalles, haga clic en Backup. Según el tamaño de la aplicación y los datos, el backup puede tardar varios minutos y el estado del backup pasa a estar disponible después de que el backup se haya completado correctamente.</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="image-alt">Astra Control Center crea una copia de seguridad</block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">Restaurar una aplicación</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">Con solo pulsar un botón, puede restaurar una aplicación en el espacio de nombres de origen del mismo clúster o en un clúster remoto para realizar tareas de protección de aplicaciones y recuperación ante desastres.</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">Para restaurar una aplicación, desplácese a la ficha aplicaciones &gt; administradas y haga clic en la aplicación en cuestión. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en Restaurar.</block>
  <block id="92955527b375720b2a586155a776c0ac" category="image-alt">Botón de clonación de Astra Control Center</block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">Introduzca el nombre del espacio de nombres de la restauración, seleccione el clúster donde desea restaurarlo y elija si desea restaurarlo desde la copia de Snapshot existente o desde el backup de la aplicación. Haga clic en Siguiente.</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="image-alt">Restauración del Centro de control de Astra</block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">En el panel de revisión, introduzca<block ref="bb2ac0b8da1f64a3498af147ba43fc10" prefix=" " category="inline-code"></block> Y haga clic en Restaurar después de haber revisado los detalles.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="image-alt">Revisión de restauración del Centro de control de Astra</block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">La nueva aplicación pasa al estado de restauración mientras Astra Control Center restaura la aplicación en el clúster seleccionado. Una vez que todos los recursos de la aplicación son instalados y detectados por Astra, la aplicación pasa al estado disponible.</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="image-alt">Astra Control Center se ha descubierto una nueva aplicación</block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">Clonar una aplicación</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">Es posible clonar una aplicación en el clúster de origen o en un clúster remoto para fines de desarrollo/pruebas o protección de aplicaciones y recuperación ante desastres. La clonado de una aplicación dentro del mismo clúster en el mismo back-end de almacenamiento utiliza la tecnología FlexClone de NetApp, que clona las RVP de forma instantánea y ahorra espacio de almacenamiento.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">Para clonar una aplicación, vaya a la ficha aplicaciones &gt; administradas y haga clic en la aplicación en cuestión. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en Clonar.</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">Introduzca los detalles del nuevo espacio de nombres, seleccione el clúster al que desea clonarlo y elija si desea clonarlo desde una snapshot existente, desde un backup o desde el estado actual de la aplicación. Haga clic en Siguiente y, a continuación, en Clonar en el panel de revisión después de haber revisado los detalles.</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">La nueva aplicación pasa al estado de descubrimiento mientras Astra Control Center crea la aplicación en el clúster seleccionado. Una vez que todos los recursos de la aplicación son instalados y detectados por Astra, la aplicación pasa al estado disponible.</block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Información general sobre VMware vSphere con Tanzania</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">VMware vSphere con Tanzu, también conocido como vSphere Pods, le permite utilizar los nodos de hipervisor ESXi en el entorno VMware vSphere como nodos de trabajo en un entorno Kubernetes con configuración básica.</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">VMware vSphere con Kubernetes</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Se habilita un entorno VMware vSphere con tanzu en Workload Management al igual que un clúster TKGS nativo.</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">Se crea un clúster de supervisor virtualizado para proporcionar un plano de control de alta disponibilidad para Kubernetes y se crean espacios de nombres individuales para cada aplicación con el fin de garantizar el aislamiento de recursos para los usuarios.</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Clúster de supervisión</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Cuando se habilita VMware vSphere con tanzu, cada uno de los hosts ESXi tiene la aplicación Spherelet instalada y configurada. De este modo, cada nodo puede actuar como trabajador en una puesta en marcha de Kubernetes y gestionar los pods puestos en marcha en cada nodo.</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">Espacio de nombres</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">Actualmente, VMware vSphere con tanzu y vSphere Pods solo son compatibles con el controlador vSphere CSI local. Esto funciona porque los administradores crean políticas de almacenamiento en el cliente de vSphere que seleccionan los destinos de almacenamiento actualmente disponibles para utilizarse como almacenes de datos de vSphere. Estas políticas se utilizan para crear volúmenes persistentes para aplicaciones en contenedores.</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">Aunque actualmente no admite el controlador Astra Trident CSI de NetApp que permite una conectividad directa a cabinas de almacenamiento ONTAP y Element externas, estos sistemas de almacenamiento de NetApp suelen utilizarse para admitir el almacenamiento principal para el entorno vSphere, Y las herramientas avanzadas de gestión de datos y eficiencia del almacenamiento de NetApp se pueden utilizar de esta manera.</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">Si desea obtener más información sobre VMware vSphere con tanzu, consulte la documentación <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">El servicio Grid de VMware Tanzu Kubernetes (también conocido como vSphere con Tanzu) le permite crear y operar clústeres de Kubernetes tanzu de forma nativa en vSphere, además de ejecutar algunas cargas de trabajo de menor tamaño directamente en los hosts ESXi.</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">Descripción general del servicio Red de Kubernetes de VMware Tanzu (TKGS)</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">El servicio Grid de VMware Tanzu Kubernetes (también conocido como vSphere con Tanzu) le permite crear y operar clústeres de Kubernetes tanzu de forma nativa en vSphere, además de ejecutar algunas cargas de trabajo de menor tamaño directamente en los hosts ESXi. Le permite transformar vSphere en una plataforma para ejecutar cargas de trabajo en contenedores de forma nativa en la capa del hipervisor. El servicio Grid de Tanzania Kubernetes pone en marcha un clúster de supervisor en vSphere cuando esta opción está habilitada, que implementa y usa los clústeres necesarios para las cargas de trabajo. Se integra de forma nativa con vSphere 7 y aprovecha muchas funciones fiables de vSphere, como vCenter SSO, Content Library, vSphere networking, vSphere Storage, vSphere ha y DRS, y seguridad vSphere para una experiencia de Kubernetes más fluida.</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">VSphere con Tanzu ofrece una única plataforma para entornos de aplicaciones híbridas donde los componentes de aplicaciones se pueden ejecutar en contenedores o máquinas virtuales, lo que proporciona una mejor visibilidad y facilidad de operaciones para desarrolladores, ingenieros de DevOps y administradores de vSphere. VMware TKGS solo se admite con entornos vSphere 7 y es la única oferta en la cartera de operaciones tanzu Kubernetes que permite ejecutar pods directamente en hosts ESXi.</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">Servicio Kubernetes de VMware Tanzania</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Para obtener más información sobre el servicio de cuadrícula de Tanzania Kubernetes, siga la documentación <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">Hay muchas consideraciones sobre la arquitectura relativas a conjuntos de funciones, redes, etc. Dependiendo de la arquitectura elegida, son distintos los requisitos previos y el proceso de puesta en marcha del servicio Grid tanzu Kubernetes. Para implementar y configurar el servicio de Grid tanzu Kubernetes en su entorno, siga la guía <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>. Además, para conectarse a los nodos del clúster de Kubernetes tanzu puestos en marcha a través de TKGS, siga el procedimiento descrito en este documento<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>.</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp recomienda que todos los entornos de producción se pongan en marcha en distintas puestas en marcha maestras para detectar fallos con la opción de configuración de los nodos de trabajo elegida a fin de satisfacer los requisitos de las cargas de trabajo previstas. Por tanto, una clase de equipo virtual recomendada para una carga de trabajo altamente intensiva tendría al menos cuatro vCPU y 12 GB de RAM.</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Cuando se crean clústeres de Kubernetes tanzu en un espacio de nombres, los usuarios con<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> o.<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> el permiso puede crear pods directamente en cualquier espacio de nombres mediante la cuenta de usuario. Esto se debe a que los usuarios con<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> o.<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> los permisos se asignan al rol de administrador del clúster. Sin embargo, al crear implementaciones, conjuntos de daemon, conjuntos de estado u otros en cualquier espacio de nombres, debe asignar una función con los permisos necesarios a las cuentas de servicio correspondientes. Esto es necesario porque las implementaciones o los conjuntos de daemon utilizan cuentas de servicio para poner en marcha los POD.</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">Consulte el siguiente ejemplo de ClusterRoleBinding para asignar la función de administrador del clúster a todas las cuentas de servicio del clúster:</block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">Este documento de referencia ofrece la validación de la puesta en marcha de distintas soluciones de VMware Tanzu Kubernetes, implementadas como Tanzania Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) o Tanzu Kubernetes Grid Integrated (TKGI) en varios entornos de centros de datos diferentes y validados por NetApp.</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166: VMware Tanzu con NetApp</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">Alan Cowles y Nikhil M Kulkarni, NetApp</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">Este documento de referencia ofrece la validación de la puesta en marcha de distintas soluciones de VMware Tanzu Kubernetes, implementadas como Tanzania Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) o Tanzu Kubernetes Grid Integrated (TKGI) en varios entornos de centros de datos diferentes y validados por NetApp. También describe la integración del almacenamiento con los sistemas de almacenamiento de NetApp y el orquestador de almacenamiento Astra Trident para la gestión del almacenamiento persistente y Astra Control Center para backup y clonado de las aplicaciones con estado mediante ese almacenamiento persistente. Por último, el documento proporciona demostraciones en vídeo de las integraciones y validaciones de las soluciones.</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">La solución VMware Tanzu con NetApp está diseñada para ofrecer un valor excepcional a los clientes con los siguientes casos prácticos:</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">Ofertas de almacenamiento Grid de VMware Tanzania Kubernetes fáciles de poner en marcha y gestionar, que se instalan en vSphere de VMware y se integran con sistemas de almacenamiento de NetApp.</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">La potencia combinada de las cargas de trabajo virtualizadas y de contenedores empresariales con las ofertas Grid de VMware Tanzania Kubernetes.</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">Casos de uso y configuración reales que destacan las funciones de VMware Tanzu al utilizar con el almacenamiento de NetApp y la suite de productos Astra de NetApp.</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">Protección o migración coherente con las aplicaciones de cargas de trabajo en contenedores puestas en marcha en clústeres de Grid de VMware Tanzu Kubernetes cuyos datos residen en sistemas de almacenamiento de NetApp mediante Astra Control Center.</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">Valor empresarial</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">Las empresas están adoptando cada vez más prácticas de DevOps para crear nuevos productos, acortar los ciclos de lanzamiento y agregar nuevas funciones con rapidez. Debido a su naturaleza ágil innata, los contenedores y microservicios tienen un papel crucial en el soporte de las prácticas de DevOps. Sin embargo, practicar DevOps a escala de producción en un entorno empresarial presenta sus propios retos e impone ciertos requisitos sobre la infraestructura subyacente, como los siguientes:</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">Alta disponibilidad en todas las capas de la pila</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">Facilidad de los procedimientos de puesta en marcha</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">Operaciones y actualizaciones no disruptivas</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">Infraestructura programable y impulsada por API para adaptarse a la agilidad de los microservicios</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">Multi-tenancy con garantías de rendimiento</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">Capacidad de ejecutar cargas de trabajo virtualizadas y en contenedores de forma simultánea</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">Capacidad de escalar la infraestructura de forma independiente en función de las demandas de las cargas de trabajo</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">Capacidad de poner en marcha en un modelo de cloud híbrido con contenedores que se ejecutan tanto en centros de datos locales como en el cloud.</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">VMware Tanzania con NetApp reconoce estos retos y presenta una solución que le ayuda a dar respuesta a cada problema mediante la puesta en marcha de ofertas de Kubernetes tanzu de VMware en el entorno de cloud híbrido que elija el cliente.</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">La solución VMware Tanzu con NetApp consta de los siguientes componentes principales:</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">Plataformas Kubernetes VMware Tanzania</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzania presenta una gran variedad de sabores que el equipo de ingeniería de soluciones de NetApp ha validado en nuestros laboratorios. Cada lanzamiento de Tanzu se integra correctamente con la cartera de almacenamiento de NetApp y cada uno de ellos contribuye a satisfacer ciertas demandas de infraestructura. Los siguientes puntos destacados con viñetas describen las características y ofertas de cada versión de Tanzania descrita en este documento.</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">* Red Kubernetes de VMware Tanzu (TKG)*</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">Entorno de Kubernetes estándar anterior puesto en marcha en un entorno de VMware vSphere.</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">Anteriormente conocido como PKS esencial (de la adquisición Heptio, febrero de 2019).</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG se pone en marcha con una instancia de clúster de gestión independiente para admitir vSphere 6.7U3 en adelante.</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">Las implementaciones de TKG se pueden implementar en el cloud, así como en AWS o Azure.</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">Permite el uso de nodos de trabajo de Windows o Linux (Ubuntu/Phototon).</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSX-T, ha Proxy, redes AVI o balanceadores de carga se pueden utilizar para el plano de control.</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG admite MetalLB para el plano de aplicación/datos.</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">Puede utilizar vSphere CSI y CSIs de terceros como NetApp Astra Trident.</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">*Servicio de Red Kubernetes de VMware Tanzu (TKGS)*</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGS implementado con clústeres de carga de trabajo y clúster de supervisor solo en vSphere 7.0U1 en adelante.</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS admite MetalLB para aplicaciones/plano de datos.</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">Ofrece compatibilidad con vSphere Pods con Tanzu, lo que permite que los POD se ejecuten directamente en hosts ESXi habilitados en el entorno.</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">* VMware Tanzu Kubernetes Grid Integrated (TKGI)*</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">Anteriormente conocido como Enterprise PKS (de Heptio adquirida, febrero de 2019).</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">Puede usar NSX-T, ha Proxy o AVI. También puede proporcionar su propio equilibrador de carga.</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">Compatible con vSphere 6.7U3 en adelante, así como AWS, Azure y GCP.</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">Configuración mediante un asistente para facilitar la puesta en marcha.</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">Ejecuta tanzu en máquinas virtuales inmutables controladas gestionadas por BOSH.</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">Puede utilizar vSphere CSI y CSIs de terceros como NetApp Astra Trident (se aplican algunas condiciones).</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*VSphere con tanzu (vSphere Pods)*</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">Los POD nativos de vSphere se ejecutan en una capa fina basada en fotones con el hardware virtual prescrito para un aislamiento completo.</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">Necesita NSX-T, pero que permite la compatibilidad de funciones adicionales como un registro de imágenes Harbour.</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">Se implementa y gestiona en vSphere 7.0U1 en adelante mediante un clúster de supervisor virtual como TKGS. Ejecuta pods directamente en nodos ESXi.</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">Totalmente integrado, máxima visibilidad y control por parte de la administración de vSphere.</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">Pods aislados basados en CRX para el máximo nivel de seguridad.</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">Solo es compatible con vSphere CSI para almacenamiento persistente. No se admiten orquestadores de almacenamiento de terceros.</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">Sistemas de almacenamiento NetApp</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp cuenta con varios sistemas de almacenamiento perfectos para centros de datos empresariales y para puestas en marcha de cloud híbrido. La cartera de NetApp incluye sistemas de almacenamiento ONTAP, NetApp Element y E-Series de NetApp, todos los cuales pueden proporcionar almacenamiento persistente para aplicaciones en contenedores.</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">Si quiere más información, visite el sitio web de NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">Integraciones de almacenamiento de NetApp</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">Astra Control Center de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, puestas en marcha en un entorno local y con la tecnología de confianza de protección de datos de NetApp.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">Si quiere más información, visite el sitio web de Astra de NetApp<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluida VMware Tanzu.</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">Si quiere más información, visite el sitio web de Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">Matriz de compatibilidad actual para versiones validadas</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">Tecnología</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Versión de software</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">Centro de control de Astra de NetApp</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">Gestión de datos para aplicaciones</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">Orquestación de almacenamiento</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="a56837df79ae6671b6b511c330431135" category="cell">Grid de Kubernetes de VMware Tanzania</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orquestación de contenedores</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4 o posterior</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">Servicio Grid de VMware Tanzania Kubernetes</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [espacios de nombres de vSphere]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [Supervisor de Kubernetes]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzania Kubernetes Grid integrado</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">Virtualización del centro de datos</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">Centro de datos NSX-T de VMware</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">Redes y seguridad</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">Equilibrador de carga avanzado de VMware NSX</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">Equilibrador de carga</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">Siguiente: Descripción general de VMware Tanzania.</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp cuenta con varias plataformas de almacenamiento cualificadas con Astra Trident y Astra Control para aprovisionar, proteger y gestionar datos para aplicaciones en contenedores y, por lo tanto, ayudar a definir y maximizar el rendimiento de DevOps.</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">Información general de los sistemas de almacenamiento de NetApp</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp cuenta con varias plataformas de almacenamiento cualificadas con Astra Trident y Astra Control para aprovisionar, proteger y gestionar datos para aplicaciones en contenedores.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">Los sistemas AFF y FAS ejecutan ONTAP de NetApp y proporcionan almacenamiento para casos de uso basados en archivos (NFS) y basados en bloques (iSCSI).</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP y ONTAP Select proporcionan las mismas ventajas en el espacio cloud y virtual respectivamente.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service (AWS/GCP) y Azure NetApp Files proporcionan almacenamiento basado en archivos en el cloud.</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">Cada sistema de almacenamiento de la cartera de NetApp puede facilitar la gestión y el movimiento de datos entre sitios locales y el cloud para que los datos estén donde están sus aplicaciones.</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">En las siguientes páginas se ofrece información adicional acerca de los sistemas de almacenamiento de NetApp validados en la solución {solution_name}:</block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">Siguiente: Información general sobre las integraciones de almacenamiento de NetApp.</block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Para permitir que Astra Control Center gestione sus cargas de trabajo, primero debe registrar sus clústeres de Kubernetes tanzu.</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">Registre sus clústeres de Kubernetes de VMware Tanzu con Astra Control Center</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">Registre clústeres de Kubernetes de VMware Tanzania</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">El primer paso es añadir los clústeres de Tanzania Kubernetes al Astra Control Center y gestionarlos. Vaya a Clusters y haga clic en Add a Cluster, cargue el archivo kubeconfig para el clúster Tanzania Kubernetes y haga clic en Select Storage.</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="image-alt">Astra Control Center crea un clúster</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center detecta las clases de almacenamiento elegibles. Ahora seleccione la forma en que storagegrid aprovisiona volúmenes mediante Trident con backup de una SVM en ONTAP de NetApp y haga clic en Review. En el panel siguiente, compruebe los detalles y haga clic en Add Cluster.</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">Cuando se agrega el clúster, se mueve al estado de detección mientras Astra Control Center lo inspecciona e instala los agentes necesarios. El estado del clúster cambia de<block ref="396d45b57c2fbe3318e7b93272a2686b" prefix=" " category="inline-code"></block> después de que se haya registrado correctamente.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="image-alt">Hay disponibles clústeres de Astra Control Center</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Todos los clústeres de Kubernetes de Tanzania que gestiona Astra Control Center deben tener acceso al registro de imágenes que se utilizó para su instalación, ya que los agentes instalados en los clústeres gestionados extraen las imágenes de ese registro.</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">Importe clústeres de ONTAP como recursos de almacenamiento que Astra Control Center gestiona como back-ends. Cuando se añaden los clústeres de Kubernetes tanzu a Astra y se configura un storagegrid, detecta e inspecciona automáticamente el clúster de ONTAP para realizar la copia de seguridad de storageecleclass pero no la importa al Centro de control de Astra para su gestión.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="image-alt">Detección de entorno de administración de Astra Control Center</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">Para importar los clústeres de ONTAP, desplácese hasta Back-ends, haga clic en el menú desplegable y seleccione Manage junto al clúster de ONTAP que se va a gestionar. Introduzca las credenciales del clúster de ONTAP, haga clic en revisar información y, a continuación, haga clic en Importar back-end de almacenamiento.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="image-alt">Astra Control Center crea backend</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">Una vez añadidos los back-ends, el estado cambia a Available. Ahora, estos back-ends presentan la información sobre los volúmenes persistentes en el clúster de Kubernetes tanzu y los volúmenes correspondientes en el sistema ONTAP.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="image-alt">Hay disponibles back-ends de Astra Control Center</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Para realizar operaciones de backup y restauración en todos los clústeres de Kubernetes de Tanzania mediante Astra Control Center, debe aprovisionar un bloque de almacenamiento de objetos que sea compatible con el protocolo S3. Las opciones admitidas actualmente son ONTAP S3, StorageGRID, AWS S3 y almacenamiento blob de Microsoft Azure. Para el objetivo de esta instalación, vamos a configurar un bloque de AWS S3. Vaya a Buckets, haga clic en Add bucket y seleccione Generic S3. Introduzca los detalles sobre el bloque de S3 y las credenciales para acceder a él, haga clic en la casilla de comprobación Mase this Bucket Default Bucket para el cloud y, a continuación, haga clic en Add.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="image-alt">Astra Control Center Create bucket</block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">Siguiente: Seleccione las aplicaciones que desea proteger.</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluida VMware Tanzu.</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Descripción general de Astra Trident</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes como {k8s_distribution_name}. Trident funciona con toda la cartera de almacenamiento de NetApp, incluidos los sistemas de almacenamiento ONTAP y Element de NetApp, y también admite conexiones NFS e iSCSI. Trident acelera el flujo de trabajo de DevOps al permitir que los usuarios finales aprovisionen y gestionen el almacenamiento desde sus sistemas de almacenamiento de NetApp sin necesidad de intervención del administrador de almacenamiento.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">Un administrador puede configurar varios back-ends de almacenamiento a partir de necesidades de proyectos y modelos de sistema de almacenamiento que permiten funciones de almacenamiento avanzadas, como compresión, tipos de disco específicos o niveles de calidad de servicio que garantizan un cierto nivel de rendimiento. Una vez definidas estos back-ends pueden ser utilizados por los desarrolladores en sus proyectos para crear reclamaciones de volumen persistente (RVP) y conectar almacenamiento persistente a sus contenedores bajo demanda.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident tiene un rápido ciclo de desarrollo y, al igual que Kubernetes, se publica cuatro veces al año.</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">La última versión de Astra Trident se lanzó en abril de 2022 en 22.04. Existe una matriz de compatibilidad con la versión de Trident probada en la que se puede encontrar la distribución de Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">A partir del lanzamiento de la versión 20.04, el operador de Trident realiza la configuración de Trident. El operador facilita las puestas en marcha a gran escala y ofrece soporte adicional, incluida la reparación automática de pods que se implementan como parte de la instalación de Trident.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">Con la versión 21.01, se puso a disposición un gráfico Helm para facilitar la instalación del operador Trident.</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Ponga en marcha al operador de Trident con Helm</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">En primer lugar, defina la ubicación del clúster de usuarios<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Archivo como variable de entorno para no tener que referirla, porque Trident no tiene opción para pasar este archivo.</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">Añada el repositorio del timón de NetApp Astra Trident.</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Actualizar los repositorios del timón.</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Cree un nuevo espacio de nombres para la instalación de Trident.</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">Cree un secreto con las credenciales de DockerHub para descargar las imágenes de Astra Trident.</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">Para los clústeres de usuarios o cargas de trabajo gestionados por TKGS (vSphere con tanzu) o TKG con implementaciones de clústeres de gestión, complete el siguiente procedimiento para instalar Astra Trident:</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">Asegúrese de que el usuario que ha iniciado sesión tiene los permisos para crear cuentas de servicio en el espacio de nombres de trident y de que las cuentas de servicio en el espacio de nombres de trident tienen los permisos para crear POD.</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">Ejecute el comando siguiente timón para instalar el operador Trident en el espacio de nombres creado.</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">Para un usuario o clúster de cargas de trabajo gestionado por implementaciones TKGI, ejecute el siguiente comando helm para instalar el operador Trident en el espacio de nombres creado.</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Compruebe que los pods de Trident estén activos y en ejecución.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">Cree back-ends del sistema de almacenamiento</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Una vez finalizada la instalación del operador de Astra Trident, debe configurar el back-end para la plataforma de almacenamiento específica de NetApp que esté usando. Siga los siguientes enlaces para continuar con la instalación y configuración de Astra Trident.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NFS de ONTAP de NetApp</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">ISCSI de ONTAP de NetApp</block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">Información adicional: VMware Tanzania con NetApp</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">Si quiere más información sobre la información descrita en este documento, consulte los siguientes sitios web:</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">Documentación de NetApp</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Documentación de Astra Trident</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">Documentación del centro de control Astra de NetApp</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Documentación de Ansible</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">Documentación de VMware Tanzu</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">Documentación de Grid de VMware Tanzania Kubernetes</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">Documentación del servicio Grid de VMware Tanzu Kubernetes</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">Documentación de VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">Después de registrar sus clústeres de Kubernetes de VMware Tanzania, podrá descubrir las aplicaciones que se implementan y gestionan a través de Astra Control Center.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">Elija las aplicaciones que desea proteger</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Después de registrar los clústeres de Tanzania Kubernetes, podrá descubrir las aplicaciones que se implementan y gestionan a través de Astra Control Center.</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">Gestione las aplicaciones</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Una vez registrados los clústeres de Tanzu Kubernetes y los back-ends de ONTAP en el Centro de control de Astra, el centro de control inicia automáticamente el descubrimiento de las aplicaciones en todos los espacios de nombres que utilizan storageeclcaso configurado con el back-end de ONTAP especificado.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="image-alt">Se han descubierto las aplicaciones de Astra Control Center</block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">Desplácese a aplicaciones &gt; descubiertas y haga clic en el menú desplegable situado junto a la aplicación que desea gestionar mediante Astra. A continuación, haga clic en gestionar.</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="image-alt">Astra Control Center gestiona las aplicaciones</block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">La aplicación entra en el estado disponible y se puede ver en la ficha gestionado de la sección aplicaciones.</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="image-alt">Hay disponibles aplicaciones de Astra Control Center</block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">Siguiente: Proteja sus aplicaciones.</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">Para integrar el sistema de almacenamiento ONTAP de NetApp con clústeres Kubernetes de VMware Tanzu para volúmenes persistentes a través de iSCSI, el primer paso consiste en preparar los nodos iniciando sesión en cada nodo y configurando las utilidades o paquetes iSCSI para montar volúmenes iSCSI.</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">Configuración de iSCSI de ONTAP de NetApp</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">Para integrar el sistema de almacenamiento ONTAP de NetApp con clústeres Kubernetes de VMware Tanzania para volúmenes persistentes a través de iSCSI, el primer paso es preparar los nodos iniciando sesión en cada nodo y configurando las utilidades o paquetes iSCSI para montar volúmenes iSCSI. Para ello, siga el procedimiento establecido en este documento <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>.</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp no recomienda este procedimiento para las puestas en marcha NAT de clústeres VMware Tanzania Kubernetes.</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI utiliza máquinas virtuales bosh como nodos para clústeres de Kubernetes tanzu que ejecutan imágenes de configuración inmutables y cualquier cambio manual de paquetes iSCSI en equipos virtuales bosh no permanece constante entre reinicios. Por lo tanto, NetApp recomienda el uso de volúmenes NFS para el almacenamiento persistente de clústeres de Kubernetes tanzu puestos en marcha y operados por TKGI.</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">Una vez que los nodos del clúster se han preparado para los volúmenes iSCSI, debe crear un back-end que permita la comunicación con el sistema de almacenamiento. Hemos configurado un back-end básico en esta solución pero, si busca opciones más personalizadas, visite la documentación <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>.</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">Para crear una SVM en ONTAP, complete los siguientes pasos:</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">Escriba un nombre para la SVM, habilite el protocolo iSCSI y a continuación, proporcione detalles para las LIF de datos.</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">LIF de datos de SVM iSCSI</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">Introduzca los detalles de la cuenta de administración de la SVM y, a continuación, haga clic en Save.</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">Administración de SVM iSCSI</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">Para asignar los agregados a la SVM, desplácese a almacenamiento &gt; Storage VMs, haga clic en los tres puntos junto a la SVM recién creada y, a continuación, haga clic en Edit. Active la casilla de comprobación Limit Volume Creation to Preferred local Tiers y adjunte los agregados necesarios.</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">Tras crear un back-end, debe crear después una clase de almacenamiento. La siguiente definición de clase de almacenamiento de ejemplo resalta los campos necesarios y básicos. El parámetro<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Debe reflejar el controlador de almacenamiento desde el back-end de Trident recién creado. Observe también el valor del campo de nombre, al que se debe hacer referencia en un paso posterior.</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">Hay un campo opcional llamado<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> que se define en este archivo. En los back-ends iSCSI, este valor se puede establecer en un tipo de sistema de archivos Linux específico (XFS, ext4, etc.) o se puede eliminar para permitir a los clústeres de Kubernetes de Tanzania decidir qué sistema de archivos utilizar.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">Siguiente: Casos prácticos y validación de la solución.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="945f7593bacdce2a986b2ea8ab58220b" category="summary">Esta página contiene enlaces a una demostración en vídeo que muestra cómo utilizar Astra Control Center para clonar aplicaciones en VMware Tanzu.</block>
  <block id="ff56b2be4aa6be0d45adf0bbeb76166d" category="doc">Utilice Astra Control Center para clonar aplicaciones en VMware Tanzu</block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp proporciona una serie de productos que ayudan a nuestros clientes a orquestar y gestionar datos persistentes en entornos basados en contenedores.</block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">Información general sobre la integración del almacenamiento de NetApp</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp proporciona una serie de productos para ayudarle a orquestar, gestionar, proteger y migrar aplicaciones con contenedores con estado y sus datos.</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">Astra Control de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes gracias a la tecnología de protección de datos de NetApp. El servicio Astra Control está disponible para admitir cargas de trabajo con estado en puestas en marcha de Kubernetes nativas para el cloud. Astra Control Center está disponible para admitir cargas de trabajo con estado en puestas en marcha en las instalaciones de plataformas Enterprise Kubernetes como {k8s_distribution_name}. Si quiere más información, visite el sitio web de Astra Control de NetApp<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes como {k8s_distribution_name}. Si quiere más información, visite el sitio web de Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">En las siguientes páginas se ofrece información adicional sobre los productos de NetApp que se han validado para la administración del almacenamiento persistente y de aplicaciones en la solución {solution_name}:</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">Siguiente: Descripción de Astra Control de NetApp.</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="9d312703c40c2d87b835076063682d59" category="summary">ONTAP de NetApp es una potente herramienta de software de almacenamiento con funcionalidades como una interfaz gráfica de usuario intuitiva, API DE REST con integración de automatización, análisis predictivos con información de IA y acciones correctivas, actualizaciones de hardware no disruptivas e importación entre almacenamiento.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">Sitio web de ONTAP de NetApp</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">Para obtener más información sobre el sistema de almacenamiento ONTAP de NetApp, visite la<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP ofrece las siguientes funciones:</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">Un sistema de almacenamiento unificado con acceso simultáneo a datos y gestión de NFS, CIFS, iSCSI, FC, FCoE, Y los protocolos FC-NVMe.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">Los diferentes modelos de puesta en marcha incluyen configuraciones locales de hardware all-flash, híbrido y all-HDD; plataformas de almacenamiento basadas en máquinas virtuales en un hipervisor compatible, como ONTAP Select; y en el cloud como Cloud Volumes ONTAP.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">Eficiencia del almacenamiento de datos aumentada en los sistemas de ONTAP con compatibilidad para niveles de datos automáticos, compresión de datos inline, deduplicación y compactación.</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">Almacenamiento basado en cargas de trabajo controlado por la calidad de servicio.</block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">Integración fluida con un cloud público para la organización en niveles y la protección de datos. ONTAP también proporciona funcionalidades de protección de datos sólidas que lo diferencian en cualquier entorno:</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">*Copias Snapshot de NetApp.* una copia de seguridad rápida y puntual de los datos con una cantidad mínima de espacio en disco sin sobrecarga adicional del rendimiento.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">*SnapMirror de NetApp.* duplica las copias Snapshot de los datos de un sistema de almacenamiento a otro. ONTAP también admite el mirroring de datos en otras plataformas físicas y servicios nativos del cloud.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">*SnapLock de NetApp.* Administración eficaz de datos no regrabables escribiéndolos en volúmenes especiales que no se puedan sobrescribir ni borrar durante un periodo determinado.</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">*SnapVault de NetApp.* realiza un backup de datos de varios sistemas de almacenamiento en una copia snapshot central que sirve de respaldo a todos los sistemas designados.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">*SyncMirror de NetApp.* proporciona mirroring de datos a nivel de RAID en tiempo real a dos complejos de discos diferentes que están conectados físicamente a la misma controladora.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">*SnapRestore de NetApp.* proporciona una rápida restauración de los datos de backup bajo demanda a partir de copias snapshot.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">*FlexClone de NetApp* proporciona el aprovisionamiento instantáneo de una copia totalmente legible y modificable de un volumen NetApp en función de una copia snapshot.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">Centro de documentación de ONTAP 9</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">Para obtener más información acerca de ONTAP, consulte<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">ONTAP de NetApp está disponible en las instalaciones, virtualizado o en el cloud.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">Plataformas NetApp</block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">AFF/FAS de NetApp</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp proporciona plataformas de almacenamiento sólidas all-flash (AFF) y híbridas de escalado horizontal (FAS) diseñadas a medida con un rendimiento de baja latencia, protección de datos integrada y compatibilidad con varios protocolos.</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">Ambos sistemas cuentan con el software para la gestión de datos ONTAP de NetApp, el software de gestión de datos más avanzado del sector para una gestión del almacenamiento integrada en el cloud, de alta disponibilidad y simplificada, para ofrecer seguridad, eficiencia y velocidad aptas para el ámbito empresarial que se ajuste a sus necesidades de Data Fabric.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">Para obtener más información sobre las plataformas AFF/FAS de NETAPP, haga clic en<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select es una puesta en marcha definida por software de ONTAP de NetApp que se puede poner en marcha en un hipervisor en su entorno. Puede instalarse en VMware vSphere o en KVM y proporciona todas las funciones y la experiencia de un sistema ONTAP basado en hardware.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">Para obtener más información acerca de ONTAP Select, haga clic en<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="section-title">Cloud Volumes ONTAP</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">Cloud Volumes ONTAP de NetApp es una versión de NetApp ONTAP que se puede poner en marcha en un gran número de clouds públicos, incluidos Amazon AWS, Microsoft Azure y Google Cloud.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Para obtener más información acerca de Cloud Volumes ONTAP, haga clic en<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra Control Center ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, puestos en marcha en un entorno local, impulsado por la tecnología de protección de datos de confianza de NetApp.</block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">Descripción general de Astra Control de NetApp</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">Astra Control Center de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes puestas en marcha en un entorno local con la tecnología de protección de datos de NetApp.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra Control Center se puede instalar en un clúster de {k8s_distribution_name} que tenga el orquestador de almacenamiento Astra Trident puesto en marcha y configurado con clases de almacenamiento y back-ends en los sistemas de almacenamiento ONTAP de NetApp.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">este documento aquí</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Si desea obtener más información sobre Astra Trident, consulte <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>.</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">En un entorno conectado a la nube, Astra Control Center utiliza Cloud Insights para proporcionar supervisión y telemetría avanzadas. Ante la ausencia de una conexión con Cloud Insights, la supervisión y la telemetría limitadas (en siete días de métricas) están disponibles y se exportan a herramientas de supervisión nativas de Kubernetes (Prometheus y Grafana) mediante extremos de métricas abiertos.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center está totalmente integrado en el ecosistema de AutoSupport y Active IQ de NetApp para proporcionar soporte a los usuarios y proporcionar asistencia para la solución de problemas y mostrar las estadísticas de uso.</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">Además de la versión pagada de Astra Control Center, también hay disponible una licencia de evaluación de 90 días. La versión de evaluación se admite a través del correo electrónico y el canal de Slack de la comunidad. Los clientes tienen acceso a estos recursos, a otros artículos de la base de conocimientos y a la documentación disponible en la consola de soporte del producto.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Sitio web de Astra</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Para obtener más información sobre la cartera de Astra, visite <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Automatización de Astra Control Center</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Center tiene una API DE REST totalmente funcional para el acceso a la programación. Los usuarios pueden utilizar cualquier lenguaje de programación o utilidad para interactuar con los extremos de la API REST de Astra Control. Para obtener más información acerca de esta API, consulte la documentación de <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>.</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">Si busca un kit de herramientas de desarrollo de software listo para usar con las API REST de Astra Control, NetApp le proporciona un kit de herramientas con Astra Control Python SDK que puede descargar <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">Si la programación no es adecuada para su situación y le gustaría utilizar una herramienta de gestión de configuración, puede clonar y ejecutar los libros de estrategia de Ansible que publica NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Requisitos previos de instalación de Astra Control Center</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">La instalación de Astra Control Center requiere los siguientes requisitos previos:</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">Uno o varios clústeres de Kubernetes de Tanzania, gestionados por un clúster de gestión o TKGS o TKGI. Se admiten clústeres de carga de trabajo TKG de 1.4+ y clústeres de usuario TKGI de 1.12.2+.</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">Astra Trident ya debe estar instalado y configurado en cada uno de los clústeres de Kubernetes de Tanzania.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">Uno o más sistemas de almacenamiento ONTAP de NetApp que ejecutan ONTAP 9.5 o superior.</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">Se trata de una mejor práctica para cada instalación de Kubernetes en Tanzania en un sitio que consiste en disponer de una SVM dedicada para el almacenamiento persistente. Las puestas en marcha de varios sitios requieren sistemas de almacenamiento adicionales.</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">Se debe configurar un back-end de almacenamiento Trident en cada clúster de Kubernetes tanzu con una SVM respaldada por un clúster de ONTAP.</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">Un StorageClass predeterminado configurado en cada clúster Kubernetes tanzu con Astra Trident como aprovisionador de almacenamiento.</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">Debe instalarse y configurar un equilibrador de carga en cada clúster de Kubernetes de Tanzu para equilibrar la carga y exponer Astra Control Center si está utilizando ingressType<block ref="0a3e1793e4eaf6bd67bdf43d1bca1c74" prefix=" " category="inline-code"></block>.</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">Debe instalar y configurar un controlador de entrada en cada clúster de Kubernetes de Tanzu para exponer Astra Control Center si utiliza ingressType<block ref="8045a0a6c688b0635e3caccc408a1446" prefix=" " category="inline-code"></block>.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">Debe configurarse un registro de imagen privada para alojar las imágenes de Astra Control Center de NetApp.</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">Debe tener acceso de administrador del clúster al clúster Tanzania Kubernetes donde se está instalando Astra Control Center.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">Debe tener acceso de administrador a los clústeres de ONTAP de NetApp.</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">Una estación de trabajo de administración de RHEL o Ubuntu.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Instalar Astra Control Center</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">Esta solución describe un procedimiento automatizado para instalar Astra Control Center mediante los libros de estrategia de Ansible. Si está buscando un procedimiento manual para instalar Astra Control Center, siga la guía detallada de instalación y operaciones <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="662609908ab8e0f372d83dea3511370b" category="inline-link">procedimiento</block>
  <block id="8575c02ec176b0f64904bcbd79e81cba" category="list-text">Para utilizar los libros de estrategia de Ansible que ponen en marcha Astra Control Center, debe tener una máquina Ubuntu/RHEL con Ansible instalada. Siga este<block ref="c1972c5d94c51919767b49f6cefbf6ba" category="inline-link-rx"></block> Para Ubuntu y esto<block ref="c4dab530b5bf152ded398881b8308451" category="inline-link-rx"></block> Para RHEL.</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Clone el repositorio de GitHub que aloja el contenido de Ansible.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">Inicie sesión en el sitio de soporte de NetApp y descargue la versión más reciente de Astra Control Center de NetApp. Para ello, es necesario disponer de una licencia adjunta a su cuenta de NetApp. Después de descargar el tarball, transfiéralo a la estación de trabajo.</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Sitio de registro de Astra</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Para empezar con una licencia de prueba de Astra Control, visite<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Cree o obtenga el archivo kubeconfig con acceso de administrador al clúster de Kubernetes de tanzu de carga de trabajo o usuario en el que se va a instalar Astra Control Center.</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">Cambie el directorio a.<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">Edite el<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> archive y rellene las variables con la información necesaria.</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">Ejecute el libro de estrategia para implementar Astra Control Center. El libro de estrategia requiere privilegios raíz para determinadas configuraciones.</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">Ejecute el siguiente comando para ejecutar el libro de estrategia si el usuario que ejecuta la tableta playbook es raíz o tiene un sudo configurado sin contraseñas.</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">Si el usuario tiene configurado un acceso sudo basado en contraseña, ejecute el siguiente comando para ejecutar la libro de estrategia y, a continuación, introduzca la contraseña sudo.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">Pasos posteriores a la instalación</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">La instalación puede tardar varios minutos en completarse. Verifique que todos los pods y servicios del<block ref="cde5355ebfdfe468e0d3516b20d95313" prefix=" " category="inline-code"></block> el espacio de nombres está activo y en funcionamiento.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">Compruebe la<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> registros para garantizar que se completa la instalación.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">El siguiente mensaje indica que la instalación de Astra Control Center se ha realizado correctamente.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">El nombre de usuario para iniciar sesión en Astra Control Center es la dirección de correo electrónico del administrador que se proporciona en el archivo CRD y la contraseña es una cadena<block ref="4e68cdd4eb0ff1a79e44dac42b52abd8" prefix=" " category="inline-code"></block> Se adjunta al UUID del Centro de control de Astra. Ejecute el siguiente comando:</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">En este ejemplo, la contraseña es<block ref="bf7a8daff076079f839129b59f2bb759" prefix=" " category="inline-code"></block>.</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">Obtenga el IP del equilibrador de carga de servicio de Traefik si el ingressType es Accefik.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Agregue una entrada en el servidor DNS apuntando al FQDN que se proporciona en el archivo CRD de Astra Control Center al<block ref="23edb0469b69e61c98ac7a9e1dca82e8" prefix=" " category="inline-code"></block> del servicio de trafik.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">Agregar entrada DNS para GUI ACC</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Inicie sesión en la GUI de Astra Control Center navegando por su FQDN.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Inicio de sesión en Astra Control Center</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">Cuando inicie sesión en la GUI de Astra Control Center por primera vez con la dirección de correo electrónico de administrador proporcionada en CRD, deberá cambiar la contraseña.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Cambio obligatorio de contraseña en Astra Control Center</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Si desea agregar un usuario a Astra Control Center, desplácese a cuenta &gt; usuarios, haga clic en Agregar, introduzca los detalles del usuario y haga clic en Agregar.</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center crea un usuario</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Center requiere una licencia para que funcionen todas sus funciones. Para añadir una licencia, vaya a cuenta &gt; Licencia, haga clic en Añadir licencia y cargue el archivo de licencia.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center añade licencia</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">Si tiene problemas con la instalación o la configuración de NetApp Astra Control Center, está disponible la base de conocimientos sobre problemas conocidos<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>.</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">Siguiente: Registre sus clústeres de Kubernetes de Tanzania.</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">Visión general de VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated (TKGI) Edition, anteriormente conocido como VMware Enterprise PKS, es una plataforma de orquestación de contenedores independiente basada en Kubernetes con funcionalidades como la gestión del ciclo de vida, la supervisión del estado del clúster, las redes avanzadas, un registro de contenedores, etc. TKGI aprovisiona y gestiona clústeres de Kubernetes con el plano de control TKGI, que consiste en BOSH y OPS Manager.</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGI se puede instalar y utilizar en entornos vSphere o OpenStack en las instalaciones o en cualquiera de los principales clouds públicos en sus respectivas ofertas de IaaS. Además, la integración de TKGI con NSX-T y Harbour permite un uso más amplio de los casos de trabajo empresariales. Para obtener más información sobre TKGI y sus capacidades, visite la documentación <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>.</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="image-alt">VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGI se instala en una variedad de configuraciones en una variedad de plataformas basadas en diferentes casos de uso y diseños. Siga la guía <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> Para instalar y configurar TKGI y sus requisitos previos. TKGI utiliza máquinas virtuales Bosh como nodos para clústeres de Kubernetes tanzu que ejecutan imágenes de configuración inmutables y cualquier cambio manual en los equipos virtuales Bosh no permanece constante entre reinicios.</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">Notas importantes:</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">Trident de NetApp requiere acceso a contenedores con privilegios. Por lo tanto, durante la instalación de TKGI, asegúrese de seleccionar la casilla de verificación Habilitar contenedores privilegiados en el paso para configurar los planes de nodo de clúster de Tanzania Kubernetes.</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">Contenedores privilegiados en TKGI</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp recomienda que todos los entornos de producción se pongan en marcha en distintas puestas en marcha principales con el fin de tolerancia a fallos en la configuración de los nodos de trabajo elegido para cumplir los requisitos de las cargas de trabajo previstas. Por lo tanto, un plan de clusters TKGI recomendado consistiría en al menos tres maestros y tres trabajadores con al menos cuatro vCPU y 12 GB de RAM para una carga de trabajo muy intensiva.</block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">Esta página contiene enlaces a vídeos que muestran algunas de las funciones descritas en este documento.</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">Vídeos y demostraciones: VMware Tanzu con NetApp</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">En los siguientes vídeos se muestran algunas de las funcionalidades descritas en este documento:</block>
  <block id="811263b3dba6ff02a02f70eb9730ca2e" category="inline-link-macro">Utilice Astra Trident para aprovisionar almacenamiento persistente en VMware Tanzu</block>
  <block id="6aa25c5e03abeab0ced9fac672bb2330" category="list-text"><block ref="6aa25c5e03abeab0ced9fac672bb2330" category="inline-link-macro-rx"></block></block>
  <block id="03a87e35f2de41c34385d72c2c717acf" category="inline-link-macro">Utilice Astra Control Center para clonar aplicaciones en VMware Tanzu</block>
  <block id="591774815c932f725e0adbded50b634b" category="list-text"><block ref="591774815c932f725e0adbded50b634b" category="inline-link-macro-rx"></block></block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">Funciones: Advanced Cluster Management para Kubernetes en Red Hat OpenShift con NetApp</block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">Gobernanza y riesgo</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">Esta función permite definir las políticas de cumplimiento de normativas para diferentes clústeres y asegurarse de que los clústeres se adhieran a ella. Puede configurar las directivas para informar o solucionar cualquier desviación o infracción de las reglas.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">Navegue hasta Gobierno y riesgo desde la barra lateral.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">Para crear políticas de cumplimiento de normativas, haga clic en Create Policy, introduzca los detalles de los estándares de políticas y seleccione los clústeres que deben ajustarse a esta política. Si desea corregir automáticamente las infracciones de esta directiva, active la casilla de verificación aplicar si es compatible y haga clic en Crear.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">Cree una política de cumplimiento</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">Una vez configuradas todas las directivas necesarias, las infracciones de directivas o clústeres se pueden supervisar y solucionar desde Advanced Cluster Management.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">Supervisión de políticas</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">Next: Características - Observabilidad.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">Gestión del ciclo de vida del clúster</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">Para administrar distintos clústeres de OpenShift, puede crearlos o importarlos a Advanced Cluster Management.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">Primero vaya a automatizar infraestructuras &gt; Clusters.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">Para crear un nuevo clúster de OpenShift, realice los siguientes pasos:</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">Crear una conexión de proveedor: Desplácese a conexiones de proveedor y haga clic en Agregar una conexión, proporcione todos los detalles correspondientes al tipo de proveedor seleccionado y haga clic en Agregar.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">Agregue la conexión del proveedor</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">Para crear un nuevo clúster, desplácese hasta Clusters y haga clic en Add a Cluster &gt; Create a Cluster. Proporcione los detalles del clúster y del proveedor correspondiente y haga clic en Create.</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">Añadir clústeres</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">Una vez creado el clúster, este aparece en la lista de clústeres con el estado Ready.</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">Para importar un clúster existente, complete los siguientes pasos:</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">Desplácese hasta Clusters y haga clic en Add a Cluster &gt; Import an Existing Cluster.</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">Introduzca el nombre del clúster y haga clic en Save Import and Generate Code. Se muestra un comando para añadir el clúster existente.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Haga clic en Copy Command y ejecute el comando en el clúster que se va a añadir al clúster de concentrador. Esto inicia la instalación de los agentes necesarios en el clúster y, una vez completado este proceso, el clúster aparece en la lista de clústeres con el estado Ready.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">Importe el clúster existente</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">Después de crear e importar varios clústeres, puede supervisarlos y gestionarlos desde una sola consola.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">Siguiente: Características - Gestión del ciclo de vida de la aplicación.</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">Flujos de trabajo: Virtualización de Red Hat OpenShift con ONTAP de NetApp</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">Crear una máquina virtual</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">Las máquinas virtuales son implementaciones con estado que requieren volúmenes para alojar el sistema operativo y los datos. Con CNV, debido a que las máquinas virtuales se ejecutan como POD, las máquinas virtuales se encuentran respaldadas por VP alojado en ONTAP de NetApp por Trident. Estos volúmenes están conectados como discos y almacenan todo el sistema de archivos, incluido el origen de arranque de la máquina virtual.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">Crear la arquitectura de VM</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">Para crear una máquina virtual en el clúster de OpenShift, lleve a cabo los siguientes pasos:</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">Desplácese hasta Workloads &gt; Virtualization &gt; Virtual Machines y haga clic en Create &gt; with Wizard.</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">Seleccione el sistema operativo que desee y haga clic en Siguiente.</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">Si el sistema operativo seleccionado no tiene configurada ninguna fuente de inicio, debe configurarla. En origen de arranque, seleccione si desea importar la imagen del sistema operativo desde una dirección URL o desde un registro y proporcione los detalles correspondientes. Expanda Advanced y seleccione el tipo de almacenamiento con backup Trident. A continuación, haga clic en Siguiente.</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">Crear origen de arranque para máquina virtual</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">Si el sistema operativo seleccionado ya tiene configurada una fuente de inicio, se puede omitir el paso anterior.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">En el panel Review and Create, seleccione el proyecto en el que desea crear la máquina virtual y proporcione los detalles de la máquina virtual. Asegúrese de que el origen de arranque está seleccionado para que sea Clone y arranque desde CD-ROM con el PVC apropiado asignado al sistema operativo seleccionado.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">Si desea personalizar la máquina virtual, haga clic en Personalizar máquina virtual y modifique los parámetros necesarios.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">Haga clic en Crear máquina virtual para crear la máquina virtual; esto hace girar un pod correspondiente en segundo plano.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">Cuando se configura un origen de arranque para una plantilla o un sistema operativo a partir de una dirección URL o de un registro, crea un PVC en el<block ref="1f9b99deb0fa755d5d42404160cfd87f" prefix=" " category="inline-code"></block> Proyecta y descarga la imagen invitada de KVM en el PVC. Debe asegurarse de que las RVP de plantilla tienen suficiente espacio aprovisionado para acomodar la imagen invitada KVM para el SO correspondiente. Estos EVs se clonan y se adjuntan como rootdisks a máquinas virtuales cuando se crean utilizando las plantillas respectivas en cualquier proyecto.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">Siguiente: Flujos de trabajo: Migración en vivo de máquinas virtuales.</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">Advanced Cluster Management para Kubernetes en Red Hat OpenShift con NetApp.</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Ponga en marcha la gestión avanzada de clústeres para Kubernetes</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">Para instalar Advanced Cluster Management para Kubernetes en un clúster OpenShift, realice los siguientes pasos:</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">Elija un clúster de OpenShift como clúster de concentrador e inicie sesión con privilegios de administrador de clúster.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Vaya a Operators &gt; Operators Hub y busque Advanced Cluster Management for Kubernetes.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Seleccione Advanced Cluster Management for Kubernetes y haga clic en Install.</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">Detalles de la ventana del ACM</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">En la pantalla Install Operator (instalar operador), proporcione la información necesaria (NetApp recomienda conservar los parámetros predeterminados) y haga clic en Install (instalar).</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">Instalar el mosaico del operador ACM</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">Espere a que finalice la instalación del operador.</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">Instalación del operador de ACM en curso</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">Una vez instalado el operador, haga clic en Crear MultiClusterHub.</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">El operador ACM MulticlusterHub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">En la pantalla Create MultiClusterHub, haga clic en Crear después de proporcionar los detalles. Esto inicia la instalación de un concentrador de varios clústeres.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">Pantalla Crear concentrador multiclúster</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">Después de que todos los pods pasan al estado en ejecución en el espacio de nombres de gestión de clúster abierto y el operador pasa al estado correcto, se instala Advanced Cluster Management for Kubernetes.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM, operador instalado</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">Se tarda algún tiempo en completar la instalación del concentrador y, una vez realizada, el concentrador multiclúster se mueve al estado en ejecución.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">Hub multiclúster listo</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">Crea una ruta en el espacio de nombres de administración de clúster abierto. Conéctese a la dirección URL de la ruta para acceder a la consola Advanced Cluster Management.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">La ruta de la consola ACM</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">Siguiente: Funciones: Gestión del ciclo de vida del clúster.</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="a003986254b5a6c136733113505348da" category="doc">Instalación de equilibradores de carga BIG-IP de F5</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">Big-IP de F5 es un controlador de entrega de aplicaciones (ADC) que ofrece un amplio conjunto de servicios avanzados de seguridad y gestión del tráfico de nivel de producción como el equilibrio de carga L4-L7, descarga SSL/TLS, DNS, firewall y muchos más. Estos servicios aumentan significativamente la disponibilidad, la seguridad y el rendimiento de sus aplicaciones.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">Big-IP de F5 se puede implementar y consumir de varias maneras, en hardware dedicado, en la nube o como un dispositivo virtual en las instalaciones. Consulte la documentación aquí para explorar e implementar BIG-IP de F5 según sus necesidades.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">Para una integración eficaz de los servicios BIG-IP de F5 con Red Hat OpenShift, F5 ofrece EL BIG-IP Container Ingresing Service (CIS). CIS se instala como un controlador que supervisa la API de OpenShift para determinadas definiciones de recursos personalizados (CRD) y gestiona la configuración del sistema BIG-IP de F5. Big-IP CIS de F5 se puede configurar para controlar tipos de servicios LoadBalancers y rutas en OpenShift.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">Además, para la asignación automática de direcciones IP para dar servicio al tipo LoadBalancer, puede utilizar el controlador F5 IPAM. El controlador IPAM de F5 se instala como un pod de controladores que mira la API de OpenShift para los servicios LoadBalancer con una anotación ipamLabel para asignar la dirección IP desde un grupo preconfigurado.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">En esta página se enumeran las instrucciones de instalación y configuración del controlador F5 BIG-IP CIS e IPAM. Como requisito previo, debe tener un sistema BIG-IP de F5 implementado y con licencia. También debe tener licencia para los servicios SDN, que se incluyen de forma predeterminada con la licencia base BIG-IP ve.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">BIG-IP de F5 se puede implementar en modo independiente o en modo cluster. A efectos de esta validación, F5 BIG-IP se implementó en modo independiente, pero, a efectos de producción, es preferible disponer de un cluster de BIG-IP para evitar un único punto de fallo.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">Un sistema BIG-IP de F5 se puede implementar en hardware dedicado, en la nube o como un dispositivo virtual en las instalaciones con versiones superiores a 12.x para que se integre con F5 CIS. A efectos de este documento, el sistema BIG-IP de F5 se validó como dispositivo virtual, por ejemplo, mediante LA edición BIG-IP ve.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">Versiones validadas</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">EDICIÓN F5 BIG-IP VE</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">Servicio de entrada de contenedores F5</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">Controlador IPAM F5</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">Instalación</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">Repositorio de F5 AS3 GitHub</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">Instale la extensión F5 Application Services 3 para permitir que los sistemas BIG-IP acepten configuraciones en JSON en lugar de comandos de imperativo. Vaya a.<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>Y descargue el último archivo RPM.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">Inicie sesión en el sistema BIG-IP de F5, desplácese a iApps &gt; Package Management LX y haga clic en Import.</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">Haga clic en elegir archivo y seleccione el archivo de RPM AS3 descargado, haga clic en Aceptar y, a continuación, haga clic en cargar.</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">Carga de iapps</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">Confirme que la extensión AS3 se ha instalado correctamente.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">Validación de instalación AS3</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">A continuación, configure los recursos necesarios para la comunicación entre los sistemas OpenShift Y BIG-IP. En primer lugar, cree un túnel entre OpenShift y EL servidor BIG-IP creando una interfaz de túnel VXLAN en EL sistema BIG-IP para OpenShift SDN. Desplácese a Red &gt; túneles &gt; Perfiles, haga clic en Crear y establezca el perfil principal en vxlan y el tipo de inundación en multidifusión. Introduzca un nombre para el perfil y haga clic en terminado.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">Crear perfil VXLAN</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Desplácese a Red &gt; túneles &gt; Lista de túneles, haga clic en Crear e introduzca el nombre y la dirección IP local del túnel. Seleccione el perfil de túnel que se creó en el paso anterior y haga clic en finalizado.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">Cree un túnel VXLAN</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">Inicie sesión en el clúster de Red Hat OpenShift con privilegios de administrador de clúster.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">Cree una subred hosten OpenShift para el servidor BIG-IP de F5, que amplía la subred del clúster OpenShift al servidor BIG-IP de F5. Descargue la definición YAML de la subred del host.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">Edite el archivo de subred del host y agregue LA IP BIG-IP VTEP (túnel VXLAN) para OpenShift SDN.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">Cambie el hostIP y otros detalles según corresponda a su entorno.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">Cree el recurso HostSubnet.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">Obtenga el intervalo de subred IP del clúster para la subred del host creada para el servidor BIG-IP de F5.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">Cree una autoIP en OpenShift VXLAN con una IP en el rango de subred de host de OpenShift correspondiente al servidor BIG-IP de F5. Inicie sesión en el sistema BIG-IP de F5, desplácese a Red &gt; IP automáticas y haga clic en Crear. Introduzca una dirección IP desde la subred IP del clúster creada para la subred de host BIG-IP de F5, seleccione el túnel VXLAN e introduzca los demás detalles. A continuación, haga clic en finalizado.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">Crear IP automática para VXLAN</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">Cree una partición en el sistema BIG-IP de F5 que se va a configurar y utilizar con CIS. Vaya a sistema &gt; usuarios &gt; Lista de particiones, haga clic en Crear e introduzca los detalles. A continuación, haga clic en finalizado.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">Crear partición BIG-IP</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5 recomienda que no se realice ninguna configuración manual en la partición que gestiona CIS.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">Instale EL F5 BIG-IP CIS utilizando el operador de OperatorHub. Inicie sesión en el clúster de Red Hat OpenShift con privilegios de administración de clúster y cree un secreto con las credenciales de inicio de sesión del sistema BIG-IP de F5, que es un requisito previo para el operador.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">Instale los CRD de F5 CIS.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Desplácese a Operators &gt; OperatorHub, busque la palabra clave F5 y haga clic en el icono F5 Container Ingresing Service.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">F5 CIS en OperatorHub</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">Lea la información del operador y haga clic en instalar.</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">Icono de información CIS de F5 en OperatorHub</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">En la pantalla instalar operador, deje todos los parámetros predeterminados y haga clic en instalar.</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">Instalar el operador F5 CIS</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">Se tarda un rato en instalar el operador.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">Progreso de instalación del operador de F5 CIS</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">Después de instalar el operador, se muestra el mensaje instalación correcta.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Vaya a operadores &gt; operadores instalados, haga clic en F5 Container Ingresing Service y, a continuación, haga clic en Crear instancia en el icono F5BigIpctlr.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">Cree F5BigIpctlr</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">Haga clic en YAML View y pegue el siguiente contenido después de actualizar los parámetros necesarios.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">Actualice los parámetros<block ref="9117e80b6a6843f23b631387abeed925" prefix=" " category="inline-code"></block>, "openshift_sdn_name",<block ref="957c32cdfcd5fb9c99f7a4e3311e7768" prefix=" " category="inline-code"></block> y..<block ref="1155b6812ea5125b3144173aaaad6205" prefix=" " category="inline-code"></block> a continuación se muestran los valores de la configuración antes de copiar el contenido.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">Después de pegar este contenido, haga clic en Crear. De esta forma se instalan los POD CIS en el espacio de nombres del sistema kube.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">Validar los POD CIS de F5</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Red Hat OpenShift, de forma predeterminada, proporciona una forma de exponer los servicios a través de rutas para el equilibrio de carga L7. Un enrutador OpenShift integrado es responsable de la publicidad y el manejo del tráfico de estas rutas. Sin embargo, también puede configurar F5 CIS para que admita las rutas a través de un sistema BIG-IP externo de F5, que puede ejecutarse como un enrutador auxiliar o como un reemplazo del enrutador OpenShift autoalojado. CIS crea un servidor virtual en EL sistema BIG-IP que actúa como enrutador para las rutas OpenShift y BIG-IP maneja el anuncio y el enrutamiento de tráfico. Consulte la documentación aquí para obtener información sobre los parámetros para habilitar esta función. Tenga en cuenta que estos parámetros se definen para el recurso de implementación de OpenShift en la API de Apps/v1. Por lo tanto, si se usan con la API de recurso cis.f5.com/v1 de F5BigIpctlr, reemplace los guiones (-) por guiones bajos (_) para los nombres de los parámetros.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">Los argumentos que se pasan a la creación de recursos CIS incluyen<block ref="49dcf57b3a065d02c9969c595e32ea50" prefix=" " category="inline-code"></block> y..<block ref="5d0d2663dc7f08b0183abaddf17f8307" prefix=" " category="inline-code"></block>. Estos parámetros son necesarios para habilitar la integración CIS con un controlador IPAM. Compruebe que CIS ha habilitado la integración IPAM creando el recurso IPAM de F5.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">Cree la cuenta de servicio, la función y el enlace de rol necesarios para el controlador IPAM de F5. Cree un archivo YAML y pegue el siguiente contenido.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">Cree los recursos.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">Cree un archivo YAML y pegue la definición de implementación de F5 IPAM que se proporciona a continuación.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">Actualice el parámetro intervalo ip en spec.template.spec.Containers[0].args a continuación para reflejar los rangos de direcciones IP y ipamLabels correspondientes a su configuración.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IpamLabels <block ref="4795fc86aa645b109548974bcffefe07" prefix="[" category="inline-code"></block> y..<block ref="0ce75607b46ab2a9cc08eab9ade2a24d" prefix=" " category="inline-code"></block> En ejemplo inferior] es necesario anotar los servicios de tipo LoadBalancer para el controlador IPAM a fin de detectar y asignar una dirección IP del intervalo definido.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">Cree la implementación del controlador IPAM de F5.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">Compruebe que se están ejecutando los POD del controlador IPAM de F5.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">Cree el esquema F5 IPAM.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">Verificación</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">Cree un servicio de tipo LoadBalancer</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">Compruebe si el controlador IPAM le asigna una IP externa.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">Cree una implementación y utilice el servicio LoadBalancer que se ha creado.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Compruebe si los pods están en ejecución.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">Compruebe si se crea el servidor virtual correspondiente en EL sistema BIG-IP para el servicio del tipo LoadBalancer en OpenShift. Desplácese a tráfico local &gt; servidores virtuales &gt; Lista de servidores virtuales.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">Validar la creación de servidores virtuales BIG-IP para el tipo de servicio correspondiente LoadBalancer</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">Siguiente: Casos prácticos y validación de soluciones: Red Hat OpenShift con NetApp.</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">En esta página se detallan las instrucciones de instalación y configuración del equilibrador de carga de MetalLB.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">Instalación de equilibradores de carga de MetalLB: Red Hat OpenShift con NetApp</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">En esta página se enumeran las instrucciones de instalación y configuración del equilibrador de carga de MetalLB.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB es un equilibrador de carga de red autoalojado instalado en el clúster de OpenShift que permite la creación de servicios OpenShift de equilibrador de carga de tipo en clústeres que no se ejecutan en un proveedor de cloud. Las dos principales características de MetalLB que trabajan conjuntamente para apoyar los servicios LoadBalancer son la asignación de direcciones y el anuncio externo.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">Opciones de configuración de MetalLB</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">Basándose en cómo MetalLB anuncia la dirección IP asignada a los servicios LoadBalancer fuera del clúster OpenShift, funciona en dos modos:</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">*Modo de capa 2.* en este modo, un nodo del clúster OpenShift asume la propiedad del servicio y responde a las solicitudes ARP de esa IP para hacerla accesible fuera del clúster OpenShift. Como solo el nodo anuncia la IP, presenta un cuello de botella de ancho de banda y unas limitaciones lentas de conmutación al respaldo. Para obtener más información, consulte la documentación <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">*Modo BGP.* en este modo, todos los nodos del clúster OpenShift establecen sesiones de BGP peering con un router y anuncian las rutas para reenviar tráfico a las IP de servicio. El requisito previo para ello es integrar MetalLB con un router en esa red. Debido al mecanismo de hash en BGP, tiene ciertas limitaciones cuando cambia la asignación de IP a nodo para un servicio. Para obtener más información, consulte la documentación <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">A efectos de este documento, configuraremos MetalLB en modo capa-2.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">Instalación del equilibrador de carga de MetalLB</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">Descargar los recursos de MetalLB.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">Editar archivo<block ref="130d214581bb0aa3e8759729c9fbc133" prefix=" " category="inline-code"></block> y retirar<block ref="635a57f17cd40dc65b36973c9e14f9d1" prefix=" " category="inline-code"></block> Desde el despliegue del controlador y el altavoz DemonSet.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">*Líneas a borrar:*</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">Cree el<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> espacio de nombres.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">Cree el MetalLB CR.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">Antes de configurar el altavoz MetalLB, conceda privilegios elevados DemonSet de altavoz para que pueda realizar la configuración de red necesaria para que los equilibradores de carga funcionen.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">Configure MetalLB creando un<block ref="a941f8adb5ae079ebc739cb59407fd30" prefix=" " category="inline-code"></block> en la<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> espacio de nombres.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">Ahora, cuando se crean servicios loadbalancer, MetalLB asigna una IP externa a los servicios y anuncia la dirección IP respondiendo a las solicitudes ARP.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">Si desea configurar MetalLB en modo BGP, omita el paso 6 anterior y siga el procedimiento descrito en la documentación de MetalLB <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">Siguiente: Casos prácticos y validación de soluciones: Red Hat OpenShift con NetApp.</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Habilite la protección de datos en la canalización de CI/CD con Astra Control Center</block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Protección de datos en canalización de CI/CD con Astra Control Center</block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">Esta sección se dedica a analizar las opciones de equilibrador de carga para los usuarios que desean personalizar su Red Hat OpenShift con la implementación de NetApp.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">Análisis de las opciones de equilibrador de carga: Red Hat OpenShift con NetApp</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">En la mayoría de los casos, Red Hat OpenShift hace que las aplicaciones estén disponibles para el mundo exterior a través de rutas. Un servicio es expuesto dándole un nombre de host accesible desde el exterior. Un enrutador OpenShift puede consumir la ruta definida y los puntos finales identificados por su servicio para proporcionar esta conectividad con nombre a clientes externos.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">Sin embargo, en algunos casos, las aplicaciones requieren la puesta en marcha y configuración de equilibradores de carga personalizados para exponer los servicios adecuados. Un ejemplo de esto es Astra Control Center de NetApp. Para satisfacer esta necesidad, hemos evaluado una serie de opciones de equilibrador de carga personalizadas. Su instalación y configuración se describen en esta sección.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">En las siguientes páginas se ofrece información adicional sobre las opciones de equilibrador de carga validadas en la solución Red Hat OpenShift con NetApp:</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">BIG-IP DE F5</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">Clonado de máquinas virtuales</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">La clonación de una VM existente en OpenShift se logra con la compatibilidad de la función de clonación Volume CSI de Astra Trident. La clonación de volúmenes CSI permite la creación de un nuevo PVC utilizando un PVC existente como origen de datos duplicando su PV. Después de crear el nuevo PVC, funciona como una entidad independiente y sin ningún vínculo ni dependencia del PVC de origen.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">Arquitectura de clonado de equipos virtuales</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">Hay ciertas restricciones en la clonación de volúmenes de CSI a tener en cuenta:</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">El PVC de origen y el PVC de destino deben estar en el mismo proyecto.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">El clonado se admite en la misma clase de almacenamiento.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">El clonado solo se puede realizar cuando los volúmenes de origen y de destino utilizan la misma configuración VolumeMode; por ejemplo, un volumen de bloques solo se puede clonar en otro volumen de bloques.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">Los equipos virtuales de un clúster de OpenShift se pueden clonar de dos formas distintas:</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">Apagando la máquina virtual de origen</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">Manteniendo activo la máquina virtual de origen</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">Apagando la máquina virtual de origen</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">Clonar una máquina virtual existente cerrando una máquina virtual es una función OpenShift nativa que se implementa con la compatibilidad de Astra Trident. Complete los siguientes pasos para clonar una máquina virtual.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">Vaya a cargas de trabajo &gt; virtualización &gt; máquinas virtuales y haga clic en los tres puntos junto a la máquina virtual que desea clonar.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Haga clic en Clone Virtual Machine e proporcione los detalles de la nueva máquina virtual.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">clon de la máquina virtual</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Haga clic en Clone Virtual Machine; se cierra la máquina virtual de origen e inicia la creación del equipo virtual clonado.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">Una vez completado este paso, puede acceder al contenido del equipo virtual clonado y verificarlo.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">También es posible clonar una máquina virtual existente clonando la RVP existente del equipo virtual de origen y, luego, crear un nuevo equipo virtual con el RVP clonado. Este método no requiere que apague la VM de origen. Complete los siguientes pasos para clonar una máquina virtual sin apagarlo.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Vaya a almacenamiento &gt; PersistentVolumeClaments y haga clic en los tres puntos junto a la RVP que está conectada a la máquina virtual de origen.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Haga clic en Clone PVC y proporcione los detalles de la nueva RVP.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">clonar rvp</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">A continuación, haga clic en Clonar. De este modo se crea una RVP para la nueva máquina virtual.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">Desplácese hasta cargas de trabajo &gt; virtualización &gt; Máquinas virtuales y haga clic en Crear &gt; con AYLMA.</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">En la sección SPEC &gt; template &gt; Spec &gt; Volumes, asocie el PVC clonado en lugar del disco de contenedor. Proporcione los demás detalles de la nueva VM de acuerdo con sus requisitos.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Haga clic en Create para crear la nueva máquina virtual.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">Una vez que la máquina virtual se haya creado correctamente, compruebe que la nueva máquina virtual sea un clon de la máquina virtual de origen.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">Siguiente: Flujos de trabajo: Crear una máquina virtual a partir de una snapshot.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">Esta sección se dedica a crear y configurar un registro de imágenes privadas respaldado por el almacenamiento persistente que proporciona Astra Trident.</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">Creación de registros privados de imágenes</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">Quay.io</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Para la mayoría de implementaciones de Red Hat OpenShift, utilizando un registro público como<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> o.<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> satisface la mayoría de las necesidades de sus clientes. Sin embargo, hay ocasiones en las que un cliente puede querer alojar sus propias imágenes privadas o personalizadas.</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">Este procedimiento documenta la creación de un registro de imágenes privadas que está respaldado por un volumen persistente proporcionado por Astra Trident y NetApp ONTAP.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center requiere un registro para alojar las imágenes que necesitan los contenedores Astra. En la siguiente sección se describen los pasos para configurar un registro privado en el clúster de Red Hat OpenShift e insertar las imágenes necesarias para admitir la instalación de Astra Control Center.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">Crear un registro de imágenes privadas</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">Elimine la anotación predeterminada de la clase de almacenamiento predeterminada actual y anote la clase de almacenamiento respaldada por Trident como predeterminada para el clúster OpenShift.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">Edite el operador imagerRegistry introduciendo los siguientes parámetros de almacenamiento en el<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sección.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">Introduzca los siguientes parámetros en el<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Sección para crear una ruta OpenShift con un nombre de host personalizado. Guarde y salga.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">La configuración de ruta anterior se utiliza cuando se desea un nombre de host personalizado para la ruta. Si desea que OpenShift cree una ruta con un nombre de host predeterminado, puede agregar los siguientes parámetros al<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sección:<block ref="b09e8357c45c55a2c3ca685c9742fa6e" prefix=" " category="inline-code"></block>.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">Certificados TLS personalizados</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">Cuando se utiliza un nombre de host personalizado para la ruta, de forma predeterminada, utiliza la configuración TLS predeterminada del operador de OpenShift Ingress. Sin embargo, puede agregar una configuración TLS personalizada a la ruta. Para ello, lleve a cabo los siguientes pasos.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">Cree un secreto con los certificados TLS y la clave de la ruta.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Edite el operador imagerRegistry agregue los siguientes parámetros al<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sección.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">Vuelva a editar el operador de imageregistry cambie el estado de administración del operador a<block ref="80c202b1c3fd395a7bfe4d846c914bc3" prefix=" " category="inline-code"></block> estado. Guarde y salga.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">Si se cumplen todos los requisitos previos, se crean EVs, POD y servicios para el registro de imágenes privadas. En unos minutos, el registro debería estar activo.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">Si utiliza los certificados TLS predeterminados para la ruta de registro del operador Ingress OpenShift, puede obtener los certificados TLS utilizando el siguiente comando.</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">Para permitir que los nodos de OpenShift accedan a las imágenes y las extractivas del Registro, agregue los certificados al cliente docker en los nodos de OpenShift. Cree un mapa de configuración en<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Espacio de nombres mediante los certificados TLS y retome la configuración de la imagen del clúster para garantizar la confianza del certificado.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">El registro interno de OpenShift se controla mediante autenticación. Todos los usuarios de OpenShift pueden tener acceso al registro de OpenShift, pero las operaciones que el usuario que ha iniciado sesión puede realizar dependen de los permisos del usuario.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">Para permitir que un usuario o un grupo de usuarios extraiga imágenes del Registro, el usuario debe tener asignada la función de visor del Registro.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">Para permitir a un usuario o grupo de usuarios escribir o insertar imágenes, el usuario debe tener asignado el rol de editor de registros.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">Para que los nodos OpenShift accedan al Registro y push o extran las imágenes, debe configurar un secreto de extracción.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">Este secreto de extracción se puede aplicar a las cuentas de servicio o hacer referencia a ellas en la definición de POD correspondiente.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">Para aplicar revisiones a las cuentas de servicio, ejecute el siguiente comando.</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">Para hacer referencia al secreto de extracción en la definición de POD, agregue el siguiente parámetro al<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> sección.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">Para insertar o extraer una imagen de estaciones de trabajo aparte del nodo OpenShift, lleve a cabo los siguientes pasos.</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Agregue los certificados TLS al cliente docker.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">Inicie sesión en OpenShift con el comando de inicio de sesión de OC.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">Inicie sesión en el registro utilizando las credenciales de usuario de OpenShift con el comando podman/docker.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">podman</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ NOTA: Si está utilizando<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> usuario para iniciar sesión en el registro privado, utilice token en lugar de contraseña.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">docker</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">Empuje o tire de las imágenes.</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">Migración dinámica de máquinas virtuales</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">Migración dinámica es un proceso de migrar una instancia de máquina virtual de un nodo a otro en un clúster de OpenShift sin tiempos de inactividad. Para que la migración en vivo funcione en un clúster OpenShift, las máquinas virtuales deben estar enlazadas a EVs con el modo de acceso compartido ReadWriteMany. Entorno de administración Trident configurado con una SVM en un clúster ONTAP de NetApp habilitado para el protocolo NFS admite el acceso compartido ReadWriteMany para las RVP. Por lo tanto, los equipos virtuales con RVP solicitados de las clases de almacenamiento aprovisionadas por Trident desde una SVM habilitada para NFS se pueden migrar sin tiempo de inactividad.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">Arquitectura de migración dinámica de máquinas virtuales</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">Para crear una VM enlazada a EVs con acceso compartido ReadWriteMany:</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">Seleccione el sistema operativo que desee y haga clic en Siguiente. Supongamos que el sistema operativo seleccionado ya tenía configurado un origen de arranque.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">Haga clic en Customize Virtual Machine y, a continuación, en Storage.</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">Haga clic en los tres puntos junto a rootdisk y asegúrese de que está seleccionada la opción storagegrid aprovisionado mediante Trident. Expanda Avanzado y seleccione acceso compartido (RWX) para el modo de acceso. A continuación, haga clic en Guardar.</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">Haga que EL disco RWX esté accesible</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">Haga clic en revisar y confirme y, a continuación, haga clic en Crear máquina virtual.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">Para migrar manualmente una máquina virtual a otro nodo del clúster de OpenShift, realice los pasos siguientes.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">Vaya a cargas de trabajo &gt; virtualización &gt; máquinas virtuales.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">En el caso de la máquina virtual que desee migrar, haga clic en los tres puntos y, a continuación, haga clic en Migrate the Virtual Machine.</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">Haga clic en migrar cuando aparezca el mensaje para confirmar.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">Una instancia de máquina virtual de un clúster de OpenShift migra automáticamente a otro nodo cuando el nodo original se pone en modo de mantenimiento si la estrategia de desalojetionStrategy se establece en LiveMigrate.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">Siguiente: Flujos de trabajo: Clonado de equipos virtuales.</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">Configuración de Multitenancy en Red Hat OpenShift con NetApp</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">Aunque Red Hat OpenShift y Astra Trident con el respaldo de ONTAP de NetApp no proporcionan aislamiento entre cargas de trabajo de forma predeterminada, ofrecen una amplia gama de funciones que se pueden utilizar para configurar multi-tenancy. Para comprender mejor el diseño de una solución multitenant en un clúster de Red Hat OpenShift con Astra Trident respaldado por ONTAP de NetApp, consideremos un ejemplo con un conjunto de requisitos y esquememos la configuración que lo rodea.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">Supongamos que una organización ejecuta dos de sus cargas de trabajo en un clúster de Red Hat OpenShift como parte de dos proyectos en los que trabajan dos equipos diferentes. Los datos de estas cargas de trabajo residen en RVP que aprovisiona de forma dinámica Astra Trident en un back-end NAS de ONTAP de NetApp. La organización tiene el requisito de diseñar una solución multitenant para estas dos cargas de trabajo y aislar los recursos utilizados para estos proyectos para garantizar que se mantiene la seguridad y el rendimiento, centrados principalmente en los datos que sirven a esas aplicaciones.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">En la siguiente figura se describe la solución multitenant en un clúster de Red Hat OpenShift con Astra Trident respaldado por ONTAP de NetApp.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">Multi-tenancy en el clúster Red Hat OpenShift con Astra Trident y con el respaldo de ONTAP de NetApp</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Requisitos tecnológicos</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">Clúster de almacenamiento ONTAP de NetApp</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Clúster de Red Hat OpenShift</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift – Recursos de clúster</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Desde el punto de vista del clúster de Red Hat OpenShift, el recurso de nivel superior con el que empezar es el proyecto. Un proyecto de OpenShift se puede ver como un recurso de clúster que divide todo el clúster de OpenShift en varios clústeres virtuales. Por lo tanto, el aislamiento a nivel de proyecto proporciona una base para configurar multi-tenancy.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">El siguiente está para configurar RBAC en el clúster. La práctica recomendada es tener todos los desarrolladores trabajando en un único proyecto o carga de trabajo configurados en un único grupo de usuarios en el proveedor de identidades (IDP). Red Hat OpenShift permite la integración de IDP y la sincronización de grupos de usuarios, lo que permite importar al clúster los usuarios y grupos del IDP. Esto ayuda a los administradores del clúster a segregar el acceso de los recursos del clúster dedicados a un proyecto a un grupo de usuarios o grupos que trabajan en ese proyecto, restringiendo de este modo el acceso no autorizado a cualquier recurso del clúster. Para obtener más información sobre la integración de IDP con Red Hat OpenShift, consulte la documentación<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">Es importante aislar el almacenamiento compartido que sirve como proveedor de almacenamiento persistente para un clúster de Red Hat OpenShift con el fin de garantizar que los volúmenes creados en el almacenamiento de cada proyecto aparecen en los hosts como si se crean en un almacenamiento separado. Para ello, cree tantos SVM (máquinas virtuales de almacenamiento) en ONTAP de NetApp como haya proyectos o cargas de trabajo, y dedique cada SVM a una carga de trabajo.</block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">Después de haber establecido diferentes SVM para diferentes proyectos creados en ONTAP de NetApp, debe asignar cada SVM a un back-end de Trident diferente. La configuración de back-end en Trident impulsa la asignación de almacenamiento persistente a recursos de clúster de OpenShift y requiere los detalles de la SVM a la que se va a asignar. Este debe ser el controlador de protocolo para el back-end como mínimo. De manera opcional, le permite definir cómo se aprovisionan los volúmenes en el almacenamiento y establecer límites para el tamaño de los volúmenes o el uso de agregados, etc. Se pueden encontrar detalles sobre la definición de los back-ends de Trident<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift – recursos de almacenamiento</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Después de configurar los back-ends de Trident, el siguiente paso es configurar StorageClasses. Configure tantas clases de almacenamiento como sean los back-ends, proporcionando acceso a cada clase de almacenamiento para activar volúmenes solo en un back-end. Podemos asignar este tipo de almacenamiento a un back-end de Trident concreto mediante el parámetro Storage Pools mientras se define la clase de almacenamiento. Se pueden encontrar los detalles para definir una clase de almacenamiento<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. Por ello, hay una asignación uno a uno desde el back-end de StorageClass a Trident que señala a una SVM. De este modo, se garantiza que todas las solicitudes de almacenamiento que realiza el clases de almacenamiento asignadas a ese proyecto sean atendidas por la SVM dedicada exclusivamente a dicho proyecto.</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">Debido a que los tipos de almacenamiento no son recursos namesped, ¿cómo podemos garantizar que las afirmaciones sobre el almacenamiento a la clase de almacenamiento de un proyecto por POD en otro espacio de nombres o proyecto sean rechazadas? La respuesta es utilizar ResourceQuotas. ResourceQuotas son objetos que controlan el uso total de recursos por proyecto. Puede limitar el número así como la cantidad total de recursos que pueden consumir los objetos del proyecto. Casi todos los recursos de un proyecto pueden limitarse utilizando ResourceQuotas y el uso eficaz de este recurso puede ayudar a las organizaciones a reducir los costes y las interrupciones debido al sobreaprovisionamiento o al sobreconsumo de recursos. Consulte la documentación<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">Para este caso de uso, es necesario limitar los pods de un proyecto en concreto de solicitar almacenamiento a clases de almacenamiento que no estén dedicadas a su proyecto. Para ello, hemos de limitar las reclamaciones por volumen persistente para otros tipos de almacenamiento al establecer<block ref="a21be23447e555ea751318f1aded4a38" prefix=" " category="inline-code"></block> a 0. Además, un administrador de clúster debe asegurarse de que los desarrolladores de un proyecto no tengan acceso para modificar ResourceQuotas.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">Siguiente: Configuración.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">Migración de cargas de trabajo: Red Hat OpenShift con NetApp</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">Integración fluida con un cloud público para la organización en niveles y protección de los datos. ONTAP también proporciona funcionalidades de protección de datos sólidas que lo diferencian en cualquier entorno:</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">Para obtener más información acerca de ONTAP, consulte<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">Ambos sistemas cuentan con el software de gestión de datos ONTAP de NetApp, el software de gestión de datos más avanzado del sector para una gestión del almacenamiento simplificada, integrada en el cloud y de alta disponibilidad, con el fin de proporcionar una velocidad, eficiencia y seguridad aptas para el ámbito empresarial que sus necesidades de Data Fabric necesitan.</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select es una puesta en marcha definida por software de ONTAP de NetApp que se puede poner en marcha en un hipervisor en su entorno. Puede instalarse en VMware vSphere o en KVM y ofrece todas las funciones y la experiencia de un sistema ONTAP basado en hardware.</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">Cloud Volumes ONTAP de NetApp es una versión de NetApp ONTAP que se pone en marcha en el cloud y que se puede poner en marcha en diversos clouds públicos, incluidos Amazon AWS, Microsoft Azure y Google Cloud.</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">Siguiente: Descripción general de las integraciones de almacenamiento de NetApp</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">Observabilidad</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Advanced Cluster Management para Kubernetes ofrece un modo de supervisar los nodos, los pods y las aplicaciones, y las cargas de trabajo en todos los clústeres.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">Navegue hasta observar entornos &gt; Descripción general.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">Página principal de observabilidad</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">Todos los pods y cargas de trabajo de todos los clústeres se supervisan y se ordenan en función de una variedad de filtros. Haga clic en pods para ver los datos correspondientes.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">Observe los pods</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">Todos los nodos de los clústeres se supervisan y se analizan en función de una variedad de puntos de datos. Haga clic en Nodes para obtener más información sobre los detalles correspondientes.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">Observe los nodos</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">Todos los clústeres se supervisan y organizan en función de diferentes parámetros y recursos del clúster. Haga clic en Clusters para ver los detalles del clúster.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">Observe los clústeres</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">Siguiente: Características - Crear recursos.</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">OpenShift Container Platform de Red Hat es una plataforma de Kubernetes empresarial totalmente compatible. Red Hat realiza varias mejoras en Kubernetes de código abierto para ofrecer una plataforma de aplicaciones con todos los componentes totalmente integrados para crear, implementar y gestionar aplicaciones en contenedores.</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">Para obtener más información, visite el sitio web de OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">Si quiere más información, visite el sitio web de NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">Astra Control Center de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, puestas en marcha en un entorno local y con la tecnología de confianza de protección de datos de NetApp.</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes como {k8s_distribution_name}.</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">NetApp cuenta con varias plataformas de almacenamiento cualificadas con Astra Trident y Astra Control para aprovisionar, proteger y gestionar datos para aplicaciones en contenedores.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">Los sistemas de almacenamiento NetApp Element ofrecen casos de uso basados en bloques (iSCSI) en un entorno altamente escalable.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">Cada sistema de almacenamiento de la cartera de NetApp puede facilitar la gestión y el movimiento de datos entre sitios locales y el cloud, lo que garantiza que los datos estén donde se encuentran las aplicaciones.</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="fcda5b98e8c212807dc088477e802757" category="inline-link-macro">NetApp Element</block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">NetApp proporciona una serie de productos para ayudarle a orquestar, gestionar, proteger y migrar aplicaciones con contenedores con estado y sus datos.</block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">Astra Control de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, con la tecnología de protección de datos de NetApp. El servicio Astra Control está disponible para admitir cargas de trabajo con estado en puestas en marcha de Kubernetes nativas para el cloud. Astra Control Center está disponible para admitir cargas de trabajo con estado en puestas en marcha en las instalaciones de plataformas Enterprise Kubernetes como {k8s_distribution_name}. Si quiere más información, visite el sitio web de Astra Control de NetApp<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">En un entorno conectado a la nube, Astra Control Center utiliza Cloud Insights para proporcionar supervisión y telemetría avanzadas. Ante la ausencia de una conexión con Cloud Insights, la supervisión y la telemetría limitadas (métricas de 7 días) están disponibles y se exportan a herramientas de supervisión nativas de Kubernetes (Prometheus y Grafana) mediante extremos de métricas abiertos.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Además de la versión de pago de Astra Control Center, hay disponible una licencia de evaluación de 90 días. La versión de evaluación se admite a través del correo electrónico y la comunidad (canal Slack). Los clientes tienen acceso a éstos y a otros artículos de la base de conocimientos y a la documentación disponible en la consola de soporte del producto.</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes como {k8s_distribution_name}. Trident funciona con toda la cartera de almacenamiento de NetApp, incluidos los sistemas de almacenamiento ONTAP y Element de NetApp, y también admite conexiones NFS e iSCSI. Trident acelera el flujo de trabajo de DevOps al permitir que los usuarios finales aprovisionen y gestionen el almacenamiento desde sus sistemas de almacenamiento de NetApp sin necesidad de intervención del administrador de almacenamiento.</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident tiene un rápido ciclo de desarrollo y, al igual que Kubernetes, se publica cuatro veces al año.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">A partir del lanzamiento de la versión 20.04, el operador de Trident realiza la configuración de Trident. El operador facilita las puestas en marcha a gran escala y ofrece soporte adicional, incluida la reparación automática de los pods que se implementan como parte de la instalación de Trident.</block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="summary">Los ejemplos que se proporcionan en esta página son las validaciones de la solución y los casos de uso de Anthos con NetApp.</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="doc">Validación de soluciones y casos prácticos</block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Instale una aplicación mediante la consola de Google Cloud</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">Creación de registros de imágenes privados</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">Este procedimiento documenta la creación de un registro de imágenes privadas respaldado por un volumen persistente proporcionado por Astra Trident y NetApp ONTAP.</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center requiere un registro para alojar las imágenes que necesitan los contenedores Astra. En la siguiente sección se describen los pasos para configurar un registro privado en un clúster de Red Hat OpenShift e insertar las imágenes necesarias para admitir la instalación de Astra Control Center.</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">Si utiliza los certificados TLS predeterminados para la ruta de registro OpenShift del operador Ingress, puede obtener los certificados TLS utilizando el siguiente comando:</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">El registro interno de OpenShift se controla mediante autenticación. Todos los usuarios de OpenShift pueden tener acceso al registro de OpenShift, pero las operaciones que el usuario que ha iniciado sesión puede realizar dependen de los permisos del usuario.</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">Para aplicar revisiones a las cuentas de servicio, ejecute el siguiente comando:</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">Para insertar o extraer una imagen de estaciones de trabajo aparte del nodo OpenShift, lleve a cabo los siguientes pasos:</block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">Si está utilizando<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> usuario para iniciar sesión en el registro privado y, a continuación, utilice un token en lugar de una contraseña.</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">Siguiente: Casos prácticos y de validación de la solución.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="doc">Instalación de equilibradores de carga de MetalLB</block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">En esta página se enumeran las instrucciones de instalación y configuración del equilibrador de carga gestionado de MetalLB.</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">El equilibrador de carga de MetalLB está totalmente integrado con los clústeres de Anthos en VMware y cuenta con una puesta en marcha automatizada como parte de las configuraciones de clúster de administrador y usuario a partir de la versión 1.11. Hay bloques de texto en los respectivos<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> archivos de configuración que debe modificar para proporcionar información de equilibrador de carga. Se aloja automáticamente en su clúster Anthos en lugar de necesitar la implementación de recursos externos, como las otras soluciones de equilibrador de carga compatibles. También le permite crear un pool ip que asigna direcciones automáticamente con la creación de servicios de Kubernetes de equilibrio de carga de tipo en clústeres que no se ejecutan en un proveedor de cloud.</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Integración con Anthos</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Al activar el equilibrador de carga de MetalLB para el administrador de Anthos, debe modificar algunas líneas en el<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> la sección que existe en la<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> archivo. Los únicos valores que debe modificar son establecer el<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block> y, a continuación, defina la<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> Como MetalLB. Consulte el siguiente fragmento de código para obtener un ejemplo:</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">Al habilitar el equilibrador de carga de MetalLB para los clústeres de usuarios de Anthos, hay dos áreas en cada uno<block ref="aba03e96a3a4305fd83dc510e1607415" prefix=" " category="inline-code"></block> archivo que debe actualizar. En primer lugar, de una manera similar a la<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> debe modificar el<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block>,<block ref="4fa041ebf362f3965af3570da03ef0fe" prefix=" " category="inline-code"></block>, y.<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> valores en la<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> sección. Consulte el siguiente fragmento de código para obtener un ejemplo:</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">Las ingressVIP IP address deben existir dentro del grupo de direcciones IP asignadas al equilibrador de carga MetalLB más adelante en la configuración.</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">A continuación, debe navegar hasta la<block ref="0ea77e636e8d12d9ce07b2dab6268822" prefix=" " category="inline-code"></block> y modifique la<block ref="045d68a12437e8212f812d2bf506dbc0" prefix=" " category="inline-code"></block> asigne un nombre al pool en la<block ref="146d8d83713f4abd99cafc739779598c" prefix=" " category="inline-code"></block> variable. También debe crear un grupo de direcciones ip que MetalLB pueda asignar a servicios de tipo LoadBalancer proporcionando un rango a<block ref="336f9e008319434aa314ef3c1b8a682f" prefix=" " category="inline-code"></block> variable.</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">El pool de direcciones se puede proporcionar como un rango como en el ejemplo, limitando a un número de direcciones en una subred determinada, o se puede proporcionar como una notación CIDR si se pone a disposición toda la subred.</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">Cuando se crean servicios de Kubernetes de tipo LoadBalancer, MetalLB asigna automáticamente una IP externa a los servicios y anuncia la dirección IP respondiendo a las solicitudes ARP.</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">Siguiente: Instalación de equilibradores de carga de Seesaw.</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp proporciona una serie de productos que ayudan a nuestros clientes a orquestar y gestionar datos persistentes en entornos basados en contenedores como Anthos.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">Descripción general de integración del almacenamiento de NetApp</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Programa para partners de almacenamiento Anthos Ready.</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud solicita periódicamente una validación actualizada de las integraciones de almacenamiento de partners con los nuevos lanzamientos de Anthos a través de su programa para partners de almacenamiento Anthos Ready. Encontrará una lista de las soluciones de almacenamiento validadas actualmente, los controladores CSI, las funciones disponibles y las versiones de Anthos admitidas<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>.</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">La siguiente tabla contiene las versiones de Anthos que han probado los ingenieros de partners de NetApp y de NetApp para validar los controladores y los conjuntos de funciones Astra Trident de NetApp como parte del programa para partners de almacenamiento Anthos:</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">Tipo de puesta en marcha</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">Sistema de almacenamiento</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Versión de Astra Trident</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">Protocolo</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="cell">Funciones</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="cell">VMware</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">Multiwriter, expansión de volumen, instantáneas</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">SAN</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">Bloque bruto, expansión de volumen, snapshots</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">nativo</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp proporciona una serie de productos que le ayudan a orquestar y gestionar datos persistentes en entornos basados en contenedores como Anthos.</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">Astra Trident de NetApp es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Anthos. Si quiere más información, visite el sitio web de Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">Las siguientes páginas contienen información adicional sobre los productos de NetApp que se han validado para la gestión de aplicaciones y almacenamiento persistente en la solución Anthos con NetApp.</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">Siguiente: Descripción general de Astra Trident de NetApp.</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">El vídeo vinculado a de esta página muestra algunas de las capacidades que se documentan en este documento.</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="doc">Vídeos y demostraciones</block>
  <block id="1adda60fb6ef5adf0c35c53442bdd87d" category="inline-link-macro">Vídeo: Puesta en marcha de Anthos en configuraciones básicas</block>
  <block id="81082fb0b2db5311a27c6cd75db69481" category="paragraph"><block ref="81082fb0b2db5311a27c6cd75db69481" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Una vez registrados los clústeres de Red Hat OpenShift, podrá descubrir las aplicaciones que se implementan y gestionan a través de Astra Control Center.</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">Una vez registrados los clústeres de OpenShift y los back-ends de ONTAP con el Centro de control de Astra, el centro de control inicia automáticamente el descubrimiento de las aplicaciones en todos los espacios de nombres que utilizan el sistema storageeclass configurado con el back-end de ONTAP especificado.</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="summary">Para habilitar la integración de Trident con el sistema de almacenamiento NetApp Element, debe crear un back-end que permita la comunicación con el sistema de almacenamiento mediante el protocolo iSCSI.</block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">Configuración de iSCSI de NetApp Element</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">Hay archivos de fondo de ejemplo disponibles en el archivo de instalación descargado en<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> jerarquía de carpetas. Para sistemas NetApp Element que sirven iSCSI, copie el<block ref="7989420add0b5baae954e866987ef264" prefix=" " category="inline-code"></block> archivar en el directorio de trabajo y editar el archivo.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">Edite el valor de usuario, contraseña y MVIP de en el<block ref="b7ae24ea48e61624a7e4078daa60bd78" prefix=" " category="inline-code"></block> línea.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">Edite el<block ref="dcda39e13b00bf6bd40a507e1833a6f5" prefix=" " category="inline-code"></block> valor.</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">Con este archivo back-end en su sitio, ejecute el siguiente comando para crear su primer back-end.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">Con el back-end creado, debe crear después una clase de almacenamiento. Al igual que con el backend, existe un archivo de clase de almacenamiento de ejemplo que se puede editar para el entorno disponible en la carpeta de entradas de ejemplo. Cópielo en el directorio de trabajo y realice las modificaciones necesarias para reflejar el backend creado.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">La única edición que se debe realizar en este archivo es definir<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> valor asignado al nombre del controlador de almacenamiento desde el back-end recién creado. Observe también el valor del campo de nombre, al que se debe hacer referencia en un paso posterior.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">Hay un campo opcional llamado<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> que se define en este archivo. En los back-ends de iSCSI, este valor se puede establecer en un tipo de sistema de archivos de Linux específico (XFS, ext4, etc.), o se puede eliminar para permitir a OpenShift decidir qué sistema de archivos utilizar.</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">Ejecute el<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> comando para crear la clase de almacenamiento.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">Con la clase de almacenamiento creada, debe crear la primera reclamación de volumen persistente (RVP). Hay una muestra<block ref="a46b72c0e3ff39640d78567a663da1aa" prefix=" " category="inline-code"></block> archivo que se puede utilizar para realizar esta acción ubicada también en entradas de ejemplo.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">La única edición que se debe realizar en este archivo es asegurarse de que<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> el campo coincide con el que se acaba de crear. La definición de PVC se puede personalizar aún más según sea necesario para el aprovisionamiento de la carga de trabajo.</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">Cree el PVC emitiendo el<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> comando. La creación puede tardar un poco de tiempo, según el tamaño del volumen de backup que se esté creando, para que pueda ver el proceso a medida que finalice.</block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">Siguiente: Opciones de configuración avanzadas.</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere es una plataforma de virtualización para gestionar de forma centralizada un gran número de servidores y redes virtualizados que se ejecutan en el hipervisor ESXi.</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="doc">Clusters Anthos en VMware</block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">Los clústeres de Anthos en VMware es una extensión de Google Kubernetes Engine que se pone en marcha en el centro de datos privado de un usuario final. Una organización puede poner en marcha las mismas aplicaciones diseñadas para ejecutarse en contenedores en Google Cloud en clústeres de Kubernetes en las instalaciones. Los clústeres de Anthos en VMware pueden ponerse en marcha en un entorno VMware vSphere existente en su centro de datos, que puede ahorrar en gastos de capital y permitir operaciones de puesta en marcha y escalado más rápidas.</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">La puesta en marcha de los clústeres de Anthos en VMware incluye los siguientes componentes:</block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">*Estación de trabajo de administración de Anthos.* un host de despliegue desde el cual<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> y..<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> Se pueden ejecutar comandos para poner en marcha e interactuar con las puestas en marcha de Anthos.</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*Clúster de administración.* el clúster inicial puesto en marcha al configurar los clústeres de Anthos en VMware. Este clúster gestiona todas las acciones subordinadas del clúster de usuario, incluidas la puesta en marcha, el escalado y la actualización.</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*Clúster de usuarios.* cada clúster de usuarios se implementa con su propia instancia o partición de equilibrador de carga, lo que le permite actuar como clúster de Kubernetes independiente para usuarios o grupos individuales, lo que ayuda a lograr una multi-tenancy completa.</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">El siguiente gráfico es una descripción de una puesta en marcha de Anthos-Clusters-on-VMware.</block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">Los clústeres de Anthos en VMware ofrecen las siguientes ventajas:</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*Multitenancy avanzado.* a cada usuario final se le puede asignar su propio clúster de usuarios, implementado con los recursos virtuales necesarios para su propio entorno de desarrollo.</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*Ahorro de costes.* los usuarios finales pueden obtener un ahorro significativo al implementar varios clústeres de usuarios en el mismo entorno físico y utilizar sus propios recursos físicos para sus implementaciones de aplicaciones en lugar de aprovisionar recursos en su entorno de Google Cloud o en grandes clústeres con configuración básica.</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*Desarrollar después publicar.* las implementaciones en las instalaciones se pueden utilizar mientras las aplicaciones están en desarrollo, lo que permite probar aplicaciones en la privacidad de un centro de datos local antes de que se pongan a disposición del público en la nube.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">*Requisitos de seguridad.* los clientes con mayores problemas de seguridad o conjuntos de datos confidenciales que no se pueden almacenar en la nube pública pueden ejecutar sus aplicaciones desde la seguridad de sus propios centros de datos, cumpliendo así los requisitos de la organización.</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">Sitio web de VMware vSphere</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">Para obtener más información sobre VMware vSphere, consulte<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere ofrece las siguientes funciones:</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">*VMware vCenter Server.* VMware vCenter Server proporciona una administración unificada de todos los hosts y equipos virtuales desde una única consola y agrega la supervisión del rendimiento de clústeres, hosts y equipos virtuales.</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">*VMware vSphere vMotion.* VMware vCenter le permite migrar en caliente equipos virtuales entre nodos del clúster a petición de manera no disruptiva.</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">*Alta disponibilidad de vSphere.* para evitar interrupciones en caso de fallos de host, VMware vSphere permite agrupar y configurar los hosts para alta disponibilidad. Las máquinas virtuales que son interrumpidas por un error de host se reinician en breve en otros hosts del clúster, restaurando los servicios.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">*Distributed Resource Scheduler (DRS).* se puede configurar un clúster de VMware vSphere para equilibrar la carga de las necesidades de recursos de los equipos virtuales que aloja. Las máquinas virtuales con referencias de recursos pueden migrarse en caliente a otros nodos del clúster para garantizar que haya suficientes recursos disponibles.</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud solicita periódicamente una validación actualizada de las plataformas de servidor de partners con las nuevas versiones de Anthos a través de su programa para partners de plataformas Anthos Ready. Puede encontrar una lista de las plataformas de servidor validadas actualmente y las versiones de Anthos admitidas<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>.</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">Fabricante</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">Marca</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="section-title">De NetApp</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">Los clústeres de Anthos en VMware pueden ponerse en marcha tanto en entornos vSphere 6 como 7, según la elección del cliente, para que pueda ajustarse a su infraestructura de centro de datos actual.</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">La siguiente tabla incluye una lista de las versiones de vSphere que han utilizado NetApp y nuestros partners para validar la solución.</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">Liberar</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Versiones de Anthos</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">Hardware adicional</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">Para completar la puesta en marcha de Anthos con NetApp como solución totalmente validada, NetApp y nuestros ingenieros de partners han probado los componentes adicionales de centro de datos para redes y almacenamiento.</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">En la siguiente tabla se incluye información sobre estos componentes de infraestructura adicionales.</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">Nombre del hardware</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">Software adicional</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">En la siguiente tabla se incluye una lista de las versiones de software puestas en marcha en el entorno de validación.</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">Nombre del software</block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">Debe haber la siguiente infraestructura antes de la puesta en marcha de Anthos:</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">Al menos un servidor DNS que proporciona una resolución de nombre de host completa a la que se puede acceder desde la red de gestión en banda y la red de VM.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">Al menos un servidor NTP al que se puede acceder desde la red de gestión en banda y la red de máquinas virtuales.</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">Un servidor DHCP disponible para proporcionar concesiones de direcciones de red bajo demanda en caso de que los clusters necesiten escalarse dinámicamente.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(Opcional) conectividad saliente de Internet tanto para la red de gestión en banda como para la red de VM.</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Ponga en marcha Anthos en un clúster ESXi de al menos tres nodos</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">A pesar de que es posible instalar Anthos en un clúster de vSphere de menos de tres nodos con fines de demostración o evaluación, no se recomienda para las cargas de trabajo de producción. Aunque dos nodos permiten la alta disponibilidad básica y la tolerancia a fallos, debe modificarse una configuración de clúster Anthos para deshabilitar la afinidad del host predeterminada, por lo que Google Cloud no admite este método de implementación.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">Configurar las máquinas virtuales y la afinidad del host</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">La distribución de nodos de clúster de Anthos en varios nodos de hipervisor se puede lograr habilitando la afinidad de host y de máquina virtual.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">La afinidad o anti-afinidad es una forma de definir reglas para un conjunto de máquinas virtuales y/o hosts que determinan si las VM se ejecutan en el mismo host o en el grupo o en hosts diferentes. Se aplica a los equipos virtuales mediante la creación de grupos de afinidad que constan de equipos virtuales y/o hosts con un conjunto de parámetros y condiciones idénticos. En función de si los equipos virtuales de un grupo de afinidad se ejecutan en el mismo host o hosts del grupo o por separado en hosts diferentes, los parámetros del grupo de afinidad pueden definir afinidad positiva o afinidad negativa.</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">Para configurar los grupos de afinidad, consulte el siguiente enlace correspondiente a su versión de VMware vSphere.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">Documentación de vSphere 6.7: Uso de las reglas de afinidad de DRS</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">Documentación de vSphere 7.0: Uso de las reglas de afinidad de DRS</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>.<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>.</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos tiene una opción de configuración en cada individuo<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> File para crear automáticamente reglas de afinidad de nodos que se pueden habilitar o deshabilitar en función del número de hosts ESXi de su entorno.</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">Siguiente: Anthos en bare metal.</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Para utilizar los libros de estrategia de Ansible para poner en marcha Astra Control Center, debe tener una máquina Ubuntu/RHEL con Ansible instalada. Siga el procedimiento descrito<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Para Ubuntu y.<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Para RHEL.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Cree u obtenga un archivo kubeconfig con acceso de administrador al clúster OpenShift en el que se va a instalar Astra Control Center.</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">Cambie el directorio a<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">Edite el archivo var/var.ydl y rellene las variables con la información necesaria.</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">Si el usuario que ejecuta el libro de estrategia es raíz o tiene sudo configurados sin contraseñas, ejecute el siguiente comando para ejecutar el libro de estrategia.</block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">Cómo poner en marcha una aplicación en su clúster GKE de Anthos en las instalaciones mediante la consola de Google Cloud.</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Ponga en marcha una aplicación desde Google Cloud Console Marketplace</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">Un clúster de Anthos puesta en marcha en las instalaciones y registrado en Google Cloud Console</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Un equilibrador de carga de MetalLB configurado en el clúster de Anthos</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">Una cuenta con permisos para implementar aplicaciones en el clúster</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">Una cuenta de facturación con Google Cloud si elige una aplicación con costes asociados (opcional)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">Implementación de una aplicación</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">Para este caso de uso, implementamos una sencilla aplicación de WordPress en uno de nuestros clústeres Anthos mediante Google Cloud Console. La puesta en marcha usa el almacenamiento persistente proporcionado por ONTAP de NetApp en un almacenamiento storagegrid predefinido. A continuación, mostramos dos métodos diferentes para modificar el servicio predeterminado de las aplicaciones, de modo que el equilibrador de carga de MetalLB lo suministra con una dirección IP y lo expone al mundo.</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">Para implementar una aplicación de esta manera, lleve a cabo los siguientes pasos:</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">Compruebe que el clúster al que desea implementar esté accesible en Google Cloud Console.</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">Clústeres registrados</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">Seleccione aplicaciones en el menú del lado izquierdo, seleccione el menú de opciones de tres puntos en la parte superior y seleccione implementar en Marketplace, que muestra una nueva ventana desde la que puede seleccionar una aplicación en Google Cloud Marketplace.</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">Mercado de aplicaciones</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">Busque la aplicación que desea instalar, en este caso WordPress.</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">Busque WordPress</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">Después de seleccionar la aplicación de WordPress, aparece una pantalla de descripción general. Haga clic en el botón Configurar.</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">Pantalla de descripción de WordPress</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">En la página siguiente deberá seleccionar el clúster al que desea poner en marcha en nuestro caso Demo-Cluster. Seleccione o cree un nuevo nombre de espacio de nombres y de instancia de la aplicación, y seleccione qué clases de almacenamiento y tamaños de volumen persistentes necesita tanto para la aplicación de WordPress como para la base de datos MariaDB de respaldo. En ambos casos elegimos la clase de almacenamiento ONTAP-NAS-CSI.</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">Configuración de WordPress</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">No seleccione Activar acceso IP público. Al hacerlo, se crea un servicio del tipo NodePort al que no se puede acceder desde una puesta en marcha de Anthos en las instalaciones.</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">Después de hacer clic en el botón desplegar, se obtiene una página que proporciona detalles de la aplicación. Puede actualizar esta página o iniciar sesión en el clúster mediante la CLI para comprobar el estado de la implementación.</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">Detalles de la aplicación</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">La CLI se puede utilizar para comprobar el estado de la aplicación mientras se está implementando ejecutando el comando para recuperar información del pod en nuestro espacio de nombres de aplicaciones:<block ref="f33e7514e1b666008863c58a5b3b8fc3" prefix=" " category="inline-code"></block>.</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Reciba los pods de Kubectl</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">Observe en esta captura de pantalla que hay un pod de la instalación en estado de error. Esto es normal. Este pod es un pod de ayuda usado por Google Cloud Console para implementar la aplicación que se autotermina después de que los otros pods hayan iniciado su proceso de inicialización.</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">Después de unos momentos, compruebe que la aplicación se está ejecutando.</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">Aplicación en ejecución</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">Exposición de la aplicación</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">Una vez implementada la aplicación, dispone de dos métodos para asignarle una IP accesible a nivel mundial.</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Mediante la consola de Google Cloud</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">Puede exponer la aplicación mediante Google Cloud Console y editar la salida YAML para los servicios en un explorador para establecer una IP accesible públicamente. Para ello, siga estos pasos:</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">En Google Cloud Console, haga clic en Services and Ingress en el menú del lado izquierdo.</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">Servicios e ingreso</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">Haga clic en la<block ref="038c7925bdf387b6bedcaa4b32ec3a83" prefix=" " category="inline-code"></block> servicio. Se abrirá la pantalla Detalles del servicio. Haga clic en el botón Editar de la parte superior.</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">Editar detalles del servicio</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">Se abre la página Editar detalles del servicio con la información de YAML para el servicio. Desplácese hacia abajo hasta que vea la<block ref="084d5d41838f6b2d8b0c1f1176d66d01" prefix=" " category="inline-code"></block> y la<block ref="3190100143eef75fa97ee36e98fa3f8b" prefix=" " category="inline-code"></block> valor, que se establece en<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block>. Cambie este valor a.<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> Y haga clic en el botón Guardar.</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">Escriba el valor ClusterIP</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">Escriba el valor de LoadBalancer</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">Cuando vuelva a la página Service Details, el<block ref="e659b52eba1f0299b2d8ca3483919e72" prefix=" " category="inline-code"></block> ahora la lista<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> y la<block ref="918d33b6c8dd822ec40bbef2e2f58f3e" prefix=" " category="inline-code"></block> El campo muestra una dirección IP asignada desde el grupo MetalLB y el puerto a través del cual se puede acceder a la aplicación.</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">Detalles del servicio final</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Aplicación de parches del servicio con Kubectl</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">Puede exponer la aplicación utilizando la CLI y el<block ref="b40dfaf71508ce779421b1c4dde5f99f" prefix=" " category="inline-code"></block> Comando para modificar la implementación y establecer una IP de acceso público. Para ello, lleve a cabo los siguientes pasos:</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">Enumere los servicios asociados a los pods del espacio de nombres con el<block ref="3841f6ce7a9f7be216fe99eef26477f6" prefix=" " category="inline-code"></block> comando.</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">Servicios de listas</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">Modifique el tipo de servicio desde<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block> para escribir<block ref="5c89f521cbb8685d397906bd6ce0efa1" prefix=" " category="inline-code"></block> con el siguiente comando:</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">A este nuevo tipo de servicio se le asigna automáticamente una dirección IP disponible desde el grupo MetalLB.</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">Patch Service to Type LoadBalancer</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">Visite la aplicación en la IP externa expuesta</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">Ahora que usted tiene la aplicación expuesta con una dirección IP accesible públicamente, usted puede visitar su instancia de WordPress mediante un navegador.</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">WordPress en el navegador</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">Inicie sesión en el sitio de soporte de NetApp y descargue la versión más reciente de Astra Control Center de NetApp. Para ello, es necesario disponer de una licencia adjunta a su cuenta de NetApp. Después de descargar el tarball, transfiéralo a la estación de trabajo de administración.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">Desembale la bola tar y cambie el directorio de trabajo a la carpeta resultante.</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">Antes de iniciar la instalación, empuje las imágenes de Astra Control Center hasta un registro de imágenes.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Puede elegir hacer esto con Docker o Podman; en este paso se proporcionan instrucciones para ambos.</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">Exporte el FQDN del registro con el nombre de organización/espacio de nombres/proyecto como una variable de entorno ‘sector’.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">Inicie sesión en el registro.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">Si está utilizando<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> usuario para iniciar sesión en el registro privado y, a continuación, utilizar token en lugar de password -<block ref="7d7ac4e834205786dd5590244b8666d4" prefix=" " category="inline-code"></block>.</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">También puede crear una cuenta de servicio, asignar el editor de Registro y/o la función de visor de Registro (en función de si necesita acceso de inserción/extracción) e iniciar sesión en el Registro mediante el token de la cuenta de servicio.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">Cree un archivo de script de shell y pegue el siguiente contenido en él.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">Si utiliza certificados que no son de confianza para el registro, edite la secuencia de comandos del shell y utilice<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> para el comando podman push<block ref="0860f2134645f92280f543681a4900f8" prefix=" " category="inline-code"></block>.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">Haga que el archivo sea ejecutable.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">Ejecute el script shell.</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">Si está utilizando<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> usuario para iniciar sesión en el registro privado y, a continuación, utilizar token en lugar de password -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">A continuación, cargue los certificados TLS del registro de imágenes en los nodos de OpenShift. Para ello, cree un mapa de configuración en<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Espacio de nombres mediante los certificados TLS y retome la configuración de la imagen del clúster para garantizar la confianza del certificado.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">Si está utilizando un registro interno OpenShift con certificados TLS predeterminados del operador Ingress con una ruta, debe seguir el paso anterior para aplicar el parche a los certificados en el nombre de host de la ruta. Para extraer los certificados del operador Ingress, puede utilizar el comando<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Cree un espacio de nombres<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Para instalar el operador del Centro de control Astra.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">Cree un secreto con credenciales para iniciar sesión en el registro de imágenes<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> espacio de nombres.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Edite el operador del Centro de control Astra CR<block ref="29815934e812e1cfba6cc38eff0d17d3" prefix=" " category="inline-code"></block>, Que es un conjunto de todos los recursos que implementa Astra Control Center. En la CR del operador, busque la definición de despliegue para<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> E introduzca el FQDN del registro junto con el nombre de la organización tal como se le dio al insertar las imágenes en el registro (en este ejemplo,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>) sustituyendo el texto<block ref="e7fbb61ffc587682a801796b46db408a" prefix=" " category="inline-code"></block> y proporcionar el nombre del secreto en el que acabamos de crear<block ref="0d9b54b29da54379cca6b8782b9faae5" prefix=" " category="inline-code"></block> sección. Verifique otros detalles del operador, guarde y cierre.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">Cree el operador ejecutando el siguiente comando.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">Cree un espacio de nombres dedicado para instalar todos los recursos de Astra Control Center.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">Cree el secreto para acceder al registro de imágenes en ese espacio de nombres.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Edite el archivo CRD de Astra Control Center<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> E introduzca el FQDN, los detalles del registro de imágenes, la dirección de correo electrónico del administrador y otros detalles.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Cree el Centro de control de Astra CRD en el espacio de nombres creado para él.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">El archivo anterior<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> Es la versión mínima de Astra Control Center CRD. Si desea crear el CRD con más control, como definir un storagegrid que no sea el predeterminado para crear RVP o proporcionar detalles SMTP para las notificaciones por correo, puede editar el archivo<block ref="70b058e54d2bda749060070a7f9c4e5c" prefix=" " category="inline-code"></block>, Introduzca los detalles necesarios y utilícela para crear el CRD.</block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp cuenta con varias plataformas de almacenamiento cualificadas con nuestro orquestador de almacenamiento Trident para aprovisionar almacenamiento para las aplicaciones puestas en marcha en Anthos.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">Información general sobre el almacenamiento de NetApp</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">Siguiente: ONTAP de NetApp.</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos une las operaciones DE desarrollo y TECNOLÓGICAS en una única plataforma para crear, poner en marcha y gestionar aplicaciones de forma coherente en las infraestructuras en las instalaciones y de cloud híbrido. Anthos lleva los clústeres de Kubernetes de GKE directamente al entorno de su centro de datos, en formatos virtuales o bare metal.</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Información general de Anthos</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">Anthos con NetApp es una arquitectura de cloud híbrido verificada y con mejores prácticas para la puesta en marcha de un entorno Google Kubernetes Engine (GKE) en las instalaciones de una forma fiable y fiable. Este documento de referencia de arquitectura verificada de NetApp sirve como guía de diseño y como validación de la puesta en marcha de la solución Anthos con NetApp puesta en marcha en entornos virtuales y de configuración básica. La arquitectura descrita en este documento ha sido validada por expertos en la materia de NetApp y Google Cloud para proporcionar las ventajas de poner a Anthos en su entorno de centro de datos empresarial.</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos es una solución de centro de datos de Kubernetes para cloud híbrido que permite a las organizaciones crear y gestionar infraestructuras de cloud híbrido modernas, al tiempo que adopta flujos de trabajo ágiles centrados en el desarrollo de aplicaciones. Anthos en VMware, una solución desarrollada con tecnologías de código abierto, se ejecuta en las instalaciones en una infraestructura basada en vSphere de VMware, que puede conectarse e interoperar con Anthos GKE en Google Cloud. Adoptar contenedores, malla de servicios y otras tecnologías para la transformación permiten a las organizaciones experimentar ciclos de desarrollo de aplicaciones consistentes y cargas de trabajo preparadas para la producción en entornos locales y basados en cloud. En la siguiente figura se muestra la solución Anthos y cómo una implementación en una interconexión del centro de datos local con la infraestructura en el cloud.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos ofrece las siguientes características:</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">*La gestión de la configuración de Anthos* automatiza la política y la seguridad de las implementaciones de Kubernetes híbridas.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Malla de servicio Anthos.* mejora la capacidad de observación, seguridad y control de aplicaciones con una malla de servicio impulsada por Istio.</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">*Google Cloud Marketplace para aplicaciones Kubernetes.* un catálogo de aplicaciones de contenedor curadas disponible para una fácil implementación.</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">*Migración para Anthos.* migración automática de servicios físicos y máquinas virtuales de las instalaciones al cloud.</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">*Stackdriver.* Servicio de administración ofrecido por Google para registrar y supervisar instancias de nube.</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Métodos de implementación para Anthos</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">Clusters Anthos en VMware</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">Los clústeres de Anthos puestos en marcha en entornos VMware vSphere son fáciles de poner en marcha, mantener y escalar con rapidez para la mayoría de cargas de trabajo de Kubernetes de usuario final.</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">Para obtener más información sobre los clústeres de Anthos en VMware, puesto en marcha con NetApp, visite la página <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>.</block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="section-title">Anthos en bare metal</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">Los clústeres de Anthos puestos en servidores con configuración básica no dependen del hardware y le permiten seleccionar una plataforma informática optimizada para su caso de uso personalizado.</block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">Para obtener más información sobre Anthos en clústeres de configuración básica puestos en marcha con NetApp, visite <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>.</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">Siguiente: Clusters de Anthos en VMware.</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">Antes de iniciar la instalación, empuje las imágenes de Astra Control Center hasta un registro de imágenes. Puede elegir hacer esto con Docker o Podman; en este paso se proporcionan instrucciones para ambos.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">Podman</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">También puede crear una cuenta de servicio, asignar el editor de Registro y/o la función de visor de Registro (en función de si necesita acceso de inserción/extracción) e iniciar sesión en el Registro mediante el token de la cuenta de servicio.</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">Cree un archivo de script de shell y pegue el siguiente contenido en él.</block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">Si utiliza certificados que no son de confianza para el registro, edite la secuencia de comandos del shell y utilice<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> para el comando podman push<block ref="fec4f991fbdc39b7083cbf10fdc5cd9d" prefix=" " category="inline-code"></block>.</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">Si está utilizando la<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> usuario para iniciar sesión en el registro privado y, a continuación, utilizar un token en lugar de una contraseña -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">También puede crear una cuenta de servicio, asignar el editor de Registro y/o el rol de visor de Registro (en función de si necesita acceso de inserción/extracción) e iniciar sesión en el Registro mediante el token de la cuenta de servicio.</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">Cuando utilice registros de imágenes privadas de confianza pública, cargue los certificados TLS del registro de imágenes en los nodos OpenShift. Para ello, cree un mapa de configuración en el espacio de nombres de openshift-config mediante los certificados TLS y realice una revisión de la configuración de la imagen del clúster para que el certificado sea de confianza.</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">Si está utilizando un registro interno OpenShift con certificados TLS predeterminados del operador Ingress con una ruta, debe seguir el paso anterior para aplicar el parche a los certificados en el nombre de host de la ruta. Para extraer los certificados del operador Ingress, puede utilizar el comando<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Cree un espacio de nombres<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Para Astra Control Center.</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">Cree un secreto con credenciales para iniciar sesión en el registro de imágenes de<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> espacio de nombres.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">Inicie sesión en la consola de la GUI de Red Hat OpenShift con acceso cluster-admin.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Seleccione Administrador en la lista desplegable perspectiva.</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Desplácese a operadores &gt; OperatorHub y busque Astra.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="inline-image-macro">OpenShift Operator Hub</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">Seleccione la<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Y haga clic en instalar.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="inline-image-macro">Mosaico del operador ACC</block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">En la pantalla instalar operador, acepte todos los parámetros predeterminados y haga clic en instalar.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="inline-image-macro">Detalles del operador de ACC</block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="inline-image-macro">El operador ACC espera la instalación</block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">Una vez que el operador se haya instalado correctamente, desplácese para hacer clic en Ver operador.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="inline-image-macro">Instalación completa del operador de ACC</block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">A continuación, haga clic en Crear instancia en el icono Astra Control Center del operador.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="inline-image-macro">Crear instancia de ACC</block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">Rellene el<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> Campos de formulario y haga clic en Crear.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">Opcionalmente, edite el nombre de la instancia de Astra Control Center.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">Opcionalmente, habilite o deshabilite el AutoSupport. Se recomienda conservar la funcionalidad de AutoSupport.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Introduzca el FQDN para Astra Control Center.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Introduzca la versión de Astra Control Center; la última se muestra de forma predeterminada.</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Introduzca un nombre de cuenta para Astra Control Center y detalles de administración como nombre, apellidos y dirección de correo electrónico.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">Introduzca la política de reclamaciones de volúmenes, el valor predeterminado es Retain.</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">En el Registro de imágenes, introduzca el FQDN del registro junto con el nombre de la organización que se le dio mientras presiona las imágenes al registro (en este ejemplo,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>).</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">Si utiliza un registro que requiere autenticación, introduzca el nombre secreto en la sección Image Registry (Registro de imágenes).</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Configurar las opciones de ampliación para los límites de recursos de Astra Control Center.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">Introduzca el nombre de la clase de almacenamiento si desea colocar las RVP en una clase de almacenamiento no predeterminada.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">Defina las preferencias de manejo de CRD.</block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">Astra Control Center de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, implementados en un entorno en las instalaciones, impulsadas por la tecnología de protección de datos de confianza de NetApp.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">Descripción general de Astra Control Center de NetApp</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center se puede instalar en un clúster de Red Hat OpenShift que tiene el orquestador de almacenamiento Astra Trident puesto en marcha y configurado con clases de almacenamiento y back-ends de almacenamiento en sistemas de almacenamiento ONTAP de NetApp.</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">este documento</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Para obtener información sobre la instalación y configuración de Astra Trident y su compatibilidad con Astra Control Center, consulte <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>.</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">En un entorno conectado a la nube, Astra Control Center utiliza Cloud Insights para proporcionar supervisión y telemetría avanzadas. Ante la ausencia de una conexión con Cloud Insights, la supervisión y la telemetría limitadas (valor equivalente a 7 días de métricas) están disponibles y se exportan a herramientas de supervisión nativas de Kubernetes (Prometheus y Grafana) mediante extremos de métricas abiertos.</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">Además de la versión de pago de Astra Control Center, hay disponible una licencia de evaluación de 90 días. La versión de evaluación se admite a través del correo electrónico y el canal de Slack de la comunidad. Los clientes tienen acceso a estos recursos, a otros artículos de la base de conocimientos y a la documentación disponible en la consola de soporte del producto.</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">Para empezar a utilizar Astra Control Center de NetApp, visite <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">Uno o más clústeres de Red Hat OpenShift. Actualmente se admiten las versiones 4.6 EUS y 4.7.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">Astra Trident ya debe estar instalado y configurado en cada clúster de Red Hat OpenShift.</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">Se trata de una práctica recomendada para cada instalación de OpenShift en un sitio a fin de tener una SVM dedicada para el almacenamiento persistente. Las puestas en marcha de varios sitios requieren sistemas de almacenamiento adicionales.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Debe configurarse un back-end de almacenamiento de Trident en cada clúster de OpenShift con una SVM respaldada por un clúster de ONTAP.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">Un StorageClass predeterminado configurado en cada clúster OpenShift con Astra Trident como aprovisionador de almacenamiento.</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">Se debe instalar y configurar un equilibrador de carga en cada clúster de OpenShift para que pueda equilibrarse la carga y exponer los servicios de OpenShift.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">Consulte el enlace <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> para obtener información sobre balanceadores de carga que se han validado para este propósito.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">Consulte el enlace <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> Para instalar y configurar un registro privado de OpenShift con este fin.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Debe tener acceso de administrador de clúster al clúster de Red Hat OpenShift.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Una estación de trabajo de administración con docker o podman, trimentctl y las herramientas OC o kudectl instaladas y agregadas a su $PATH.</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Las instalaciones de Docker deben tener una versión de docker superior a 20.10, y las instalaciones de Podman deben tener una versión de podman superior a 3.0.</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">Uso de OperatorHub</block>
  <block id="60e34857d044a02ae86f645c2e97e40f" category="paragraph">Directiva no resuelta en &lt;stdin&gt; - incluir::Containers/rh-os-n_overview_astra_cc_install_manual.adoc[]</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">[Ansible] automatizado</block>
  <block id="2b0a99e34b337bd6d8ed27dd9482c9e6" category="paragraph">Directiva no resuelta en &lt;stdin&gt; - incluir::Containers/rh-os-n_overview_astra_cc_install_ansible.adoc[]</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">Pasos posteriores a la instalación</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">Compruebe la<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> registros para verificar que la instalación se ha completado.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">Obtenga la IP del equilibrador de carga del servicio de Traefik.</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">Cuando inicie sesión en la GUI de Astra Control Center por primera vez con la dirección de correo electrónico de administrador proporcionada en CRD, deberá cambiar la contraseña.</block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center requiere una licencia para que funcionen todas las funciones de TI. Para añadir una licencia, vaya a cuenta &gt; Licencia, haga clic en Añadir licencia y cargue el archivo de licencia.</block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">Si tiene problemas con la instalación o la configuración de NetApp Astra Control Center, está disponible la base de conocimientos sobre problemas conocidos<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">Siguiente: Registre sus Red Hat OpenShift Clusters.</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="summary">Para habilitar la integración de Trident con el sistema de almacenamiento ONTAP de NetApp, debe crear un back-end que permita la comunicación con el sistema de almacenamiento.</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">Hay archivos de fondo de ejemplo disponibles en el archivo de instalación descargado en<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> jerarquía de carpetas. Para los sistemas ONTAP de NetApp que sirven NFS, copie el<block ref="d897e4d05156cbf9998e98200d6190aa" prefix=" " category="inline-code"></block> archivar en el directorio de trabajo y editar el archivo.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">Editar la backendName, managementLIF, dataLIF, svm, nombre de usuario, y los valores de contraseña en este archivo.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">Con este archivo back-end en su lugar, ejecute el siguiente comando para crear su primer back-end.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">Hay un campo opcional llamado<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> que se define en este archivo. Esta línea se puede eliminar en los back-ends de NFS.</block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">Siguiente: ISCSI con ONTAP de NetApp.</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Anthos.</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Descripción general de Astra Trident</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">Un administrador puede configurar varios back-ends de almacenamiento a partir de necesidades de proyectos y modelos de sistema de almacenamiento que permiten funciones de almacenamiento avanzadas, como compresión, tipos de disco específicos y niveles de calidad de servicio que garantizan un cierto nivel de rendimiento. Una vez definidas estos back-ends pueden ser utilizados por los desarrolladores en sus proyectos para crear reclamaciones de volumen persistente (RVP) y conectar almacenamiento persistente a sus contenedores bajo demanda.</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">Con la versión 22.04, se puso a disposición un gráfico Helm para facilitar la instalación del operador Trident.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Instale el operador Trident con Helm</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Primero, establezca la ubicación del clúster de usuarios<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Archivo como variable de entorno para no tener que referirla, porque Trident no tiene opción para pasar este archivo.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Ejecute el comando Helm para instalar al operador Trident desde el tarball en el directorio helm mientras crea el espacio de nombres de trident en su clúster de usuarios.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">Puede verificar que Trident se haya instalado correctamente comprobando los pods que se ejecutan en el espacio de nombres o mediante el binario trimentctl para comprobar la versión instalada.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">En algunos casos, los entornos del cliente pueden requerir la personalización de la puesta en marcha de Trident. En estos casos, también es posible instalar manualmente el operador Trident y actualizar los manifiestos incluidos para personalizar la implementación.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Instale manualmente el operador de Trident</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">Extraiga la instalación de Trident del paquete descargado.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">La<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block> el directorio contiene manifiestos para definir todos los recursos necesarios. Con los manifiestos adecuados, cree la<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block> definición de recursos personalizados.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Si no existe ninguno, cree un espacio de nombres Trident en el clúster mediante el manifiesto proporcionado.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">Cree los recursos necesarios para la puesta en marcha del operador Trident, como, por ejemplo, la<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block> para el operador, un<block ref="d7d354d0f9d0780e168c895c92a32c24" prefix=" " category="inline-code"></block> y..<block ref="e866afd8290d5c73cda6260e04e6eef0" prefix=" " category="inline-code"></block> para la<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block>, un dedicado<block ref="316707d12484dd3afede08839dee49bc" prefix=" " category="inline-code"></block>o el propio operador.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">Puede comprobar el estado del operador después de desplegarlo con los siguientes comandos:</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">Con el operador puesto en marcha, ahora podemos utilizarlo para instalar Trident. Esto requiere crear un<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block>.</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">El software NetApp Element ofrece un rendimiento modular y escalable con cada nodo de almacenamiento que ofrece capacidad y rendimiento garantizados para el entorno. Los sistemas NetApp Element pueden escalarse de 4 a 100 nodos en un único clúster y ofrecen una serie de funciones avanzadas de gestión del almacenamiento.</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">El software NetApp Element ofrece un rendimiento modular y escalable con cada nodo de almacenamiento que ofrece capacidad y rendimiento garantizados para el entorno. Los sistemas NetApp Element pueden escalarse de 4 a 100 nodos en un único clúster y ofrecen diversas funciones avanzadas de gestión del almacenamiento.</block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">Sitio web de SolidFire de NetApp</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">Para obtener más información sobre los sistemas de almacenamiento NetApp Element, visite<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">Redirección de inicio de sesión iSCSI y capacidades de reparación automática</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">El software NetApp Element aprovecha el protocolo de almacenamiento iSCSI, una forma estándar de encapsular comandos SCSI en una red TCP/IP tradicional. Cuando los estándares SCSI cambian o cuando el rendimiento de las redes Ethernet mejora, el protocolo de almacenamiento iSCSI se beneficia sin necesidad de hacer cambios.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">Aunque todos los nodos de almacenamiento tienen una IP de gestión y una IP de almacenamiento, el software NetApp Element anuncia una única dirección IP virtual de almacenamiento (dirección SVIP) para todo el tráfico de almacenamiento del clúster. Como parte del proceso de inicio de sesión iSCSI, el almacenamiento puede responder que el volumen objetivo se ha movido a otra dirección y, por lo tanto, no puede continuar con el proceso de negociación. A continuación, el host vuelve a enviar la solicitud de inicio de sesión a la nueva dirección en un proceso que no requiere reconfiguración del lado del host. Este proceso se conoce como redireccionamiento de inicio de sesión iSCSI.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">La redirección de inicio de sesión iSCSI es una parte clave del cluster de software de NetApp Element. Cuando se recibe una solicitud de inicio de sesión de host, el nodo decide qué miembro del clúster debe encargarse del tráfico según las IOPS y los requisitos de capacidad del volumen. Los volúmenes se distribuyen por el clúster de software de NetApp Element y se redistribuyen si un solo nodo gestiona demasiado tráfico de sus volúmenes o si se añade un nodo nuevo. Se asignan varias copias de un volumen determinado en la cabina.</block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">De este modo, si a un fallo de un nodo le sigue una redistribución del volumen, no se produce ningún efecto en la conectividad de host más allá del cierre de sesión y el inicio de sesión mediante redirección a la nueva ubicación. Con la redirección de inicio de sesión iSCSI, un clúster de software NetApp Element es una arquitectura de escalabilidad horizontal y reparación automática que puede realizar operaciones y actualizaciones no disruptivas.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">Calidad de servicio de clústeres de software NetApp Element</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">Un clúster de software NetApp Element permite que la calidad de servicio se configure de forma dinámica por cada volumen. Puede utilizar la configuración de calidad de servicio por volumen para controlar el rendimiento de almacenamiento en función de los acuerdos de nivel de servicio que haya definido. Los tres siguientes parámetros configurables definen la calidad de servicio:</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">*IOPS mínimo.* el número mínimo de IOPS sostenidas que el clúster de software de NetApp Element proporciona a un volumen. El nivel mínimo de IOPS configurado para un volumen es el nivel garantizado de rendimiento de un volumen. El rendimiento por volumen no se sitúa por debajo de este nivel.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">*IOPS máximo.* el número máximo de IOPS sostenidas que el clúster de software de NetApp Element proporciona a un volumen en particular.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">*Burst IOPS.* el número máximo de IOPS permitidas en un escenario de ráfaga breve. El valor de duración de ráfaga se puede configurar, con un valor predeterminado de 1 minuto. Si un volumen se ejecuta por debajo del nivel máximo de IOPS, se acumulan créditos de ráfaga. Cuando los niveles de rendimiento llegan a ser muy altos e incluso se ven presionados, se permiten ráfagas breves de IOPS que superen los IOPS máximos en el volumen.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">Multi-tenancy</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">La funcionalidad multi-tenancy seguro se logra con las siguientes funciones:</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">*Autenticación segura.* el Protocolo de autenticación por desafío mutuo (CHAP) se utiliza para el acceso seguro al volumen. El protocolo ligero de acceso a directorios (LDAP) se utiliza para acceder de forma segura al clúster con fines de gestión e informes.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">*Grupos de acceso de volúmenes (VAG).* opcionalmente, los VAG se pueden utilizar en lugar de la autenticación, asignando cualquier número de nombres calificados iSCSI específicos del iniciador iSCSI (IQN) a uno o más volúmenes. Para acceder a un volumen en un VAG, el IQN del iniciador debe estar en la lista de IQN permitido para el grupo de volúmenes.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">*Redes LAN virtuales de inquilino (VLAN).* a nivel de red, la seguridad de red integral entre los iniciadores iSCSI y el clúster de software NetApp Element se facilita mediante VLAN. Para cualquier VLAN que se cree para aislar una carga de trabajo o un inquilino, NetApp Element Software crea una dirección SVIP de destino iSCSI independiente a la que solo se puede acceder a través de la VLAN específica.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">*VLAN habilitadas para VRF.* para admitir más la seguridad y escalabilidad en el centro de datos, el software NetApp Element le permite habilitar cualquier VLAN de inquilino para la funcionalidad de VRF. Esta función añade estas dos funcionalidades clave:</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">*Enrutamiento L3 a una dirección SVIP de arrendatario.* esta función le permite ubicar iniciadores iSCSI en una red o VLAN independiente de la del clúster de software NetApp Element.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">*Subredes IP duplicadas o superpuestas.* esta función le permite agregar una plantilla a entornos de arrendatarios, permitiendo a cada VLAN de arrendatario respectiva asignar direcciones IP desde la misma subred IP. Esta funcionalidad puede ser útil en entornos de proveedores de servicio en los que la escala y la conservación del espacio IP son importantes.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">Eficiencias de almacenamiento para empresas</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">El clúster de software NetApp Element aumenta el rendimiento y la eficiencia general del almacenamiento. Las siguientes funciones se realizan en línea, están siempre activas y el usuario no requiere ninguna configuración manual:</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">*Deduplicación.* el sistema sólo almacena bloques 4K únicos. Todos los bloques 4K duplicados se asocian automáticamente a una versión ya almacenada de los datos. Los datos se encuentran en unidades de bloques y se duplican mediante la protección de datos Helix del software NetApp Element. Este sistema reduce significativamente el consumo de capacidad y las operaciones de escritura en el sistema.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">*Compresión.* la compresión se realiza en línea antes de que los datos se escriban en la NVRAM. Los datos se comprimen, almacenan en bloques de 4 K y siguen comprimidos en el sistema. Esta compresión reduce significativamente el consumo de capacidad, las operaciones de escritura y el consumo de ancho de banda en el clúster.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">*Thin-Provisioning.* esta funcionalidad proporciona la cantidad adecuada de almacenamiento en el momento en que lo necesita, eliminando el consumo de capacidad causado por volúmenes sobreaprovisionados o volúmenes infrautilizados.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix.* los metadatos de un volumen individual se almacenan en una unidad de metadatos y se replican en una unidad de metadatos secundaria por motivos de redundancia.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element se diseñó para la automatización. Todas las funciones de almacenamiento están disponibles mediante API. Estas API son el único método que utiliza la interfaz de usuario para controlar el sistema.</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">Siguiente: Descripción general de las integraciones de almacenamiento de NetApp.</block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">Este documento de referencia proporciona la validación de la puesta en marcha de la solución Anthos con NetApp y está puesto en marcha en entornos de centros de datos múltiples validados por NetApp y nuestros partners de ingeniería.</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165: Anthos con NetApp</block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">Este documento de referencia proporciona la validación de la puesta en marcha de la solución Anthos con NetApp y nuestros partners de ingeniería cuando se pone en marcha en varios entornos de centros de datos. Además, se detalla la integración del almacenamiento con los sistemas de almacenamiento de NetApp, mediante el orquestador de almacenamiento Astra Trident, con el fin de gestionar el almacenamiento persistente. Por último, exploramos y documentamos una serie de validaciones de soluciones y casos de uso reales.</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">La solución Anthos con NetApp está diseñada para ofrecer un valor excepcional a los clientes con los siguientes casos prácticos:</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">Es fácil poner en marcha y gestionar el entorno de Anthos puesto en marcha utilizando el proporcionado<block ref="f9d1b8d1854865b695167e2c5829f633" prefix=" " category="inline-code"></block> de metal desnudo o de<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Herramienta en VMware vSphere.</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">reconocimiento de la virtualización</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">Combine la potencia de las cargas de trabajo virtualizadas y de contenedores empresariales con Anthos puesto en vSphere o de forma básica con<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>.</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">Casos prácticos y de configuración reales que destacan las funciones de Anthos cuando se utiliza con el almacenamiento de NetApp y Astra Trident, el orquestador de almacenamiento de código abierto para Kubernetes.</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">La capacidad de ejecutar cargas de trabajo virtualizadas y en contenedores de forma simultánea</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">La capacidad de escalar la infraestructura de forma independiente en función de las demandas de las cargas de trabajo</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">La solución Anthos con NetApp reconoce estos retos y presenta una solución que ayuda a abordar cada problema implementando la puesta en marcha totalmente automatizada de Anthos en las instalaciones en el entorno de centro de datos que elija el cliente.</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">La solución Anthos con NetApp incluye los siguientes componentes principales:</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Anthos en el entorno local</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Anthos en las instalaciones es una plataforma de Kubernetes empresarial con soporte completo que se puede poner en marcha en el hipervisor VMware vSphere o en una infraestructura básica de su elección.</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Anthos.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">Opciones de configuración avanzadas</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">Esta sección se dedica a personalizaciones que los usuarios del mundo real probablemente tendrían que realizar al implementar esta solución en la producción, como la creación de un registro de imagen privada dedicado o la implementación de instancias de equilibrador de carga personalizadas.</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8, 9.9.1</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">Orquestación de contenedores</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">Siguiente: Información general de Anthos.</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">Hay archivos de fondo de ejemplo disponibles en el archivo de instalación descargado en<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> jerarquía de carpetas. Para los sistemas ONTAP de NetApp que proporcionan servicio iSCSI, copie el<block ref="684351d8ace6c8daa15d6a5ec881647e" prefix=" " category="inline-code"></block> archivar en el directorio de trabajo y editar el archivo.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">Edite los valores managementLIF, dataLIF, svm, username y password de este archivo.</block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">Hay un campo opcional llamado<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> que se define en este archivo. En los back-ends iSCSI, este valor se puede establecer en un tipo de sistema de archivos Linux específico (XFS, ext4, etc.), o se puede eliminar para permitir que el sistema operativo del nodo de trabajo decida qué sistema de ficheros utilizar.</block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">Esta sección se dedica a analizar las opciones de equilibrador de carga para los usuarios que desean personalizar su Anthos con la puesta en marcha de NetApp.</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">Exploración de las opciones de equilibrador de carga</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Una aplicación implementada en Anthos está expuesta al mundo por un servicio que ofrece un equilibrador de carga implementado en el entorno local de Anthos.</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">Las siguientes páginas tienen información adicional sobre las opciones de equilibrador de carga validadas en la solución Anthos con NetApp:</block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="inline-link-macro">Instalación de equilibradores de carga BIG-IP de F5</block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="inline-link-macro">Instalación de equilibradores de carga de Seesaw</block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">Siguiente: Instalación del equilibrador de carga BIG-IP de F5.</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">En esta página se detallan las instrucciones de instalación y configuración del equilibrador de carga de la guiñada.</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">En esta página se enumeran las instrucciones de instalación y configuración del equilibrador de carga administrado Seesaw.</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">Seesaw es el equilibrador de carga de red gestionado por defecto instalado en un entorno de Anthos Clusters en VMware de las versiones 1.6 a 1.10.</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">Instalación del equilibrador de carga de la mordaza</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">El equilibrador de carga de Seesaw está totalmente integrado con Anthos Clusters en VMware y ha realizado una puesta en marcha automatizada como parte de la configuración de clústeres de administrador y usuario. Hay bloques de texto en el<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> archivos de configuración que se deben modificar para proporcionar información de equilibrio de carga y, a continuación, hay un paso adicional antes de la puesta en marcha del clúster para implementar el equilibrador de carga mediante el incorporado<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> herramienta.</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">Los equilibradores de carga de Seesaw se pueden poner en marcha en modo ha o no. A efectos de esta validación, el equilibrador de carga de la guiñada se implementó en modo no ha, que es la configuración predeterminada. Por motivos de producción, NetApp recomienda poner en marcha la guiahasta en una configuración de alta disponibilidad con tolerancia a fallos y fiabilidad.</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">Hay una sección en cada archivo de configuración, respectivamente, para el clúster de administración y en cada clúster de usuarios que elija implementar para configurar el equilibrador de carga de modo que Anthos lo gestione en las instalaciones.</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">El texto siguiente es un ejemplo de la configuración de la partición para el clúster GKE-Admin. Los valores que deben no comentarse y modificarse se colocan en negrita a continuación:</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">El equilibrador de carga de la guiñada también tiene una estática independiente<block ref="d218bc0ba36a7fb2d7aea32df7659206" prefix=" " category="inline-code"></block> archivo que debe proporcionar para la implementación de cada clúster. Este archivo debe estar ubicado en el mismo directorio con respecto a<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> el archivo de implementación o la ruta completa se deben especificar en la sección anterior.</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">Una muestra del<block ref="1db10b36979626249cbedcd8e8818146" prefix=" " category="inline-code"></block> el archivo tiene el aspecto del siguiente script:</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">Este archivo proporciona la pasarela y la máscara de red para la red que el equilibrador de carga proporciona al clúster subyacente, así como la IP y el nombre de host de gestión para la máquina virtual que se implementa para ejecutar el equilibrador de carga.</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="8a7ac28f4ab44e0d4f4da82c8faf774a" category="summary">En este vídeo vinculado a esta página se muestra cómo poner en marcha Anthos en un clúster de configuración básica.</block>
  <block id="6ca531ff48fc42e961c1b239f4302fab" category="doc">Puesta en marcha de Anthos en un clúster de configuración básica</block>
  <block id="cb0b7b75afe3f65d378ff6ab2c93d899" category="paragraph">En este vídeo se muestra cómo poner en marcha Anthos en un clúster de configuración básica.</block>
  <block id="97c62d2df3f6258616bde0882c4b890e" category="inline-link-macro">Siguiente: Información adicional.</block>
  <block id="5866caac5ce4e920cd3e5d0cd82ea8b7" category="paragraph"><block ref="5866caac5ce4e920cd3e5d0cd82ea8b7" category="inline-link-macro-rx"></block></block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="summary">Big-IP de F5 es un controlador de entrega de aplicaciones (ADC) que ofrece un amplio conjunto de servicios avanzados de seguridad y gestión del tráfico de nivel de producción, como el equilibrio de carga L4-L7, la descarga de SSL/TLS, DNS, firewall y muchos más. Estos servicios aumentan significativamente la disponibilidad, la seguridad y el rendimiento de sus aplicaciones.</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">Big-IP de F5 es un controlador de entrega de aplicaciones (ADC) que ofrece un amplio conjunto de servicios avanzados de seguridad y gestión del tráfico de nivel de producción, como equilibrio de carga L4-L7, descarga de SSL/TLS, DNS, firewall, etc. Estos servicios aumentan significativamente la disponibilidad, la seguridad y el rendimiento de sus aplicaciones.</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">Big-IP de F5 se puede implementar y consumir de diversas maneras, incluido el hardware dedicado, la nube o como un dispositivo virtual en las instalaciones. Consulte la documentación aquí para explorar e implementar BIG-IP de F5.</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">BIG-IP de F5 fue el primero de las soluciones de equilibrador de carga disponibles en Anthos en entornos locales y se utilizó en varias de las primeras validaciones de partners de Anthos Ready para la solución Anthos con NetApp.</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">BIG-IP de F5 se puede implementar en modo independiente o en modo cluster. Para esta validación, F5 BIG-IP se implementó en modo independiente. Sin embargo, por motivos de producción, NetApp recomienda crear un cluster de instancias DE BIG-IP para evitar un único punto de error.</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">Esta solución utiliza el dispositivo virtual puesto en marcha en VMware vSphere. Las redes del dispositivo virtual Big-IP de F5 se pueden configurar en una configuración de dos o tres armas, en función del entorno de red. La puesta en marcha de este documento se basa en la configuración con dos armas. Encontrará más información sobre la configuración del dispositivo virtual para utilizarlo con Anthos<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>.</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">El equipo de ingeniería de soluciones de NetApp ha validado los lanzamientos de la siguiente tabla en nuestro laboratorio para trabajar con las puestas en marcha de Anthos en las instalaciones:</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Tipo</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">Para instalar F5 BIG-IP, lleve a cabo los siguientes pasos:</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">Descargue el archivo de aplicación virtual Open Virtual Appliance (OVA) de F5<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>.</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">Para descargar el dispositivo, el usuario debe registrarse con F5. Proporcionan una licencia de demostración de 30 días para Big-IP Virtual Edition Load Balancer. NetApp recomienda una licencia permanente de 10 Gbps para el despliegue de producción de un dispositivo.</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">Haga clic con el botón derecho en el grupo de recursos de infraestructura y seleccione implementar plantilla OVF. Se inicia un asistente que permite seleccionar el archivo OVA que acaba de descargar en el paso 1. Haga clic en Siguiente.</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="inline-image-macro">Implemente el dispositivo Big-IP</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">Haga clic en Siguiente para continuar con cada paso y aceptar los valores predeterminados de cada pantalla que se presenta hasta que llegue a la pantalla de selección de almacenamiento. Seleccione el VM_Datastore en el que desea implementar la máquina virtual y, a continuación, haga clic en Next.</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">La siguiente pantalla que presenta el asistente le permite personalizar las redes virtuales para su uso en el entorno. Seleccione VM_Network en el campo External y seleccione Management_Network en el campo Management. Los dispositivos Big-IP de F5 utilizan configuraciones internas y de alta disponibilidad para configuraciones avanzadas y no están configurados. Estos parámetros se pueden dejar solos o se pueden configurar para conectarse a grupos de puertos distribuidos que no sean de infraestructura. Haga clic en Siguiente.</block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Implemente el dispositivo Big_IP, parte 2</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">Revise la pantalla de resumen del dispositivo y, si toda la información es correcta, haga clic en Finalizar para iniciar la implementación.</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">Después de poner en marcha el dispositivo virtual, haga clic con el botón derecho del ratón en él y encirelo. Debe recibir una dirección DHCP en la red de gestión. El dispositivo está basado en Linux y tiene instaladas VMware Tools, por lo que puede ver la dirección DHCP que recibe en el cliente vSphere.</block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">Implemente el dispositivo Big-IP, parte 3</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">Abra un explorador Web y conéctese al dispositivo en la dirección IP del paso anterior. El inicio de sesión predeterminado es admin/admin y, después del primer inicio de sesión, el dispositivo solicita inmediatamente que cambie la contraseña de administrador. A continuación, volverá a una pantalla en la que deberá iniciar sesión con las nuevas credenciales.</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="inline-image-macro">Configuración de Big-IP</block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">La primera pantalla solicita al usuario que complete la utilidad de configuración. Para iniciar la utilidad, haga clic en Siguiente.</block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">Configuración Big-IP, parte 2</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">En la siguiente pantalla se solicita la activación de la licencia del dispositivo. Haga clic en Activar para comenzar. Cuando se le solicite en la página siguiente, pegue la clave de licencia de evaluación de 30 días que recibió cuando se registró para la descarga o la licencia permanente que adquirió al adquirir el dispositivo. Haga clic en Siguiente.</block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">Configuración Big-IP, parte 3</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">Para que el dispositivo realice la activación, la red definida en la interfaz de administración debe poder llegar a Internet.</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">En la siguiente pantalla, se presenta el Contrato de licencia para el usuario final (EULA). Si los términos de la licencia son aceptables, haga clic en Aceptar.</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">La siguiente pantalla cuenta el tiempo transcurrido, ya que verifica los cambios de configuración que se han realizado hasta ahora. Haga clic en continuar para reanudar con la configuración inicial.</block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">Configuración Big-IP, parte 4</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">La ventana Cambio de configuración se cierra y la utilidad de configuración muestra el menú aprovisionamiento de recursos. En esta ventana se enumeran las características con licencia y las asignaciones de recursos actuales para el dispositivo virtual y cada servicio en ejecución.</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">Al hacer clic en la opción de menú Plataforma de la izquierda se activa la modificación adicional de la plataforma. Las modificaciones incluyen establecer la dirección IP de administración configurada con DHCP, establecer el nombre de host y la zona horaria en la que se instaló el dispositivo y proteger el dispositivo de la accesibilidad a SSH.</block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">Configuración Big-IP, parte 6</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">A continuación, haga clic en el menú Red, que le permite configurar las características de red estándar. Haga clic en Siguiente para iniciar el asistente de configuración de red estándar.</block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">Configuración Big-IP, parte 7</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">La primera página del asistente configura la redundancia; deje los valores predeterminados y haga clic en Siguiente. La página siguiente le permite configurar una interfaz interna en el equilibrador de carga. La interfaz 1.1 se asigna al VMNIC con la etiqueta Internal en el asistente de implementación de OVF.</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">Configuración Big-IP, parte 8</block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">Los espacios de esta página para Dirección IP automática, máscara de red y dirección IP flotante se pueden rellenar con una dirección IP no enrutable para su uso como marcador de posición. También se pueden rellenar con una red interna que se ha configurado como un grupo de puertos distribuido para invitados virtuales si está implementando la configuración de tres armas. Deben completarse para continuar con el asistente.</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">La siguiente página permite configurar una red externa que se usará para asignar servicios a los pods implementados en Kubernetes. Seleccione una IP estática del rango VM_Network, la máscara de subred adecuada y una IP flotante del mismo rango. La interfaz 1.2 se asigna al VMNIC con la etiqueta External en el asistente de implementación de OVF.</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">Configuración Big-IP, parte 9</block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">En la página siguiente, puede configurar una red de alta disponibilidad interna si va a poner en marcha varios dispositivos virtuales en el entorno. Para continuar, debe rellenar los campos Dirección IP automática y máscara de red, y debe seleccionar la interfaz 1.3 como interfaz VLAN, que se asigna a la red ha definida por el asistente de plantilla OVF.</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">Configuración Big-IP, parte 10</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">La página siguiente le permite configurar los servidores NTP. A continuación, haga clic en Siguiente para continuar con la configuración de DNS. El servidor DHCP ya debe rellenar los servidores DNS y la lista de búsqueda de dominios. Haga clic en Siguiente para aceptar los valores predeterminados y continuar.</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">Para el resto del asistente, haga clic en Siguiente para continuar con la configuración avanzada de la relación de paridad, cuya configuración está más allá del alcance de este documento. A continuación, haga clic en Finalizar para salir del asistente.</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Cree particiones individuales para el clúster de administración de Anthos y cada clúster de usuario implementado en el entorno. Haga clic en sistema en el menú de la izquierda, desplácese a usuarios y haga clic en Lista de particiones.</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">Configuración Big-IP, parte 11</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">La pantalla mostrada sólo muestra la partición común actual. Haga clic en Crear a la derecha para crear la primera partición adicional y asigne un nombre<block ref="7b8bd901f7c351d00688bb6fecf79a3c" prefix=" " category="inline-code"></block>. A continuación, haga clic en repetir y asigne un nombre a la partición<block ref="b328b4839c0f0e2bfc22ab6fca60065e" prefix=" " category="inline-code"></block>. Vuelva a hacer clic en el botón repetir para asignar un nombre a la siguiente partición<block ref="916e48fa5c2bc8c7765c99a8f011dccb" prefix=" " category="inline-code"></block>. Por último, haga clic en Finalizar para completar el asistente. La pantalla de lista de particiones vuelve con todas las particiones que se muestran ahora.</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">Configuración Big-IP, parte 12</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">Hay una sección en cada archivo de configuración, respectivamente, para el clúster de administración y cada clúster de usuarios que elija poner en marcha para configurar el equilibrador de carga de modo que Anthos lo gestione en las instalaciones.</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">La siguiente secuencia de comandos es un ejemplo de la configuración de la partición para el clúster GKE-Admin. Los valores que deben no comentarse y modificarse se colocan en negrita a continuación:</block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">Siguiente: Instalación de equilibradores de carga de MetalLB.</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">Creación de una instantánea de aplicación</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">Una copia Snapshot de una aplicación crea una copia Snapshot de ONTAP que se puede utilizar para restaurar o clonar la aplicación en un momento específico según esa copia Snapshot.</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">Crear un backup de aplicación</block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">Un backup de una aplicación captura el estado activo de la aplicación y la configuración de sus recursos, los coloca en archivos y los almacena en un bloque de almacenamiento de objetos remotos.</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">Para crear una copia de seguridad de la aplicación, lleve a cabo los siguientes pasos:</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Para crear una copia de seguridad de la aplicación gestionada en Astra Control Center, desplácese a aplicaciones &gt; gestionado y haga clic en la aplicación de la que desea realizar una copia de seguridad. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en copia de seguridad.</block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">Introduzca los detalles de backup, seleccione el bucket de almacenamiento de objetos que contiene los archivos de backup y haga clic en Next. Tras revisar los detalles, haga clic en Backup. En función del tamaño de la aplicación y los datos, el backup puede tardar varios minutos. El estado del backup pasa a estar disponible después de que el backup se completa correctamente.</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">Para restaurar una aplicación, lleve a cabo los siguientes pasos:</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">Desplácese a la ficha aplicaciones &gt; administradas y haga clic en la aplicación en cuestión. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en Restaurar.</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">Para clonar una aplicación, vaya a la ficha aplicaciones &gt; administradas y haga clic en la aplicación en cuestión. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en Clonar.</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">Introduzca los detalles del nuevo espacio de nombres, seleccione el clúster al que desea clonarlo y elija si desea clonarlo desde una copia de Snapshot existente, un backup o el estado actual de la aplicación. Haga clic en Siguiente y, a continuación, en Clonar en el panel revisar una vez que haya revisado los detalles.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">La nueva aplicación entra en el estado de descubrimiento mientras Astra Control Center crea la aplicación en el clúster seleccionado. Una vez que Astra instala y detecta todos los recursos de la aplicación, la aplicación pasa al estado disponible.</block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">ONTAP de NetApp es una potente herramienta de software de almacenamiento con funcionalidades como una interfaz gráfica de usuario intuitiva, API DE REST con integración de la automatización, análisis predictivos con inteligencia artificial y acción correctiva, actualizaciones de hardware no disruptivas e importación entre almacenamiento.</block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">*SnapLock de NetApp.* Administración eficaz de datos que no se pueden sobrescribir escribiéndolos en volúmenes especiales que no se puedan sobrescribir ni borrar durante un periodo determinado.</block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp proporciona plataformas de almacenamiento sólidas all-flash (AFF) y híbridas de escalado horizontal (FAS) diseñadas a medida con un rendimiento de baja latencia, protección de datos integrada y compatibilidad con varios protocolos.</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">Ambos sistemas cuentan con el software de gestión de datos ONTAP de NetApp, el software de gestión de datos más avanzado del sector para una gestión del almacenamiento simplificada, integrada en el cloud y de alta disponibilidad, con el fin de proporcionar la velocidad, la eficiencia y la seguridad empresariales que necesita su Data Fabric.</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">Para obtener más información sobre las plataformas FAS y AFF de NETAPP, haga clic en<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="summary">Las funcionalidades que no dependen del hardware de Anthos en configuraciones básicas le permiten seleccionar una plataforma informática optimizada para su caso de uso personalizado y también proporcionan muchas ventajas adicionales.</block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">Entre los ejemplos se incluyen los siguientes:</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*Traiga su propio servidor.* puede utilizar servidores que coincidan con su infraestructura existente para reducir gastos de capital y costos de administración.</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*Traiga su propio sistema operativo Linux.* al elegir el sistema operativo Linux que desea desplegar su entorno Anthos en entornos bare-metal, puede asegurarse de que el entorno Anthos se adapta perfectamente a su infraestructura y esquemas de gestión existentes.</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">*Rendimiento mejorado y coste reducido.* sin el requisito de un hipervisor, los clústeres de Anthos en metal requieren un acceso directo a los recursos de hardware del servidor, incluidos los dispositivos de hardware optimizados para el rendimiento, como las GPU.</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">*Rendimiento de red mejorado y menor latencia.* debido a que los nodos de servidor de Anthos on-bare-metal están directamente conectados a su red sin una capa de abstracción virtualizada, pueden ser optimizados para una baja latencia y rendimiento.</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">La siguiente tabla contiene plataformas de servidores que han sido probadas por los ingenieros de partners de NetApp y NetApp para validar Anthos en puestas en marcha de configuración básica.</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">ProLiant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">Los nodos Anthos-on-bare-metal se pueden configurar con varias distribuciones diferentes de Linux, según el cliente, para ayudar a igualar la infraestructura actual de su centro de datos.</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">La siguiente tabla contiene una lista de sistemas operativos Linux que han utilizado NetApp y nuestros partners para validar la solución.</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8.4</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="6a3bfb64d8c5e16ce63f46624e637b30" category="cell">18.04 LTS</block>
  <block id="d4a5ee60a5a19102b6c00749a050feaf" category="cell">20.04 LTS</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">Para completar la puesta en marcha de Anthos en entornos de configuración básica como solución totalmente validada, NetApp y nuestros ingenieros de partners han probado componentes adicionales de centro de datos para redes y almacenamiento.</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250, A220</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">En la siguiente tabla se incluye una lista de versiones de software adicionales implementadas en el entorno de validación.</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">Nombre del software</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3(5)</block>
  <block id="6ff97c39e8de9255f8ab9ffb6a483dce" category="cell">9.9.1, 9.10.1</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">Durante la validación de la plataforma Anthos Ready realizada por NetApp y nuestro equipo de partners de la World Wide Technology (WWT), el entorno de laboratorio se creó en función del siguiente diagrama, lo que nos permitió probar la funcionalidad de cada tipo de servidor, sistema operativo y dispositivos de red, y sistemas de almacenamiento instalados en la solución.</block>
  <block id="f8caba75d33af6e6a5a53160c246688e" category="paragraph"><block ref="f8caba75d33af6e6a5a53160c246688e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">Este entorno de varios SO muestra interoperabilidad con versiones de SO compatibles para la solución Anthos en configuraciones básicas. Prevemos que los clientes se estandarizarán en uno o un subconjunto de sistemas operativos para su puesta en marcha.</block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">Recursos de soporte de infraestructura</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">Debe existir la siguiente infraestructura antes de la puesta en marcha de Anthos en servidores bare metal:</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">Al menos un servidor DNS que proporciona una resolución de nombre de host completa a la que se puede acceder desde la red de gestión.</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">Al menos un servidor NTP accesible desde la red de gestión.</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(Opcional) conectividad saliente de Internet para la red de gestión en banda.</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">En la sección Vídeos y demostraciones de este documento, hay un vídeo de demostración de Anthos sobre la puesta en marcha de bare metal.</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">Siguiente: Descripción general de los sistemas de almacenamiento de NetApp.</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Para habilitar Astra Control Center para gestionar sus cargas de trabajo, primero debe registrar su clúster Red Hat OpenShift.</block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Registre sus clústeres de Red Hat OpenShift con Astra Control Center</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Registre clústeres de Red Hat OpenShift</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">El primer paso es agregar los clústeres de OpenShift al Centro de control de Astra y gestionarlos. Vaya a Clusters, haga clic en Add a Cluster, cargue el<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> File para el clúster OpenShift y haga clic en Select Storage.</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">El archivo kubeconfig se puede generar para autenticarse con un nombre de usuario y una contraseña o un token. Los tokens caducan tras una cantidad limitada de tiempo y es posible que no se pueda acceder al clúster registrado. NetApp recomienda utilizar un archivo kubeconfig con un nombre de usuario y una contraseña para registrar los clústeres de OpenShift en Astra Control Center.</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center crea el almacenamiento seleccionado en clúster</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">Registre ambos clústeres de OpenShift como se describe en el paso 1. Cuando se añaden, los clústeres se mueven al estado de detección mientras Astra Control Center los inspecciona e instala los agentes necesarios. El estado del clúster cambia a en ejecución después de que se hayan registrado correctamente.</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Todos los clústeres de Red Hat OpenShift que gestiona Astra Control Center deben tener acceso al registro de imágenes que se utilizó para su instalación, ya que los agentes instalados en los clústeres gestionados extraen las imágenes de ese registro.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Importe clústeres de ONTAP como recursos de almacenamiento que Astra Control Center gestiona como back-ends. Cuando se agregan clústeres de OpenShift a Astra y se configura un storagegrid, detecta e inspecciona automáticamente el clúster de ONTAP para respaldar el storageeclcaso pero no lo importa en el Centro de control de Astra para su gestión.</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">Para importar los clústeres de ONTAP, vaya a Back-ends, haga clic en el menú desplegable y seleccione Manage junto al clúster de ONTAP que se va a gestionar. Introduzca las credenciales del clúster de ONTAP, haga clic en revisar información y, a continuación, haga clic en Importar back-end de almacenamiento.</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">Una vez añadidos los back-ends, el estado cambia a Available. Estos back-ends ahora tienen información sobre los volúmenes persistentes en el clúster de OpenShift y los volúmenes correspondientes en el sistema ONTAP.</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Para realizar backups y restauraciones en todos los clústeres de OpenShift con Astra Control Center, debe aprovisionar un bloque de almacenamiento de objetos que sea compatible con el protocolo S3. Actualmente, las opciones admitidas son ONTAP S3, StorageGRID y AWS S3. Para el objetivo de esta instalación, vamos a configurar un bloque de AWS S3. Vaya a Buckets, haga clic en Add bucket y seleccione Generic S3. Introduzca los detalles sobre el bloque de S3 y las credenciales para acceder a él, haga clic en la casilla de comprobación make this Bucket the Default Bucket for the Cloud y, a continuación, haga clic en Add.</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">Siguiente: Elija las aplicaciones que desea proteger.</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">Esta sección se dedica a personalizaciones que los usuarios reales tendrían que realizar al implementar esta solución en la producción, como la implementación de instancias de equilibrador de carga personalizadas.</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">Normalmente, la solución más fácil de implementar es la mejor, pero, en algunos casos, se requieren personalizaciones avanzadas para cumplir los requisitos o especificaciones de una aplicación específica o del entorno al que se está implementando la solución. Con este fin, la solución Red Hat OpenShift con NetApp permite que las siguientes personalizaciones cumplan estas necesidades.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">En esta sección hemos documentado algunas opciones de configuración avanzadas, como el uso de equilibradores de carga de terceros o la creación de un registro privado para alojar imágenes de contenedor personalizadas, que son requisitos previos para la instalación de Astra Control Center de NetApp.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">En las siguientes páginas encontrará información adicional sobre las opciones de configuración avanzadas validadas en la solución Red Hat OpenShift con NetApp:</block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">Siguiente: Exploración de las opciones de equilibrio de carga.</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">Documentación de NetApp Astra Trident</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">Anthos Clusters en documentación de VMware</block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Anthos en documentación de configuración básica</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">Documentación de VMware vSphere</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">Este documento de referencia proporciona la validación de la puesta en marcha de Anthos de Google Cloud en varios entornos de centros de datos diferentes y ha sido validada por NetApp. Además, se detalla la integración del almacenamiento con los sistemas de almacenamiento de NetApp mediante el uso del orquestador de almacenamiento Astra Trident para la gestión del almacenamiento persistente y el Centro Astra Control Center de NetApp para la gestión y protección de aplicaciones con estado. Por último, se exploran y documentan una serie de validaciones de soluciones y casos de uso reales.</block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">Esta sección se dedica a personalizaciones que los usuarios del mundo real probablemente deban realizar al implementar esta solución en la producción, como la creación de un registro de imagen dedicado o la implementación de instancias personalizadas de equilibrador de carga.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">Exploración de las opciones de equilibrio de carga</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">Configuración de registros de imágenes privadas</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV es una plataforma de centro de datos virtual empresarial que se ejecuta en Red Hat Enterprise Linux (RHEL) y utiliza el hipervisor KVM.</block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="doc">OpenShift en Red Hat Virtualization</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization (RHV) es una plataforma de centro de datos virtual empresarial que se ejecuta en Red Hat Enterprise Linux (RHEL) y utiliza el hipervisor KVM.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Sitio web de Red Hat Virtualization</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">Para obtener más información acerca de RHV, consulte<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV proporciona las siguientes funciones:</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">*Gestión centralizada de VM y hosts.* el administrador de RHV se ejecuta como una máquina física o virtual (VM) en la implementación y proporciona una interfaz gráfica de usuario basada en web para la administración de la solución desde una interfaz central.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">*Motor autoalojado.* para minimizar los requisitos de hardware, RHV permite implementar RHV Manager (RHV-M) como una VM en los mismos hosts que ejecutan VM huésped.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">*Alta disponibilidad.* para evitar interrupciones en caso de fallos de host, RHV permite configurar las VM para alta disponibilidad. Las máquinas virtuales de alta disponibilidad se controlan en el nivel de clúster mediante políticas de flexibilidad.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">*Alta escalabilidad.* Un único clúster RHV puede tener hasta 200 hosts de hipervisor que le permiten admitir requisitos de máquinas virtuales masivas para alojar cargas de trabajo de clase empresarial y con gran consumo de recursos.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">*Seguridad mejorada.* heredado de las tecnologías RHV, Secure Virtualization (sVirt) y Security Enhanced Linux (SELinux) son empleados por RHV con el propósito de una seguridad elevada y endurecimiento para los hosts y los equipos virtuales. La ventaja clave de estas funciones es el aislamiento lógico de un equipo virtual y sus recursos asociados.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">La solución Red Hat OpenShift en NetApp utiliza dos switches de datos para proporcionar conectividad de datos principal a 25 Gbps. También usa dos switches de gestión adicionales que proporcionan conectividad a 1 Gbps para la gestión en banda de los nodos de almacenamiento y la gestión fuera de banda para la funcionalidad de IPMI. OCP utiliza la red lógica de máquina virtual en RHV para la administración de clústeres. En esta sección se describe la disposición y el propósito de cada segmento de red virtual utilizado en la solución y se describen los requisitos previos para implementar la solución.</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">Red Hat OpenShift en RHV está diseñado para separar lógicamente el tráfico de red para diferentes fines mediante redes de área local virtual (VLAN). Esta configuración se puede ampliar para satisfacer las demandas del cliente o para proporcionar un aislamiento adicional para servicios de red específicos. La siguiente tabla enumera las VLAN necesarias para implementar la solución mientras valida la solución en NetApp.</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">Gestión para nodos físicos e IPMI</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">Red de equipos virtuales</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">Acceso a la red de invitados virtuales</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">Gestión de los nodos RHV-H, RHV-Manager y la red ovirtmgmt</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">Red de almacenamiento</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">Red de almacenamiento para iSCSI de NetApp Element</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">Red de migración</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">Para la migración de invitados virtuales</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">Implemente OpenShift en un clúster RHV de al menos tres nodos</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">La arquitectura verificada descrita en este documento presenta la puesta en marcha mínima de hardware adecuada para operaciones de alta disponibilidad mediante la puesta en marcha de dos nodos de hipervisor RHV-H y la garantía de una configuración tolerante a fallos donde ambos hosts puedan gestionar el motor alojado y los equipos virtuales puestos en marcha pueden migrar entre los dos hipervisores.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Puesto que Red Hat OpenShift se implementa inicialmente con tres nodos maestros, se garantiza en una configuración de dos nodos que al menos dos maestros ocuparán el mismo nodo, lo que puede provocar una posible interrupción en OpenShift si ese nodo específico deja de estar disponible. Por lo tanto, es una práctica recomendada de Red Hat que se implementen al menos tres nodos de hipervisor RHV-H como parte de la solución para que los maestros de OpenShift se puedan distribuir uniformemente y la solución reciba un grado añadido de tolerancia a fallos.</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">Puede distribuir los maestros de OpenShift en varios nodos de hipervisor si habilita la afinidad de VM/host.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">La afinidad es una forma de definir reglas para un conjunto de VM y/o hosts que determinan si los VM se ejecutan en el mismo host o hosts del grupo o en hosts diferentes. Se aplica a los equipos virtuales mediante la creación de grupos de afinidad que constan de equipos virtuales y/o hosts con un conjunto de parámetros y condiciones idénticos. En función de si los equipos virtuales de un grupo de afinidad se ejecutan en el mismo host o hosts del grupo o por separado en hosts diferentes, los parámetros del grupo de afinidad pueden definir afinidad positiva o afinidad negativa.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">Las condiciones definidas para los parámetros pueden ser de aplicación estricta o de aplicación suave. El cumplimiento estricto garantiza que las VM de un grupo de afinidad siempre siguen la afinidad positiva o negativa estrictamente sin tener en cuenta las condiciones externas. La implementación suave garantiza que se establezca una preferencia mayor para que las VM de un grupo de afinidad sigan la afinidad positiva o negativa siempre que sea posible. En la configuración de dos o tres hipervisores descrita en este documento, se recomienda la afinidad suave. En clústeres de mayor tamaño, la afinidad dura puede distribuir correctamente los nodos de OpenShift.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11. Documentación de grupos de afinidad</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">Para configurar grupos de afinidad, consulte<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI facilita la implementación de los clústeres de OpenShift a través del asistente interactivo que se ha tratado anteriormente en este documento. Sin embargo, es posible que haya algunos valores predeterminados que deban cambiarse como parte de la puesta en marcha del clúster.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift instalación de un clúster en RHV con personalizaciones</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">En estas instancias, puede ejecutar y ejecutar el asistente sin implementar inmediatamente un clúster. En cambio, se crea un archivo de configuración a partir del cual se puede implementar el clúster más adelante. Esto resulta muy útil si desea cambiar cualquier valor predeterminado de IPI o si desea implementar varios clústeres idénticos en su entorno para otros usos como multi-tenancy. Para obtener más información acerca de cómo crear una configuración de instalación personalizada para OpenShift, consulte<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">Siguiente: Información general sobre el almacenamiento de NetApp.</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">Configurar multitenancy en Red Hat OpenShift con NetApp</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">Muchas organizaciones que ejecutan varias aplicaciones o cargas de trabajo en contenedores tienden a implementar un clúster de Red Hat OpenShift por aplicación o carga de trabajo. Esta característica les permite implementar un aislamiento estricto para la aplicación o la carga de trabajo, optimizar el rendimiento y reducir las vulnerabilidades de seguridad. Sin embargo, la implementación de un clúster Red Hat OpenShift independiente para cada aplicación plantea su propio conjunto de problemas. Aumenta los gastos generales operativos teniendo que supervisar y gestionar cada clúster por sí solo, aumenta los costes debido a los recursos dedicados para distintas aplicaciones y obstaculiza la escalabilidad eficiente.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">Para solucionar estos problemas, se puede considerar la posibilidad de ejecutar todas las aplicaciones o cargas de trabajo en un único clúster de Red Hat OpenShift. Pero en una arquitectura de este tipo, el aislamiento de recursos y las vulnerabilidades de seguridad de las aplicaciones son uno de los principales retos. Cualquier vulnerabilidad de seguridad en una carga de trabajo podría extenderse naturalmente a otra carga de trabajo, aumentando así la zona de impacto. Además, cualquier uso abrupto y no controlado de los recursos en una aplicación puede afectar al rendimiento de otra, ya que no hay ninguna política de asignación de recursos de forma predeterminada.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">Por ello, las organizaciones buscan soluciones que recojan lo mejor de ambos mundos, permitiéndoles ejecutar todas sus cargas de trabajo en un único clúster y, aun así, ofrecer las ventajas de un clúster dedicado para cada carga de trabajo.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">Una de estas soluciones tan eficaz es configurar multi-tenancy en Red Hat OpenShift. Multi-tenancy es una arquitectura que permite que varios clientes coexistan en el mismo clúster con el aislamiento adecuado de recursos, seguridad, etc. En este contexto, un arrendatario puede verse como un subconjunto de los recursos del clúster que están configurados para ser utilizados por un grupo particular de usuarios para un propósito exclusivo. La configuración de multi-tenancy en un clúster de Red Hat OpenShift ofrece las siguientes ventajas:</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">Una reducción en los gastos de capital y operativos al permitir compartir los recursos de clúster</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">Reducción de los gastos generales operativos y de gestión</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">Proteger las cargas de trabajo de casos de contaminación cruzada de infracciones de seguridad</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">Protección de las cargas de trabajo de degradación del rendimiento inesperada debido a la contención de recursos</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">En el caso de un clúster OpenShift multitenant completamente observado, es necesario configurar cuotas y restricciones para los recursos del clúster que pertenecen a diferentes bloques de recursos: Computación, almacenamiento, redes, seguridad, etc. Aunque trataremos ciertos aspectos de todos los grupos de recursos de esta solución, Nos centramos en las prácticas recomendadas para aislar y proteger los datos que sirven o consumen varias cargas de trabajo en el mismo clúster de Red Hat OpenShift configurando el multi-tenancy en recursos de almacenamiento que asigna de forma dinámica Astra Trident con el respaldo de ONTAP de NetApp.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">Ejecute el<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> comando para crear la clase de almacenamiento.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">Cree el PVC emitiendo el<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> comando. La creación puede tardar un poco de tiempo, según el tamaño del volumen de backup que se esté creando, para que pueda ver el proceso a medida que finalice.</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Para obtener información sobre la instalación y configuración de Astra Trident y su compatibilidad con Astra Control Center, consulte <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">Es recomendable que cada instalación de OpenShift en un sitio tenga una SVM dedicada para almacenamiento persistente. Las puestas en marcha de varios sitios requieren sistemas de almacenamiento adicionales.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Las instalaciones de Docker deben tener la versión de docker superior a 20.10 y las instalaciones de Podman deben tener una versión de podman superior a 3.0.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">Antes de iniciar la instalación, empuje las imágenes de Astra Control Center hasta un registro de imágenes. Puede elegir hacer esto con Docker o Podman, las instrucciones para ambos se proporcionan en este paso.</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">Seleccione<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> mosaico y haga clic en<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">En la pantalla instalar operador, acepte todos los parámetros predeterminados y haga clic en<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">Una vez que la instalación del operador se realice correctamente, desplácese hasta hacer clic en<block ref="6423332325de5a7100cc070ffad7a372" prefix=" " category="inline-code"></block>.</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">A continuación, haga clic en<block ref="43f8527e733785e2ca7a92853d30e4f7" prefix=" " category="inline-code"></block> En el mosaico del Centro de control de Astra del operador.</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Rellene el<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> campos de formulario y haga clic en<block ref="686e697538050e4664636337cc3b834f" prefix=" " category="inline-code"></block>.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Introduzca un nombre de cuenta para Astra Control Center y detalles de administración como nombre, apellidos y dirección de correo electrónico.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">En el Registro de imágenes, introduzca el FQDN del registro junto con el nombre de la organización que se le dio mientras presiona las imágenes al registro (en este ejemplo,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>)</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">Si utiliza un registro que requiere autenticación, introduzca el nombre secreto en la sección Image Registry (Registro de imágenes).</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Configurar las opciones de ampliación para los límites de recursos de Astra Control Center.</block>
  <block id="f1fc5bef6accc6d1fab4ab73142df7f3" category="list-text">Para utilizar los libros de estrategia de Ansible para poner en marcha Astra Control Center, necesita una máquina Ubuntu/RHEL con Ansible instalado. Siga el procedimiento<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Para Ubuntu y el procedimiento<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Para RHEL.</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">Inicie sesión en el sitio de soporte de NetApp y descargue la versión más reciente de Astra Control Center de NetApp. Para ello, es necesario disponer de una licencia adjunta a su cuenta de NetApp. Después de descargar el tarball, transfiéralo a la estación de trabajo.</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Cree o obtenga el archivo kubeconfig con acceso de administrador al clúster OpenShift en el que se va a instalar Astra Control Center.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">Cambie el directorio a na_astra_control_Suite.</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">Edite el<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> y rellene las variables con la información necesaria.</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">Si el usuario tiene configurado un acceso sudo basado en contraseña, ejecute el siguiente comando para ejecutar la libro de estrategia y, a continuación, introduzca la contraseña sudo.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">Siguiente: Registre sus clústeres de Red Hat OpenShift: Red Hat OpenShift con NetApp.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp ofrece una serie de productos que ayudan a nuestros clientes a orquestar y gestionar datos persistentes en entornos basados en contenedores, como Red Hat OpenShift.</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp proporciona una serie de productos que le ayudan a orquestar y gestionar datos persistentes en entornos basados en contenedores, como Red Hat OpenShift.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">Astra Control de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes, con la tecnología de protección de datos de NetApp. El servicio Astra Control está disponible para admitir cargas de trabajo con estado en puestas en marcha de Kubernetes nativas para el cloud. Astra Control Center está disponible para admitir cargas de trabajo con estado en implementaciones en las instalaciones, como Red Hat OpenShift. Si quiere más información, visite el sitio web de Astra Control de NetApp<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">Astra Trident de NetApp es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Red Hat OpenShift. Si quiere más información, visite el sitio web de Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">En las siguientes páginas encontrará información adicional sobre los productos de NetApp que se han validado para la gestión de aplicaciones y almacenamiento persistente en la solución Red Hat OpenShift con NetApp:</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">Siguiente: Descripción general de Astra Control Center de NetApp</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">Implementación de una máquina virtual con OpenShift Virtualization: Red Hat OpenShift con NetApp</block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">Instalación de OpenShift Virtualization: Red Hat OpenShift con NetApp</block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="doc">OpenShift con configuración básica</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">OpenShift on Bare Metal proporciona una implementación automatizada de OpenShift Container Platform en servidores genéricos.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">OpenShift on Bare Metal es similar a las implementaciones virtuales de OpenShift, que proporcionan facilidad de implementación, aprovisionamiento rápido y escalado de clústeres de OpenShift, al tiempo que admiten cargas de trabajo virtualizadas para aplicaciones que no están listas para contenerizadas. Al implementar con configuración básica, no necesita la sobrecarga adicional necesaria para gestionar el entorno de hipervisor del host además del entorno OpenShift. Al implementar directamente en servidores con configuración básica, también puede reducir las limitaciones de sobrecarga física de tener que compartir recursos entre el host y el entorno OpenShift.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">OpenShift on Bare Metal ofrece las siguientes características:</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">*IPI o implementación asistida del instalador.* con un clúster OpenShift implementado por Installer provisioned Infrastructure (IPI) en servidores bare metal, los clientes pueden implementar un entorno OpenShift altamente versátil y fácilmente escalable directamente en servidores genéricos, sin necesidad de gestionar una capa de hipervisor.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">*Diseño de clúster compacto.* para minimizar los requisitos de hardware, OpenShift con configuración básica permite a los usuarios implementar clústeres de sólo 3 nodos, al permitir que los nodos de plano de control de OpenShift actúen también como nodos de trabajo y contenedores de host.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">*OpenShift Virtualization.* OpenShift puede ejecutar máquinas virtuales dentro de contenedores mediante OpenShift Virtualization. Esta virtualización nativa de contenedor ejecuta el hipervisor KVM dentro de un contenedor y conecta volúmenes persistentes para el almacenamiento de máquinas virtuales.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">*Infraestructura optimizada para IA/ML.* implemente aplicaciones como Kubeflow para aplicaciones de aprendizaje automático incorporando nodos de trabajo basados en GPU en su entorno OpenShift y aprovechando OpenShift Advanced Scheduling.</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">La solución Red Hat OpenShift en NetApp utiliza dos switches de datos para proporcionar conectividad de datos principal a 25 Gbps. También utiliza dos switches de gestión que proporcionan conectividad a 1 Gbps para la gestión en banda de los nodos de almacenamiento y la gestión fuera de banda para la funcionalidad de IPMI.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">Para la implementación de IPI nativo de OpenShift, debe crear un nodo de aprovisionador, una máquina Red Hat Enterprise Linux 8 que debe tener interfaces de red conectadas a redes independientes.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">*Red de aprovisionamiento.* esta red se utiliza para arrancar los nodos de configuración básica e instalar las imágenes y paquetes necesarios para implementar el clúster OpenShift.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">*Red Bare-metal.* esta red se utiliza para la comunicación pública del clúster después de su implementación.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">Para la configuración del nodo de aprovisionamiento, el cliente crea interfaces de puente que permiten que el tráfico se dirija correctamente al nodo mismo y a la máquina virtual de inicio que se aprovisiona con fines de implementación. Una vez que se ha implementado el clúster, las direcciones API y VIP de entrada se migran del nodo bootstrap al clúster recién implementado.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">Las imágenes siguientes muestran el entorno durante la implementación de IPI y una vez completada la implementación.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">La solución Red Hat OpenShift con NetApp se ha diseñado para separar de forma lógica el tráfico de red para distintos fines mediante redes de área local virtual (VLAN).</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">Gestión para nodos de configuración básica e IPMI</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">Red con configuración básica</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">Red para servicios OpenShift una vez que el clúster está disponible</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">Aprovisionando red</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Red para arranque PXE e instalación de nodos de metal desnudo a través de IPI</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">Aunque cada una de estas redes está virtualmente separada por VLAN, cada puerto físico se debe configurar en modo de acceso con la VLAN principal asignada, ya que no hay manera de pasar una etiqueta VLAN durante una secuencia de arranque PXE.</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">La siguiente infraestructura debe estar en funcionamiento antes de la implementación de la plataforma de contenedores OpenShift:</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">Al menos un servidor DNS que proporciona una resolución de nombre de host completa a la que se puede acceder desde la red de gestión en banda y la red de VM.</block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">Gestión del ciclo de vida de las aplicaciones</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">Para crear una aplicación y gestionarla en un conjunto de clústeres,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">Vaya a Administrar aplicaciones en la barra lateral y haga clic en Crear aplicación. Proporcione los detalles de la aplicación que desea crear y haga clic en Guardar.</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">Crear aplicación</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">Una vez instalados los componentes de la aplicación, la aplicación aparece en la lista.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">Aplicaciones</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">La aplicación ahora puede supervisarse y gestionarse desde la consola.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">Siguiente: Características - gobernabilidad y riesgo.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">Ponga en marcha Red Hat OpenShift Virtualization con ONTAP de NetApp</block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">Para instalar OpenShift Virtualization, lleve a cabo los siguientes pasos:</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">Inicie sesión en el clúster de configuración básica de Red Hat OpenShift con acceso de administrador de clúster.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Desplácese a OperatorHub y busque OpenShift Virtualization.</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">Seleccione el icono virtualización OpenShift y haga clic en instalar.</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">Recuadro del operador de virtualización OpenShift</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">En la pantalla instalar operador, deje todos los parámetros predeterminados y haga clic en instalar.</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">Detalles del operador de virtualización de OpenShift</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">Instalación del operador de virtualización OpenShift</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">Una vez instalado el operador, haga clic en Crear hiperconvergente.</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - Crear Hyperconverged</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">En la pantalla Crear Hiperconvergente, haga clic en Crear, aceptando todos los parámetros predeterminados. Este paso inicia la instalación de OpenShift Virtualization.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - Información hiperconvergente</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">Después de que todos los POD se trasladen al estado en ejecución en el espacio de nombres openshift-cnv y el operador de OpenShift Virtualization se encuentre en el estado correcto, el operador estará listo para usarse. Ahora se pueden crear equipos virtuales en el clúster de OpenShift.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">Se ha completado la instalación del operador de virtualización OpenShift</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">Siguiente: Flujos de trabajo: Crear una máquina virtual.</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Migración de cargas de trabajo con Astra Control Center: Red Hat OpenShift con NetApp</block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp cuenta con varias plataformas de almacenamiento cualificadas con nuestro Trident Storage Orchestrator para aprovisionar almacenamiento para aplicaciones implementadas en Red Hat OpenShift.</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp cuenta con varias plataformas de almacenamiento cualificadas con nuestra Astra Trident Storage Orchestrator para aprovisionar almacenamiento para las aplicaciones implementadas en Red Hat OpenShift.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">En las siguientes páginas encontrará información adicional sobre los sistemas de almacenamiento de NetApp validados en la solución Red Hat OpenShift con NetApp:</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="doc">Implementación de Red Hat OpenShift en RHV: Red Hat OpenShift con NetApp</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element: Red Hat OpenShift con NetApp</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">De este modo, si a un fallo de un nodo le sigue una redistribución del volumen, no se produce ningún efecto en la conectividad de host más allá del cierre de sesión y el inicio de sesión mediante redirección a la nueva ubicación. Con la redirección de inicio de sesión iSCSI, un clúster de software NetApp Element es una arquitectura de escalabilidad horizontal y reparación automática que puede realizar operaciones y actualizaciones no disruptivas.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Registre sus clústeres de Red Hat OpenShift con Astra Control Center</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">El primer paso es agregar los clústeres de OpenShift al Centro de control de Astra y gestionarlos. Vaya a Clusters y haga clic en Add a Cluster, cargue el archivo kubeconfig para el clúster OpenShift y haga clic en Select Storage.</block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Para realizar backups y restauraciones en todos los clústeres de OpenShift con Astra Control Center, debe aprovisionar un bloque de almacenamiento de objetos que sea compatible con el protocolo S3. Actualmente, las opciones admitidas son ONTAP S3, StorageGRID y AWS S3. Para el objetivo de esta instalación, vamos a configurar un bloque de AWS S3. Vaya a Buckets, haga clic en Add bucket y seleccione Generic S3. Introduzca los detalles sobre el bloque de S3 y las credenciales para acceder a él, haga clic en la casilla "make this bucket the default bucket for the cloud" y, a continuación, haga clic en Add.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">Información adicional: Red Hat OpenShift con NetApp</block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Documentación de Red Hat OpenShift</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Documentación de Red Hat OpenStack Platform</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Documentación de Red Hat Virtualization</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Un clúster de Red Hat OpenShift (posterior a la versión 4.6) instalado en una infraestructura con configuración básica con nodos de trabajo RHCOS</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">El clúster OpenShift debe instalarse a través de la infraestructura aprovisionada por el instalador (IPI).</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">Ponga en marcha comprobaciones de estado de la máquina para mantener la alta disponibilidad de las máquinas virtuales</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">Un clúster ONTAP de NetApp</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">Astra Trident se ha instalado en el clúster OpenShift</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">Un back-end de Trident configurado con una SVM en un clúster de ONTAP</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">Un StorageClass configurado en el clúster OpenShift con Astra Trident como aprovisionador</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Acceso de administrador de clúster al clúster de Red Hat OpenShift</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">Acceso de administrador al clúster de ONTAP de NetApp</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">Una estación de trabajo de administración con herramientas trimentctl y oc instaladas y agregadas a $PATH</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">Puesto que OpenShift Virtualization es gestionado por un operador instalado en el clúster OpenShift, impone gastos adicionales en memoria, CPU y almacenamiento, que se deben tener en cuenta al planificar los requisitos de hardware para el clúster. Consulte la documentación<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> para obtener más detalles.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">Opcionalmente, también puede especificar un subconjunto de los nodos del clúster de OpenShift para alojar los operadores, controladores y equipos virtuales de OpenShift mediante la configuración de reglas de colocación de nodos. Para configurar reglas de colocación de nodos para OpenShift Virtualization, siga la documentación<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">En el caso del backup de almacenamiento que ofrece OpenShift Virtualization, NetApp recomienda tener un tipo de almacenamiento dedicado que solicite almacenamiento desde un back-end de Trident concreto, el cual, a su vez, se encuentra respaldado por una SVM dedicada. Esto mantiene un nivel de multi-tenancy con respecto a los datos que se sirven para cargas de trabajo basadas en equipos virtuales en el clúster OpenShift.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">Siguiente: Despliegue a través del operador.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">Uso de la tecnología FlexClone para realizar una puesta en marcha rápida</block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">Acelere el desarrollo de software con la tecnología FlexClone de NetApp</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">El clonado de una aplicación puesta en marcha en un clúster de Kubernetes es una herramienta muy útil para los desarrolladores que desean acelerar sus flujos de trabajo al compartir entornos con partners o probar nuevas versiones de código en un entorno de desarrollo sin interferir con la versión en la que trabajan actualmente. El clonado con estado y consistente con las aplicaciones de una aplicación Kubernetes es una de las principales funciones que se incluyen en Astra Control de NetApp, junto con el backup y la restauración de aplicaciones. Si una aplicación se clona en el mismo clúster de Kubernetes con el mismo back-end de almacenamiento, Astra Control utiliza de forma predeterminada la tecnología FlexClone de NetApp para la deduplicación de volúmenes de datos persistentes, lo que acelera considerablemente el proceso. Al acelerar este proceso, el entorno clonado se aprovisiona y está disponible para su uso en pocos momentos, lo que permite a los desarrolladores reanudar su trabajo con una breve pausa en comparación con la nueva puesta en marcha de su entorno de pruebas o desarrollo. Además, para una mayor comodidad, todas las funciones disponibles en Astra Control de NetApp se pueden llamar con una API, que permite una integración sencilla en marcos de automatización como Ansible. Por lo tanto, los entornos se pueden almacenar en niveles incluso más rápido porque solo se necesitan cambios menores en un libro de aplicaciones o un rol para comenzar el procedimiento de clonación.</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">¿Qué es la tecnología FlexClone de NetApp?</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">La tecnología FlexClone de NetApp es una copia editable, basada en copias Snapshot de un momento específico de un FlexVol de NetApp. Se aprovisionan casi al instante, contienen todos los datos del volumen de origen y no consumen espacio de almacenamiento adicional hasta que los datos del nuevo volumen empiecen a desviarse del origen. A menudo se utilizan en entornos basados en desarrollo o en plantillas cuando varias copias de datos son útiles para fines de configuración y los sistemas de almacenamiento tienen recursos limitados para aprovisionar estos volúmenes. En comparación con un sistema de almacenamiento tradicional en el que los datos deben copiarse varias veces, por lo que se consume un tiempo y un espacio de almacenamiento considerable, la tecnología FlexClone de NetApp acelera las tareas dependientes del almacenamiento.</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">Imagen de FlexClone</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documentos de NetApp</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">Si quiere más información sobre la tecnología FlexClone de NetApp, visite la página en<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>.</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Una distribución de Kubernetes compatible, como Red Hat OpenShift 4.6.8 o posterior, Rancher 2.5 o Kubernetes 1.19 o posterior.</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra Control Center 21.12+.</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">Un sistema ONTAP de NetApp con un back-end de almacenamiento configurado mediante la Astra Trident de NetApp.</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9 o posterior.</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">Plantillas para los entornos que le gustaría clonar como aplicaciones gestionadas en Astra Control de NetApp.</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">Introducción a casos de uso</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">Para este caso de uso, visualizamos algo similar al siguiente flujo de trabajo:</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">Imagen del flujo de trabajo</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">Un usuario ejecuta el libro de estrategia de Ansible para crear un nuevo entorno de almacenamiento provisional.</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible utiliza el módulo URI-API para llamar a Astra Control y ejecutar la operación de clonado.</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control ejecuta una operación de clonación en un entorno de plantilla preaprovisionado, creando así una nueva aplicación administrada.</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">Este entorno puede ser una única aplicación independiente en desarrollo o en todo un entorno de desarrollo, como una canalización CI/CD de Jenkins.</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">A continuación, el usuario extrae una versión de su código al entorno de desarrollo clonado desde un repositorio en línea como Gitea.</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">La nueva versión de la aplicación se pone en marcha y gestiona con Astra Control de NetApp.</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">Estos dos procesos se pueden automatizar.</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">El usuario puede desarrollar código nuevo en este entorno clonado.</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">Cuando el usuario está satisfecho con sus esfuerzos de desarrollo, puede devolver el código al repositorio alojado.</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">El caso de uso que se presenta aquí depende de la existencia de plantillas maestras para los entornos o aplicaciones concretas que desee clonar. En nuestro entorno hemos creado tres de estas plantillas, una para la implementación de Wordpress, otra para la implementación de Magento y otra para un entorno CI/CD de Jenkins con Gitea que hemos titulado DevTools.</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">Imagen de plantillas</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">Cada uno de estos entornos se gestiona mediante Astra Control de NetApp, con volúmenes persistentes que se almacenan actualmente en un sistema de almacenamiento ONTAP de NetApp con un back-end NFS proporcionado por Astra Trident de NetApp.</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">Validación de casos de uso</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">Clone el kit de herramientas de Ansible que proporciona el equipo de ingeniería de soluciones de NetApp, que incluye el rol de clonado y el libro de estrategia de actualización de aplicaciones.</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">Editar<block ref="c4fe4210b1a8cc125caf1d344db07732" prefix=" " category="inline-code"></block> Y rellene los valores globales que se ajusten a su entorno de Astra Control.</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">Los valores del entorno global que debe rellenar están disponibles en el icono de perfil de usuario de NetApp Astra Control, en el menú API Access.</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">Imagen de acceso API</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">Una vez completadas las variables globales, puede elegir los valores de la aplicación específica que desea clonar. Para clonar el entorno devtools a un entorno personal llamado<block ref="2ab4557e919d8388e34d63b073eb0704" prefix=" " category="inline-code"></block>, haría lo siguiente:</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">Para aprovechar la tecnología FlexClone de NetApp en el proceso de clonación,<block ref="4235aba0b7240b55d6c0b4e16f2b0c9a" prefix=" " category="inline-code"></block> y..<block ref="57d3fb1ffc6c61e8386a14142cad2cfe" prefix=" " category="inline-code"></block> debe ser igual.</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">Ahora puede ejecutar el libro de aplicaciones para clonar la aplicación.</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">el libro de aplicaciones como escrito debe ser ejecutado por el usuario raíz o por alguien que pueda escalar a través del proceso sudo pasando el argumento "-K".</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">Una vez que el libro de aplicaciones complete su ejecución, la aplicación clonada aparecerá como disponible en la consola del Centro de control de Astra.</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">Imagen de la aplicación clonada</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">A continuación, un usuario puede iniciar sesión en el entorno Kubernetes en el que se ha puesto en marcha la aplicación, comprobar que la aplicación está expuesta con una nueva dirección IP e iniciar el trabajo de desarrollo.</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">Para ver una demostración de este caso práctico y un ejemplo de cómo actualizar una aplicación, consulte <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>.</block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">Siguiente: Vídeos y demos: DevOps con NetApp Astra.</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Red Hat OpenShift.</block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">Consulte la documentación <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Para instalar y usar Astra Trident.</block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">Siguiente: Validaciones de casos prácticos: DevOps con NetApp Astra.</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">Validación de casos prácticos: DevOps con NetApp Astra</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">Se han validado los siguientes casos de uso para DevOps con NetApp Astra:</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="inline-link-macro">Integrar la protección en canalizaciones CI/CD con Astra Control de NetApp</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">Aproveche Astra Control para facilitar el análisis post mortem y la restauración de la aplicación</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">Aceleración del desarrollo de software con FlexClones de NetApp</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Para obtener una guía de instalación y funcionamiento detallada de Astra Control Center, siga la documentación <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">Si busca un kit de herramientas de desarrollo de software listo para usar con las API REST de Astra Control, NetApp le proporciona un kit de herramientas con Astra Control Python SDK, que puede descargar <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">Si la programación no es una corrección adecuada para su situación y le gustaría utilizar una herramienta de gestión de configuración, puede clonar y ejecutar los libros de estrategia de Ansible que publica NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">Siguiente: Validaciones de casos prácticos: DevOps con NetApp Astra</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">Este informe técnico describe cómo NetApp hace que los casos prácticos de DevOps sean sencillos y eficientes en varios frentes, cuando se utilizan aplicaciones en contenedores. El primer paso es detallar los sistemas de almacenamiento de NetApp y su integración con las plataformas de Kubernetes por medio de la cartera Astra. Por último, se exploran y documentan una serie de validaciones de soluciones y casos de uso reales.</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919: DevOps con NetApp Astra</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">La solución DevOps con NetApp Astra ha sido diseñada para ofrecer un valor excepcional a los clientes con los siguientes casos prácticos:</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">Es fácil de poner en marcha y gestionar entornos de aplicaciones y desarrollo implementados sobre las distribuciones de Kubernetes compatibles.</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">Discusión de casos prácticos reales para flujos de trabajo de DevOps y ejemplos de herramientas y métodos que puede proporcionar NetApp para facilitar la adopción y el uso de estos métodos.</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">Exploración de cómo se pueden usar las copias Snapshot, los backups y los clones coherentes con las aplicaciones para mejorar la experiencia de DevOps.</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">Alta disponibilidad en todas las capas de la pila, de forma que los flujos de trabajo nunca se interrumpen.</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">Facilidad de los procedimientos de puesta en marcha y gestión para el usuario final.</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">Infraestructura programable y condicionada por API para seguir el ritmo de los microservicios y la agilidad de los desarrolladores.</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">Capacidad de escalar la infraestructura de forma independiente y automatizada en función de las demandas de las cargas de trabajo.</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">La protección de aplicaciones junto con sus conjuntos de datos persistentes de backup para flujos de trabajo de DevOps acelera el plazo de comercialización al no tener que depender de la repuesta en marcha o de la copia manual de datos.</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">Reconociendo estas funcionalidades y retos, este informe técnico describe el proceso de mejorar y simplificar los casos prácticos de DevOps para aplicaciones en contenedores utilizando la amplia cartera de productos de NetApp.</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">DevOps con la solución NetApp consta de los siguientes componentes principales:</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">Prácticas de DevOps</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">Las prácticas de DevOps se centran en operaciones automatizadas, repetibles y fácilmente gestionables que mejoran el flujo de trabajo del desarrollo, al permitir al usuario final controlar el entorno en el que desarrolla su código. Esta solución proporciona varios ejemplos y casos de uso en los que la tecnología de NetApp puede ser de mayor beneficio para dichas operaciones.</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">Actualmente, existen numerosas plataformas de orquestación de contenedores en uso. Aunque la mayoría de estas plataformas se basan en Kubernetes, cada una tiene un pros y contras. Por lo tanto, es importante comprender los conjuntos de funciones y las integraciones al seleccionar una plataforma de orquestación de contenedores para los flujos de trabajo de DevOps. Con la suite Astra de productos de NetApp, somos compatibles con las siguientes plataformas para los casos prácticos de DevOps completo:</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8+</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">Guardabosques</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5 o posterior</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20 o posterior</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4 o posterior</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2 o posterior</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">Astra Control Center de NetApp ofrece un amplio conjunto de servicios de gestión de datos para aplicaciones y almacenamiento para cargas de trabajo con estado de Kubernetes puestas en marcha en un entorno local y con la tecnología de protección de datos de confianza de NetApp.</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">Siguiente: Información general de DevOps.</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">Uno de los usos más comunes de los flujos de trabajo de DevOps es la integración continua y las canalizaciones de implementación continua (CI/CD) que crean, integran y ejecutan suites de pruebas automatizadas en aplicaciones, mientras los desarrolladores aplican nuevo código. Los ingenieros de DevOps y los ingenieros de fiabilidad del sitio (SRE, "Site-reliability engineer") suelen tener canalizaciones dedicadas a los distintos flujos de trabajo para el desarrollo de nuevas funciones, las pruebas de regresión, las correcciones de errores, la ingeniería de calidad y otras funciones del proceso de desarrollo.</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">A medida que los equipos aumentan su nivel de automatización, el ritmo de los cambios de las aplicaciones en producción puede resultar abrumador. Por lo tanto, algunos equipos prefieren proteger los servicios o las aplicaciones de producción. Además de proteger las imágenes de código y contenedor, también quieren proteger el estado de la aplicación, los datos de configuración (como objetos y recursos de Kubernetes asociados con la aplicación) y los datos persistentes de una aplicación.</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">En este caso de uso, analizamos con detalle una canalización de promoción a producción que pone en marcha una nueva versión de una aplicación: Primero, a un entorno de almacenamiento provisional y, finalmente, a un entorno de producción. Este ejemplo se aplica de igual forma a los principales clouds públicos y también a un entorno local. Aunque mostramos el despliegue de una versión de la aplicación, la canalización también se puede utilizar con otras estrategias, como la implementación azul/verde o canaria. Como parte de la canalización de CI/CD, vamos a proteger la aplicación creando una copia de seguridad completa de la aplicación. Un backup coherente con las aplicaciones de la aplicación de producción y sus datos, estado y configuración pueden ser útiles para numerosos flujos de trabajo de DevOps.</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">DevOps con la arquitectura Astra de NetApp para el caso de uso 1</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">Kit de desarrollo de software Astra Control Python de NetApp</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">Se utilizó la aplicación para validar este caso de uso<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>, Una solución de comercio electrónico con un front-end basado en la web; una instancia de Elasticsearch para las funciones de búsqueda y análisis; y una base de datos MariaDB que realiza un seguimiento de todos los detalles del inventario de compras y las transacciones. Esta aplicación en contenedor se instaló en un clúster de Red Hat OpenShift. Cada pod de la aplicación usaba volúmenes persistentes para almacenar datos. Los volúmenes persistentes fueron creados automáticamente por NetApp Astra Trident, el orquestador de almacenamiento compatible con Container Storage Interface para Kubernetes que permite aprovisionar el almacenamiento en los sistemas de almacenamiento de NetApp. Además, para utilizar las funcionalidades de protección de aplicaciones de Astra Control Center, Astra Control gestiona esta aplicación, que se utiliza para activar los backups de aplicaciones que almacenaban el estado de la aplicación y los datos contenidos en volúmenes persistentes. Utilizamos la<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> Para automatizar el proceso de activación de backups de aplicaciones, que posteriormente se introdujo en una canalización de CI/CD. Esta canalización se creó y ejecutó utilizando una herramienta de CI/CD conocida llamada <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>] para automatizar el flujo para crear, proteger e implementar la aplicación.</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">Repasemos los requisitos previos y el procedimiento para introducir la protección en una canalización CI/CD.</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">Requisitos previos de validación de casos de uso</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">Se pusieron en marcha y configuraron como requisitos previos las siguientes herramientas o plataformas:</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="list-text">OpenShift Container Platform de Red Hat</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">Astra Trident de NetApp instalado en OpenShift con un back-end al sistema ONTAP de NetApp configurado</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">Se configuró un storagegrid predeterminado, que apunta al back-end ONTAP de NetApp</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">NetApp Astra Control Center instalado en un clúster OpenShift</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">OpenShift Cluster se ha agregado como un clúster gestionado a Astra Control Center</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins se ha instalado en un clúster de OpenShift y se ha configurado con un nodo de agente con un motor Docker instalado en él</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">Instalación de la aplicación</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">Comencemos por la instalación inicial de la aplicación en los entornos de configuración y producción. Para este caso de uso, este paso es un requisito previo, por lo que se realiza de forma manual. La canalización de CI/CD se utiliza para los flujos de trabajo posteriores de creación e implementación como resultado de las versiones nuevas de la aplicación.</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">El entorno de producción en este caso de uso es un espacio de nombres llamado<block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix=" " category="inline-code"></block>y el entorno de ensayo correspondiente es un espacio de nombres denominado<block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix=" " category="inline-code"></block> Configurado en el clúster de Red Hat OpenShift. Para aplicar la aplicación, realice los siguientes pasos:</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">Instale la aplicación Magento mediante el gráfico de timón de bitnami en el entorno de producción. Utilizamos RWX PVs para las vainas Magento y MariaDB.</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">La tabla de timón de Magento bitnami requiere un servicio LoadBalancer para exponer el servicio de GUI de Magento. Nosotros usamos <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> para proporcionar un servicio de equilibrador de carga en las instalaciones en este ejemplo.</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">Después de unos minutos, verifique que estén en ejecución todos los pods y servicios.</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">Repita el mismo procedimiento para el entorno de ensayo.</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Gestione la aplicación Magento en Astra Control Center</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">Desplácese a aplicaciones y seleccione la ficha aplicaciones detectadas.</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">Haga clic en los puntos suspensivos con la aplicación Magento en el entorno de producción <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>) Y haga clic en Administrar.</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">La aplicación Magento es ahora gestionada por Astra Control Center. Todas las operaciones compatibles con Astra Control se pueden realizar en la aplicación. Anote también la versión de la aplicación.</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">Comprobación de la versión de Magento antes de la actualización</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">Repita los pasos para administrar la aplicación Magento en el entorno de ensayo <block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix="(" category="inline-code"></block>).</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">Canalización de CI/CD con protección integrada</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">Cuando trabajamos con nuevas versiones de aplicaciones, utilizamos una canalización CI/CD para construir la imagen de contenedor, realizar backups tanto de los entornos de ensayo como de producción, implementar la nueva versión de la aplicación en el entorno de ensayo, esperar la aprobación de la promoción a la producción, a continuación, implemente la nueva versión de la aplicación en el entorno de producción. Para utilizar una canalización de CI/CD, lleve a cabo los siguientes pasos:</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Inicie sesión en Jenkins y cree las credenciales necesarias: Una para Magento creds, una para MariaDB admin creds y la tercera para MariaDB root creds.</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Desplácese hasta Manage Jenkins &gt; Manage Credentials y haga clic en el dominio adecuado.</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">Haga clic en Agregar credenciales y establezca el tipo en Nombre de usuario con contraseña y ámbito establecido en Global. Introduzca el nombre de usuario, la contraseña y el ID para las credenciales y haga clic en OK.</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">Cree credenciales</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">Repita el mismo procedimiento para las otras dos credenciales.</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">Vuelva a la consola, cree una canalización haciendo clic en Nuevo elemento y, a continuación, haga clic en canalización.</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Copie la canalización del archivo Jenkinsfile<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>.</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">Pegue la canalización en la sección de canalización Jenkins y, a continuación, haga clic en Guardar.</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Rellene los parámetros de la canalización Jenkins con los detalles respectivos, incluida la versión del gráfico del timón, la versión de la aplicación Magento a la que se va a actualizar, la versión del kit de herramientas de Astra, el FQDN de Astra Control Center, el token de API y su ID de instancia. Especifique el registro docker, el espacio de nombres y Magento IP tanto de los entornos de producción como de ensayo, y también especifique los identificadores de credenciales de las credenciales creadas.</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">Haga clic en Crear ahora. La canalización comienza a ejecutarse y avanza a lo largo de los pasos. La imagen de la aplicación se crea primero y se carga en el registro del contenedor.</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">Progreso de la canalización</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">Las copias de seguridad de aplicaciones se inician mediante Astra Control.</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">Backup iniciado</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">Una vez que las fases de copia de seguridad se hayan completado correctamente, compruebe las copias de seguridad desde Astra Control Center.</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">Backup realizado correctamente</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">A continuación, la nueva versión de la aplicación se implementa en el entorno de almacenamiento provisional.</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">Se inició la implementación de almacenamiento provisional</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">Una vez completado este paso, el programa espera a que el usuario apruebe la implementación a producción. En esta fase, suponga que el equipo de QA realiza algunas pruebas manuales y aprueba la producción. A continuación, puede hacer clic en aprobar para implementar la nueva versión de la aplicación en el entorno de producción.</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">Esperando promoción</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">Compruebe que la aplicación de producción también se ha actualizado a la versión deseada.</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">Prod App actualizada</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">Como parte de la canalización CI/CD, demostramos la capacidad para proteger la aplicación creando un backup completo compatible con aplicaciones. Dado que se ha realizado un backup de toda la aplicación como parte de la canalización de promoción a producción, puede sentirse más seguro de las puestas en marcha de aplicaciones altamente automatizadas. Este backup consciente de la aplicación que contiene los datos, el estado y la configuración de la aplicación puede ser útil para numerosos flujos de trabajo de DevOps. Un flujo de trabajo importante sería volver a la versión anterior de la aplicación en caso de problemas imprevistos.</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Aunque demostramos un flujo de trabajo CI/CD a través de la herramienta Jenkins, este concepto se puede extrapolar de forma sencilla y eficiente a distintas herramientas y estrategias. Para ver este caso de uso en acción, vea el vídeo <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>.</block>
  <block id="8b682694b3e16be71600ae19c5a6e2fe" category="doc">Aproveche Astra Control de NetApp para realizar análisis post mortem y restaurar su aplicación</block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">Siguiente: Información adicional: DevOps con NetApp Astra.</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="1c333560e2edbd1cefb05f127658b17f" category="doc">Protección de datos en canalización CI/CD con Astra Control Center</block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">Información adicional: DevOps con NetApp Astra</block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Documentación de rancher</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Documentación de Kubernetes</block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">Descripción general de devops y casos de uso potenciales en este informe técnico.</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">Información general de DevOps</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">A lo largo de los últimos años, las organizaciones que crean software han ido adoptando los conceptos de DevOps. Las prácticas de DevOps eliminan las barreras de la organización y acercan a los equipos de desarrollo y operaciones. Las prácticas de DevOps también permiten a los equipos acelerar la entrega, aumentar la disponibilidad y lograr que los servicios y las aplicaciones sean más estables; de este modo, se mejora la productividad del equipo. Además, la adopción de un marco de automatización también es una característica clave del éxito: Desde la creación, la prueba y el funcionamiento de aplicaciones a escala o la gestión de una plataforma o una pila de infraestructura completamente automatizada. A continuación comentamos algunos casos prácticos principales de DevOps en los que se pueden implementar las soluciones de NetApp para ayudar a mejorar las experiencias que los profesionales de DevOps encuentran durante su práctica diaria.</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">Casos de uso de DevOps</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">Aunque DevOps no tiene una definición única y universalmente aceptada, las soluciones para los practicantes de DevOps suelen contener construcciones o ideologías similares que permiten una implementación, repetición y gestión sencillas a escala. En las siguientes secciones se describen posibles casos de uso para los flujos de trabajo de DevOps que ofrecen las soluciones de NetApp.</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">Integración continua, entrega continua e implementación continua (CI/CD)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">Integración continua, entrega continua e implementación continua (CI/CD) es una filosofía de codificación que anima a los desarrolladores a implementar y transformar sus prácticas de codificación mediante el establecimiento de un método mediante el cual pueden actualizar, probar e implementar su código de manera automatizada y coherente. El método más popular por el que se implementa CI/CD en la mayoría de los flujos de trabajo de DevOps es el de la canalización de CI/CD y existen varias aplicaciones de software de terceros que pueden ayudar a conseguirlo.</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">Imagen de CI/CD</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">Consulte los siguientes ejemplos de aplicaciones conocidas que pueden ayudar con los flujos de trabajo de tipo CI/CD:</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ArgoCD</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">Tekton</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">Algunos de los casos de uso incluidos más adelante en este informe técnico se han demostrado en Jenkins, pero los principios fundamentales de CI/CD pueden aplicarse a cualquier herramienta que una organización haya implementado en sus propias prácticas.</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">Infraestructura como código</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">La infraestructura como código ayuda a aprovisionar y gestionar recursos TECNOLÓGICOS mediante comandos automatizados, API y kits de desarrollo de software (SDK). Este concepto mejora considerablemente la experiencia de DevOps al eliminar las limitaciones de recursos o centros de datos físicos que podrían impedir que los desarrolladores cumplieran sus objetivos.</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">Infraestructura como imagen de código</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">Puppet</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">Los usuarios finales suelen utilizar lenguajes de programación como<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> o herramientas de automatización como<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> o.<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> para crear acciones de escalado de infraestructura automatizadas y repetibles que pueden llamar los desarrolladores cuando sea necesario.</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">Tanto ONTAP de NetApp como Astra Control contienen API que se enfrentan al público y módulos de Ansible o kits de herramientas de desarrollo de software que facilitan la automatización de las operaciones y la integración en los procesos de DevOps.</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">Vídeos y demostraciones: DevOps con NetApp Astra</block>
  <block id="47a3fe612643a48831699e345fc50086" category="inline-link-macro">Vídeo: Integre la protección de datos en la canalización de CI/CD con Astra Control</block>
  <block id="b137de00495bfd71913e4fe2ecc2fbb5" category="list-text"><block ref="b137de00495bfd71913e4fe2ecc2fbb5" category="inline-link-macro-rx"></block></block>
  <block id="11a855b91bda336c24ae0014cf0b01aa" category="list-text"><block ref="11a855b91bda336c24ae0014cf0b01aa" category="inline-link-macro-rx"></block></block>
  <block id="760ebcab0161b35f2cbcee21a65a788a" category="list-text"><block ref="760ebcab0161b35f2cbcee21a65a788a" category="inline-link-macro-rx"></block></block>
  <block id="a7f77f303480f7b7143a247c228eaebb" category="doc">Acelere el desarrollo de software con Astra Control y la tecnología FlexClone de NetApp</block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">Utilice Astra Control para facilitar el análisis post mortem y restaurar la aplicación</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">primer caso de uso</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">En la <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>, Demostramos cómo usar Astra Control Center de NetApp para proteger sus aplicaciones en Kubernetes. En esa sección se describe cómo integrar los backups de aplicaciones a través de Astra Control directamente en su flujo de trabajo de desarrollo gracias al SDK de Python del kit de herramientas Astra de NetApp. Este enfoque permite la protección de los entornos de desarrollo y producción mediante la automatización de backups bajo demanda durante el proceso de integración continua y de implementación continua (CI/CD). Con esta capa adicional de protección de datos consistente con las aplicaciones añadida a la canalización CI/CD y a las aplicaciones de producción, los procesos de desarrollo son seguros si algo sale mal en el proceso, lo que promueve buenas prácticas de continuidad del negocio.</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">En un flujo de trabajo tradicional, después de haber encontrado un error cuando la aplicación se actualiza a una nueva versión, el equipo de desarrollo intentaría solucionar el problema en tiempo real a partir de los informes de errores que proporcionaban los clientes. Como alternativa, en el primer signo de problema, el equipo podría intentar volver a implementar la aplicación en un entorno de depuración paralelo para desconectar ese proceso. Podrían volver a poner en marcha una base de código anterior de una versión anterior a la producción, lo que restauraría la aplicación a la orden de trabajo.</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">Flujo de trabajo tradicional</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">Aunque este enfoque funciona, el equipo tendría que asegurarse de que el estado de la aplicación de producción rota coincide con el de la versión que se ve en producción cuando se produjeron los problemas. También tendrían que dedicar tiempo a la promoción de la producción de funcionalidad comprobada obteniendo código desde su repositorio y volviendo a poner en marcha las imágenes de la máquina para restaurar la aplicación a un estado en buen funcionamiento. Asimismo, en este escenario no se tuvo en cuenta si el código defectuoso corromía la base de datos de producción en sí. Lo ideal es que existan procesos de backup independientes para los datos de la base de datos, pero, ¿debemos asumir que son coherentes con el estado de la aplicación tal como se publicó? Aquí es donde las ventajas de los backups con estado y consistentes con las aplicaciones, las restauraciones y los clones con Astra Control realmente muestran su valor.</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">En primer lugar, podemos utilizar Astra Control para facilitar el análisis post mortem sobre el estado de la aplicación. Para ello, clonamos la versión de producción con buggy en un entorno de prueba paralelo con la aplicación. Tener este entorno separado en su estado de bugs-plot nos permite solucionar el problema en tiempo real.</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">Además, Astra Control admite la función de restauración in situ que nos permite restaurar la aplicación de producción a una última copia de seguridad aceptable (que precedió a la versión afligida del código). La versión restaurada asume la posición de la aplicación de producción de buggy anterior, de manera coherente con la aplicación y con estado, incluida la IP de entrada asignada previamente. Por lo tanto, los clientes que acceden al interfaz de usuario no tendrían conocimiento de la transición a la versión de backup.</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">Flujo de trabajo post mortem</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">OpenShift Container Platform de Red Hat.</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">Astra Trident de NetApp instalado en OpenShift con un back-end configurado para un sistema ONTAP de NetApp.</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">Se configuró un storagegrid predeterminado, que apunta al back-end ONTAP de NetApp.</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">NetApp Astra Control Center instalado en un clúster OpenShift.</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">OpenShift Cluster se ha agregado como un clúster gestionado a Astra Control Center.</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins se ha instalado en un clúster de OpenShift.</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">Aplicación Magento instalada en el entorno de producción. El entorno de producción en este caso de uso es un espacio de nombres llamado "evento-prod" en un clúster de Red Hat OpenShift.</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">Aplicación de producción gestionada por Astra Control Center.</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Backup(s) de funcionalidad comprobada de la aplicación de producción capturada con Astra Control.</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">Clonar y restaurar la canalización</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">Teniendo en cuenta que la aplicación se ha actualizado a una nueva versión, la aplicación del entorno de producción <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>) no se comporta como se pretende después de la actualización. Supongamos que los datos que devuelven las consultas de interfaz de usuario no coinciden con la solicitud o que la base de datos se ha dañado de hecho. Para clonar y restaurar la canalización, siga estos pasos:</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">Error de aplicación</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Inicie sesión en Jenkins y cree una canalización haciendo clic en Nuevo elemento y, a continuación, en canalización.</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Copie la canalización del archivo Jenkinsfile<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>.</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">Rellene los parámetros de la canalización Jenkins con los detalles respectivos, como la versión actual de la aplicación Magento en producción, el FQDN de Astra Control Center, el token de API, el ID de instancia y el nombre de aplicación o el espacio de nombres de los entornos de producción y depuración, y los nombres de los clústeres de origen y destino. Para este caso de uso, el entorno de producción es un espacio de nombres denominado "evento-prod" y el entorno de depuración es un espacio de nombres denominado "depuración" configurado en un clúster de Red Hat OpenShift.</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">Haga clic en Crear ahora. La canalización comienza a ejecutarse y avanza a lo largo de los pasos. La aplicación se clona primero en el estado actual en un entorno de depuración y, a continuación, se restaura a un backup de trabajo conocido.</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">Canalización post mortem</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">Compruebe que la aplicación clonada sea la versión que contiene errores.</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">Error al clonar la aplicación</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">Comprobar que el entorno de producción se ha restaurado en un backup en funcionamiento y que la aplicación en producción funciona de la forma esperada.</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">Prod App restaurada</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">Estas dos operaciones en tándem aceleran el retorno a las operaciones empresariales normales. Para ver este caso de uso en acción, vea el vídeo <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>.</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform unifica las operaciones DE desarrollo y TI en una única plataforma para crear, implementar y administrar aplicaciones de forma coherente en infraestructuras locales y de cloud híbrido. Red Hat OpenShift se basa en la innovación de código abierto y en estándares del sector, incluidos Kubernetes y Red Hat Enterprise Linux CoreOS, la distribución de Linux empresarial líder en el mundo diseñada para cargas de trabajo basadas en contenedores.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">Visión general de OpenShift</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform unifica las operaciones DE desarrollo y TI en una única plataforma para crear, implementar y administrar aplicaciones de forma coherente en infraestructuras locales y de cloud híbrido. Red Hat OpenShift se basa en la innovación de código abierto y en estándares del sector, incluidos Kubernetes y Red Hat Enterprise Linux CoreOS, la distribución de Linux empresarial líder en el mundo diseñada para cargas de trabajo basadas en contenedores. OpenShift forma parte del programa Kubernetes certificado Cloud Native Computing Foundation (CNCF) y proporciona portabilidad e interoperabilidad de cargas de trabajo de contenedores.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift ofrece las siguientes capacidades:</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">*Aprovisionamiento de autoservicio.* los desarrolladores pueden crear aplicaciones a petición rápida y fácilmente desde las herramientas que más utilizan, mientras que las operaciones mantienen un control total sobre todo el entorno.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">*Almacenamiento persistente.* al ofrecer compatibilidad para almacenamiento persistente, OpenShift Container Platform le permite ejecutar tanto aplicaciones con estado como aplicaciones sin estado nativas en la nube.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">*Integración continua y desarrollo continuo (CI/CD).* esta plataforma de código fuente gestiona las imágenes de creación e implementación a escala.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">*Estándares de código abierto.* estos estándares incorporan la Open Container Initiative (OCI) y Kubernetes para la orquestación de contenedores, además de otras tecnologías de código abierto. No se limita a la tecnología ni al mapa de ruta comercial de un proveedor específico.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">*Canalizaciones CI/CD.* OpenShift ofrece compatibilidad inmediata para canalizaciones CI/CD de modo que los equipos de desarrollo puedan automatizar cada paso del proceso de entrega de la aplicación y asegurarse de que se ejecuta en cada cambio que se realice en el código o la configuración de la aplicación.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">*Control de acceso basado en funciones (RBAC).* esta función proporciona seguimiento de equipo y usuario para ayudar a organizar un gran grupo de desarrolladores.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">*Compilación e implementación automatizada.* OpenShift ofrece a los desarrolladores la opción de crear sus aplicaciones en contenedor o hacer que la plataforma cree los contenedores a partir del código fuente de la aplicación o incluso de los binarios. Luego, la plataforma automatiza la puesta en marcha de estas aplicaciones en toda la infraestructura, en función de la característica definida para las aplicaciones. Por ejemplo, cómo se debe asignar la cantidad de recursos y dónde en la infraestructura que se deben implementar para que cumplan con las licencias de terceros.</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">*Entornos coherentes.* OpenShift garantiza que el entorno aprovisionado para desarrolladores y durante todo el ciclo de vida de la aplicación es coherente desde el sistema operativo hasta bibliotecas, versión en tiempo de ejecución (por ejemplo, Java Runtime), e incluso el tiempo de ejecución de la aplicación en uso (por ejemplo, tomcat) para eliminar los riesgos originados en entornos incoherentes.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">*Administración de la configuración.* la configuración y la gestión de datos confidenciales se integran en la plataforma para garantizar que se proporciona una configuración de aplicación coherente y que no dependa del entorno a la aplicación independientemente de qué tecnologías se utilicen para crear la aplicación o qué entorno se implementa.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">*Registros y métricas de aplicaciones.* la respuesta rápida es un aspecto importante del desarrollo de aplicaciones. La supervisión integrada y la administración de registros de OpenShift proporcionan a los desarrolladores métricas inmediatas para que estudien cómo se comporta la aplicación a lo largo de los cambios y puedan resolver problemas lo antes posible en el ciclo de vida de la aplicación.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">*Catálogo de contenedores y seguridad.* OpenShift ofrece multi-tenancy y protege al usuario de la ejecución de código perjudicial mediante el uso de la seguridad establecida con Security-Enhanced Linux (SELinux), CGroups y Secure Computing Mode (seccomp) para aislar y proteger contenedores. También proporciona cifrado mediante certificados TLS para los diversos subsistemas y acceso a contenedores certificados de Red Hat (access.redhat.com/containers) que se analizan y clasifican con un énfasis específico en la seguridad para proporcionar contenedores de aplicaciones certificados, de confianza y seguros a los usuarios finales.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Métodos de implementación para Red Hat OpenShift</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">A partir de Red Hat OpenShift 4, los métodos de implementación para OpenShift incluyen implementaciones manuales utilizando infraestructura aprovisionada por el usuario (UPI) para implementaciones altamente personalizadas o implementaciones totalmente automatizadas utilizando infraestructura aprovisionada por el instalador (IPI).</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">El método de instalación IPI es el método preferido en la mayoría de los casos porque permite la rápida implementación de clústeres OCP para entornos de desarrollo, prueba y producción.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Instalación IPI de Red Hat OpenShift</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">La implementación de la infraestructura aprovisionada del instalador (IPI) de OpenShift incluye estos pasos de alto nivel:</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">sitio web</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Visite Red Hat OpenShift<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> E inicie sesión con sus credenciales de SSO.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Seleccione el entorno en el que desea implementar Red Hat OpenShift.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">En la siguiente pantalla, descargue el instalador, el secreto único y las herramientas de CLI para realizar la gestión.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">Siga la<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Proporcionado por Red Hat para implementar en el entorno que usted elija.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">Implementaciones validadas de OpenShift de NetApp</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp ha probado y validado la implementación de Red Hat OpenShift en sus laboratorios mediante el método de implementación de Infraestructura aprovisionada por instalador (IPI) en cada uno de los siguientes entornos de centro de datos:</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">OpenShift en VMware vSphere</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Red Hat OpenShift. Trident funciona con toda la cartera de almacenamiento de NetApp, incluidos los sistemas de almacenamiento ONTAP y Element de NetApp, y también admite conexiones NFS e iSCSI. Trident acelera el flujo de trabajo de DevOps al permitir que los usuarios finales aprovisionen y gestionen el almacenamiento desde sus sistemas de almacenamiento de NetApp sin necesidad de intervención del administrador de almacenamiento.</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">La última versión de Astra Trident se lanzó en enero de 2022 en 22.01. Existe una matriz de compatibilidad con la versión de Trident probada en la que se puede encontrar la distribución de Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Descargue Astra Trident</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">Para instalar Trident en el clúster de usuarios implementado y aprovisionar un volumen persistente, complete los siguientes pasos:</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">Descargue el archivo de instalación en la estación de trabajo de administración y extraiga el contenido. La versión actual de Trident es la 22.01, que se puede descargar<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">Prepare los nodos de trabajo para el almacenamiento</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">La mayoría de las distribuciones de Kubernetes incluyen los paquetes y utilidades para montar los back-ends de NFS instalados de forma predeterminada, incluido Red Hat OpenShift.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">Sin embargo, para NFSv3, no hay ningún mecanismo para negociar la concurrencia entre el cliente y el servidor. Por ello, el número máximo de entradas de la tabla de ranuras sunrpc del lado del cliente debe sincronizarse manualmente con el valor compatible del servidor para garantizar el mejor rendimiento de la conexión NFS sin que el servidor tenga que reducir el tamaño de la ventana de la conexión.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">En el caso de ONTAP, el número máximo admitido de entradas de la tabla de ranuras de sunrpc es de 128, es decir, ONTAP puede atender 128 solicitudes de NFS simultáneas en un momento. Sin embargo, de forma predeterminada, Red Hat CoreOS/Red Hat Enterprise Linux tiene un máximo de 65,536 entradas de tabla de ranuras sunrpc por conexión. Tenemos que establecer este valor en 128 y esto se puede hacer usando el operador de configuración de máquina (MCO) en OpenShift.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">Para modificar el número máximo de entradas de la tabla de ranuras de sunrpc en los nodos de trabajo de OpenShift, realice los pasos siguientes:</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">Inicie sesión en la consola web de OCP y desplácese hasta Compute &gt; Machine Configs. Haga clic en Crear configuración de máquina. Copie y pegue el archivo YAML y haga clic en Crear.</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">Una vez creada la MCO, la configuración debe aplicarse a todos los nodos de trabajo y reiniciarse uno por uno. Todo el proceso tarda aproximadamente de 20 a 30 minutos. Compruebe si la configuración de la máquina se aplica mediante<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> y asegúrese de que el grupo de configuración de la máquina para los trabajadores esté actualizado.</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="section-title">ISCSI</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">Para preparar los nodos de trabajo y permitir la asignación de volúmenes de almacenamiento en bloques mediante el protocolo iSCSI, debe instalar los paquetes necesarios para que admitan dicha funcionalidad.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">En Red Hat OpenShift, esto se maneja aplicando una MCO (operador de configuración de máquina) a su clúster después de desplegarla.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">Para configurar los nodos de trabajo para que ejecuten servicios iSCSI, lleve a cabo los siguientes pasos:</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">Cuando no se utiliza el acceso múltiple:</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">Cuando se utiliza el acceso múltiple:</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">Una vez creada la configuración, se tarda entre 20 y 30 minutos aproximadamente en aplicar la configuración a los nodos de trabajo y volver a cargarlos. Compruebe si la configuración de la máquina se aplica mediante<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> y asegúrese de que el grupo de configuración de la máquina para los trabajadores esté actualizado. También puede iniciar sesión en los nodos de trabajo para confirmar que el servicio iscsid se está ejecutando (y el servicio multipathd se está ejecutando si se utiliza la función multivía).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">También es posible confirmar que MachineConfig se ha aplicado correctamente y que los servicios se han iniciado como se esperaba ejecutando el<block ref="5c237bbde25a8cf47cdca465191a6c1d" prefix=" " category="inline-code"></block> comando con los indicadores apropiados.</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Una vez finalizada la instalación del operador de Astra Trident, debe configurar el back-end para la plataforma de almacenamiento específica de NetApp que esté usando. Siga los siguientes enlaces para continuar con la instalación y configuración de Astra Trident.</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">ISCSI de NetApp Element</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Advanced Cluster Management para Kubernetes: Red Hat OpenShift con NetApp</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">A medida que una aplicación en contenedor pasa de desarrollo a producción, muchas organizaciones necesitan varios clústeres de Red Hat OpenShift para poder realizar las pruebas y la implementación de dicha aplicación. En conjunto con esto, las organizaciones suelen alojar varias aplicaciones o cargas de trabajo en clústeres OpenShift. Por lo tanto, cada organización acaba de gestionar un conjunto de clústeres, y los administradores de OpenShift deben afrontar, pues, el reto añadido de gestionar y mantener varios clústeres en una variedad de entornos que abarquen varios centros de datos locales y clouds públicos. Para hacer frente a estos retos, Red Hat ha presentado Advanced Cluster Management for Kubernetes.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Red Hat Advanced Cluster Management for Kubernetes le permite realizar las siguientes tareas:</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">Cree, importe y gestione varios clústeres en centros de datos y clouds públicos</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">Ponga en marcha y gestione aplicaciones o cargas de trabajo en varios clústeres desde una única consola</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">Supervisar y analizar el estado y el estado de diferentes recursos del clúster</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">Supervise e implemente el cumplimiento de normativas de seguridad en varios clústeres</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat Advanced Cluster Management for Kubernetes se instala como complemento de un clúster de Red Hat OpenShift y utiliza este clúster como controladora central para todas sus operaciones. Este clúster se conoce como clúster concentrador y expone un plano de administración para que los usuarios se conecten a la administración avanzada del clúster. Todos los demás clústeres de OpenShift que se importan o crean a través de la consola de Advanced Cluster Management son gestionados por el clúster de concentrador y se denominan clústeres administrados. Instala un agente llamado Klusterlet en los clústeres gestionados para conectarlos al clúster de concentradores y atender las solicitudes de diferentes actividades relacionadas con la gestión del ciclo de vida de los clústeres, la gestión del ciclo de vida de las aplicaciones, la capacidad de observación y el cumplimiento de la seguridad.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">Arquitectura de ACM</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">Para obtener más información, consulte la documentación<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">Siguiente: Requisitos previos de la implementación.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">Este documento de referencia proporciona la validación de la puesta en marcha de la solución Red Hat OpenShift, implementada a través de la infraestructura aprovisionada de Installer (IPI) en varios entornos de centros de datos diferentes, validados por NetApp. Además, se detalla la integración del almacenamiento con los sistemas de almacenamiento de NetApp, al utilizar el orquestador de almacenamiento Astra Trident para la gestión de almacenamiento persistente. Por último, se exploran y documentan una serie de validaciones de soluciones y casos de uso reales.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: Red Hat OpenShift con NetApp</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">La solución Red Hat OpenShift con NetApp se ha creado para ofrecer un valor excepcional a los clientes con los siguientes casos prácticos:</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">Fácil de poner en marcha y gestionar Red Hat OpenShift implementado mediante IPI (infraestructura aprovisionada por el instalador) en configuración básica, Red Hat OpenStack Platform, Red Hat Virtualization y VMware vSphere.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">Combinación de la potencia de los contenedores empresariales y las cargas de trabajo virtualizadas con Red Hat OpenShift implementado virtualmente en OSP, RHV o vSphere, o en bare metal con OpenShift Virtualization.</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">Casos de uso y configuración reales que destacan las funciones de Red Hat OpenShift cuando se utiliza con el almacenamiento de NetApp y Astra Trident, el orquestador de almacenamiento de código abierto para Kubernetes.</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">Red Hat OpenShift con NetApp reconoce estos retos y presenta una solución que le ayuda a abordar cada problema implementando la implementación totalmente automatizada de RedHat OpenShift IPI en el entorno de centro de datos que elija el cliente.</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">La solución Red Hat OpenShift con NetApp se compone de los siguientes componentes principales:</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Plataforma Red Hat OpenStack</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">Infraestructura de cloud privado</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Virtualización de Red Hat</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">Siguiente: Visión general de Red Hat OpenShift.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">Un clúster de Red Hat OpenShift (superior a la versión 4.5) para el clúster de concentrador</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">Clústeres de Red Hat OpenShift (superiores a la versión 4.4.3) para clústeres administrados</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Acceso de administrador de clúster al clúster de Red Hat OpenShift</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Una suscripción a Red Hat para Advanced Cluster Management para Kubernetes</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management es un complemento para el clúster OpenShift, por lo que existen ciertos requisitos y restricciones en los recursos de hardware basados en las funciones utilizadas en el concentrador y clústeres administrados. Debe tener en cuenta estos problemas al configurar los clústeres. Consulte la documentación<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> para obtener más detalles.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">De manera opcional, si el clúster de concentrador tiene nodos dedicados para alojar componentes de infraestructura y desea instalar recursos de Advanced Cluster Management solo en esos nodos, deberá añadir toleraciones y selectores a esos nodos según corresponda. Para obtener más detalles, consulte la documentación de<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">Siguiente: Instalación.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">Para restaurar una aplicación, desplácese a la ficha aplicaciones &gt; gestionadas y haga clic en la aplicación en cuestión. Haga clic en el menú desplegable junto al nombre de la aplicación y haga clic en<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block>.</block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">Introduzca los detalles del nuevo espacio de nombres, seleccione el clúster al que desea clonarlo y elija si desea clonarlo desde una copia de Snapshot existente o un backup o el estado actual de la aplicación. A continuación, haga clic en Siguiente y en Clonar en el panel de revisión una vez que haya revisado los detalles.</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">Las soluciones de contenedores de NetApp son puestas en marcha validadas de muchos de los orquestadores de contenedores basados en Kubernetes más populares y su integración con los sistemas y el software de gestión del almacenamiento de NetApp.</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">Soluciones de contenedor de NetApp</block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">Anthos con configuraciones básicas de NetApp proporciona una plataforma robusta para ejecutar cargas de trabajo basadas en contenedores de manera eficiente al permitir la personalización de la infraestructura puesta en marcha.</block>
  <block id="65ffe919dd9568cce4454508d8e543bd" category="paragraph">Anthos con configuraciones básicas de NetApp proporciona una plataforma robusta para ejecutar cargas de trabajo basadas en contenedores de manera eficiente al permitir la personalización de la infraestructura puesta en marcha. Los clientes pueden utilizar la infraestructura de servidor y el sistema operativo compatible de su elección o incluso poner en marcha la solución dentro de su infraestructura existente. La potencia y la flexibilidad de estos entornos aumentan enormemente gracias a la integración de ONTAP de NetApp y Astra Trident de NetApp, que admiten cargas de trabajo de aplicaciones con estado mediante el aprovisionamiento y la gestión eficientes del almacenamiento persistente para contenedores. Al ampliar el potencial de Google Cloud a su centro de datos con tecnología de NetApp, un cliente puede conocer las ventajas de una solución de Kubernetes totalmente compatible, de alta disponibilidad, fácilmente escalable y totalmente gestionada para el desarrollo y la producción de las cargas de trabajo de sus aplicaciones.</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">AFF de NetApp es una sólida plataforma de almacenamiento all-flash que proporciona un rendimiento de baja latencia, protección de datos integrada, compatibilidad multiprotocolo y operaciones no disruptivas. Con la tecnología del software para la gestión de datos ONTAP de NetApp, AFF de NetApp garantiza operaciones no disruptivas, desde el mantenimiento a las actualizaciones hasta la sustitución completa de su sistema de almacenamiento.</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">ONTAP de NetApp en AFF/FAS de NetApp</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">*FlexClone de NetApp* proporciona el aprovisionamiento instantáneo de una copia totalmente legible y modificable de un volumen NetApp en función de una copia snapshot. Para obtener más información acerca de ONTAP, consulte<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a5e993e443aa30456050e2589b6e1a7" category="paragraph">Astra Trident de NetApp es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Google Cloud Anthos. Funciona con toda la cartera de almacenamiento de NetApp, incluido el software ONTAP de NetApp. Trident es totalmente compatible con CSI y acelera el flujo de trabajo de DevOps al permitirle aprovisionar y gestionar el almacenamiento de sus sistemas de almacenamiento de NetApp sin que sea necesaria la intervención de un administrador de almacenamiento. Trident se pone en marcha como operador que se comunica directamente con el extremo de la API de Kubernetes para atender solicitudes de almacenamiento de contenedores en forma de reclamaciones de volúmenes persistentes (RVP) mediante la creación y la gestión de volúmenes en el sistema de almacenamiento de NetApp.</block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">Los volúmenes persistentes (VP) se aprovisionan en función de las clases de almacenamiento definidas en el entorno de Kubernetes. Utilizan back-ends de almacenamiento creados por un administrador de almacenamiento (que se puede personalizar en función de las necesidades de los proyectos) y modelos de sistema de almacenamiento para permitir cualquier número de funciones de almacenamiento avanzadas, como compresión, tipos de disco específicos o niveles de calidad de servicio que garantizan el rendimiento.</block>
  <block id="eb3bc37ad07db70234f55e02bb4fa499" category="paragraph">Si quiere más información sobre Astra Trident de NetApp, consulte<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> página.</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident orquesta el almacenamiento de cada sistema y servicio de la cartera de NetApp.</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="section-title">Anthos de Google Cloud</block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Anthos de Google Cloud es una solución de centro de datos de Kubernetes basada en cloud que permite a las organizaciones crear y gestionar infraestructuras de cloud híbrido modernas a la vez que adoptan flujos de trabajo ágiles centrados en el desarrollo de aplicaciones. Anthos en bare metal amplía la funcionalidad de Anthos para ejecutarse directamente en las instalaciones en servidores físicos sin una capa de hipervisor e interopera con los clústeres Anthos GKE en Google Cloud.</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">Adoptar contenedores, malla de servicios y otras tecnologías para la transformación permiten a las organizaciones experimentar ciclos de desarrollo de aplicaciones consistentes y cargas de trabajo preparadas para la producción en entornos locales y basados en cloud.</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">*Google Cloud Marketplace para aplicaciones Kubernetes.* un catálogo de aplicaciones de contenedor curadas disponible para una fácil implementación.</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">*Migración para Anthos.* migración automática de servicios físicos y máquinas virtuales de las instalaciones al cloud. En la figura 3 se muestra la solución Anthos y cómo una puesta en marcha en una interconexión del centro de datos local con la infraestructura en el cloud.</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Sitio web de Anthos</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Para obtener más información sobre Anthos, consulte<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>.</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">La siguiente figura presenta la arquitectura Anthos de Google Cloud.</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">Anthos en bare metal es una extensión de GKE que se implementa en el centro de datos privado de un cliente. Una organización puede poner en marcha las mismas aplicaciones diseñadas para ejecutarse en contenedores en Google Cloud en clústeres Anthos en las instalaciones. Anthos se ejecuta directamente en servidores físicos con el sistema operativo subyacente Linux que el usuario elija y proporciona a los clientes un entorno de cloud híbrido completo con la capacidad de funcionar en el núcleo o la periferia de sus centros de datos.</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">Anthos en bare metal ofrece las siguientes ventajas:</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">*Agnóstico de hardware.* los clientes pueden ejecutar Anthos en su elección de plataforma de hardware optimizada en sus centros de datos existentes.</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">*Ahorro de costes.* puede obtener un ahorro significativo utilizando sus propios recursos físicos para implementaciones de aplicaciones en lugar de aprovisionar recursos en el entorno de Google Cloud.</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">*Desarrollar después publicar.* puede utilizar implementaciones locales mientras las aplicaciones están en desarrollo, lo que permite la prueba de aplicaciones en la privacidad de su centro de datos local antes de que estén disponibles públicamente en la nube.</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">*Mejor rendimiento.* las aplicaciones intensivas que requieren baja latencia y los niveles más altos de rendimiento pueden ejecutarse más cerca del hardware.</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">*Gestión y operaciones.* Anthos en bare metal viene con una amplia gama de instalaciones que aumentan la eficiencia operativa, como redes integradas, gestión del ciclo de vida, diagnósticos, comprobaciones de estado, registro, y supervisión.</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">Siguiente: Requisitos de la solución.</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">Para la validación inicial de esta solución, NetApp se asoció con World Wide Technology (WWT) para establecer un entorno en Advanced Technology Center (ATC) de WWT. Anthos se puso en marcha en una infraestructura de configuración básica con la herramienta bmctl proporcionada por Google Cloud. La siguiente sección detalla la puesta en marcha utilizada para fines de validación.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">Resumen de la implementación</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">Anthos con la solución de reconstrucción completa de NetApp se ha creado como un clúster híbrido de alta disponibilidad con tres nodos de plano de control de Anthos y cuatro nodos de trabajo de Anthos.</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">Los nodos de plano de control utilizados fueron servidores blade Cisco UCS B200M3 alojados en un chasis y configurados con una única tarjeta de interfaz de red virtual (VNIC) en cada uno, lo que permitió la recuperación tras fallos A/B en el nivel de plataforma Cisco UCS para la tolerancia a fallos. El chasis de Cisco UCS se conectó de forma ascendente a un par de interconexiones de estructura Cisco UCS 6248, lo que proporciona rutas dispares para la separación del tráfico a lo largo de la estructura A y la estructura B. Esas interconexiones de estructura se conectan antes de un par de switches de centros de datos Cisco Nexus 5548 que estaban conectados a la red principal de WWT.</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">Los nodos de trabajo eran nodos HP ProLiant DL360, cada uno de los cuales ejecutaba una de las distribuciones de Linux compatibles para Anthos en metal desnudo: Red Hat Enterprise Linux 8.2, CentOS 8.2, Ubuntu 20.04 LTS o Ubuntu 18.04 LTS. Los nodos Red Hat Enterprise Linux 8 y CentOS 8 se configuraron con equipos NIC ejecutándose en modo LACP y se cablearon a dos switches Nexus 9k C93180YC-FX para tolerancia a fallos. Los servidores Ubuntu se configuraron para el enlace de red en modo LACP y se cableó a la misma pareja de switches Nexus 9k para la tolerancia a fallos.</block>
  <block id="4ed7e16612fd7090efc8d89c68421b74" category="paragraph">Se instaló y conectó físicamente el sistema de almacenamiento AFF A300 de NetApp con el software ONTAP 9.7 al mismo par de switches Nexus 9k que los nodos de trabajo Anthos. Estos enlaces ascendentes de redes se agregaron a un grupo de interfaces (a0a) y se etiquetó la VLAN de red de datos adecuada para permitir que los nodos de trabajo interactúen con el sistema de almacenamiento. Se creó una máquina virtual de almacenamiento (SVM) con LIF de datos que admiten el protocolo NFS y operaciones de almacenamiento dedicadas para Trident a fin de proporcionar almacenamiento persistente a los contenedores puestos en marcha en Anthos en un clúster de configuración básica. Estos volúmenes persistentes fueron proporcionados por Astra Trident 20.10 de NetApp, la versión más reciente del orquestador de almacenamiento de código abierto de NetApp para Kubernetes totalmente compatible.</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">En la siguiente figura se muestra un diagrama de cableado físico de la solución a la parte superior de los switches de centros de datos en rack.</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">En la siguiente figura, se presenta una visión lógica de la solución tal como se pone en marcha y se valida en el hardware del laboratorio en el WWT, partner de NetApp.</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">Siguiente: Validación de la solución.</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="c8a326f53d0d33a113452a303c243987" category="summary">NetApp y Google Cloud han mantenido una sólida relación desde hace varios años, con la primera introducción de servicios de datos en el cloud en Google Cloud con Cloud Volumes ONTAP y Cloud Volumes Service. Esta relación se amplió después mediante la validación de la plataforma NetApp HCI para su uso con Google Cloud Anthos en las instalaciones, una solución Kubernetes híbrida basada en hipervisores y basada en hipervisores puesta en marcha en VMware vSphere. A continuación, NetApp superó la cualificación Anthos preparada para NetApp Astra Trident, ONTAP y el protocolo NFS para proporcionar almacenamiento persistente dinámico para contenedores.</block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337: Anthos en Bare Metal</block>
  <block id="f989491ea62ea4778f84ec6b21a68adf" category="paragraph">NetApp y Google Cloud han mantenido una sólida relación desde hace varios años, con la primera introducción de servicios de datos en el cloud para Google Cloud con Cloud Volumes ONTAP y Cloud Volumes Service. Esta relación se amplió después mediante la validación de la plataforma NetApp HCI para su uso con Google Cloud Anthos en las instalaciones, una solución Kubernetes híbrida basada en hipervisores y basada en hipervisores puesta en marcha en VMware vSphere. A continuación, NetApp superó la cualificación Anthos preparada para NetApp Astra Trident, ONTAP y el protocolo NFS para proporcionar almacenamiento persistente dinámico para contenedores.</block>
  <block id="1349318f8c0f3a02420c7453ca5cda7d" category="paragraph">Anthos puede instalarse ahora directamente en servidores con configuración básica en el entorno de un cliente, lo que agrega una opción adicional para que los clientes puedan ampliar Google Cloud a sus centros de datos locales sin un hipervisor. Además, al aprovechar las funcionalidades del sistema operativo de almacenamiento ONTAP de NetApp y Astra Trident de NetApp, puede ampliar sus funciones mediante la integración del almacenamiento persistente para contenedores.</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">Esta combinación le permite aprovechar todo el potencial de sus servidores, almacenamiento y red, en combinación con el soporte, los niveles de servicio, la facturación mensual y la flexibilidad bajo demanda que proporciona Google Cloud. Dado que utiliza su propio hardware, red y almacenamiento, dispone de control directo sobre la escala de las aplicaciones, la seguridad y la latencia de la red, así como de la ventaja de las aplicaciones gestionadas y en contenedores con Anthos en entornos bare metal.</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">Siguiente: Descripción general de la solución.</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="d7b2cdc877c7db996d45c651b4e7834a" category="paragraph">Este documento describe la configuración y la validación de la plataforma de almacenamiento ONTAP de NetApp con Anthos de Google Cloud en una plataforma bare metal con el orquestador de almacenamiento de código abierto Astra Trident de NetApp, el orquestador de almacenamiento de código abierto para Kubernetes, para poner en marcha y gestionar el almacenamiento persistente para contenedores de aplicaciones con estado.</block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">Las funcionalidades que no dependen del hardware de Anthos en configuraciones básicas le permiten seleccionar una plataforma informática optimizada para su caso de uso. Por lo tanto, puede adaptarse a su infraestructura actual y reducir los gastos de capital.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">Requisitos de la solución</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">Computación: Traiga su propio servidor</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">Las funcionalidades que no dependen del hardware de Anthos en configuraciones básicas le permiten seleccionar una plataforma de computación optimizada para su caso de uso. Por lo tanto, puede adaptarse a su infraestructura actual y reducir los gastos de capital.</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">En la siguiente tabla se muestra el número mínimo de componentes de hardware de computación necesarios para implementar esta solución, aunque los modelos de hardware utilizados pueden variar en función de los requisitos del cliente.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">Uso</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">Hardware y modelo</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">Nodos de administración</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">Nodos de trabajo</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">Almacenamiento: ONTAP de NetApp</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">En la siguiente tabla se muestra el número mínimo de componentes de hardware de almacenamiento necesarios para implementar la solución, aunque los modelos de hardware utilizados pueden variar en función de los requisitos del cliente.</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">AFF de NetApp</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">AFF A300 de NetApp</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 (1 par de alta disponibilidad)</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">Las versiones de software identificadas en la siguiente tabla fueron utilizadas por NetApp y nuestros partners para validar la solución con NetApp, aunque los componentes de software utilizados pueden variar en función de los requisitos del cliente.</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">So para 3 administradores</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Os en Worker4</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Os en Worker3</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Os en Worker2</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Os en Worker1</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">El sistema operativo de almacenamiento</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Gestión del almacenamiento de contenedores</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">Este entorno de varios SO muestra la interoperabilidad con versiones de SO compatibles de la solución Anthos en bare metal. Anticipamos que los clientes estandarizarán uno o un subconjunto de sistemas operativos para su puesta en marcha.</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Anthos en documentación de configuración básica</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">Para ver Anthos en requisitos de hardware y software de configuración básica, consulte<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> página.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">Siguiente: Resumen de la implementación.</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">Centro de documentación de ONTAP de NetApp</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">La puesta en marcha actual de esta solución se realizó mediante dos rigurosos procesos de validación mediante herramientas proporcionadas por el equipo de Google Cloud.</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">Validación de la solución</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">La puesta en marcha actual de esta solución se realizó mediante dos rigurosos procesos de validación mediante herramientas proporcionadas por el equipo de Google Cloud. Estas validaciones incluyen un subconjunto de las siguientes pruebas:</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Validación por parte del partner de la plataforma lista para Anthos:</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">Confirme que todos los servicios de Anthos en plataformas con configuración básica están instalados y en funcionamiento.</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">Escale el Anthos físico en un clúster de configuración básica de cuatro nodos de trabajo a tres y, a continuación, vuelva a cuatro.</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">Crear y eliminar un espacio de nombres personalizado.</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Cree una implementación del servidor web Nginx, escalando dicha implementación aumentando el número de réplicas.</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Cree una entrada para la aplicación Nginx y verifique la conectividad mediante el curling index.html.</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">Limpiar correctamente todas las actividades del conjunto de pruebas y devolver el clúster a un estado de prueba previa.</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Validación por parte del partner del almacenamiento preparado para Anthos:</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">Cree una implementación con una reclamación de volumen persistente.</block>
  <block id="2b9593caebc55ca069d98dcb7a3473c8" category="list-text">Utilice Astra Trident de NetApp para aprovisionar y adjuntar el volumen persistente solicitado de ONTAP de NetApp.</block>
  <block id="c0724935c9b9fa3acfd0441317cac5e4" category="list-text">Valide la capacidad de desvincular y volver a asociar volúmenes persistentes.</block>
  <block id="05053a6eeca3d00f1ffdaead4d65118f" category="list-text">Validar el acceso para múltiples conexiones y solo lectura de volúmenes persistentes desde otros pods del nodo.</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">Validar la operación de cambio de tamaño de volumen sin conexión.</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">Compruebe que el volumen persistente sobrevive a una operación de escalado de clúster.</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">Esta sección proporciona los pasos para poner en marcha una canalización de integración continua y de entrega o implementación continua con Jenkins para validar el funcionamiento de la solución.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">Implemente una canalización CI/CD de Jenkins con almacenamiento persistente: Red Hat OpenShift con NetApp</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">En esta sección se proporcionan los pasos para poner en marcha una canalización de integración/entrega continua o de puesta en marcha (CI/CD) con Jenkins para validar el funcionamiento de la solución.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Cree los recursos necesarios para la implementación de Jenkins</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Para crear los recursos necesarios para implementar la aplicación Jenkins, realice los siguientes pasos:</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Cree un nuevo proyecto denominado Jenkins.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">En este ejemplo, hemos puesto en marcha Jenkins con almacenamiento persistente. Para respaldar la compilación de Jenkins, cree la RVP. Desplácese hasta almacenamiento &gt; reclamaciones de volumen persistente y haga clic en Crear solicitud de volumen persistente. Seleccione la clase de almacenamiento que se creó, asegúrese de que el nombre de reclamación de volumen persistente es jenkins, seleccione el tamaño adecuado y el modo de acceso y, a continuación, haga clic en Create.</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">Ponga en marcha Jenkins con almacenamiento persistente</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">Para poner en marcha Jenkins con almacenamiento persistente, realice los siguientes pasos:</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">En la esquina superior izquierda, cambie la función de Administrador a Programador. Haga clic en +Agregar y seleccione de Catálogo. En la barra Filtrar por palabra clave, busque jenkins. Seleccione Jenkins Service with persistent Storage.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">Haga clic en<block ref="42dcbbaa226af66223d0680206ea8547" prefix=" " category="inline-code"></block>.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">De forma predeterminada, se completan los detalles de la aplicación Jenkins. En función de sus requisitos, modifique los parámetros y haga clic en Crear. Este proceso crea todos los recursos necesarios para soportar Jenkins en OpenShift.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Los POD de Jenkins tardan aproximadamente de 10 a 12 minutos en introducir el estado Listo.</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">Después de crear una instancia de los POD, desplácese a Networking &gt; Routes. Para abrir la página web de Jenkins, haga clic en la dirección URL proporcionada para la ruta de jenkins.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Puesto que se utilizó OpenShift OAuth durante la creación de la aplicación Jenkins, haga clic en Iniciar sesión con OpenShift.</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Autorice a la cuenta de servicio de Jenkins a acceder a los usuarios de OpenShift.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Aparece la página de bienvenida de Jenkins. Debido a que estamos utilizando un Maven Build, complete la instalación de Maven primero. Desplácese hasta Manage Jenkins &gt; Global Tool Configuration y, a continuación, en el subtítulo de Maven, haga clic en Add Maven. Introduzca el nombre que desee y asegúrese de que la opción instalar automáticamente está seleccionada. Haga clic en Guardar.</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">Ahora puede crear una canalización para demostrar el flujo de trabajo de CI/CD. En la página de inicio, haga clic en Crear nuevos trabajos o Nuevo elemento en el menú de la izquierda.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">En la página Create Item, introduzca el nombre que desee, seleccione Pipeline y haga clic en OK.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Seleccione la pestaña canalización. En el menú desplegable probar canalización de muestra, seleccione Github + Maven. El código se rellena automáticamente. Haga clic en Guardar.</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">Haga clic en generar ahora para activar el desarrollo a través de la fase de preparación, creación y prueba. Puede tardar varios minutos en completar todo el proceso de compilación y mostrar los resultados del desarrollo.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">Siempre que haya cambios en el código, la canalización se puede reconstruir para revisar la nueva versión del software permitiendo una integración continua y entrega continua. Haga clic en cambios recientes para realizar un seguimiento de los cambios de la versión anterior.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">Escala: Agregar más proyectos</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">En una configuración multitenant, agregar nuevos proyectos con recursos de almacenamiento requiere una configuración adicional para asegurarse de que no se infringe la multi-tenancy. Para agregar más proyectos en un clúster multitenant, realice los siguientes pasos:</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">Inicie sesión en el clúster de ONTAP de NetApp como administrador de almacenamiento.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">Vaya a.<block ref="ba7ff8660fabd8daa8e7fbd0c74dd990" prefix=" " category="inline-code"></block> y haga clic en<block ref="ec211f7c20af43e742bf2570c3cb84f9" prefix=" " category="inline-code"></block>. Cree una nueva SVM dedicada al proyecto-3. Además, cree una cuenta de vsadmin para gestionar la SVM y sus recursos.</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">Cree una SVM para el escalado</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Inicie sesión en el clúster de Red Hat OpenShift como administrador de clúster.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">Cree un proyecto nuevo.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">Asegúrese de que el grupo de usuarios para project-3 se crea en IDP y se sincroniza con el clúster OpenShift.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">Cree el rol de desarrollador para el proyecto-3.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">La definición de rol proporcionada en esta sección es sólo un ejemplo. La función de desarrollador debe definirse en función de los requisitos del usuario final.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">Crear RoleBinding para desarrolladores en el proyecto-3 enlazar el rol de desarrollador-proyecto-3 al grupo correspondiente (ocp-proyecto-3) en el proyecto-3.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Inicie sesión en el clúster Red Hat OpenShift como administrador de almacenamiento</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Cree un back-end de Trident y asígnelo al SVM dedicado al proyecto-3. NetApp recomienda utilizar la cuenta vsadmin de la SVM para conectar el back-end a la SVM en lugar de utilizar el administrador del clúster de ONTAP.</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">En este ejemplo, estamos usando el controlador ontap-nas. Utilice el controlador apropiado para crear el backend basado en el caso de uso.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Asumimos que Trident se instala en el proyecto trident.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">Cree la clase de almacenamiento para el proyecto-3 y configúrela para que utilice los pools de almacenamiento desde back-end dedicado al proyecto-3.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">Cree un ResourceQuota para restringir los recursos del proyecto-3 solicitando almacenamiento de storagegrid dedicado a otros proyectos.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">Aplicar un parche a ResourceQuotas en otros proyectos para restringir el acceso de los recursos de dichos proyectos al almacenamiento desde storageeclass dedicado al proyecto 3.</block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">Configuración</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">Para cualquier solución multitenant, ningún usuario puede tener acceso a más recursos del clúster de los que necesita. Por lo tanto, todo el conjunto de recursos que se van a configurar como parte de la configuración de multi-tenancy se divide entre cluster-admin, Storage-admin y los desarrolladores que trabajan en cada proyecto.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">En la siguiente tabla se describen las distintas tareas que deben realizar los distintos usuarios:</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Función</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">Tareas</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">*Cluster-admin*</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">Crear proyectos para distintas aplicaciones o cargas de trabajo</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">Cree ClusterRoles y RoleBindings para Storage-admin</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">Cree funciones y RoleBindings para los desarrolladores que asignan acceso a proyectos específicos</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[Opcional] Configure proyectos para programar pods en nodos específicos</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">*Storage-admin*</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">Creación de SVM en ONTAP de NetApp</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Cree los back-ends de Trident</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">Cree clases de almacenamiento</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">Cree el recurso Quotas de almacenamiento</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">*Desarrolladores*</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">Validar el acceso para crear o revisar CVP o pods en el proyecto asignado</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">Validar el acceso para crear o revisar CVP o pods en otro proyecto</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">Valide el acceso para ver o editar proyectos, ResourceQuotas y StorageClasses</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">Siguiente: Requisitos previos.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">*VMware vSphere vMotion.* VMware vCenter le permite migrar en caliente equipos virtuales entre nodos del clúster a petición de forma no disruptiva.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">*Alta disponibilidad de vSphere.* para evitar interrupciones en caso de fallos de host, VMware vSphere permite agrupar y configurar los hosts para alta disponibilidad. Las máquinas virtuales que son interrumpidas por un error de host se reinician en breve en otros hosts del clúster, restaurando los servicios.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">La solución Red Hat OpenShift en NetApp utiliza dos switches de datos para proporcionar conectividad de datos principal a 25 Gbps. También usa dos switches de gestión adicionales que proporcionan conectividad a 1 Gbps para la gestión en banda de los nodos de almacenamiento y la gestión fuera de banda para la funcionalidad de IPMI. OCP utiliza la red lógica de equipos virtuales en VMware vSphere para la gestión de clústeres. En esta sección se describe la disposición y el propósito de cada segmento de red virtual utilizado en la solución y se describen los requisitos previos para la implementación de la solución.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">Red Hat OpenShift en VMware vSphere se ha diseñado para separar de forma lógica el tráfico de red para distintos fines mediante redes de área local virtual (VLAN). Esta configuración se puede ampliar para satisfacer las demandas del cliente o para proporcionar un aislamiento adicional para servicios de red específicos. La siguiente tabla enumera las VLAN necesarias para implementar la solución mientras valida la solución en NetApp.</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">Red de almacenamiento para NFS de ONTAP</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">Red de almacenamiento para iSCSI de ONTAP</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">Gestión para nodos ESXi, vCenter Server y ONTAP Select</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">Implemente OpenShift en un clúster ESXi de al menos tres nodos</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">La arquitectura verificada que se describe en este documento presenta la puesta en marcha de hardware mínima adecuada para las operaciones de alta disponibilidad al poner en marcha dos nodos de hipervisor ESXi y garantizar una configuración con tolerancia a fallos al habilitar VMware vSphere ha y VMware vMotion. Esta configuración permite migrar máquinas virtuales implementadas entre los dos hipervisores y el reinicio en caso de que un host deje de estar disponible.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Puesto que Red Hat OpenShift se implementa inicialmente con tres nodos maestros, al menos dos maestros de una configuración de dos nodos pueden ocupar el mismo nodo en determinadas circunstancias, lo que puede provocar una posible interrupción en OpenShift si ese nodo específico deja de estar disponible. Por lo tanto, es una práctica recomendada de Red Hat que debe poner en marcha al menos tres nodos de hipervisor ESXi para que los maestros de OpenShift se puedan distribuir de forma uniforme, lo que proporciona un grado añadido de tolerancia a fallos.</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">Para garantizar la distribución de los maestros de OpenShift en varios nodos de hipervisor, se puede lograr activando la afinidad entre equipos virtuales y hosts.</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">Para configurar grupos de afinidad, consulte<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift instalación de un clúster en vSphere con personalizaciones</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">En estas instancias, puede ejecutar y efectuar las tareas del asistente sin implementar inmediatamente un clúster, pero en su lugar, el asistente crea un archivo de configuración a partir del cual se puede implementar el clúster más adelante. Esto es muy útil si necesita cambiar cualquier valor predeterminado de IPI o si desea implementar varios clústeres idénticos en su entorno para otros usos como multi-tenancy. Para obtener más información acerca de cómo crear una configuración de instalación personalizada para OpenShift, consulte<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">Validación</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">Para validar la arquitectura multi-tenant configurada en los pasos anteriores, realice los siguientes pasos:</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">Validar el acceso para crear RVP o pods en el proyecto asignado</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">Inicie sesión como ocp-project-1-usuario, desarrollador en proyecto-1.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">Compruebe el acceso para crear un proyecto nuevo.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">Cree un PVC en el proyecto-1 utilizando el storagegrid que está asignado al proyecto-1.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">Compruebe el VP asociado a la RVP.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">Validar que el VP y su volumen se crean en una SVM dedicada al proyecto-1 en ONTAP de NetApp.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">Cree un pod en el proyecto-1 y monte el PVC creado en el paso anterior.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">Compruebe si el pod está en ejecución y si montó el volumen.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">Validar el acceso para crear RVP o pods en otro proyecto o utilizar recursos dedicados a otro proyecto</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">Cree un PVC en el proyecto-1 utilizando el storagegrid que está asignado al proyecto-2.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">Cree un PVC en el proyecto-2.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">Asegúrese de que las EVs<block ref="1ff946dbad16e896f78812f54d491d28" prefix=" " category="inline-code"></block> y..<block ref="146dc2badf14b242d7e386acd7f9b2aa" prefix=" " category="inline-code"></block> no se han creado.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">Cree un pod en el proyecto-2.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">Valide el acceso para ver y editar proyectos, ResourceQuotas y StorageClasses</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">Compruebe el acceso para crear nuevos proyectos.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">Validar el acceso para ver los proyectos.</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">Compruebe si el usuario puede ver o editar ResourceQuotas en project-1.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">Valide que el usuario tiene acceso para ver storagegrid.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">Compruebe el acceso para describir storagegrid.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">Valide el acceso del usuario para editar storagegrid.</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">Siguiente: Escalado.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">Cree recursos en varios clústeres</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Advanced Cluster Management para Kubernetes permite a los usuarios crear recursos en uno o varios clústeres gestionados simultáneamente desde la consola. Por ejemplo, si tiene clústeres de OpenShift en diferentes sitios respaldados por distintos clústeres de ONTAP de NetApp y desea aprovisionar PVC en ambos sitios, puede hacer clic en el inicio de sesión (+) en la barra superior. A continuación, seleccione los clústeres en los que desea crear el PVC, pegue el recurso YAML y haga clic en Create.</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">Crear recursos</block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Crear una máquina virtual desde una snapshot</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Con Astra Trident y Red Hat OpenShift, los usuarios pueden hacer una copia Snapshot de un volumen persistente en las clases de almacenamiento que aprovisiona. Con esta función, los usuarios pueden tomar una copia de un momento específico de un volumen y usarla para crear un nuevo volumen o restaurar el mismo volumen de vuelta a un estado anterior. Esto permite o admite una serie de casos prácticos, desde la reversión a clones y la restauración de datos.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">Para las operaciones de Snapshot en OpenShift, se deben definir los recursos VolumeSnapshotClass, VolumeSnapshot y VolumeSnapshotContent.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">Una copia de Snapshot de VolumeSnapshotContent es la copia de Snapshot real que se toma de un volumen del clúster. Es un recurso para todo el clúster análogo al volumen persistente para almacenamiento.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">Una copia Snapshot de volumen es una solicitud para crear la copia Snapshot de un volumen. Es análogo a una reclamación de volumen persistente.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass permite que el administrador especifique diferentes atributos para una copia VolumeSnapshot. Permite tener distintos atributos para las diferentes copias Snapshot realizadas desde el mismo volumen.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">Equipos virtuales desde la arquitectura de Snapshot</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">Para crear una instantánea de un equipo virtual, complete los siguientes pasos:</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">Cree una copia Snapshot de VolumeshotClass que puede utilizarse para crear una copia Snapshot de Volume. Vaya a almacenamiento &gt; VolumeSnapshotClasses y haga clic en Create VolumeSnapshotClass.</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">Introduzca el nombre de la clase de Snapshot, introduzca csi.trident.netapp.io para el controlador y haga clic en Create.</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Cree la clase Snapshot</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">Identifique la RVP que está Unido a la máquina virtual de origen y, a continuación, cree una copia Snapshot de esa RVP. Vaya a.<block ref="fbbf264c8665570001a09df2b42a9873" prefix=" " category="inline-code"></block> Y haga clic en Create VolumeSnapshots.</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Seleccione la RVP para la que desea crear la Snapshot, introduzca el nombre de la Snapshot o acepte el valor predeterminado y seleccione VolumeSnapshotClass adecuado. A continuación, haga clic en Crear.</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Cree Snapshot</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">Esto crea la snapshot de la RVP en ese momento específico.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">Crear una nueva máquina virtual a partir de la copia de Snapshot</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">En primer lugar, restaure la snapshot en una nueva RVP. Desplácese hasta almacenamiento &gt; VolumeSnapshots, haga clic en los tres puntos junto a la snapshot que desea restaurar y haga clic en Restore como nueva RVP.</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">Introduzca los detalles del nuevo PVC y haga clic en Restore. De este modo se crea una nueva RVP.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Restaurar snapshot en una nueva RVP</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">A continuación, cree una nueva máquina virtual a partir de esta RVP. Desplácese hasta cargas de trabajo &gt; virtualización &gt; Máquinas virtuales y haga clic en Crear &gt; con AYLMA.</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">En la sección Spec &gt; template &gt; Volumes, especifique la nueva RVP creada en Snapshot en lugar de en el disco de contenedor. Proporcione los demás detalles de la nueva VM de acuerdo con sus requisitos.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">Una vez que la máquina virtual se haya creado correctamente, acceda y compruebe que la nueva máquina virtual tenga el mismo estado que la de la máquina virtual cuyo RVP se utilizó para crear la snapshot en el momento en que se creó la snapshot.</block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">Configuration: Tareas del administrador del almacenamiento</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">Un administrador de almacenamiento debe configurar los siguientes recursos:</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">Inicie sesión en el clúster de ONTAP de NetApp como administrador.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Vaya a almacenamiento &gt; Storage VMs y haga clic en Add. Cree dos SVM, una para el proyecto-1 y otra para el proyecto-2, proporcionando los detalles necesarios. Además, cree una cuenta de vsadmin para gestionar la SVM y sus recursos.</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">Creación de SVM en ONTAP</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">Inicie sesión en el clúster de Red Hat OpenShift como administrador de almacenamiento.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">Cree el back-end para el proyecto-1 y asígnelo a la SVM dedicada al proyecto. NetApp recomienda utilizar la cuenta vsadmin de la SVM para conectar el back-end a SVM en lugar de utilizar el administrador del clúster de ONTAP.</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">En este ejemplo, estamos usando el controlador ontap-nas. Utilice el controlador adecuado al crear el backend según el caso de uso.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">De forma similar, cree el back-end de Trident para el proyecto-2 y asígnelo al proyecto 2 dedicado.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">A continuación, cree las clases de almacenamiento. Cree la clase de almacenamiento para el proyecto-1 y configúrela para que utilice los pools de almacenamiento desde back-end dedicado al proyecto-1 mediante la configuración del parámetro storagePools.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">Del mismo modo, cree una clase de almacenamiento para el proyecto 2 y configúrela para que utilice los pools de almacenamiento desde back-end dedicado al proyecto 2.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">Cree un ResourceQuota para restringir los recursos del proyecto-1 solicitando el almacenamiento de storagegrid dedicado a otros proyectos.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">Del mismo modo, cree un ResourceQuota para restringir los recursos del proyecto 2 solicitando almacenamiento de storagegrid dedicado a otros proyectos.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">Siguiente: Validación.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">Hay un campo opcional llamado<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> que se define en este archivo. En los back-ends de iSCSI, este valor se puede establecer en un tipo de sistema de archivos de Linux específico (XFS, ext4, etc.) o se puede eliminar para permitir a OpenShift decidir qué sistema de archivos utilizar.</block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Configuration: Tareas del administrador del clúster</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">El administrador de clúster de Red Hat OpenShift realiza las siguientes tareas:</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Inicie sesión en el clúster de Red Hat OpenShift como cluster-admin.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">Crear dos proyectos correspondientes a diferentes proyectos.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">Cree el rol de desarrollador para el proyecto-1.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">La definición de rol proporcionada en esta sección es sólo un ejemplo. Las funciones de desarrollador deben definirse en función de los requisitos del usuario final.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">Del mismo modo, cree roles de desarrollador para project-2.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">Todos los recursos de almacenamiento de OpenShift y NetApp suelen gestionarse mediante un administrador de almacenamiento. El acceso a los administradores de almacenamiento se controla mediante el rol del operador trident que se crea al instalar Trident. Además, el administrador de almacenamiento también necesita acceder a ResourceQuotas para controlar el consumo del almacenamiento.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">Cree un rol para administrar ResourceQuotas en todos los proyectos del clúster para adjuntarlo al administrador de almacenamiento.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">Asegúrese de que el clúster esté integrado con el proveedor de identidades de la organización y de que los grupos de usuarios estén sincronizados con los grupos de clústeres. En el ejemplo siguiente se muestra que el proveedor de identidades se ha integrado con el clúster y se ha sincronizado con los grupos de usuarios.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">Configure ClusterRoleBindings para los administradores de almacenamiento.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">Para los administradores de almacenamiento, deben enlazar dos roles: trident-operador y Resource-Quotas.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Cree RoleBindings para desarrolladores que vinculen la función de desarrollador-proyecto-1 al grupo correspondiente (ocp-project-1) en el proyecto-1.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">De forma similar, cree RoleBindings para desarrolladores que vinculen las funciones de desarrollador al grupo de usuarios correspondiente en Project-2.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">Siguiente: Tareas del administrador de almacenamiento.</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">Acelere el desarrollo de software con Astra Control y la tecnología FlexClone de NetApp: Red Hat OpenShift con NetApp</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">Según el caso de uso específico, tanto los contenedores como las máquinas virtuales (VM) pueden servir como plataformas óptimas para diferentes tipos de aplicaciones. Por lo tanto, muchas organizaciones ejecutan algunas de sus cargas de trabajo en contenedores y otras en máquinas virtuales. A menudo, esto lleva a las organizaciones a enfrentarse a retos adicionales al tener que gestionar plataformas independientes: Un hipervisor para máquinas virtuales y un orquestador de contenedores para aplicaciones.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">Para hacer frente a este reto, Red Hat presentó OpenShift Virtualization (antes conocido como Container Native Virtualization) a partir de OpenShift versión 4.6. La función de virtualización OpenShift le permite ejecutar y gestionar máquinas virtuales junto con contenedores en la misma instalación de OpenShift Container Platform, lo que proporciona una capacidad de gestión híbrida para automatizar la implementación y gestión de máquinas virtuales a través de operadores. Además de crear máquinas virtuales en OpenShift, con OpenShift Virtualization, Red Hat también admite la importación de máquinas virtuales desde implementaciones de VMware vSphere, Red Hat Virtualization y Red Hat OpenStack Platform.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">Virtualización OpenShift</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">OpenShift Virtualization con ayuda de Astra Trident cuando se realiza un backup de ONTAP de NetApp, también admite ciertas funciones como la migración en vivo de máquinas virtuales, la clonación de discos de máquinas virtuales, las copias Snapshot de máquinas virtuales, etc. Más adelante en este documento se tratan ejemplos de cada uno de estos flujos de trabajo en sus respectivas secciones.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Para obtener más información sobre Red Hat OpenShift Virtualization, consulte la documentación<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">Este documento de referencia proporciona la validación de la puesta en marcha de la solución Red Hat OpenShift, implementada a través de la infraestructura aprovisionada de Installer (IPI) en varios entornos de centros de datos diferentes, validados por NetApp. Además, se detalla la integración del almacenamiento con los sistemas de almacenamiento de NetApp mediante el uso del orquestador de almacenamiento Astra Trident para la gestión del almacenamiento persistente y el Centro Astra Control Center de NetApp para la gestión y protección de aplicaciones con estado. Por último, se exploran y documentan una serie de validaciones de soluciones y casos de uso reales.</block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">Clúster de ONTAP de NetApp</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident se instaló en el clúster</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">Estación de trabajo de administración con herramientas trimentctl y oc instaladas y agregadas a $PATH</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">Acceso de administrador a ONTAP</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">Acceso de administrador de clúster a clúster OpenShift</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">El clúster se integra con el proveedor de identidades</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">El proveedor de identidades está configurado para distinguir eficientemente entre usuarios de distintos equipos</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">Siguiente: Tareas del administrador de clústeres.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923: SQL Server en AWS EC2 mediante Amazon FSX para ONTAP de NetApp</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">Autores: Pat Sinthutan y Niyaz Mohamed, NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">A muchas empresas que desean migrar aplicaciones de las instalaciones al cloud les parece que el esfuerzo se ve obstaculizado por las diferencias en las funcionalidades que ofrecen los sistemas de almacenamiento en las instalaciones y los servicios de almacenamiento en cloud. Esta brecha ha hecho que la migración de aplicaciones empresariales como Microsoft SQL Server sea mucho más problemática. En particular, la falta de servicios necesarios para ejecutar una aplicación empresarial, como copias Snapshot sólidas, funcionalidades de eficiencia del almacenamiento, alta disponibilidad, fiabilidad y rendimiento consistente han obligado a los clientes a realizar sacrificios en diseño o renunciar a la migración de aplicaciones. Con FSX para ONTAP de NetApp, los clientes ya no necesitan sacrificar. FSX de ONTAP de NetApp es un servicio nativo de AWS (de primer lugar) vendido, compatible, facturado y totalmente gestionado por AWS. Utiliza la potencia de ONTAP de NetApp para ofrecer las mismas funcionalidades de gestión de datos y almacenamiento empresarial que NetApp ha proporcionado en las instalaciones durante tres décadas en AWS como servicio gestionado.</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">ONTAP FSX de AWS</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">Con SQL Server en instancias EC2, los administradores de bases de datos pueden acceder a su entorno de base de datos y personalizarlo con el sistema operativo subyacente. Un servidor SQL Server en una instancia de EC2 junto con<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> para almacenar archivos de base de datos, permite un alto rendimiento, gestión de datos y una ruta de migración simple y sencilla mediante la replicación a nivel de bloque. Por lo tanto, se puede ejecutar la compleja base de datos en AWS VPC con un método de sencillo cambio y elevación, menos clics y sin conversiones de esquemas.</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">Ventajas de utilizar Amazon FSX para ONTAP de NetApp con SQL Server</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">Amazon FSX para ONTAP de NetApp es el almacenamiento de archivos perfecto para puestas en marcha de SQL Server en AWS. Sus ventajas incluyen los siguientes:</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">Alto rendimiento y rendimiento uniformes con baja latencia</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">Almacenamiento en caché inteligente con la caché NVMe para mejorar el rendimiento</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">Dimensionamiento flexible para que pueda aumentar o reducir la capacidad, el rendimiento y la tasa de IOPS sobre la marcha</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">Replicación eficiente de bloques de las instalaciones a AWS</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">El uso de iSCSI es un protocolo muy conocido para el entorno de bases de datos</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">Funciones de eficiencia del almacenamiento como thin provisioning y clones sin huella</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">El tiempo de backup se reduce de horas a minutos, con lo que se reduce el objetivo de tiempo de recuperación</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">Backup y recuperación granular de bases de datos de SQL con la intuitiva interfaz de usuario de SnapCenter de NetApp</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">La posibilidad de realizar varias migraciones de pruebas antes de la migración real</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">Tiempo de inactividad más corto durante la migración y superando los retos de la migración con los niveles de archivo o de copia a nivel de I/O.</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">Reducción del MTTR al encontrar la causa raíz después de una actualización importante de una versión o parche</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">La puesta en marcha de bases de datos de SQL Server en ONTAP FSX con el protocolo iSCSI, como se suele utilizar en las instalaciones, proporciona un entorno de almacenamiento de base de datos ideal con rendimiento, eficiencia del almacenamiento y funcionalidades de gestión de datos superiores. Mediante el uso de varias sesiones iSCSI, suponiendo que se trata de un tamaño de conjunto de trabajo del 5 %, la conexión a Flash Cache proporciona más de 100 000 IOPS con el servicio ONTAP FSX. Esta configuración proporciona un control completo sobre el rendimiento de las aplicaciones más exigentes. SQL Server que se ejecuta en instancias de EC2 más pequeñas conectadas a FSX para ONTAP puede realizar el mismo funcionamiento que SQL Server que se ejecuta en una instancia de EC2 mucho más grande, ya que solo se aplican límites de ancho de banda de red al FSX para ONTAP. Al reducir el tamaño de las instancias también se reduce el coste informático, lo que proporciona una puesta en marcha optimizada para TCO. La combinación de SQL con iSCSI, SMB3.0 con recursos compartidos de disponibilidad continua y multicanal en FSX para ONTAP proporciona grandes ventajas para las cargas de trabajo de SQL.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">Antes de empezar</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">La combinación de Amazon FSX para ONTAP de NetApp y SQL Server en la instancia de EC2 permite la creación de diseños de almacenamiento de bases de datos de nivel empresarial que pueden cumplir los requisitos de las aplicaciones más exigentes del momento de hoy en día. Para optimizar ambas tecnologías, es vital comprender los patrones de I/o y las características de SQL Server. Gracias a una buena distribución de almacenamiento para una base de datos de SQL Server, el rendimiento de SQL Server y la gestión de la infraestructura de SQL Server. Un buen diseño del almacenamiento también permite que la puesta en marcha inicial tenga éxito y que el entorno crezca sin problemas a medida que crece su negocio.</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">Antes de completar los pasos de este documento, debe tener los siguientes requisitos previos:</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">Una cuenta de AWS</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">Roles IAM adecuados para aprovisionar EC2 y FSX para ONTAP</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">Un dominio de Windows Active Directory en EC2</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">Todos los nodos de SQL Server deben poder comunicarse entre sí</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">Asegúrese de que la resolución DNS funciona y de que se pueden resolver los nombres de host. Si no es así, utilice la entrada del archivo host.</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">Conocimientos generales de la instalación de SQL Server</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">Asimismo, consulte las prácticas recomendadas de NetApp para entornos de SQL Server a fin de garantizar la mejor configuración de almacenamiento.</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">Prácticas recomendadas para entornos de SQL Server en EC2</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">Con FSX ONTAP, la obtención del almacenamiento es la tarea más sencilla y se puede realizar actualizando el sistema de archivos. Este sencillo proceso permite una optimización dinámica de costes y rendimiento según sea necesario, ayuda a equilibrar la carga de trabajo de SQL y también es un excelente habilitador de thin provisioning. La tecnología de thin provisioning de ONTAP de FSX ha sido diseñada para presentar más almacenamiento lógico a las instancias EC2 que ejecutan SQL Server que el aprovisionado en el sistema de archivos. En lugar de asignar un espacio inicial, el espacio de almacenamiento se asigna de forma dinámica a cada volumen o LUN a medida que se escriben los datos. En la mayoría de configuraciones, el espacio libre también se libera cuando se eliminan datos del volumen o la LUN (y no quedan en ninguna copia Snapshot). La siguiente tabla proporciona ajustes de configuración para asignar almacenamiento de forma dinámica.</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Ajuste</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garantía de volumen</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">Ninguno (establecido de forma predeterminada)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">Reserva de LUN</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Activado</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">reserva_fraccionaria</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0% (definido de forma predeterminada)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">snap_reserve</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0 %</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">Eliminación automática</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">volumen / oldest_first</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">Tamaño automático</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">Encendido</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">try_first</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">Crecimiento automático</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">Política de organización en niveles del volumen</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">Solo Snapshot</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">Política de Snapshot</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">Con esta configuración, el tamaño total de los volúmenes puede ser mayor que el almacenamiento real disponible en el sistema de archivos. Si los LUN o las copias snapshot requieren más espacio del disponible en el volumen, los volúmenes se ampliarán automáticamente y ocupan más espacio del sistema de archivos que contiene. El crecimiento automático permite que ONTAP FSX aumente automáticamente el tamaño del volumen hasta un tamaño máximo que se predetermina. Debe haber espacio disponible en el sistema de archivos contenedor para admitir el crecimiento automático del volumen. Por lo tanto, con el crecimiento automático habilitado, debe supervisar el espacio libre en el sistema de archivos que contiene y actualizar el sistema de archivos cuando sea necesario.</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">asignación de espacio</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">Junto con esto, ajuste la<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> Opción de LUN a habilitada para que FSX ONTAP notifique al host EC2 cuando el volumen se ha quedado sin espacio y la LUN del volumen no puede aceptar escrituras. Además, esta opción permite que FSX para ONTAP reclame espacio automáticamente cuando el servidor SQL en el host de EC2 elimina los datos. La opción asignación de espacio está establecida en deshabilitada de forma predeterminada.</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">Si se crea un LUN con reserva de espacio en un volumen sin garantía, la LUN se comporta como un LUN sin espacio reservado. Esto se debe a que un volumen sin garantía de ninguno no tiene espacio para asignar a la LUN; el volumen en sí solo puede asignar espacio a medida que se escribe debido a su ninguna garantía.</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">Con esta configuración, los administradores de ONTAP de FSX generalmente pueden ajustar el tamaño del volumen para que deban gestionar y supervisar el espacio usado en la LUN en el lado del host y en el sistema de archivos.</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">NetApp recomienda utilizar un sistema de archivos independiente para cargas de trabajo de SQL Server. Si el sistema de archivos se utiliza para varias aplicaciones, supervise el uso de espacio tanto del sistema de archivos como de los volúmenes del sistema de archivos para asegurarse de que los volúmenes no compitan por el espacio disponible.</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">Las copias de Snapshot utilizadas para crear volúmenes FlexClone no se eliminan mediante la opción de eliminación automática.</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">El exceso de compromiso de almacenamiento debe considerarse y gestionarse cuidadosamente para una aplicación esencial, como SQL Server, para la cual no se puede tolerar ninguna interrupción mínima. En este caso, lo mejor es supervisar las tendencias de consumo de almacenamiento para determinar cuánto, si corresponde, es aceptable un exceso de compromiso.</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="cell">Mejores prácticas</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">Es necesaria una supervisión adecuada, acompañada de un plan de acción eficaz, cuando se usa el aprovisionamiento ligero para evitar tiempos de inactividad de las aplicaciones.</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">Asegúrese de configurar las alertas de Cloudwatch y otras herramientas de supervisión para que se pueda contactar con las personas con el tiempo suficiente para reaccionar a medida que se llena el almacenamiento.</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">Configurar almacenamiento para SQL Server e implementar SnapCenter para operaciones de backup, restauración y clonado</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">Para realizar operaciones de SQL Server con SnapCenter, primero debe crear volúmenes y LUN para SQL Server.</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">Crear volúmenes y LUN para SQL Server</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">Para crear volúmenes y LUN para SQL Server, complete los pasos siguientes:</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">Abra la consola de Amazon FSX en<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">Cree un Amazon FSX para el sistema de archivos ONTAP de NetApp mediante la opción Standard Create del método de creación. Esto permite definir credenciales FSxadmin y vsadmin.</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">Especifique la contraseña para fsxadmin.</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">Especifique la contraseña para las SVM.</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">Creación de un volumen en FSX para ONTAP de NetApp</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">Cree volúmenes mediante el paso que se indica en<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="cell">Mejores prácticas</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">Deshabilite los programas de copia de Snapshot de almacenamiento y las políticas de retención. En su lugar, utilice SnapCenter de NetApp para coordinar las copias Snapshot de los volúmenes de registros y datos de SQL Server.</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">Configure bases de datos en LUN individuales en volúmenes independientes para aprovechar la funcionalidad de restauración rápida y granular.</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">Coloque los archivos de datos de usuario (.mdf) en volúmenes independientes debido a que son cargas de trabajo de lectura/escritura aleatorias. Es común crear backups de registros de transacciones con más frecuencia que los backups de bases de datos. Por este motivo, coloque los archivos de registro de transacciones (.ldf) en un volumen aparte de los archivos de datos para poder crear programaciones de backup independientes para cada uno de ellos. Esta separación también aísla la E/S de escritura secuencial de los archivos de registro de la E/S de lectura/escritura aleatoria de los archivos de datos y mejora significativamente el rendimiento de SQL Server.</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">Tempdb es una base de datos del sistema utilizada por Microsoft SQL Server como espacio de trabajo temporal, especialmente para operaciones DBCC CHECKDB con un uso intensivo de E/S. Por lo tanto, coloque esta base de datos en un volumen dedicado. En entornos grandes en los que el número de volúmenes es un reto, puede consolidar tempdb en menos volúmenes y almacenarlo en el mismo volumen que otras bases de datos del sistema tras una planificación cuidadosa. La protección de datos para tempdb no es una prioridad alta porque esta base de datos se vuelve a crear cada vez que se reinicia Microsoft SQL Server.</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">Use el siguiente comando SSH para crear volúmenes:</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Inicie el servicio iSCSI con PowerShell con privilegios elevados en servidores Windows.</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Instale Multipath-IO en PowerShell utilizando privilegios elevados en servidores Windows.</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Busque el nombre del iniciador de Windows con PowerShell mediante privilegios elevados en servidores Windows.</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">Conéctese a máquinas virtuales de almacenamiento (SVM) mediante putty y cree un iGroup.</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">Use el siguiente comando de SSH para crear LUN:</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">Para alinear la I/o con el esquema de particiones del SO, utilice Windows_2008 como tipo de LUN recomendado. Consulte<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> para obtener más información.</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">Utilice el siguiente comando SSH para asignar el igroup a las LUN que acaba de crear.</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Para un disco compartido que utiliza el clúster de conmutación al nodo de respaldo de Windows, ejecute un comando SSH para asignar la misma LUN al igroup que pertenece a todos los servidores que participan en el clúster de conmutación al nodo de respaldo de Windows.</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">Conecte Windows Server a una SVM con un destino iSCSI. Busque la dirección IP de destino en AWS Portal.</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">En el Administrador del servidor y en el menú Herramientas, seleccione el iniciador iSCSI. Seleccione la pestaña detección y, a continuación, seleccione detectar portal. Proporcione la dirección IP de iSCSI del paso anterior y seleccione Avanzada. En adaptador local, seleccione Iniciador iSCSI de Microsoft. En IP del iniciador, seleccione la IP del servidor. A continuación, seleccione Aceptar para cerrar todas las ventanas.</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">Repita el paso 12 para la segunda IP de iSCSI desde la SVM.</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">Seleccione la ficha *Targets*, seleccione *Connect* y seleccione *Enable muti-path*.</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">Para obtener el mejor rendimiento, añada más sesiones; NetApp recomienda crear cinco sesiones iSCSI. Seleccione *Propiedades *&gt; *Añadir sesión *&gt; *Avanzado* y repita el paso 12.</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">Configure cinco sesiones iSCSI por interfaz de destino para conseguir un rendimiento óptimo.</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">Configure una normativa por turnos para el mejor rendimiento iSCSI global.</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">Asegúrese de que el tamaño de la unidad de asignación esté establecido en 64K para las particiones al formatear las LUN</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">Ejecute el siguiente comando de PowerShell para asegurarse de que la sesión iSCSI persiste.</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">Inicializar discos con el siguiente comando de PowerShell.</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">Ejecute los comandos Create Partition y Format Disk con PowerShell.</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">Puede automatizar la creación de volúmenes y LUN mediante el script de PowerShell del Apéndice B. También se pueden crear LUN con SnapCenter.</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">Una vez definidos los volúmenes y los LUN, debe configurar SnapCenter para poder realizar las operaciones de la base de datos.</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">Información general de SnapCenter</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">SnapCenter de NetApp es un software de protección de datos de última generación para aplicaciones empresariales de nivel 1. SnapCenter, con su interfaz de gestión de panel único, automatiza y simplifica los procesos manuales, complejos y que requieren mucho tiempo asociados con el backup, la recuperación y el clonado de varias bases de datos y otras cargas de trabajo de aplicaciones. SnapCenter aprovecha las tecnologías de NetApp, como las copias Snapshot de NetApp, SnapMirror, SnapRestore y FlexClone de NetApp. Esta integración permite a las organizaciones TECNOLÓGICAS escalar su infraestructura de almacenamiento, cumplir con compromisos de acuerdos de nivel de servicios cada vez más exigentes y mejorar la productividad de los administradores en toda la empresa.</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">Requisitos del servidor de SnapCenter</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">En la tabla siguiente, se enumeran los requisitos mínimos para instalar SnapCenter Server y el plugin en Microsoft Windows Server.</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">Componentes</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">Requisito</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">Recuento de CPU mínimo</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">Cuatro núcleos/vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="paragraph">Memoria</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">Mínimo: Se recomiendan 8 GB: 32 GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">Espacio de almacenamiento</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">Espacio mínimo para la instalación: 10 GB espacio mínimo PARA el repositorio: 10 GB</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">Sistema operativo compatible</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="list-text">Windows Server 2019</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">Paquetes de software</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2 o posterior</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework (WMF) 4.0 o posterior</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 o posterior</block>
  <block id="427d30c4045ae36c0130a14658100185" category="paragraph">Para obtener información detallada, consulte los requisitos de espacio y tamaño <block ref="bcc48263fbca83f546b0bc02edad3f56" category="inline-link-rx"></block></block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">Para obtener compatibilidad de versiones, consulte<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>.</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">Distribución de almacenamiento de la base de datos</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">La figura siguiente muestra algunas consideraciones que se deben tener en cuenta para crear el diseño de almacenamiento de la base de datos de Microsoft SQL Server al realizar backups con SnapCenter.</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">Coloque bases de datos con consultas intensivas de I/o o o con un tamaño de base de datos grande (digamos 500 GB o más) en un volumen aparte para agilizar la recuperación. Este volumen también debe realizarse backup mediante trabajos independientes.</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">Consolide bases de datos de tamaño pequeño a mediano que son menos críticas o tienen menos requisitos de I/o en un único volumen. El backup de un gran número de bases de datos que residen en el mismo volumen da lugar a menos copias de Snapshot que es necesario mantener. También se recomienda consolidar las instancias de Microsoft SQL Server para utilizar los mismos volúmenes para controlar el número de copias de Snapshot de backup realizadas.</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">Cree LUN independientes para almacenar archivos de texto completo y archivos relacionados con streaming de archivos.</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Asigne LUN independientes por host para almacenar backups de registros de Microsoft SQL Server.</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">Las bases de datos del sistema que almacenan la configuración de metadatos del servidor de bases de datos y los detalles del trabajo no se actualizan con frecuencia. Coloque las bases de datos del sistema/tempdb en unidades o LUN por separado. No coloque las bases de datos del sistema en el mismo volumen que las bases de datos del usuario. Las bases de datos de usuario tienen una política de backup diferente y la frecuencia del backup de la base de datos de usuario no es la misma para las bases de datos del sistema.</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Para la configuración del grupo de disponibilidad de Microsoft SQL Server, coloque los archivos de datos y de registro de las réplicas en una estructura de carpetas idéntica en todos los nodos.</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">Además de la ventaja en cuanto al rendimiento que supone separar el diseño de la base de datos del usuario en distintos volúmenes, la base de datos también afecta significativamente el tiempo necesario para las tareas de backup y restauración. La existencia de volúmenes separados para los archivos de datos y de registro mejora considerablemente el tiempo de restauración en comparación con un volumen que aloja varios archivos de datos de usuario. Del mismo modo, las bases de datos de usuario con una aplicación con un gran volumen de I/o son propensas a aumentar el tiempo de backup. Más adelante en este documento se ofrece una explicación más detallada sobre las prácticas de copia de seguridad y restauración.</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">A partir de SQL Server 2012 (11.x), bases de datos del sistema (Master, Model, MSDB y TempDB), Las bases de datos de usuario de Database Engine se pueden instalar con un servidor de archivos SMB como opción de almacenamiento. Esto se aplica tanto a instalaciones independientes de clúster de conmutación al nodo de respaldo de SQL Server como de SQL Server. Esto le permite utilizar FSX para ONTAP con todas sus funcionalidades de gestión de datos y rendimiento, incluidas la capacidad de volumen, la escalabilidad del rendimiento y las funciones de protección de datos, de las que SQL Server puede aprovechar. Los recursos compartidos utilizados por los servidores de aplicaciones deben configurarse con el conjunto de propiedades continuamente disponibles y el volumen se debe crear con el estilo de seguridad NTFS. SnapCenter de NetApp no se puede utilizar con bases de datos colocadas en recursos compartidos de SMB de FSX para ONTAP.</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">Para las bases de datos de SQL Server que no utilizan SnapCenter para realizar backups, Microsoft recomienda colocar los archivos de datos y de registro en unidades independientes. Para las aplicaciones que actualizan y solicitan datos simultáneamente, el archivo de registro tiene un gran consumo de escrituras y el archivo de datos (en función de la aplicación) tiene un gran volumen de lecturas y escrituras. Para la recuperación de datos, el archivo de registro no es necesario. Por lo tanto, las solicitudes de datos pueden satisfacerse desde el archivo de datos ubicado en su propia unidad.</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">Cuando se crea una nueva base de datos, Microsoft recomienda especificar unidades independientes para los datos y los registros. Para mover archivos después de crear la base de datos, ésta debe desconectarse. Para obtener más recomendaciones de Microsoft, vea colocar datos y archivos de registro en unidades independientes.</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">Instalación y configuración para SnapCenter</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">Instale el servidor SnapCenter</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">Instalar el plugin de SnapCenter para Microsoft SQL Server</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">Siga la<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> y..<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> Para instalar y configurar SnapCenter.</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">Después de instalar SnapCenter, lleve a cabo los siguientes pasos para configurarlo.</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">Para configurar las credenciales, seleccione *Ajustes* &gt; *Nuevo* y, a continuación, introduzca la información de las credenciales.</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">Añada el sistema de almacenamiento seleccionando sistemas de almacenamiento &gt; Nuevo y proporcione el FSX adecuado para la información del almacenamiento ONTAP.</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">Agregue hosts seleccionando *hosts* &gt; *Agregar* y, a continuación, proporcione la información del host. SnapCenter instala automáticamente los complementos de Windows y SQL Server. Este proceso puede tardar algún tiempo.</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">Después de instalar todos los plugins, debe configurar el directorio de registro. Esta es la ubicación donde reside el backup de registros de transacciones. Puede configurar el directorio de registro seleccionando el host y luego seleccione configurar el directorio de registro.</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter utiliza un directorio de registro de host para almacenar datos de backup de registros de transacciones. Se encuentra en el nivel de host e instancia. Cada host de SQL Server utilizado por SnapCenter debe tener un directorio de registro del host configurado para realizar backups de registros. SnapCenter tiene un repositorio de base de datos, por lo que los metadatos relacionados con las operaciones de backup, restauración o clonado se almacenan en un repositorio de base de datos central.</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">El tamaño del directorio de registro de host se calcula de la siguiente manera:</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">Tamaño del directorio del registro del host = ((tamaño de la base de datos del sistema + (tamaño máximo de LDF de base de datos × tasa de cambio diaria de registro %)) × (retención de copias de Snapshot) ÷ (1 – porcentaje de espacio de sobrecarga de LUN)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">La fórmula de ajuste de tamaño del directorio de registro de host asume lo siguiente:</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">Copia de seguridad de la base de datos del sistema que no incluya la base de datos tempdb</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">SpacePlace, sobre una sobrecarga del 10% de LUN, el directorio de registro del host en un volumen o una LUN dedicados. La cantidad de datos en el directorio de registro del host depende del tamaño de los backups y de la cantidad de días que se retienen los backups.</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">Si las LUN ya se han aprovisionado, puede seleccionar el punto de montaje para representar el directorio del registro del host.</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">Ahora está listo para realizar operaciones de backup, restauración y clonado para SQL Server.</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">Base de datos de backups con SnapCenter</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">Después de colocar los archivos de base de datos y de registro en los LUN de ONTAP FSX, se puede usar SnapCenter para realizar backups de las bases de datos. Se utilizan los siguientes procesos para crear un backup completo.</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">En términos de SnapCenter, el objetivo de punto de recuperación se puede identificar como la frecuencia de backup, por ejemplo, con la frecuencia con la que se desea programar el backup para que se pueda reducir la pérdida de datos hasta unos minutos. SnapCenter le permite programar backups con la frecuencia de cada cinco minutos. Sin embargo, puede haber algunas instancias en las que un backup puede no completarse en un plazo de cinco minutos durante los períodos de máxima transacción o cuando la tasa de cambio de los datos es más elevada en el tiempo determinado. Una práctica recomendada es programar backups frecuentes de registros de transacciones en lugar de backups completos.</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">Existen muchos métodos para gestionar el objetivo de punto de recuperación y el objetivo de tiempo de recuperación. Una alternativa a este método de backup es tener políticas de backup separadas para datos y registros con intervalos diferentes. Por ejemplo, desde SnapCenter, programar backups de registros en intervalos de 15 minutos y backups de datos en intervalos de 6 horas.</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">Use un grupo de recursos para llevar a cabo una configuración de backup para la optimización de Snapshot y la cantidad de trabajos que deben gestionarse.</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">Seleccione *Recursos* y, a continuación, seleccione *Microsoft SQL Server *en el menú desplegable de la parte superior izquierda. Seleccione *Actualizar recursos*.</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">Seleccione la base de datos de la que desea realizar la copia de seguridad y, a continuación, seleccione *Siguiente* y (*+*) para agregar la directiva si no se ha creado una. Siga la *Nueva política de copia de seguridad de SQL Server* para crear una nueva directiva.</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">Seleccione el servidor de verificación si es necesario. Este servidor es el servidor que SnapCenter ejecuta DBCC CHECKDB después de crear una copia de seguridad completa. Haga clic en *Siguiente* para la notificación y, a continuación, seleccione *Resumen* para revisar. Después de revisar, haga clic en *Finalizar*.</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">Haga clic en *copia de seguridad ahora* para probar la copia de seguridad. En las ventanas emergentes, seleccione *copia de seguridad*.</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">Seleccione *Monitor* para comprobar que la copia de seguridad se ha completado.</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">Realizar una copia de seguridad del registro de transacciones desde SnapCenter para que, durante el proceso de restauración, SnapCenter pueda leer todos los archivos de copia de seguridad y restaurar automáticamente en secuencia.</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">Si se utilizan productos de terceros para el backup, seleccione Copy backup en SnapCenter para evitar problemas con la secuencia de registros y pruebe la funcionalidad de restauración antes de pasar a la producción.</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">Restaurar base de datos con SnapCenter</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">Una de las principales ventajas del uso de FSX ONTAP con SQL Server en EC2 es su capacidad de realizar restauraciones rápidas y granulares a nivel de base de datos.</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">Complete los siguientes pasos para restaurar una base de datos individual a un momento específico o hasta un minuto con SnapCenter.</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">Seleccione Resources y, a continuación, seleccione la base de datos que desea restaurar.</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">Seleccione el nombre de backup desde el que debe restaurarse la base de datos y, a continuación, seleccione restore.</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">Siga las ventanas emergentes de *Restaurar* para restaurar la base de datos.</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">Seleccione *Monitor* para comprobar que el proceso de restauración se ha realizado correctamente.</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">Consideraciones sobre una instancia con un gran número de bases de datos de tamaño pequeño a grande</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter puede realizar el backup de un gran número de bases de datos importantes en una instancia o un grupo de instancias dentro de un grupo de recursos. El tamaño de una base de datos no es el factor principal del tiempo de backup. La duración de un backup puede variar en función del número de LUN por volumen, la carga en Microsoft SQL Server, el número total de bases de datos por instancia y, específicamente, el ancho de banda de I/o y el uso. Al configurar la política para realizar un backup de bases de datos desde una instancia o un grupo de recursos, NetApp recomienda restringir el máximo backup de la base de datos por copia de Snapshot a 100 por host. Asegúrese de que el número total de copias Snapshot no supere el límite de 1,023 copias.</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">NetApp también recomienda limitar los trabajos de backup que se ejecutan en paralelo mediante la agrupación de la cantidad de bases de datos en lugar de la creación de varios trabajos para cada base de datos o instancia. Para lograr un rendimiento óptimo de la duración del backup, se reduce la cantidad de tareas de backup a una cantidad que puede incluir en un backup de unas 100 bases de datos o menos a la vez.</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">Como se ha mencionado anteriormente, el uso de I/o es un factor importante en el proceso de backup. El proceso de backup debe esperar a que se desactive hasta que se hayan completado todas las operaciones de I/o de una base de datos. Las bases de datos con operaciones de I/o altamente intensivas deben aplazarse hasta otro tiempo de backup o deben aislarse de otras tareas de backup para evitar afectar a otros recursos del mismo grupo de recursos que se debe realizar un backup.</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">Para un entorno con seis hosts de Microsoft SQL Server que alojan 200 bases de datos por instancia, suponiendo que se tienen cuatro LUN por host y una LUN por volumen creado, se debe establecer una política de backup completa con el número máximo de bases de datos de las que se realiza un backup por copia Snapshot a la versión 100. Cada instancia proporciona doscientos bases de datos, como 200 archivos de datos distribuidos equitativamente en dos LUN y 200 archivos de registro se distribuyen equitativamente en dos LUN, lo que consiste en 100 archivos por LUN y por volumen.</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">Para programar tres tareas de backup, cree tres grupos de recursos, cada uno agrupando dos instancias que incluyan un total de 400 bases de datos.</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">Ejecutar las tres tareas de backup en paralelo realiza backups de 1,200 bases de datos simultáneamente. En función de la carga del servidor y del uso de E/S, la hora de inicio y de finalización de cada instancia puede variar. En este ejemplo, se crean un total de 24 copias Snapshot.</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">Además del backup completo, NetApp recomienda configurar un backup de registros de transacciones para las bases de datos más importantes. Asegúrese de que la propiedad de base de datos está establecida en el modelo de recuperación completa.</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">No incluya la base de datos tempdb en una copia de seguridad porque los datos que contiene son temporales. Coloque tempdb en un LUN o un recurso compartido de SMB que se encuentra en un volumen del sistema de almacenamiento en el que no se crearán copias de Snapshot.</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">Una instancia de Microsoft SQL Server con una aplicación con una alta tasa de I/o debe aislarse en una tarea de backup diferente para reducir el tiempo general de respaldo de otros recursos.</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">Limite el conjunto de bases de datos que se incluirán en un backup simultáneo a 100 y configure el conjunto restante de backups de bases de datos para evitar un proceso simultáneo.</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Utilice el nombre de la instancia de Microsoft SQL Server en el grupo de recursos en lugar de varias bases de datos porque cada vez que se crean bases de datos nuevas en la instancia de Microsoft SQL Server, SnapCenter considera automáticamente una nueva base de datos para el backup.</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">Si se modifica la configuración de la base de datos, como cambiar el modelo de recuperación de base de datos al modelo de recuperación completa, se debe ejecutar un backup de inmediato para permitir las operaciones de restauración de último minuto.</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter no puede restaurar los backups de registros de transacciones creados fuera de SnapCenter.</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">Al clonar volúmenes de FlexVol, asegúrese de tener suficiente espacio para los metadatos del clon.</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">Cuando se restaura una base de datos, se debe asegurarse de que haya espacio suficiente en el volumen.</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">Cree una política aparte para gestionar y realizar backup de bases de datos del sistema al menos una vez a la semana.</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">Clonado de bases de datos con SnapCenter</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">Para restaurar una base de datos en otra ubicación en un entorno de prueba o desarrollo o crear una copia para análisis empresarial, la práctica recomendada por NetApp es aprovechar la metodología de clonación para crear una copia de la base de datos en la misma instancia o en una alternativa.</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">Normalmente, la clonado de bases de datos que 500 GB en un disco iSCSI alojado en un entorno FSX para ONTAP tarda menos de cinco minutos. Una vez finalizada la clonado, el usuario puede realizar toda la operación de lectura/escritura requerida en la base de datos clonada. La mayor parte del tiempo se consume para el análisis de disco (diskpart). Por lo general, el procedimiento de clonación de NetApp lleva menos de 2 minutos independientemente del tamaño de las bases de datos.</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">La clonado de una base de datos puede realizarse con el método doble: Puede crear un clon a partir del backup más reciente o bien utilizar la gestión del ciclo de vida de clones a través del cual la copia más reciente puede estar disponible en la instancia secundaria.</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter permite montar la copia de clonado en el disco necesario para mantener el formato de la estructura de carpetas en la instancia secundaria y continuar programar tareas de backup.</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">Clonar las bases de datos en el nuevo nombre de la base de datos en la misma instancia</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">Se pueden seguir los pasos siguientes para clonar bases de datos en el nombre de la nueva base de datos en la misma instancia de servidor SQL que se ejecuta en EC2:</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">Seleccione Resources y, a continuación, la base de datos que debe clonarse.</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">Seleccione el nombre de backup que desea clonar y seleccione Clone.</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">Siga las instrucciones de clonación de las ventanas de backup para finalizar el proceso de clonación.</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">Seleccione Monitor para asegurarse de que se ha completado la clonación.</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">Clone bases de datos en la nueva instancia de SQL Server que se ejecuta en EC2</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">El siguiente paso se utiliza para clonar bases de datos en la nueva instancia de SQL Server que se ejecuta en EC2:</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">Cree un nuevo servidor SQL Server en EC2 en el mismo VPC.</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">Habilite el protocolo iSCSI y MPIO y, a continuación, configure la conexión iSCSI con FSX para ONTAP siguiendo los pasos 3 y 4 de la sección “Crear volúmenes y LUN para SQL Server”.</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">Agregue un servidor SQL nuevo en EC2 en SnapCenter siguiendo el paso 3 de la sección “instalación y configuración de SnapCenter”.</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">Seleccione Resource &gt; View instance y, a continuación, Refresh Resource.</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">Seleccione Resources y, a continuación, la base de datos que desea clonar.</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">Seleccione el nombre de backup que desea clonar y, a continuación, seleccione Clone.</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">Siga las instrucciones Clone from Backup proporcionando la nueva instancia de SQL Server en EC2 y el nombre de la instancia para finalizar el proceso de clonado.</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">Apéndices</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">Apéndice A: Archivo YAML para su uso en plantilla de formación en la nube</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">El siguiente archivo .yaml se puede utilizar con la plantilla de formación en la nube en la Consola de AWS.</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">Este enlace de GitHub</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">Para automatizar la creación de LUN ISCSI y la instalación de SnapCenter de NetApp con PowerShell, clone el repo desde<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>.</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">Apéndice B: Secuencias de comandos PowerShell para aprovisionar volúmenes y LUN</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">El siguiente script se utiliza para aprovisionar volúmenes y LUN, así como para configurar iSCSI basándose en las instrucciones anteriores. Existen dos scripts de PowerShell:</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">Ejecute el archivo<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> la primera y la segunda secuencia de comandos se ejecuta automáticamente después de que se haya reiniciado el servidor. Estos scripts de PowerShell pueden eliminarse una vez ejecutados debido al acceso a las credenciales a la SVM.</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="list-text">Amazon FSX para ONTAP de NetApp</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">Introducción a FSX para ONTAP de NetApp</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">Descripción general de la interfaz de SnapCenter</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">Recorrido por las opciones del panel de navegación de SnapCenter</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">Configure el complemento SnapCenter 4.0 para SQL Server</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">Cómo realizar backup y restaurar bases de datos con SnapCenter con el plugin de SQL Server</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">Cómo clonar una base de datos con SnapCenter con el plugin de SQL Server</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250: SAP con Oracle en UNIX y NFS con Clustered Data ONTAP de NetApp y SnapManager para SAP 3.4</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">Nils Bauer: NetApp</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">El TR-4250 aborda los retos que se presentan al diseñar soluciones de almacenamiento compatibles con los productos paquete empresarial de SAP mediante una base de datos de Oracle. El objetivo principal de este documento es los retos comunes de diseño, puesta en marcha, funcionamiento y gestión de la infraestructura de almacenamiento a los que se enfrentan los líderes de negocio Y DE TI que utilizan la última generación de soluciones SAP. Las recomendaciones de este documento son genéricas; no son específicas de una aplicación SAP ni del tamaño y alcance de la implementación SAP. En TR-4250 se asume que el lector tiene conocimientos básicos de la tecnología y el funcionamiento de los productos de NetApp y SAP. TR-4250 se desarrolló en función de la interacción del personal técnico de NetApp, SAP, Oracle y nuestros clientes.</block>
  <block id="fb558936249b78a9b426ac6a575ece20" category="paragraph"><block ref="fb558936249b78a9b426ac6a575ece20" category="inline-link-macro-rx"></block></block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">TR-3633: Bases de datos de Oracle en ONTAP</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">Jeffrey Steiner, NetApp</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link-macro">Herramienta de matriz de interoperabilidad (IMT)</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">Consulte la <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> Para determinar si el entorno, las configuraciones y las versiones especificadas en TR-3633 son compatibles con su entorno.</block>
  <block id="8b742cda768ff35bcc87798d5c8efcf1" category="paragraph"><block ref="8b742cda768ff35bcc87798d5c8efcf1" category="inline-link-macro-rx"></block></block>
  <block id="653a98af1c9a004c51b4e7358f06db9a" category="summary">La solución proporciona información general y detalles para la puesta en marcha de la base de datos PostgreSQL y la configuración de alta disponibilidad/recuperación ante desastres, conmutación al nodo de respaldo y resincronización basada en la tecnología SnapMirror de NetApp integrada en la oferta de almacenamiento FSX ONTAP y el kit de herramientas de automatización Ansible de NetApp en AWS.</block>
  <block id="e5f44d648a9d8c4db4e2b580d3370fbf" category="doc">TR-4956: Puesta en marcha automatizada de alta disponibilidad y recuperación ante desastres de PostgreSQL en AWS FSX/EC2</block>
  <block id="7e6f7643afec42d9c47efa933debef3e" category="paragraph">Allen Cao, Niyaz Mohamed, NetApp</block>
  <block id="03784a7c5600d29113972955e602a944" category="inline-link-macro">Motores DB</block>
  <block id="1d8f1bdc206db1d9edd9fa46f02aa08c" category="paragraph">PostgreSQL es una base de datos de código abierto ampliamente utilizada que ocupa el cuarto puesto entre los diez motores de base de datos más populares por <block ref="6e2d0e5987102894082cbdb135303e4d" category="inline-link-macro-rx"></block>. Por un lado, PostgreSQL deriva su popularidad de su modelo libre de licencias y de código abierto, al tiempo que todavía posee características sofisticadas. Por otro lado, al obtener código abierto, hay escasez de orientación detallada para la puesta en marcha de bases de datos de nivel de producción en el área de alta disponibilidad y recuperación ante desastres (ha/DR), especialmente en el cloud público. En general, puede ser difícil configurar un sistema PostgreSQL ha/DR típico con reserva activa y en caliente, replicación en streaming, etc. Probar el entorno de alta disponibilidad/recuperación ante desastres promocionando el sitio de reserva y, a continuación, volver al primario puede provocar interrupciones en la producción. Existen problemas de rendimiento bien documentados en el volumen principal cuando se ponen en marcha cargas de trabajo de lectura en streaming en espera.</block>
  <block id="3ba3cda3d91af072810327bfd691205c" category="paragraph">En esta documentación, mostramos cómo puede eliminar una solución PostgreSQL de alta disponibilidad/recuperación ante desastres en el nivel de las aplicaciones y crear una solución PostgreSQL de alta disponibilidad/recuperación ante desastres basada en almacenamiento AWS FSX ONTAP y instancias informáticas de EC2 mediante la replicación a nivel del almacenamiento. La solución crea un sistema más sencillo y comparable y ofrece resultados equivalentes en comparación con la replicación por streaming a nivel de aplicación PostgreSQL tradicional para alta disponibilidad/recuperación ante desastres.</block>
  <block id="e2543d0568626be8ab6adad9d9a78652" category="paragraph">Esta solución se basa en tecnología de replicación probada y madura de NetApp SnapMirror, disponible en almacenamiento en cloud FSX ONTAP nativo de AWS para PostgreSQL ha/DR. Es fácil de implementar con un kit de herramientas de automatización que proporciona el equipo de soluciones de NetApp. Proporciona una funcionalidad similar a la vez que elimina la complejidad y el lastre del rendimiento del sitio primario con la solución de alta disponibilidad/recuperación ante desastres basada en streaming de nivel de aplicaciones. La solución se puede implementar y probar con facilidad sin que afecte al sitio primario activo.</block>
  <block id="f67bd3c0833b1d6bf90bb26a55f0a9ce" category="list-text">Puesta en marcha de alta disponibilidad/recuperación ante desastres para PostgreSQL en el cloud público de AWS</block>
  <block id="420a5f3809172bb0dc9d501758fe94d2" category="list-text">Probar y validar una carga de trabajo PostgreSQL en el cloud público de AWS</block>
  <block id="c9d6a5076f52c5abce5f2003446ab211" category="list-text">Probar y validar una estrategia ha/DR PostgreSQL basada en la tecnología de replicación SnapMirror de NetApp</block>
  <block id="82aa3e78c2089a2941fb745bb8c72f01" category="paragraph">Esta solución está dirigida a las siguientes personas:</block>
  <block id="4a7bde15fa2753ce507cef621fd789b2" category="list-text">Los administradores de bases de datos interesados en poner en marcha PostgreSQL con alta disponibilidad/recuperación ante desastres en el cloud público de AWS.</block>
  <block id="c5e04df584e0992a5dbdae10d89ded97" category="list-text">El arquitecto de soluciones de bases de datos que está interesado en probar cargas de trabajo de PostgreSQL en el cloud público de AWS.</block>
  <block id="ba083ee91407315383bac538162833ff" category="list-text">El administrador de almacenamiento que está interesado en poner en marcha y gestionar instancias de PostgreSQL implementadas en almacenamiento AWS FSX.</block>
  <block id="73ad058c671f3e1e105d92585f5ece7a" category="list-text">Propietario de la aplicación interesado en poner en marcha un entorno PostgreSQL en AWS FSX/EC2.</block>
  <block id="d17a638ff086388dc5bfbe98528ccfab" category="section-title">Entorno de prueba y validación de la solución</block>
  <block id="863fb5b3a3b3b63b57a387bab70de0a9" category="paragraph">Las pruebas y la validación de esta solución se llevaron a cabo en un entorno AWS FSX y EC2 que podría no coincidir con el entorno de puesta en marcha final. Para obtener más información, consulte la sección <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>.</block>
  <block id="bfa420253f0a67626a51ce1fa045944c" category="image-alt">Esta imagen proporciona una imagen detallada de la organización de la solución de cloud híbrido PostgreSQL, que incluye tanto el entorno local como el sitio de AWS.</block>
  <block id="34d0b9b49aa480630e91a3619ba7ffb2" category="section-title">Componentes de hardware y software</block>
  <block id="a09dc18a1bff4fa8388afca4627d0911" category="cell">Almacenamiento FSX ONTAP</block>
  <block id="011fedf4050817b8826f95a53d9555b2" category="cell">Versión actual</block>
  <block id="0b70cdec9293f5625e5aaae9cdd38526" category="cell">Dos pares de alta disponibilidad FSX en el mismo VPC y zona de disponibilidad como clústeres de alta disponibilidad primarios y en espera</block>
  <block id="6a79356b19d3b59e92b358357c5b9053" category="cell">Instancia de EC2 para computación</block>
  <block id="cc4def82629f09f253176dba801a85f0" category="cell">t2.xlarge/4vCPU/16G</block>
  <block id="e3d6d4b94f9415561957f8c22f5fea2e" category="cell">Dos EC2 T2 xlarge como instancias informáticas primarias y en espera</block>
  <block id="3008feb4272787858d4d27f7e8acb08b" category="cell">Controladora de Ansible</block>
  <block id="26b9568eac10de69d574b84626735921" category="cell">CentOS de VM en las instalaciones/4vCPU/8G</block>
  <block id="7f151fffe66dad0021b1918085977654" category="cell">Una máquina virtual para alojar la controladora de automatización de Ansible, ya sea en las instalaciones o en el cloud</block>
  <block id="8b56d55f3caeb71ab2513c28fb1a52fc" category="cell">Red Hat Linux</block>
  <block id="52359c9653f33c68cd1b454f7d05a27b" category="cell">RHEL-8.6.0_HVM-20220503-x86_64-2-Hourly2-GP2</block>
  <block id="fe6120dacb84838d71b1f43da1a3a514" category="cell">Suscripción RedHat implementada para pruebas</block>
  <block id="8003cafa06ec27e11cb235ec9544ef74" category="cell">CentOS de Linux</block>
  <block id="04cd32c57cf3229ae9374fc80cd50d96" category="cell">CentOS Linux versión 8.2.2004 (núcleo)</block>
  <block id="63b6df5ba9d257bb0f6fbda5541d9171" category="cell">Alojamiento de controladora Ansible puesta en marcha en laboratorios locales</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="cell">PostgreSQL</block>
  <block id="a3c20b719830dc5fda947c7b6f3e42be" category="cell">Versión 14.5</block>
  <block id="f8c3d3a84c62eb07a1009aacdc46a50f" category="cell">La automatización saca la última versión disponible de PostgreSQL del postgresql.ora yum repo</block>
  <block id="202351f581b52c61061d29151c81d061" category="cell">Versión 2.10.3</block>
  <block id="d222003898249e4a560d569acb0b5563" category="cell">Requisitos previos para las colecciones y bibliotecas necesarias instaladas con el libro de aplicaciones de requisitos</block>
  <block id="cd1aedf83959dd52fc058b9120f500e3" category="section-title">Factores clave a tener en cuenta la puesta en marcha</block>
  <block id="b062352f67359ac6729601c60a9a57a2" category="list-text">*Copia de seguridad, restauración y recuperación de bases de datos PostgreSQL.* una base de datos PostgreSQL soporta una serie de métodos de copia de seguridad, como una copia de seguridad lógica utilizando pg_dump, una copia de seguridad física en línea con pg_basebackup o un comando de copia de seguridad del SO de bajo nivel, y instantáneas consistentes a nivel de almacenamiento. Esta solución utiliza snapshots de grupo de consistencia de NetApp para los datos de bases de datos PostgreSQL y backup, restauración y recuperación de DATOS DE WAL-Volumes en el sitio de espera. Las snapshots de volúmenes de grupos de coherencia de NetApp graban las I/o mientras se escriben en el almacenamiento y protegen la integridad de los archivos de datos de la base de datos.</block>
  <block id="a28c157802547f294e145f164007d752" category="list-text">*Instancias de computación EC2.* en estas pruebas y validaciones, utilizamos el tipo de instancia AWS EC2 t2.xlarge para la instancia de computación de base de datos PostgreSQL. NetApp recomienda utilizar una instancia de EC2 de tipo M5 como instancia de computación para PostgreSQL en la puesta en marcha porque está optimizada para cargas de trabajo de bases de datos. La instancia de computación en espera siempre debe implementarse en la misma zona que el sistema de archivos pasivo (en espera) implementado para el clúster de alta disponibilidad de FSX.</block>
  <block id="d7aed04148f8b6ba1b91a7ed84d3fd10" category="list-text">*Implementación de clústeres de alta disponibilidad de almacenamiento FSX de una o varias zonas.* en estas pruebas y validaciones, implementamos un clúster de alta disponibilidad FSX en una única zona de disponibilidad de AWS. Para la puesta en marcha en producción, NetApp recomienda la puesta en marcha de un par de alta disponibilidad FSX en dos zonas de disponibilidad diferentes. Se puede configurar un par de alta disponibilidad en espera para la recuperación ante desastres para la continuidad empresarial en una región diferente si se requiere una distancia específica entre el primario y el en espera. Un clúster de alta disponibilidad FSX se aprovisiona en una pareja de alta disponibilidad que se sincroniza con un par de sistemas de archivos activo-pasivo para proporcionar redundancia a nivel de almacenamiento.</block>
  <block id="c6f1f46bc7e80b73e6d77a7f862e0625" category="list-text">*Colocación de datos y registros de PostgreSQL.* las implementaciones típicas de PostgreSQL comparten el mismo directorio raíz o volúmenes para archivos de datos y registro. En nuestras pruebas y validaciones, hemos separado los datos de PostgreSQL e iniciado sesión en dos volúmenes distintos para mejorar el rendimiento. En el directorio de datos se utiliza un enlace de software para señalar al directorio o volumen de registro que aloja registros DE POSTGRESQL WAL y registros DE WAL archivados.</block>
  <block id="6e6dddb70c24cf218d0163faa3fb6a8f" category="list-text">*Temporizador de retardo de inicio del servicio PostgreSQL.* esta solución utiliza volúmenes montados en NFS para almacenar el archivo de base de datos PostgreSQL y los archivos de registro WAL. Durante el reinicio del host de la base de datos, el servicio PostgreSQL puede intentar iniciarse mientras el volumen no está montado. Esto provoca un error de inicio del servicio de base de datos. Para que la base de datos PostgreSQL se inicie correctamente, se necesita un retardo de 10 a 15 segundos en el temporizador.</block>
  <block id="ee79ca09fee704e63d972baa3c1319a2" category="list-text">*RPO/RTO para la continuidad empresarial.* la replicación de datos FSX del primario al de espera para la recuperación ante desastres se basa en ASYNC, lo que significa que el RPO depende de la frecuencia de los backups de Snapshot y la replicación de SnapMirror. Una mayor frecuencia de copia Snapshot y replicación de SnapMirror reduce el objetivo de punto de recuperación. Por lo tanto, existe un equilibrio entre la pérdida de datos potencial en caso de desastre y los costes incrementales del almacenamiento. Hemos determinado que la copia Snapshot y la replicación de SnapMirror pueden implementarse en intervalos de tan solo 5 minutos para los objetivos de punto de recuperación, y PostgreSQL suele recuperarse en el centro de recuperación ante desastres en menos de un minuto para el objetivo de tiempo de recuperación.</block>
  <block id="cbeb123cc0c2c950a65a0c39f8412dc4" category="list-text">*Copia de seguridad de la base de datos.* después de implementar o migrar una base de datos PostgreSQL al almacenamiento AWS FSX desde un centro de datos basado en las instalaciones, los datos se sincronizan automáticamente en el par de alta disponibilidad FSX para su protección. Los datos se protegen aún más con un sitio en espera replicado en caso de desastre. Para la retención de backup a largo plazo o la protección de datos, NetApp recomienda usar la utilidad incorporada de PostgreSQL pg_basebackup para ejecutar un backup completo de base de datos que puede trasladarse al almacenamiento BLOB de S3.</block>
  <block id="d2598d7d09e212cad1231cd233c5f7dc" category="paragraph">La puesta en marcha de esta solución se puede completar automáticamente con el kit de herramientas de automatización basado en Ansible de NetApp si sigue las instrucciones detalladas que se describen a continuación.</block>
  <block id="7cfbd2a753781ece3080a48b0a56dad2" category="inline-link-macro">na_postgresql_aws_deploy_hadr</block>
  <block id="fce91619a13ef0fd71e3ffe1da6b5724" category="list-text">Lea las instrucciones del kit de herramientas de automatización readme.md <block ref="139722adb31b9bbcb8f923b221d78595" category="inline-link-macro-rx"></block>.</block>
  <block id="9a1c6815d4b1e7dc53acf5a926ab662e" category="list-text">Vea el siguiente vídeo.</block>
  <block id="c73ece4b7be6bb88143afe096ded59aa" category="list-text">Configure los archivos de parámetros necesarios <block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix="(" category="inline-code"></block>,<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block>,<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block>) introduciendo parámetros específicos del usuario en la plantilla en las secciones correspondientes. A continuación, use el botón Copy para copiar los archivos en el host de la controladora de Ansible.</block>
  <block id="00aaa5ff8fbd0841ab311f7d9b1e4e78" category="section-title">Requisitos previos para la implementación automatizada</block>
  <block id="fd10b9eacfe4eed8040bda8cae9ea050" category="paragraph">La implementación requiere los siguientes requisitos previos.</block>
  <block id="e7491272f69c8efda69a595782f44d45" category="list-text">Se configuró una cuenta de AWS y se crearon el VPC y los segmentos de red necesarios en la cuenta de AWS.</block>
  <block id="f71558e9ad22e37a70099d8b5d8ac06c" category="inline-link-macro">Guía de usuario para instancias de Linux</block>
  <block id="eb03aa8f939650517c1c56a6d0b9ad2f" category="list-text">Desde la consola de AWS EC2, debe poner en marcha dos instancias EC2 Linux, una como servidor PostgreSQL DB principal en el sitio principal y otra en el sitio de recuperación ante desastres en espera. Para obtener redundancia informática en los sitios de recuperación ante desastres principal y en espera, implemente dos instancias de EC2 Linux adicionales como servidores de base de datos PostgreSQL en espera. Consulte el diagrama de arquitectura de la sección anterior para obtener más información sobre la configuración del entorno. Revise también la <block ref="32934851360be4fd00506586c2cbc221" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="inline-link-macro">Creación de FSX para sistemas de archivos ONTAP</block>
  <block id="933d3e5f984811b21da2922f3deb56c4" category="list-text">Desde la consola de AWS EC2, ponga en marcha dos clústeres de alta disponibilidad de almacenamiento de ONTAP FSX para alojar los volúmenes de base de datos PostgreSQL. Si no está familiarizado con la implementación de almacenamiento FSX, consulte la documentación <block ref="d73b8b529985c5c89147bd81cb29dbfb" category="inline-link-macro-rx"></block> para obtener instrucciones paso a paso.</block>
  <block id="7053a216e34d0f83be18a65f22ce62ce" category="list-text">Cree un equipo virtual CentOS de Linux para alojar la controladora de Ansible. La controladora de Ansible puede estar ubicada en las instalaciones o en el cloud de AWS. Si se encuentra en las instalaciones, debe tener conectividad SSH al VPC, a las instancias de Linux EC2 y a los clústeres de almacenamiento de FSX.</block>
  <block id="d1186b859105640e1dc347ae7b714afa" category="list-text">Configure la controladora de Ansible como se describe en la sección "Configuración del nodo de control de Ansible para las puestas en marcha de la CLI en RHEL/CentOS" desde el recurso <block ref="a9149ecc8f33f363a4eae3089d5c6cb7" category="inline-link-macro-rx"></block>.</block>
  <block id="007fa0067fff9abdcd3e5b9ce9f20c06" category="list-text">Clone una copia del kit de herramientas de automatización del sitio público de GitHub de NetApp.</block>
  <block id="0ca21e6da2c89e765706d9a77f412898" category="list-text">Desde el directorio raíz del kit de herramientas, ejecute los libros de estrategia de requisitos previos para instalar las colecciones y bibliotecas necesarias para el controlador de Ansible.</block>
  <block id="df40cb16c4a24c991c143fbddeedd0bc" category="list-text">Recupere los parámetros de instancia de EC2 FSX necesarios para el archivo de variables de host de la base de datos<block ref="ea858a411f1af6150f14b84176148712" prefix=" " category="inline-code"></block> y el archivo de variables globales<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> configuración.</block>
  <block id="57c7844b0a299340cf9b625ce4a0745a" category="section-title">Configure el archivo hosts</block>
  <block id="ed578fbfbec5634c4fa508cde5bc4e85" category="paragraph">Introduzca los nombres de host de las instancias de EC2 y IP de administración del clúster ONTAP de FSX principales en el archivo hosts.</block>
  <block id="6ef214427ca7b42201d0b0508f56df98" category="section-title">Configure el archivo host_name.yml en la carpeta host_var</block>
  <block id="6967d323b85203ba993572c1cd814dc1" category="paragraph">Introduzca los parámetros apropiados para el sistema en los campos subrayados azules y, a continuación, copie y pegue las entradas en el<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Archivo en la controladora de Ansible<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> carpeta.</block>
  <block id="77ac1da2cd356e327eb4bfc4c5a21bcc" category="section-title">Configure el archivo fsx_var.ydl global en la carpeta var</block>
  <block id="7876ddba2c3af67cbee2b37f64072428" category="paragraph">Introduzca los parámetros apropiados para el sistema en los campos subrayados azules y, a continuación, copie y pegue las entradas en el<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> Archivo en el host de la controladora de Ansible.</block>
  <block id="d56625a35762821798a2f3dd55ead05d" category="section-title">Puesta en marcha de PostgreSQL y configuración de alta disponibilidad/recuperación ante desastres</block>
  <block id="943a124028d8f011631df765453640dc" category="paragraph">Las siguientes tareas implementan el servicio del servidor de la base de datos PostgreSQL e inicializa la base de datos en el sitio principal en el host principal del servidor de la base de datos EC2. A continuación, se configura un host de servidor de base de datos EC2 primario en espera en la ubicación en espera. Por último, la replicación de volúmenes de la base de datos se configura del clúster FSX de la ubicación principal y del clúster FSX de la ubicación en espera para la recuperación ante desastres.</block>
  <block id="08f6dd070ef1adfcbe3d7f3c70b08905" category="list-text">Cree volúmenes de base de datos en el clúster FSX principal y configure postgresql en el host de la instancia EC2 principal.</block>
  <block id="bf22091495c9a041dcbdba3a97795095" category="list-text">Configure el host de la instancia de EC2 de DR en espera.</block>
  <block id="f2dd18dfc82378171d01bdd3f956bc6f" category="list-text">Configurar la agrupación en clústeres de ONTAP de FSX y la replicación de volúmenes de base de datos.</block>
  <block id="d681aef28cf1f863d0683a6896f12995" category="list-text">Consolide los pasos anteriores en una puesta en marcha de PostgreSQL en un único paso y una configuración de alta disponibilidad/recuperación ante desastres.</block>
  <block id="fe217a2e30a79cebc71db6d5cb676a71" category="list-text">Para configurar un host de la base de datos PostgreSQL en espera en los sitios principal o en espera, comente todos los demás servidores del archivo de hosts [dr_postgresql] y, a continuación, ejecute la tableta postgresql_standby_setup.yml con el host de destino correspondiente (como psql_01ps o la instancia de EC2 en espera en la ubicación principal). Asegúrese de que un archivo de parámetros host como<block ref="7c0f59fa275836ef9c4f28bec839acca" prefix=" " category="inline-code"></block> se configura en la<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="d3ecdce9695eacdb90ec80fa276865d4" category="section-title">Copia de seguridad de instantánea de la base de datos PostgreSQL y replicación al sitio en espera</block>
  <block id="3b320790a7f864b473e3baa86de785fe" category="paragraph">La copia de seguridad y replicación de instantáneas de la base de datos PostgreSQL al sitio en espera se pueden controlar y ejecutar en el controlador de Ansible con un intervalo definido por el usuario. Hemos comprobado que el intervalo puede ser de hasta 5 minutos. Por tanto, en caso de fallo en el centro principal, hay 5 minutos de posible pérdida de datos si se produce un fallo justo antes del siguiente backup snapshot programado.</block>
  <block id="421057a9fa982de2a1c1f79f5f03d750" category="section-title">Conmutación al respaldo en el sitio de espera para recuperación ante desastres</block>
  <block id="6ddcc779c247e4adb5b5a56a34edd75d" category="paragraph">Para probar el sistema ha/DR de PostgreSQL como ejercicio de recuperación ante desastres, ejecute la conmutación por error y la recuperación de bases de datos de PostgreSQL en la instancia principal de la base de datos EC2 en espera en el sitio en espera ejecutando el siguiente libro de aplicaciones. En una situación de recuperación ante desastres real, ejecute lo mismo para una recuperación real tras fallos en un site de recuperación ante desastres.</block>
  <block id="724a617bc1dcc9b26fedb732f63a569d" category="section-title">Volver a sincronizar los volúmenes de base de datos replicados después de la prueba de conmutación por</block>
  <block id="6a08e960bd12a4fcddfd08082fbece4b" category="paragraph">Ejecute una resincronización después de la prueba de recuperación tras fallos para restablecer la replicación de SnapMirror para bases de datos-volúmenes.</block>
  <block id="145966bc8e38b26c384abaf4e450f6a7" category="section-title">Conmutación por error del servidor de la base de datos EC2 principal al servidor de la base de datos EC2 en espera debido a un fallo de la instancia informática de EC2</block>
  <block id="32d16eeba786f125b3c1e4750ad34e08" category="paragraph">NetApp recomienda ejecutar la conmutación por error manual o utilizar una solución de clúster de sistema operativo bien establecida que pueda requerir una licencia.</block>
  <block id="73bc97f640d8c1cae3fa624183216b41" category="inline-link-macro"><block ref="73bc97f640d8c1cae3fa624183216b41" category="inline-link-rx"></block></block>
  <block id="40285fa8e3dc4d66bfadb679f67dfde6" category="paragraph"><block ref="40285fa8e3dc4d66bfadb679f67dfde6" category="inline-link-macro-rx"></block></block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="list-text">Amazon EC2</block>
  <block id="68253b5715937494905ba0cb9db91d2e" category="inline-link-macro"><block ref="be48c1546d351a5e48dcf4f28738754b" category="inline-link-rx"></block></block>
  <block id="6dcfba5adaa9302bd59dd5a601b947a2" category="paragraph"><block ref="95bfcff1050e9160bb2bd645993e8c18" category="inline-link-macro-rx"></block></block>
  <block id="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-macro"><block ref="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-rx"></block></block>
  <block id="b898d8d538a4529dfdb2b8bf025323c2" category="paragraph"><block ref="b898d8d538a4529dfdb2b8bf025323c2" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">Soluciones de bases de datos en cloud híbridas con flujo de trabajo de recuperación ante desastres de SnapCenter</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">Flujo de trabajo de recuperación ante desastres</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">Anterior: Flujo de trabajo para ráfagas de desarrollo y pruebas al cloud.</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">Las empresas han adoptado el cloud público como recurso viable y destino para la recuperación ante desastres. SnapCenter hace que este proceso sea lo más sencillo posible. Este flujo de trabajo de recuperación ante desastres es muy similar al flujo de trabajo clonado, pero la recuperación de las bases de datos se ejecuta a través del último registro disponible replicado en el cloud para recuperar todas las transacciones de negocio posibles. No obstante, existen pasos adicionales de preconfiguración y posconfiguración específicos para la recuperación ante desastres.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">Clonar una base de datos de producción de Oracle en las instalaciones al cloud para realizar la recuperación ante desastres</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">Para validar que la recuperación tras clones se ejecuta en el último registro disponible, creamos una pequeña tabla de prueba e insertamos una fila. Los datos de prueba se recuperarían después de una recuperación completa para el último registro disponible.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Inicie sesión en SnapCenter como un ID de usuario de gestión de bases de datos para Oracle. Desplácese hasta la pestaña Resources, donde se muestran las bases de datos de Oracle que está protegida por SnapCenter.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Seleccione el grupo de recursos de registro de Oracle y haga clic en Backup Now para ejecutar manualmente un backup del registro de Oracle para vaciar la última transacción al destino en el cloud. En un supuesto de recuperación ante desastres real, la última transacción recuperable depende de la frecuencia de replicación del volumen de registro de la base de datos al cloud, que a su vez depende del objetivo de tiempo de recuperación o de la política de RPO de la empresa.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">SnapMirror asíncrono pierde datos que no los ha realizado al destino del cloud en el intervalo de backup del registro de la base de datos en un escenario de recuperación ante desastres. Para minimizar la pérdida de datos, es posible programar backups de registro más frecuentes. Sin embargo, existe un límite para la frecuencia de backup de registros que se puede lograr técnicamente.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">Seleccione el último backup de registro en los backups de reflejo secundario y monte el backup de registros.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">Seleccione el último backup completo de la base de datos y haga clic en Clone para iniciar el flujo de trabajo de clonado.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">Seleccione un ID de base de datos de clon único en el host.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">Aprovisionar un volumen de registro y montarlo en el servidor de recuperación ante desastres de destino para el área de recuperación flash de Oracle y registros en línea.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">El procedimiento de clonado de Oracle no crea un volumen de registro, que debe aprovisionarse en el servidor de recuperación ante desastres antes de realizar el clonado.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">Seleccione el host del clon de destino y la ubicación para colocar los archivos de datos, los archivos de control y los registros de recuperación.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">Seleccione las credenciales para el clon. Rellene los detalles de la configuración inicial de Oracle en el servidor de destino.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">Especifique los scripts que se van a ejecutar antes de clonar. Los parámetros de la base de datos se pueden ajustar si es necesario.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">Seleccione Until Cancel como opción de recuperación de manera que la recuperación se ejecute en todos los registros de archivos disponibles para recuperar la última transacción replicada en la ubicación del cloud secundario.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">Configure el servidor SMTP para la notificación por correo electrónico si es necesario.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">Resumen de los clones de recuperación ante desastres.</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">Las bases de datos clonadas se registran en SnapCenter inmediatamente después de la finalización del clon y, a continuación, se encuentran disponibles para la protección del backup.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Validación y configuración del clon posterior a la recuperación ante desastres para Oracle</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">Validar la última transacción de prueba que se ha vaciado, replicado y recuperado en la ubicación de recuperación ante desastres en el cloud.</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">Configure el área de recuperación de flash.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">Configure el listener de Oracle para el acceso de los usuarios.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">Divida el volumen clonado entre el volumen de origen replicado.</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">Invierta la replicación del cloud a las instalaciones y reconstruya el servidor de bases de datos en las instalaciones con fallos.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">La división de clones puede incurrir en un uso de espacio de almacenamiento temporal mucho mayor que el funcionamiento normal. Sin embargo, después de reconstruir el servidor de base de datos local, se puede liberar espacio adicional.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">Clonar una base de datos de producción de SQL en las instalaciones al cloud para recuperación ante desastres</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">De igual modo, para validar que la recuperación del clon SQL se ejecutó mediante el último registro disponible, creamos una tabla de pruebas pequeña e insertamos una fila. Los datos de prueba se recuperarían después de una recuperación completa en el último registro disponible.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">Inicie sesión en SnapCenter con un ID de usuario de administración de bases de datos para SQL Server. Desplácese hasta la pestaña Resources, que muestra el grupo de recursos de protección de SQL Server.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">Ejecute manualmente un backup de registros para vaciar la última transacción que se replique en el almacenamiento secundario en el cloud público.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">Seleccione el último backup completo de SQL Server para el clon.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">Establezca las opciones de configuración de clon, como Clone Server, Clone Instance, Clone Name y Mount. La ubicación de almacenamiento secundario donde se realiza la clonado se completa automáticamente.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">Seleccione todos los backups de registros que se aplicarán.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">Especifique cualquier script opcional que se ejecute antes o después del clonado.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">Especifique un servidor SMTP si se desea recibir una notificación por correo electrónico.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">Resumen de los clones de recuperación ante desastres. Las bases de datos clonadas se registran inmediatamente en SnapCenter y se encuentran disponibles para la protección de backups.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">Validación del clon y configuración posteriores a la recuperación ante desastres para SQL</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">Supervise el estado del trabajo de clonado.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">Validar que se ha replicado y recuperado la última transacción con todos los clones y la recuperación de archivos de registro.</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">Configurar un nuevo directorio de registro de SnapCenter en el servidor DR para el backup de registros de SQL Server.</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">¿Dónde obtener ayuda?</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">La comunidad de automatización de soluciones de NetApp admite el canal de Slack</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">Si necesita ayuda con esta solución y casos de uso, únase al <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> y busque el canal de automatización de soluciones para publicar sus preguntas o preguntas.</block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">Esta solución proporciona a NetApp y a los clientes instrucciones y directrices para configurar, operar y migrar bases de datos a un entorno de cloud híbrido mediante la herramienta basada en la interfaz gráfica de usuario de SnapCenter de NetApp y CVO del servicio de almacenamiento de NetApp en clouds públicos.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908: Soluciones de bases de datos para el cloud híbrido con información general de SnapCenter</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">Alan Cao, Felix Melligan, NetApp</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">Esta solución proporciona a NetApp y a los clientes instrucciones y directrices para configurar, operar y migrar bases de datos a un entorno de cloud híbrido mediante la herramienta basada en la interfaz gráfica de usuario de SnapCenter de NetApp y el servicio de almacenamiento de NetApp CVO en clouds públicos para los siguientes casos de uso:</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">Las operaciones de desarrollo y pruebas de bases de datos en el cloud híbrido</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">Recuperación ante desastres de bases de datos en el cloud híbrido</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">En la actualidad, muchas bases de datos empresariales siguen residiendo en centros de datos corporativos privados por motivos de rendimiento, seguridad u otros motivos. Esta solución de bases de datos de cloud híbrido permite a las empresas operar sus bases de datos principales in situ mientras utilizan un cloud público para operaciones de bases de datos de desarrollo y pruebas, así como para recuperación ante desastres, con el fin de reducir los costes operativos y de licencias.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Muchas bases de datos empresariales, como Oracle, SQL Server, SAP HANA, etc., lleve consigo elevados costes operativos y de licencias. Muchos clientes pagan una licencia única y los costes de soporte anuales en función del número de núcleos informáticos de su entorno de bases de datos, independientemente de si se utilizan núcleos para desarrollo, pruebas, producción o recuperación ante desastres. Es posible que muchos de estos entornos no se utilicen por completo a lo largo de todo el ciclo de vida de las aplicaciones.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">Las soluciones proporcionan a los clientes una opción para reducir potencialmente el número de núcleos con licencia mediante el movimiento de sus entornos de base de datos dedicados al desarrollo, la prueba o la recuperación ante desastres al cloud. Al usar el escalado de cloud público, la redundancia, la alta disponibilidad y un modelo de facturación basado en el consumo, el ahorro en costes de licencias y operaciones puede ser sustancial sin sacrificar la facilidad de uso o la disponibilidad de las aplicaciones.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">Más allá del posible ahorro en costes de licencias de bases de datos, el modelo de licencias de CVO basado en capacidad de NetApp permite a los clientes ahorrar costes de almacenamiento por GB al tiempo que les permite disfrutar de un alto nivel de capacidad de gestión de bases de datos que no se encuentra disponible con los servicios de almacenamiento de la competencia. El siguiente gráfico muestra una comparación de costes del almacenamiento de los servicios de almacenamiento populares disponibles en el cloud público.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">Esta solución demuestra que, al utilizar la herramienta de software basada en interfaz gráfica de usuario de SnapCenter y la tecnología SnapMirror de NetApp, las operaciones de bases de datos del cloud híbrido se pueden configurar, implementar y utilizar fácilmente.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">Los siguientes vídeos demostrarán que SnapCenter está en acción:</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">Backup de una base de datos de Oracle en un cloud híbrido con SnapCenter</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter: Clone EL PROCESO DE DESARROLLO y PRUEBAS en AWS Cloud para una base de datos de Oracle</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">En particular, aunque las ilustraciones de este documento muestran CVO como una instancia de almacenamiento objetivo en el cloud público, la solución también está completamente validada para la nueva versión del motor de almacenamiento de ONTAP FSX para AWS.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">Para probar usted mismo la solución y los casos de uso, puede solicitarse un laboratorio de NetApp bajo demanda SL10680 en el siguiente enlace: https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD: AWS - NW,SnapCenter(OnPrem)].</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">Siguiente: Arquitectura de las soluciones.</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="cffc2899d8dda4926e6563cef4e76608" category="summary">En esta sección, se ofrecen detalles sobre los factores que deben tenerse en cuenta al poner en marcha la base de datos de Oracle en máquinas virtuales de Azure y el almacenamiento de Azure NetApp Files.</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Factores que deben tenerse en cuenta para la instalación de bases de datos de Oracle</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">Anterior: Arquitectura de la solución.</block>
  <block id="3cc4738ed2ec2e682ab2002688fa632b" category="paragraph"><block ref="3cc4738ed2ec2e682ab2002688fa632b" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">Un cloud público proporciona diversas opciones de computación y almacenamiento y usar el tipo de motor de almacenamiento y instancia de computación correcto es un buen lugar para comenzar con la puesta en marcha de las bases de datos. También debe seleccionar configuraciones de computación y almacenamiento optimizadas para bases de datos de Oracle.</block>
  <block id="1a6a6241c0105da34f664d1e12534598" category="paragraph">En las siguientes secciones se describen las consideraciones fundamentales que se deben tener en cuenta al poner en marcha una base de datos de Oracle en el cloud público de Azure en una instancia de máquina virtual de Azure con almacenamiento de Azure NetApp Files.</block>
  <block id="c2b3b1e82aa97a133f0f6bbc12843085" category="section-title">Tipo y ajuste de tamaño de VM</block>
  <block id="4ca9712a9cd82ea80c8e225977fae1bb" category="inline-link-macro">Tamaños de las máquinas virtuales en Azure</block>
  <block id="7c4a17715675ccfa7ce507eea6098318" category="paragraph">Seleccionar el tipo y el tamaño adecuados de máquina virtual para optimizar el rendimiento de una base de datos relacional en un cloud público. Una máquina virtual de Azure ofrece una amplia variedad de instancias de computación que se pueden utilizar para alojar cargas de trabajo de bases de datos de Oracle. Consulte la documentación de Microsoft <block ref="d854faa84ea41d8819c42ca3741a3561" category="inline-link-macro-rx"></block> Para distintos tipos de máquinas virtuales de Azure y su tamaño. En general, NetApp recomienda el uso de una máquina virtual Azure de uso general para la puesta en marcha de bases de datos de Oracle de tamaño pequeño y mediano. Para la puesta en marcha de bases de datos de Oracle de mayor tamaño, es adecuado un Azure VM optimizado para la memoria. Con una mayor cantidad de RAM disponible, se puede configurar una mayor cantidad de SGA de Oracle o una caché flash inteligente para reducir la actividad de I/o física, lo que a su vez mejora el rendimiento de la base de datos.</block>
  <block id="84942a15b69259aab0ff7c2620afcaf6" category="inline-link-macro">TR-4780: Bases de datos de Oracle en Microsoft Azure</block>
  <block id="760a7b6c1bd4f6ebab6918d42feb4825" category="paragraph">Azure NetApp Files funciona como un montaje NFS conectado a una máquina virtual de Azure, que ofrece un mayor rendimiento y supera el límite de rendimiento de la máquina virtual optimizada para el almacenamiento con el almacenamiento local. Por lo tanto, ejecutar Oracle en Azure NetApp Files podría reducir el conteo de núcleos de CPU de Oracle con licencia y los costes de licencia. Consulte <block ref="b46cbe9b7b18b9ff8101a014c206465f" category="inline-link-macro-rx"></block>, Sección 7 - ¿Cómo funciona Oracle Licensing?</block>
  <block id="71b93ac808ac25bb511ebcbb028e32e8" category="paragraph">Otros factores a tener en cuenta son los siguientes:</block>
  <block id="592bc946b588ad0e83c05f528895bcc8" category="list-text">Elija la combinación de vCPU y RAM correcta en función de las características de la carga de trabajo. A medida que aumenta el tamaño de la RAM en la máquina virtual, también lo hace el número de núcleos vCPU. En algún momento debería haber un equilibrio, ya que las tarifas de licencia de Oracle se cobran por el número de núcleos vCPU.</block>
  <block id="fb9844eb7ee0ff341d6f7066f78918ff" category="list-text">Agregar espacio de intercambio a una máquina virtual. La puesta en marcha predeterminada de una máquina virtual de Azure no crea un espacio de intercambio, lo cual no es óptimo para una base de datos.</block>
  <block id="81afc696937e3786d5701212de79c536" category="section-title">Rendimiento de Azure NetApp Files</block>
  <block id="c7bc5faed38f5284386f25a6fc3a5752" category="paragraph">Los volúmenes Azure NetApp Files se asignan desde un pool de capacidad que el cliente debe aprovisionar en su cuenta de almacenamiento de Azure NetApp Files. Cada pool de capacidad está asignado de la siguiente manera:</block>
  <block id="3af20f4cec87eac026d0990a8a3f4169" category="list-text">A un nivel de servicio que define la funcionalidad de rendimiento general.</block>
  <block id="dd1fb66595c069d1b267fb8ca87e46eb" category="list-text">La capacidad de almacenamiento aprovisionada inicialmente o por niveles para ese pool de capacidad. Un nivel de calidad de servicio que define el rendimiento máximo general por espacio aprovisionado.</block>
  <block id="9dc50220b7e70511b5aeebb862346fad" category="paragraph">El nivel de servicio y la capacidad de almacenamiento que se aprovisiona inicialmente determinan el nivel de rendimiento de un volumen de base de datos de Oracle en particular.</block>
  <block id="59b8b6b998c3c0fcd2f1b107a68c290a" category="section-title">1. Niveles de servicio para Azure NetApp Files</block>
  <block id="f02ad1a8080bf1b50f8a15cb346ed483" category="paragraph">Azure NetApp Files admite tres niveles de servicio: Ultra, Premium y Standard.</block>
  <block id="3eec40f71dc46b07f32031c9703968ec" category="list-text">*Almacenamiento ultra.* este nivel proporciona hasta 128MiBps de rendimiento por 1 TIB de cuota de volumen asignada.</block>
  <block id="1b0fa75a1e8b815e03fb38f8a90d2a73" category="list-text">*Almacenamiento Premium.* este nivel proporciona hasta 64 MiBps de rendimiento por 1 TIB de cuota de volumen asignada.</block>
  <block id="00792f6ec40d3e2833834d90802a7aa5" category="list-text">*Almacenamiento estándar.* este nivel proporciona hasta 16 MiBps de rendimiento por 1 TIB de cuota de volumen asignada.</block>
  <block id="7a720602d11a97fd37964c9979e2f1a5" category="section-title">Pool de capacidad y calidad de servicio</block>
  <block id="36ac84521252c58a4238292bf0c21d92" category="paragraph">Cada uno de los niveles de servicio deseados tiene un costo asociado para la capacidad aprovisionada e incluye un nivel de calidad de servicio (QoS) que define el rendimiento máximo general para el espacio aprovisionado.</block>
  <block id="7a93db9cf06fd65415faf241927e2087" category="paragraph">Por ejemplo, un pool de capacidad única aprovisionado de 10 TIB con el nivel de servicio premium proporciona un rendimiento general disponible para todos los volúmenes de este pool de capacidad de 10x 64 Mbps, de modo que 640 MBps con 40,000 (16K) IOPS o 80,000 (8K) IOPS.</block>
  <block id="18dc8b2cbfb938a0ba32c141664fba0e" category="paragraph">El tamaño mínimo del pool de capacidad es 4 TIB. Es posible cambiar el tamaño de un pool de capacidad en incrementos de 1 TIB en respuesta a cambios en los requisitos de la carga de trabajo para gestionar las necesidades y los costos de almacenamiento.</block>
  <block id="8a26494cf7b0c3c3ca7cd38e89c068eb" category="section-title">3. Calcular el nivel de servicio en un volumen de base de datos</block>
  <block id="9ce59559a0b99338ee0bad0c153c961a" category="paragraph">El límite de rendimiento para un volumen de base de datos de Oracle se determina mediante una combinación de los siguientes factores: El nivel de servicio del pool de capacidad al que pertenece el volumen y la cuota asignada al volumen.</block>
  <block id="b87e1c6e437216fc2d3719c3dad93cb8" category="paragraph">El siguiente diagrama muestra cómo se calcula el límite de rendimiento de un volumen de base de datos de Oracle.</block>
  <block id="1624b6f83446cd1719c94bae28cbbeb7" category="inline-image-macro">Esta imagen muestra la ecuación aplicada a los tres niveles de capacidad para determinar el rendimiento bruto.</block>
  <block id="4d06f88a6f007c9821ac2ea5741860c5" category="paragraph"><block ref="4d06f88a6f007c9821ac2ea5741860c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ce3321601c29c87cb29ae9817843b8d" category="paragraph">En el ejemplo 1, se asigna a un volumen de un pool de capacidad con el nivel de almacenamiento Premium al que se asignan 2 TIB de cuota un límite de rendimiento de 128 TIB (2 TIB * 64 bits). Esta situación se aplica con independencia del tamaño del pool de capacidad o del consumo de volumen real.</block>
  <block id="69da5d3e48cc26414a9177d843bd55d9" category="paragraph">En el ejemplo 2, se asigna un límite de rendimiento de 6.25MiBps a un volumen de un pool de capacidad con el nivel de almacenamiento Premium al que se asignan 100 GIB de cuota (0.09765625TIB * 64MiBps). Esta situación se aplica con independencia del tamaño del pool de capacidad o del consumo de volumen real.</block>
  <block id="def2c2ae4fa72ee296eada07b44a0cc9" category="paragraph">Tenga en cuenta que el tamaño mínimo de volumen es de 100 GIB.</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">Distribución de almacenamiento y configuración</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">NetApp recomienda la siguiente distribución de almacenamiento:</block>
  <block id="78ad659ec79d8ee9e7432271167d18d3" category="list-text">Para bases de datos pequeñas, usando la distribución de un volumen único para todos los archivos de Oracle.</block>
  <block id="51672f1f7a65c28f28e5e113376309bd" category="inline-image-macro">En esta imagen, se muestran tres bases de datos (DB1, DB2 y DB3) que contienen cada una archivos de datos, registros de recuperación, registros de archivo y archivos de control, todo ello dentro de un único pool de capacidad.</block>
  <block id="c12ff13215c1f6de4c6dad4b8a475398" category="paragraph">[Underline]#*Vídeos para la base de datos de SQL Server*#</block>
  <block id="b4aaa3fbc0d85cfa527c7cb7f59187fd" category="video-title">Ponga en marcha SQL Server en AWS EC2 mediante Amazon FSX para ONTAP de NetApp</block>
  <block id="785e5e204bcb101e73976a8c3ad22887" category="paragraph">Para obtener más información sobre este proceso, vea el siguiente vídeo:</block>
  <block id="c91dcf7c665570f3603fa32cb3a8c644" category="list-text">Utilice el nivel Premium o estándar para cargas de trabajo condicionadas por la capacidad y Ultra Tier para cargas de trabajo condicionadas por el rendimiento cuando sea necesario, además de complementar el almacenamiento VSAN predeterminado.</block>
  <block id="60ce6ba5fcd445684c9982883f234b8c" category="paragraph">Para obtener más información acerca del rendimiento de Azure NetApp Files Volume por tamaño o cuota, consulte <block ref="62d66f64400ed6e4ba5e012bbe140a31" category="inline-link-macro-rx"></block>.</block>
  <block id="a01ca5d7b443422e0bc655c4d457707f" category="inline-link-macro">Vínculo de Microsoft</block>
  <block id="37028a2422f1f35ed56a07f1003896d1" category="admonition">El volumen de Azure NetApp Files puede adjuntarse a su cloud privado mediante el portal de Azure. Siga este <block ref="c627cf01abf17d7b29d4322a9f16e21d" category="inline-link-macro-rx"></block> Para el enfoque paso a paso del uso del portal de Azure para montar un almacén de datos Azure NetApp Files.</block>
  <block id="7dfe1e95238cceec93165ab8ff605d28" category="paragraph">Consulte este apartado <block ref="06f6144b70bdd3c5a376672271533656" category="inline-link-macro-rx"></block> para obtener pruebas de rendimiento detalladas que pueden utilizarse durante un ejercicio de configuración.</block>
  <block id="b1404b6b3614fe54358fb1bdb8bd294a" category="list-text">Use el nivel Premium o estándar para volúmenes de almacenes de datos para obtener un rendimiento y una capacidad óptimos. Si se requiere rendimiento, se puede utilizar Ultra Tier.</block>
  <block id="1048ee221e43763386324d16721681fc" category="list-text">Para los requisitos de montaje de invitado, utilice los volúmenes de nivel Standard o Premium y destinados a los requisitos de uso compartido de archivos para las máquinas virtuales invitadas.</block>
  <block id="e421004f0e3e2303f272ef4b0fa6c089" category="list-text">Para volúmenes Azure NetApp Files con funciones de red "estándar", es compatible ExpressRoute FastPath. Cuando se habilita esta opción, FastPath envía tráfico de red directamente a los volúmenes Azure NetApp Files, saltando la puerta de enlace, lo que proporciona un ancho de banda mayor y una latencia menor.</block>
  <block id="80a4a92a47a4b87bb9d0fcf9ded1dda8" category="list-text">VAAI no está habilitado.</block>
  <block id="94e2529c9624e06356bacdc7dc76dab9" category="admonition">Póngase en contacto con los arquitectos de soluciones de NetApp o de Microsoft de su región para obtener información adicional sobre el uso de almacenes de datos ANF.</block>
  <block id="a8a748d1990bd3dbc648c22396cec9c4" category="admonition">VMware Cloud en AWS es compatible con las puestas en marcha de FSX para ONTAP, tanto de Multi-AZ como de Single-AZ.</block>
  <block id="c3b1da56e0792b4ce28bc91a4bf79841" category="inline-link-macro">Migración de cargas de trabajo mediante VMware HCX al almacén de datos NFS de Cloud Volume Service de NetApp</block>
  <block id="c2dd2858771476e1bd26526be2c1f5ad" category="list-text"><block ref="c2dd2858771476e1bd26526be2c1f5ad" category="inline-link-macro-rx"></block></block>
  <block id="7ca47d49ee6c57c993203315ea11c82b" category="doc">Migre cargas de trabajo al almacén de datos de Cloud Volume Service de NetApp en Google Cloud VMware Engine mediante la guía de inicio rápido de VMware HCX</block>
  <block id="925d41ba352b91ef0de674e109988a23" category="section-title">Descripción general: Migrar máquinas virtuales con VMware HCX, almacenes de datos de Cloud Volume Service de NetApp y Google Cloud VMware Engine (GCVE)</block>
  <block id="ecca6d9dd6ca6c76191faa472f8c6df9" category="paragraph">Uno de los casos de uso más comunes de los almacenes de datos de Google Cloud VMware Engine y Cloud Volume Service es la migración de las cargas de trabajo de VMware. HCX de VMware es la opción preferida y ofrece diversos mecanismos de migración para mover las máquinas virtuales (VM) locales y sus datos a los almacenes de datos NFS de Cloud Volume Service.</block>
  <block id="d5230db8260d991194ad332af34aa9de" category="paragraph">VMware HCX es principalmente una plataforma de migración diseñada para simplificar la migración de aplicaciones, el reequilibrado de las cargas de trabajo e incluso la continuidad de negocio entre clouds. Se incluye como parte de Google Cloud VMware Engine Private Cloud y ofrece muchas formas de migrar cargas de trabajo y se puede utilizar para operaciones de recuperación ante desastres.</block>
  <block id="cac5c7468f43bdedfbaa5b47e384516c" category="paragraph">Este documento proporciona orientación paso a paso para aprovisionar el almacén de datos de Cloud Volume Service seguido de la descarga, la puesta en marcha y la configuración de VMware HCX, incluidos todos sus componentes principales en las instalaciones y Google Cloud VMware Engine, que incluye interconexión, extensión de red y optimización de WAN para habilitar diversos mecanismos de migración de máquinas virtuales.</block>
  <block id="256044a3a14b99a48569af0ee614f2c4" category="admonition">VMware HCX funciona con cualquier tipo de almacén de datos, ya que la migración se realiza a nivel de equipo virtual. Por lo tanto, este documento es aplicable a clientes existentes de NetApp y clientes que no son de NetApp que planeen poner en marcha Cloud Volume Service con Google Cloud VMware Engine para una puesta en marcha de cloud VMware rentable.</block>
  <block id="b0568534d9aa25692e3a5fe6337361bc" category="paragraph">Esta lista contiene los pasos de alto nivel necesarios para emparejar y migrar las máquinas virtuales a HCX Cloud Manager en el lado de Google Cloud VMware Engine desde HCX Connector on-premises:</block>
  <block id="08ac9dd8c46a01de111ff552302c4b8b" category="list-text">Prepare HCX a través del portal Google VMware Engine.</block>
  <block id="c51c3de337c64144b065b508d7092f70" category="list-text">Empareje el conector VMware HCX en las instalaciones con Google Cloud VMware Engine HCX Cloud Manager.</block>
  <block id="b8da85496a56d9f8f2c4db60c06b6c4a" category="paragraph">Antes de empezar, asegúrese de que se cumplan los siguientes requisitos previos. Para obtener más información, consulte este tema<block ref="d195855fe41d7993983c9e07318b9bad" category="inline-link-rx"></block>. Una vez que se hayan establecido los requisitos previos, incluida la conectividad, descargue la clave de licencia de HCX del portal Google Cloud VMware Engine. Después de descargar el instalador de OVA, continúe con el proceso de instalación como se describe a continuación.</block>
  <block id="e2f64bf47a1540374c40a3ede73573e5" category="admonition">HCX Advanced es la opción predeterminada y VMware HCX Enterprise Edition también está disponible a través de un ticket de soporte y se admite sin coste adicional. Consulte<block ref="d860d3a39c377ffee7e9262276d5a062" category="inline-link-rx"></block></block>
  <block id="8cea371309574d6004c96292961aae25" category="inline-link">Vínculo de Google</block>
  <block id="2fe1711b46889920c53ebb512b61bc78" category="list-text">Utilice un centro de datos definido por software (SDDC) de Google Cloud VMware Engine o cree un cloud privado utilizando este método<block ref="e829d3b8e1188066e830ce55cc4a4e51" category="inline-link-rx"></block> o esto<block ref="a00f1cbf0fed787208cc1bff752e650f" category="inline-link-rx"></block>.</block>
  <block id="792178f6051d02890db289c3d249504a" category="inline-link">Configure una conexión de Cloud VPN o de Cloud Interconnect</block>
  <block id="136020259e42699a5f3259ade2d1a34f" category="list-text">La migración de equipos virtuales y datos asociados desde el centro de datos integrado con VMware vSphere en las instalaciones requiere conectividad de red del centro de datos al entorno SDDC. Antes de migrar cargas de trabajo,<block ref="bef4838acfa84f7c195dab1fed38f189" category="inline-link-rx"></block> entre el entorno local y el cloud privado correspondiente.</block>
  <block id="b62ace404956042129e3b88bdf88cc9d" category="list-text">La ruta de red desde el entorno local de VMware vCenter Server al cloud privado de Google Cloud VMware Engine debe admitir la migración de las máquinas virtuales mediante vMotion.</block>
  <block id="20ced0e16abf47f28e1313f368ad6f6f" category="list-text">Asegúrese de que es necesario<block ref="75de7fce953864ac8abf1081d395e485" category="inline-link-rx"></block> Se permiten para el tráfico de vMotion entre la instancia local de vCenter Server y SDDC vCenter.</block>
  <block id="2991589cdf3c2d6d60db9953585e1b04" category="list-text">El volumen de NFS de Cloud Volume Service debe montarse como un almacén de datos en Google Cloud VMware Engine. Siga los pasos detallados en este documento<block ref="5c088b3a89e196aaeb81f75ec6428544" category="inline-link-rx"></block> Para conectar almacenes de datos de Cloud Volume Service a los hosts de Google Cloud VMware Engines.</block>
  <block id="4d74daf8e004df493e26c50161d35bd9" category="paragraph">Para realizar las pruebas, el entorno de laboratorio de las instalaciones que se emplean para esta validación se conectó a través de una VPN de cloud que permite la conectividad local con Google Cloud VPC.</block>
  <block id="44197d2707e0d62a7cdddb22b96b5d73" category="paragraph"><block ref="44197d2707e0d62a7cdddb22b96b5d73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdd8ea25a7e8ed9b55cbe0a3d16b342d" category="paragraph">Para obtener un diagrama más detallado del HCX, consulte<block ref="7d6a057cc94389224fa6745cc76b1870" category="inline-link-rx"></block></block>
  <block id="cd7d4a329d381d6c2399222be4a728d6" category="example-title">Paso 1: Preparación del HCX a través del portal Google VMware Engine</block>
  <block id="5435b8e0738b76228bad99efecb45790" category="paragraph">El componente DE HCX Cloud Manager se instala automáticamente a medida que aprovisiona el cloud privado con VMware Engine. Para preparar el emparejamiento de sitios, lleve a cabo los siguientes pasos:</block>
  <block id="f6f646bebf3c14227b9b610041749d2b" category="list-text">Inicie sesión en el portal Google VMware Engine e inicie sesión en HCX Cloud Manager.</block>
  <block id="f3c4e020173d4055af3d73eabb546a5f" category="inline-image-macro">Acceso A la consola HCX con enlace en el recurso GCVE</block>
  <block id="d481d49ad5e07c065daa1b652e1e93f6" category="inline-image-macro">Acceso A la consola HCX con enlace FQDN</block>
  <block id="1509189c3a021030c9c75afd5e0ee142" category="paragraph">Puede iniciar sesión en la consola HCX haciendo clic en el enlace de la versión HCX<block ref="e0eabfd77e9b6a166bd62bce317f2ca6" category="inline-image-macro-rx" type="image"></block>O bien, haga clic en HCX FQDN en la pestaña vSphere Management Network.<block ref="1bc7b537d1e927f2f5e06674a9fb9636" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72580ca988ce9234d221d19195a8ced9" category="list-text">En HCX Cloud Manager, vaya a *Administración &gt; actualizaciones del sistema*.</block>
  <block id="4477d36b1c0d580b9493616b9a3cdc6a" category="inline-image-macro">Solicitar enlace de descarga</block>
  <block id="e3428ddcd1ea8611a819b5a63134abdd" category="list-text">Haga clic en *solicitar enlace de descarga* y descargue el archivo OVA.<block ref="b27b0af334d354a85d901dbf7f557880" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b2574bff5f52ebae3e52462b6f64628" category="list-text">Actualice HCX Cloud Manager a la última versión disponible desde la interfaz de usuario de HCX Cloud Manager.</block>
  <block id="71c11944a5e7c7a2e01d85bf931a4e0c" category="paragraph">Para que el conector local se conecte al HCX Manager en Google Cloud VMware Engine, asegúrese de que los puertos de firewall adecuados están abiertos en el entorno local.</block>
  <block id="cded3ab78e1131b2cb252673847fc8cd" category="list-text">Haga que la ova se descargue de la consola HCX en Google Cloud VMware Engine como se indica en el paso anterior.</block>
  <block id="80177ed47e2799b2f8133ec987c4f413" category="paragraph"><block ref="80177ed47e2799b2f8133ec987c4f413" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f35d393de16f7f328d28c3c3f9a36fd" category="paragraph">Para obtener instrucciones paso a paso, consulte<block ref="6281ad4977a05e5987f07e864fefe4fe" category="inline-link-rx"></block>.</block>
  <block id="3981acf431a0cb2b387f1fc62e246114" category="paragraph">Después de implementar el OVA del conector HCX de VMware en las instalaciones e iniciar el dispositivo, lleve a cabo los siguientes pasos para activar el conector HCX. Genere la clave de licencia desde el portal Google Cloud VMware Engine y actívela en VMware HCX Manager.</block>
  <block id="842413b7e215b2d5b82a5bb3dd7a07cd" category="inline-image-macro">Descargar la licencia HCX</block>
  <block id="61b61b56e3a9ddaa25f900492dbfaafc" category="list-text">En el portal VMware Engine, haga clic en Resources, seleccione la nube privada y *haga clic en el icono de descarga en HCX Manager Cloud Version*.<block ref="be9330ae20074d9fd27022c3077c5923" category="inline-image-macro-rx" type="image"></block>Abra el archivo descargado y copie la cadena de claves de licencia.</block>
  <block id="8680173d99521ba5a429ed524d3615e3" category="admonition">Utilice hcxmanagerIP y la contraseña definidos durante la implementación de OVA.</block>
  <block id="35c93ae128c86187e819ac86d8df4979" category="list-text">En *Configurar SSO/PSC*, proporcione el FQDN o la dirección IP del controlador de servicios de plataforma (PSC) y haga clic en *continuar*.</block>
  <block id="6098ad379dba0c94396b9b690b83b1b0" category="admonition">Para el PSC integrado, introduzca el FQDN de VMware vCenter Server o la dirección IP.</block>
  <block id="09bf9812f77e2e14861b7f3360ca026c" category="paragraph"><block ref="09bf9812f77e2e14861b7f3360ca026c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b23a293b550e17ca6e836b05c01b4a76" category="example-title">Paso 4: Emparejar el conector VMware HCX en las instalaciones con Google Cloud VMware Engine HCX Cloud Manager</block>
  <block id="47234b871b1edd33168f7394e72a5b4d" category="paragraph">Después de implementar y configurar el conector HCX en el vCenter local, establezca la conexión con Cloud Manager añadiendo el emparejamiento. Para configurar el emparejamiento de sitios, lleve a cabo los siguientes pasos:</block>
  <block id="594e3fbccf355af479f921ff2a455e68" category="list-text">Para crear una pareja de sitios entre el entorno local de vCenter y el motor SDDC de Google Cloud VMware, inicie sesión en la instancia local de vCenter Server y acceda al nuevo complemento HCX vSphere Web Client.</block>
  <block id="bf29c65588093243bdcd92d7e57d228c" category="paragraph"><block ref="bf29c65588093243bdcd92d7e57d228c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b3c5cdedf84c785d5ee65ca00324e36" category="admonition">Introduzca la dirección URL o dirección IP de HCX Cloud Manager de Google Cloud Engine y las credenciales para el usuario con privilegios de rol de propietario de cloud para acceder al cloud privado.</block>
  <block id="6b5c33ae4600df59658bcd86a24ca532" category="inline-image-macro">Captura de pantalla URL o dirección IP y credenciales para el rol CloudOwner.</block>
  <block id="b7b6a499bbb533c0e3da098fa71d75c8" category="paragraph"><block ref="b7b6a499bbb533c0e3da098fa71d75c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3874f23d22312a1be0f07b98dda866c" category="paragraph"><block ref="a3874f23d22312a1be0f07b98dda866c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="593c226b2f1fa412557c01630aaaafa0" category="paragraph"><block ref="593c226b2f1fa412557c01630aaaafa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="575a0d0e1243eeff47338ea176157139" category="inline-image-macro">Captura de pantalla del perfil de red.</block>
  <block id="47a6f72e73b15b7be0f3c4cf577c9229" category="paragraph"><block ref="47a6f72e73b15b7be0f3c4cf577c9229" category="inline-image-macro-rx" type="image"></block></block>
  <block id="179a1380fec15d2ca58ae44d36bc70ea" category="list-text">Cree la malla de servicio seleccionando la pestaña *malla de servicio* en la opción *interconexión* y seleccione los sitios SDDC en las instalaciones y GCVE.</block>
  <block id="4200f06936ac63230a0663a772209a07" category="paragraph"><block ref="4200f06936ac63230a0663a772209a07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="347a982d83a0b2cce2d1ec814a70ae8f" category="inline-image-macro">Captura de pantalla de los dispositivos HCX en la página vSphere Client Interconnect.</block>
  <block id="26c83c715efad97126cacdaebf25d274" category="paragraph"><block ref="26c83c715efad97126cacdaebf25d274" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070b97376b0c0aea0c9cb598600c4662" category="paragraph">Las cargas de trabajo se pueden migrar de manera bidireccional entre los centros de datos de GCVE y sus instalaciones mediante diversas tecnologías de migración de VMware HCX. Los equipos virtuales se pueden mover hacia y desde entidades activadas por HCX de VMware mediante varias tecnologías de migración, como la migración masiva de HCX, HCX vMotion, migración en frío de HCX, el asistente de replicación de HCX vMotion (disponible con la edición de HCX Enterprise) y la migración asistida por SO HCX (disponible con la edición de HCX Enterprise).</block>
  <block id="a50268e48a4ee751d804978922edf189" category="paragraph">Para obtener más información sobre varios mecanismos de migración de HCX, consulte<block ref="78adb493f3638835899da003743379e3" category="inline-link-rx"></block>.</block>
  <block id="de5218d95fb66ad99c822109709a45af" category="paragraph">*HCX vMotion*</block>
  <block id="803853313afe589d091d3f55583d78c2" category="paragraph">En esta sección se describe el mecanismo HCX vMotion. Esta tecnología de migración utiliza el protocolo VMware vMotion para migrar un equipo virtual a GCVE. La opción de migración de vMotion se utiliza para migrar el estado de las máquinas virtuales de una única máquina virtual a la vez. No se produce ninguna interrupción del servicio durante este método de migración.</block>
  <block id="6b253c8fd6849183f558040da38608cb" category="paragraph"><block ref="6b253c8fd6849183f558040da38608cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="844c529dbe1866abc23447f68eb60ba6" category="list-text">En el asistente Migrate Virtual Machine, seleccione Remote Site Connection (GCVE de destino).</block>
  <block id="4e862b96a802868c38004aa7c404252b" category="paragraph"><block ref="4e862b96a802868c38004aa7c404252b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2a3abee640eaa37034e3ce3f7b7075e" category="list-text">Actualice los campos obligatorios (clúster, almacenamiento y red de destino), haga clic en Validate.</block>
  <block id="dbccaf1da09c1555918b6548737f4c62" category="paragraph"><block ref="dbccaf1da09c1555918b6548737f4c62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a88d0b48c0e4e339e4f73353d906d12" category="admonition">La transferencia de vMotion captura la memoria activa de la máquina virtual, su estado de ejecución, su dirección IP y su dirección MAC. Para obtener más información sobre los requisitos y las limitaciones de HCX vMotion, consulte<block ref="23e132bfd0fa1c0804ce8b87a8fad5cd" category="inline-link-rx"></block>.</block>
  <block id="9292100550c5fda83387e2e78b8a2a2a" category="paragraph"><block ref="9292100550c5fda83387e2e78b8a2a2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38f70a328b4ae90f9650bc4c029b6a3f" category="admonition">El almacén de datos CVS NFS de destino debe tener espacio suficiente para manejar la migración.</block>
  <block id="2de1e2776c8a8d3b752e50dc8c6550df" category="paragraph">Tanto si su objetivo es el cloud híbrido como el cloud, y los datos residen en un almacenamiento de cualquier tipo o proveedor en las instalaciones, Cloud Volume Service y HCX proporcionan opciones excelentes para poner en marcha y migrar las cargas de trabajo de las aplicaciones, a la vez que reduce el TCO porque los requisitos de datos se adaptan perfectamente a la capa de la aplicación. Sea cual sea el caso práctico, elija Google Cloud VMware Engine junto con Cloud Volume Service para obtener rápidamente las ventajas del cloud, una infraestructura consistente y operaciones en las instalaciones y en varios clouds, portabilidad bidireccional de cargas de trabajo, y capacidad y rendimiento de clase empresarial. Se trata del mismo proceso y procedimientos que ya conoce que se utiliza para conectar el almacenamiento y migrar máquinas virtuales mediante la replicación de VMware vSphere, VMware vMotion o incluso la copia de archivos de red (NFC).</block>
  <block id="6bb8d723218f4efa76cd05165c603ac6" category="list-text">Ahora puede usar Cloud Volume Service como almacén de datos en Google Cloud VMware Engine SDDC.</block>
  <block id="06b37831abeee3229c61a3285dc4100c" category="list-text">Puede migrar datos fácilmente desde las instalaciones a un almacén de datos de Cloud Volume Service.</block>
  <block id="dcb763cc64570798740f3e41b84fff0e" category="list-text">Puede ampliar y reducir fácilmente el almacén de datos de Cloud Volume Service para satisfacer los requisitos de capacidad y rendimiento durante la actividad de migración.</block>
  <block id="267029140dfbe181dd69e7d084de9b69" category="section-title">Vídeos de Google y VMware como referencia</block>
  <block id="e35dee203b7c81af1f3954054112ba15" category="example-title">De Google</block>
  <block id="50144090c2258cae139ecf6022e7367b" category="inline-link-macro">Despliegue el conector HCX con GCVE</block>
  <block id="b7b1de0b057bbef976725c6fff3da9b9" category="list-text"><block ref="b7b1de0b057bbef976725c6fff3da9b9" category="inline-link-macro-rx"></block></block>
  <block id="328f11633999c58a7b282b8632e2797d" category="inline-link-macro">Configure HCX ServiceMesh con GCVE</block>
  <block id="79cb5f4e657f45df30765c695fd1925a" category="list-text"><block ref="79cb5f4e657f45df30765c695fd1925a" category="inline-link-macro-rx"></block></block>
  <block id="7a749829f023d0ee25c026f4f6bbba9a" category="inline-link-macro">Migrar VM con HCX a GCVE</block>
  <block id="a53a9cd13cd53b632a558fc3657092ab" category="list-text"><block ref="a53a9cd13cd53b632a558fc3657092ab" category="inline-link-macro-rx"></block></block>
  <block id="252de7413389db6514f76f43d66fd8e3" category="example-title">De VMware</block>
  <block id="13e623e9a14240dd859556650e9b531a" category="inline-link-macro">Despliegue del conector HCX para GCVE</block>
  <block id="d323fc5e6199a5240de090ee56887d79" category="list-text"><block ref="d323fc5e6199a5240de090ee56887d79" category="inline-link-macro-rx"></block></block>
  <block id="691fd2fc5f5666a82025c09044b4227e" category="inline-link-macro">Configuración DE ServiceMesh DE HCX para GCVE</block>
  <block id="1d057bc0c304f69e3c2b912a056d3823" category="list-text"><block ref="1d057bc0c304f69e3c2b912a056d3823" category="inline-link-macro-rx"></block></block>
  <block id="f27a9b33e86b3a166fd93f5581d2fd88" category="inline-link-macro">Migración de carga de trabajo HCX a GCVE</block>
  <block id="4ac5ecc506f53d87d5405d25cca52053" category="list-text"><block ref="4ac5ecc506f53d87d5405d25cca52053" category="inline-link-macro-rx"></block></block>
  <block id="b5375bdf07e11b544fe361d241528cd4" category="list-text">Documentación de Google Cloud VMware Engine</block>
  <block id="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link"><block ref="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link-rx"></block></block>
  <block id="c403f0f0cd3710f7ff6a40c31193feef" category="paragraph"><block ref="c403f0f0cd3710f7ff6a40c31193feef" category="inline-link-rx"></block></block>
  <block id="19e28367f565bf74c0b929f09ffdeb90" category="list-text">Documentación de Cloud Volume Service</block>
  <block id="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link"><block ref="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link-rx"></block></block>
  <block id="bc99ee2635f4933c3a1ae1a2d397722f" category="paragraph"><block ref="bc99ee2635f4933c3a1ae1a2d397722f" category="inline-link-rx"></block></block>
  <block id="92cbc7969081067fa7972b77f8b4c803" category="inline-link"><block ref="92cbc7969081067fa7972b77f8b4c803" category="inline-link-rx"></block></block>
  <block id="dccf3c5043aaab19b4c6eed2cd51be7e" category="paragraph"><block ref="dccf3c5043aaab19b4c6eed2cd51be7e" category="inline-link-rx"></block></block>
  <block id="16844b6a71b4ccf3790079518b5286c4" category="sidebar">Migre cargas de trabajo al almacén de datos NFS de Cloud Volume Service de NetApp mediante VMware HCX</block>
  <block id="204c2f72244c7b6bb96fa507fcbfdde0" category="sidebar">Migrar cargas de trabajo al almacén de datos NFS de Cloud Volume Service mediante VMware HCX</block>
  <block id="fbaad71632f1f86a6aec0eb25bf981d7" category="list-text">Para obtener un rendimiento óptimo del almacenamiento, aprovisione una capacidad del sistema de archivos de hasta 1,35 veces mayor que el tamaño del uso total de la base de datos.</block>
  <block id="697ac904ffe5f281c2b20466e99a46ec" category="paragraph"><block ref="697ac904ffe5f281c2b20466e99a46ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ea2cbade31de8af1dca89093e681575" category="paragraph">En el siguiente vídeo se muestran algunas de las funcionalidades descritas en este documento:</block>
  <block id="f1633856fe511230f9c635e7a1c53316" category="inline-link-macro">Vídeo: Puesta en marcha de Trident en el clúster Anthos 1.14</block>
  <block id="cf1f8100313c03361151f9caa6715bac" category="paragraph"><block ref="cf1f8100313c03361151f9caa6715bac" category="inline-link-macro-rx"></block></block>
  <block id="1780877562a197bb240c255e7ebc64a6" category="paragraph"><block ref="1780877562a197bb240c255e7ebc64a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f281f23fa0eaa9fab3de640f4c4ed29" category="cell">1.14</block>
  <block id="b2311a2cf7a04db2bfe860c3fa17635c" category="cell">Componente de hardware</block>
  <block id="7b42b4827c459034b51ee8ce9f497ca3" category="cell">switch (red de datos)</block>
  <block id="d5cbf018e46e897c3774dc4576d35dbe" category="cell">switch (red de gestión)</block>
  <block id="4c6ba3c2ecfdab7b2b5151a4715c51c0" category="cell">Sistema de almacenamiento AFF</block>
  <block id="eba1f3287bdc33dfa25c084b5e15a4c5" category="cell">9.12.1</block>
  <block id="8dfda84fc7f59655e20a770603bf9231" category="cell">23.01</block>
  <block id="a6eee2bc9df13513ff08680b88b5140c" category="paragraph">Durante la validación de la plataforma Anthos Ready realizada por NetApp, el entorno de laboratorio se creó en función del siguiente diagrama, lo que nos permitió probar varios escenarios utilizando varios back-ends de almacenamiento de ONTAP de NetApp.</block>
  <block id="ba18949144254244b0c22a4dda957809" category="paragraph"><block ref="ba18949144254244b0c22a4dda957809" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link"><block ref="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link-rx"></block></block>
  <block id="ce31d50048cf83e159c11cdf9571f300" category="paragraph"><block ref="ce31d50048cf83e159c11cdf9571f300" category="inline-link-rx"></block></block>
  <block id="e961adb60321df286b916effec21c9d5" category="paragraph">NetApp cuenta con varias plataformas de almacenamiento cualificadas con nuestro orquestador de almacenamiento Astra Trident para aprovisionar almacenamiento para las aplicaciones puestas en marcha como contenedores.</block>
  <block id="82dc86caf99045e3dfd059ffe973d587" category="list-text">NetApp Cloud Volumes Service (GCP) y Azure NetApp Files proporcionan almacenamiento basado en archivos en el cloud.</block>
  <block id="e0219edd422866b0cdb0aaa5f2b9352e" category="list-text">Amazon FSX para ONTAP de NetApp es un servicio totalmente gestionado en AWS que proporciona almacenamiento para casos prácticos basados en archivos.</block>
  <block id="8490bfef5919608f9d8461a6bb270666" category="paragraph">NetApp ha mantenido un cumplimiento regular trimestralmente con solicitudes para validar el orquestador de almacenamiento compatible con CSI de Astra Trident y nuestro sistema de almacenamiento ONTAP con versiones de Anthos.</block>
  <block id="594e1ec3daa27e540baa061f731f028f" category="cell">ONTAP 9.12.1</block>
  <block id="7f7813d8ff1a7fae9bca0ef452fb1346" category="cell">Multiwriter, expansión de volumen, instantáneas, PVCDataSource</block>
  <block id="8c56d327dfefc3dfd3c4c4fbe25a8bd1" category="cell">Bloque sin procesar, expansión de volumen, instantáneas, PVCDataSource</block>
  <block id="9fe6d7d50b2c6958117a19834e038c82" category="cell">1.13</block>
  <block id="775d4bb28d257a6aa23992563a82c458" category="cell">22.10</block>
  <block id="74eb178224c5fa701fbcd96998feaafe" category="cell">ONTAP 9.9.1</block>
  <block id="e0076fd5294e757abc41b2328ed8c57d" category="cell">Elemento 12.3</block>
  <block id="7f35d44665a62879611c82424828f0fd" category="inline-link-macro">Siguiente: Opciones de configuraciones avanzadas para Anthos.</block>
  <block id="bff5cad56bec414a2d44f250d8a8ad3d" category="paragraph"><block ref="bff5cad56bec414a2d44f250d8a8ad3d" category="inline-link-macro-rx"></block></block>
  <block id="001a38f118eab6df015a51079735d9c9" category="paragraph">Para obtener más información sobre Anthos, consulte el sitio web de Anthos que se encuentra<block ref="984918f1ee4e70aa6181e0564d0768e7" category="inline-link-rx"></block>.</block>
  <block id="dbadbc59fa29afd33e371d5285fde4cf" category="paragraph">Banu Sundhar y Suresh Thoppay, NetApp</block>
  <block id="94806f6a6daed15d3a6ea4f0146cf8ee" category="paragraph">NetApp cuenta con varios sistemas de almacenamiento perfectos para centros de datos empresariales y para puestas en marcha de cloud híbrido. La cartera de NetApp incluye ONTAP, Cloud Volumes ONTAP, Cloud Volumes Service, Azure NetApp Files y FSxN de NetApp para los sistemas de almacenamiento ONTAP de NetApp, todos los cuales pueden proporcionar almacenamiento persistente para aplicaciones en contenedores.</block>
  <block id="57f64c5c85667657a2c67b472c545e5a" category="paragraph">Consulte<block ref="0c665fc00d0d39d9ca9d157ca926b271" category="inline-link-rx"></block> para conocer la matriz de soporte de versiones validadas.</block>
  <block id="8986a7e5e5d0b79b5251a648f9f67ef6" category="paragraph">Astra Trident es un orquestador de almacenamiento de código abierto y totalmente compatible para contenedores y distribuciones de Kubernetes, incluido Anthos. Trident funciona con toda la cartera de almacenamiento de NetApp, incluido ONTAP de NetApp, y también admite conexiones NFS e iSCSI. Trident acelera el flujo de trabajo de DevOps al permitir que los usuarios finales aprovisionen y gestionen el almacenamiento desde sus sistemas de almacenamiento de NetApp sin necesidad de intervención del administrador de almacenamiento.</block>
  <block id="5be08e29583206baf8c89778e711c743" category="paragraph"><block ref="5be08e29583206baf8c89778e711c743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e79464fd5ecc0abac7a7f768780ea0f4" category="paragraph">Encontrará la documentación de la última versión de Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>. Existe una matriz de compatibilidad con la versión de Trident probada en la que se puede encontrar la distribución de Kubernetes<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="dee50dd9c6fd0b4d11789e8a074455c0" category="paragraph">Para obtener más información sobre la instalación de Astra Trident, consulte<block ref="df28848dc0c60e349970187bfd75a0df" category="inline-link-rx"></block>.</block>
  <block id="6cfca408e9e3b476e6440302dbe3a550" category="section-title">Cree un back-end de sistema de almacenamiento</block>
  <block id="6d82ca16bfbce249e1f9ea541bff13ff" category="inline-link-macro">Cree un back-end.</block>
  <block id="1e449644660ede384d0f8370105c8852" category="paragraph">Una vez finalizada la instalación del operador de Astra Trident, debe configurar el back-end para la plataforma de almacenamiento específica de NetApp que esté usando. Siga el siguiente enlace para continuar con la instalación y configuración de Astra Trident.<block ref="0510ad325b52db9e306380d77ace3c72" category="inline-link-macro-rx"></block></block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Cree una clase de almacenamiento</block>
  <block id="69dd4ff02a34defa6f31ed5f8bb209f6" category="paragraph">Después de crear el back-end, debe crear una clase de almacenamiento que los usuarios de Kubernetes especifiquen cuando quieran un volumen. Los usuarios de Kubernetes aprovisionan volúmenes mediante reclamaciones de volumen persistente (RVP) que especifican una clase de almacenamiento por nombre. Siga el enlace siguiente para crear una clase de almacenamiento.<block ref="034759ff187a64d8fb38f587d14777c0" category="inline-link-macro-rx"></block></block>
  <block id="50cbd0d28725f746b370915ee052232c" category="section-title">Aprovisione un volumen de forma dinámica</block>
  <block id="72407fd74e9ce26b706ed85bc90bd124" category="inline-link-macro">Cree una RVP</block>
  <block id="35a0b000c0ba5920cef3268fee2323b4" category="paragraph">Debe crear un objeto de solicitud de volumen persistente (RVP) de Kubernetes mediante la clase de almacenamiento para aprovisionar dinámicamente un volumen. Siga el siguiente vínculo para crear un objeto de PVC.<block ref="0af94896212bb2843496226f6871904c" category="inline-link-macro-rx"></block></block>
  <block id="279865aaa331ec925a99c3272eb45478" category="section-title">Utilice el volumen</block>
  <block id="fed9c63a200801110024280f08877e16" category="inline-link-macro">Monte el volumen en un pod</block>
  <block id="d822bbb4d6960be49b781e594679db64" category="paragraph">El volumen aprovisionado en el paso anterior puede ser utilizado por una aplicación montando el volumen en el pod.el enlace siguiente muestra un ejemplo.<block ref="48fadb04c46cf19aa1b5e274dd9b5da9" category="inline-link-macro-rx"></block></block>
  <block id="7a11d367cfedc152ce1db261fb8f21fd" category="inline-link-macro">Siguiente: Opciones de configuración avanzada para Anthos.</block>
  <block id="fca5cd0af87c3fa0c3d74ee21a3d346f" category="paragraph"><block ref="fca5cd0af87c3fa0c3d74ee21a3d346f" category="inline-link-macro-rx"></block></block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">Este documento describe los siguientes temas, el nombre tonto de problema y la validación de soluciones, la reducción del uso de CPU para reducir el tiempo de espera de I/o, el tiempo de recuperación de Kafka broker más rápido y el rendimiento en el cloud y en las instalaciones.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Carga de trabajo de Apache Kafka con almacenamiento NFS de NetApp: Validación y rendimiento funcionales</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam y Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka es un sistema de mensajería distribuida de suscripción a publicación con una cola sólida que puede aceptar grandes cantidades de datos de mensajes. Con Kafka, las aplicaciones pueden escribir y leer datos en los temas de un modo muy rápido. Debido a su tolerancia a fallos y su escalabilidad, Kafka se utiliza a menudo en el espacio de Big Data como una forma fiable de procesar y mover muchos flujos de datos muy rápidamente. Entre los casos de uso se incluyen el procesamiento de flujos, el seguimiento de la actividad de sitios web, la recopilación y supervisión de métricas, la agregación de registros, el análisis en tiempo real, etc.</block>
  <block id="91bd7e3ce9e18912d60b1c4cd3f9f7d2" category="inline-link">tonto renombrar</block>
  <block id="7453e2e58a9df0c80d79a8fd0ab4ed1e" category="paragraph">Aunque las operaciones normales de Kafka en NFS funcionan bien, el<block ref="99770e723960c674a5dd9394155d2111" category="inline-link-rx"></block> Issue bloquea la aplicación durante el cambio de tamaño o la partición de un clúster Kafka que se ejecuta en NFS. Esto es un problema significativo debido a que debe cambiarse el tamaño de un clúster Kafka o reparticionarse para fines de mantenimiento o equilibrio de carga. Puede encontrar más información<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>.</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Este documento describe los siguientes temas:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">El problema tonto-renombrar y la validación de solución</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Reducción del uso de CPU para reducir el tiempo de espera de I/O.</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Tiempo de recuperación más rápido de los agentes Kafka</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Rendimiento en el cloud y en las instalaciones</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">¿Por qué utilizar almacenamiento NFS para las cargas de trabajo de Kafka?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">Las cargas de trabajo Kafka en aplicaciones de producción pueden transmitir enormes cantidades de datos entre aplicaciones. Estos datos se guardan y almacenan en los nodos de agente de Kafka en el clúster de Kafka. Kafka también se conoce por la disponibilidad y el paralelismo, que logra al dividir temas en particiones y luego replicarlas en el clúster. Esto eventualmente significa que la enorme cantidad de datos que fluye por un clúster de Kafka se multiplica por lo general en tamaño. NFS hace que el reequilibrio de datos a medida que el número de agentes cambia sea muy rápido y sencillo. En entornos de gran tamaño, hay que reequilibrar los datos en DAS cuando cambia el número de intermediarios y, en la mayoría de los entornos Kafka, el número de agentes cambia con frecuencia.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Entre otras ventajas, se incluyen las siguientes:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Madurez.* NFS es un protocolo maduro, que significa que la mayoría de los aspectos de implementación, seguridad y uso son bien entendidos.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Open.* NFS es un protocolo abierto, y su continuo desarrollo está documentado en las especificaciones de Internet como un protocolo de red libre y abierto.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Rentable.* NFS es una solución de bajo coste para compartir archivos de red que es fácil de configurar porque utiliza la infraestructura de red existente.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gestión centralizada.* la administración centralizada de NFS reduce la necesidad de añadir software y espacio en disco en sistemas de usuario individuales.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Distributed.* NFS se puede utilizar como un sistema de archivos distribuido, reduciendo la necesidad de dispositivos de almacenamiento multimedia extraíbles.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">¿Por qué elegir NetApp para las cargas de trabajo de Kafka?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">La implantación de NFS de NetApp se considera un estándar oro para el protocolo y se utiliza en innumerables entornos NAS empresariales. Además de la credibilidad de NetApp, también ofrece las siguientes ventajas:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Fiabilidad y eficiencia</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Escalabilidad y rendimiento</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Alta disponibilidad (partner de alta disponibilidad en un clúster ONTAP de NetApp)</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Recuperación ante desastres (SnapMirror de NetApp).* su sitio se cae o quiere empezar desde otro sitio y continuar desde el punto de partida.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Capacidad de gestión del sistema de almacenamiento (administración y gestión con OnCommand de NetApp).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Equilibrio de carga.* el clúster le permite acceder a diferentes volúmenes desde LIF de datos alojadas en diferentes nodos.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Operaciones no disruptivas.* los LIF o movimientos de volúmenes son transparentes para los clientes NFS.</block>
  <block id="4d7de9fb7cbfcd5bb144aea084dd9e99" category="inline-link-macro">Siguiente: Solución de NetApp para cargas de trabajo de NFS a Kafka con el fin de cambiar el nombre más tonto.</block>
  <block id="771648345c64342ddd78bfb7ade5c3df" category="paragraph"><block ref="771648345c64342ddd78bfb7ade5c3df" category="inline-link-macro-rx"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">En esta sección se describe el problema del nombre más tonto y los cambios necesarios para que el servidor NFS y el cliente NFS aborden el problema.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Solución de NetApp para el problema del cambio de nombre más tonto de las cargas de trabajo de NFS a Kafka</block>
  <block id="5b7b60a56a6be9e9e9e8ff305a6e8ac6" category="paragraph"><block ref="5b7b60a56a6be9e9e9e8ff305a6e8ac6" category="inline-link-macro-rx"></block></block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka se construye con la suposición de que el sistema de ficheros subyacente es compatible con POSIX: Por ejemplo, XFS o Ext4. El reequilibrio de recursos de Kafka elimina los archivos mientras la aplicación se sigue utilizando. Un sistema de archivos compatible con POSIX permite que se realice la desvinculación. Sin embargo, sólo quita el archivo una vez que todas las referencias al archivo hayan desaparecido. Si el sistema de archivos subyacente está conectado a la red, el cliente NFS intercepta las llamadas de desenlace y administra el flujo de trabajo. Dado que hay abiertos pendientes en el archivo que se está desvinculando, el cliente NFS envía una solicitud de cambio de nombre al servidor NFS y, en el último cierre del archivo sin vincular, emite una operación de eliminación en el archivo cuyo nombre ha cambiado. Este comportamiento se conoce comúnmente como nombre tonto de NFS y está orquestado por el cliente NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Cualquier agente de Kafka que utilice almacenamiento de un servidor NFSv3 se ejecuta en problemas debido a este comportamiento. Sin embargo, el protocolo NFSv4.x tiene funciones para solucionar este problema permitiendo al servidor asumir la responsabilidad de los archivos abiertos sin vínculos. Los servidores NFS que admiten esta función opcional comunican la capacidad de propiedad al cliente NFS en el momento de abrir un archivo. A continuación, el cliente NFS detiene la gestión de desenlace cuando hay pendientes y permite que el servidor gestione el flujo. Aunque la especificación NFSv4 proporciona directrices para la implementación, hasta ahora no hubo ninguna implementación conocida de servidores NFS que admita esta función opcional.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Para que el servidor NFS y el cliente NFS aborden el problema del cambio de nombre más tonto, son necesarios los siguientes cambios:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Cambios en el cliente NFS (Linux).* al abrir el archivo, el servidor NFS responde con un indicador, indicando la capacidad de manejar la desvinculación de los archivos abiertos. Los cambios en el cliente NFS permiten que el servidor NFS gestione el desvínculo en presencia del indicador. NetApp ha actualizado el cliente Linux NFS de código abierto con estos cambios. El cliente NFS actualizado ahora está disponible en general en RHEL8.7 y RHEL9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Cambios en el servidor NFS.* el servidor NFS realiza un seguimiento de los abiertos. El servidor gestiona ahora la desvinculación de un archivo abierto existente para que coincida con la semántica POSIX. Cuando se cierra la última apertura, el servidor NFS inicia entonces la eliminación real del archivo y evita así el tonto proceso de cambio de nombre. El servidor NFS de ONTAP ha implementado esta funcionalidad en su última versión, ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Con los cambios anteriores en el cliente y el servidor NFS, Kafka puede obtener de forma segura todas las ventajas del almacenamiento NFS conectado a la red.</block>
  <block id="29d38aea11265de7104c96a7a3818299" category="inline-link-macro">Siguiente: Validación funcional - arreglo Silly rename.</block>
  <block id="b75f47bcddf300f706113b833f9e5857" category="paragraph"><block ref="b75f47bcddf300f706113b833f9e5857" category="inline-link-macro-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">La solución de NetApp para el tonto problema del cambio de nombre proporciona una forma de almacenamiento sencilla, económica y gestionada de forma centralizada para cargas de trabajo que antes eran incompatibles con NFS.</block>
  <block id="83abec4269fdeaff3d2819895273a563" category="inline-link-macro">Anterior: Información general y validación del rendimiento con AFF en las instalaciones.</block>
  <block id="d620ffb7e12e202c45f9f8ca1cd8c18a" category="paragraph"><block ref="d620ffb7e12e202c45f9f8ca1cd8c18a" category="inline-link-macro-rx"></block></block>
  <block id="e6f7341043f7816d4a31b223bf8d3be3" category="paragraph">La solución de NetApp para el tonto problema del cambio de nombre proporciona una forma de almacenamiento sencilla, económica y gestionada de forma centralizada para cargas de trabajo que antes eran incompatibles con NFS. Este nuevo paradigma permite a los clientes crear clústeres Kafka más gestionables con más facilidad para migrar y hacer mirroring con fines específicos a efectos de la recuperación ante desastres y la protección de datos. También hemos observado que NFS proporciona ventajas adicionales como un uso de CPU reducido y un tiempo de recuperación más rápido, una eficiencia del almacenamiento mejorada y un rendimiento mejorado con ONTAP de NetApp.</block>
  <block id="7cd1d87ec9e0fa1c7a867ad6377c7d37" category="paragraph"><block ref="7cd1d87ec9e0fa1c7a867ad6377c7d37" category="inline-link-macro-rx"></block></block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">En las instalaciones, utilizamos la controladora de almacenamiento AFF A900 de NetApp con ONTAP 9.12.1RC1 para validar el rendimiento y el escalado de un clúster Kafka. Utilizamos el mismo banco de pruebas que en nuestras prácticas recomendadas de almacenamiento por niveles anteriores con ONTAP y AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Descripción general y validación del rendimiento con AFF A900 en las instalaciones</block>
  <block id="8f5ebe1b5fee3c826c16a4c5e9c8f473" category="inline-link-macro">Anterior: Información general y validación del rendimiento en AWS.</block>
  <block id="dfaa047aba8947a9ca42df42a70eb4ad" category="paragraph"><block ref="dfaa047aba8947a9ca42df42a70eb4ad" category="inline-link-macro-rx"></block></block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">En las instalaciones, utilizamos la controladora de almacenamiento AFF A900 de NetApp con ONTAP 9.12.1RC1 para validar el rendimiento y el escalado de un clúster Kafka. Utilizamos el mismo banco de pruebas que en nuestras prácticas recomendadas de almacenamiento por niveles anteriores con ONTAP y AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Utilizamos Confluent Kafka 6.2.0 para evaluar el AFF A900. El clúster dispone de ocho nodos de broker y tres nodos de zomantenimiento. Para realizar pruebas de rendimiento, utilizamos cinco nodos de trabajo OMB.</block>
  <block id="e41e134e8e174865d04443048e1866af" category="paragraph"><block ref="e41e134e8e174865d04443048e1866af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Hemos utilizado instancias de NetApp FlexGroups para proporcionar un espacio de nombres único para directorios de registro, lo que simplifica la recuperación y la configuración. Hemos utilizado NFSv4.1 y pNFS para proporcionar acceso directo de ruta a los datos del segmento de registro.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Ajuste del cliente</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Cada cliente montó la instancia de FlexGroup con el siguiente comando.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Además, aumentamos la<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> del valor predeterminado<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> para<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>. Esto coincide con el límite de ranuras de sesión predeterminado en ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Ajuste de broker Kafka</block>
  <block id="8f9087ae165490f7d809fb8ffd625bba" category="paragraph">Para maximizar el rendimiento en el sistema que se está probando, hemos aumentado de forma significativa los parámetros predeterminados para determinados grupos de subprocesos clave. Recomendamos seguir las prácticas recomendadas de Confluent Kafka para la mayoría de las configuraciones. Este ajuste se utilizó para maximizar la concurrencia de I/o excepcionales en el almacenamiento. Estos parámetros se pueden ajustar para ajustarse a los recursos informáticos y atributos de almacenamiento de su intermediario.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Metodología de pruebas del generador de cargas de trabajo</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Utilizamos las mismas configuraciones de OMB que para las pruebas en la nube para el controlador de rendimiento y la configuración de temas.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Se aprovisionó una instancia de FlexGroup con Ansible en un clúster de AFF.</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">PNFs se habilitó en la SVM de ONTAP.</block>
  <block id="7fe5c7aaf126c7432ba86d9e145f59a4" category="list-text">La carga de trabajo se activó con el controlador de rendimiento utilizando la misma configuración de carga de trabajo que para Cloud Volumes ONTAP. Consulte la sección “<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block>” más abajo. La carga de trabajo utilizó un factor de replicación de 3, lo que significa que se mantuvieron tres copias de segmentos de registro en NFS.</block>
  <block id="dfe2c8a29d6798ed2d2dae4af3b4e5e7" category="inline-xref">análisis de los límites de almacenamiento</block>
  <block id="c2a038ea3f35076598b99806cd90a3c5" category="list-text">Por último, hemos completado las mediciones con un pedido atrasado para medir la capacidad de los consumidores para ponerse al día con los últimos mensajes. OMB construye un atraso al pausar a los consumidores durante el comienzo de una medición. Esto produce tres fases distintas: Creación de acumulación (tráfico sólo para productores), drenaje de acumulación (una fase de consumo pesado en la que los consumidores se quedan al tanto de los eventos perdidos en un tema) y el estado estable. Consulte la sección “<block ref="a2eee99fc052f067d68a9273d62093f1" category="inline-xref-macro-rx"></block>” para más información.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Rendimiento en estado constante</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Evaluamos la plataforma AFF A900 utilizando la prueba de rendimiento de OpenMessaging para ofrecer una comparación similar a la de Cloud Volumes ONTAP en AWS y DAS en AWS. Todos los valores de rendimiento representan el rendimiento de Kafka-cluster a nivel de productor y consumidor.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">El rendimiento constante con Confluent Kafka y AFF A900 logró un rendimiento medio de 3,4 Gbps tanto para el productor como para el consumidor. Esto es más de 3.4 millones de mensajes en el cluster Kafka. Al visualizar el rendimiento sostenido en bytes por segundo para BrokerTopicMetrics, observamos el excelente rendimiento en estado constante y el tráfico apoyado por la AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">En este gráfico se muestra el rendimiento de la red de Broker.</block>
  <block id="0b01283779b69987a07a2c2d50ccb15d" category="paragraph"><block ref="0b01283779b69987a07a2c2d50ccb15d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Esto se alinea correctamente con la vista de los mensajes entregados por tema. El siguiente gráfico proporciona un desglose por tema. En la configuración probada, hemos visto unos 900 mensajes por tema en cuatro temas.</block>
  <block id="a0a1dff924171568d861731a12802528" category="paragraph"><block ref="a0a1dff924171568d861731a12802528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Rendimiento extremo y exploración de los límites de almacenamiento</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Para AFF, también hemos probado con OMB mediante la función de acumulación. La función de acumulación detiene las suscripciones de consumidores mientras se crea una acumulación de eventos en el clúster Kafka. Durante esta fase, sólo se produce el tráfico de producción, que genera eventos que están comprometidos con los registros. De este modo, se emulan de forma más estrecha el procesamiento por lotes o los flujos de trabajo de análisis sin conexión; en estos flujos de trabajo, se inician las suscripciones de consumidores y se deben leer datos históricos que ya se han expulsado de la memoria caché de intermediarios.</block>
  <block id="5519a4dc3c42cae95400800bbaeaecfc" category="paragraph">Para comprender las limitaciones del almacenamiento en el rendimiento de consumo en esta configuración, medimos la fase de solo producción para comprender cuánto tráfico de escritura podría absorber A900. Consulte la siguiente sección “<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block>” para comprender cómo aprovechar estos datos.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Durante la parte sólo para el productor de esta medición, observamos un alto rendimiento máximo que ha elevado los límites del rendimiento de A900 (cuando otros recursos de broker no estaban saturados al servicio del tráfico de productores y consumidores).</block>
  <block id="364db2a868997ed12ba4b16039b53a68" category="paragraph"><block ref="364db2a868997ed12ba4b16039b53a68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Hemos aumentado el tamaño del mensaje a 16 k para esta medición para limitar la sobrecarga por mensaje y maximizar la capacidad de almacenamiento a los puntos de montaje NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">El clúster Confluent Kafka logró un rendimiento máximo del productor de 4,03 Gbps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Una vez que OMB completó la acumulación de eventos, se reinició el tráfico de consumo. Durante las mediciones con drenaje de pedidos atrasados, observamos un rendimiento de consumo máximo de más de 20 Gbps en todos los temas. El rendimiento combinado que se aproximaba al volumen NFS donde se almacenaban los datos de registro de OMB era de unos 30 Gbps.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Orientación para la configuración</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guía de tamaños</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services ofrece un<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> Para el ajuste de tamaño y el escalado de clústeres de Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Este ajuste de tamaño proporciona una fórmula útil para determinar los requisitos de rendimiento del almacenamiento para el clúster Kafka:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Para un rendimiento agregado producido en el clúster de tcluster con un factor de replicación de r, el rendimiento recibido por el almacenamiento de broker es el siguiente:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Esto se puede simplificar aún más:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">Con esta fórmula se puede seleccionar la plataforma ONTAP adecuada para las necesidades del nivel de sobrecarga Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">En la siguiente tabla se explica el rendimiento previsto del productor para el A900 con diferentes factores de replicación:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Factor de replicación</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Producción (GPPS)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (medidas)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="e5a7cf20f86f14251d25ab33d3eb07fb" category="paragraph"><block ref="e5a7cf20f86f14251d25ab33d3eb07fb" category="inline-link-macro-rx"></block></block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Para la validación funcional, demostramos que un clúster Kafka con un montaje NFSv3 para el almacenamiento no realiza operaciones Kafka como la redistribución de particiones, mientras que otro clúster montado en NFSv4 con la corrección puede realizar las mismas operaciones sin interrupciones.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Validación funcional: Corrección de nombre de Silly</block>
  <block id="bfc46a432aa7385a6228ff50401aca2b" category="inline-link-macro">Anterior: Solución de NetApp para problema con el nombre más tonto de NFS a la carga de trabajo de Kafka.</block>
  <block id="6e56361f7ef0ac98b8b5c8c120de1fd8" category="paragraph"><block ref="6e56361f7ef0ac98b8b5c8c120de1fd8" category="inline-link-macro-rx"></block></block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Configuración de validación</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">La configuración se ejecuta en AWS. La siguiente tabla muestra los diferentes componentes de la plataforma y la configuración del entorno utilizados para la validación.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Plataforma Confluente, versión 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 zookeepers – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 servidores de broker - r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 centro de control – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x productor/consumidor</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 o posterior</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Instancia de Cloud Volumes ONTAP de NetApp</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Instancia de un solo nodo: M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">En la siguiente figura, se muestra la configuración de la arquitectura para esta solución.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Estas imágenes muestran la topología de AWS que contiene un VPC que contiene tres subredes privadas con un descalido de productor, el clúster de Kafka y la instancia de CVO, respectivamente.</block>
  <block id="2eee6b516bfba2cd7f7f3bbe52d98104" category="paragraph"><block ref="2eee6b516bfba2cd7f7f3bbe52d98104" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Flujo arquitectónico</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Compute.* utilizamos un clúster Kafka de cuatro nodos con un conjunto de zoomkeeper de tres nodos que se ejecuta en servidores dedicados.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Supervisión.* utilizamos dos nodos para una combinación Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Carga de trabajo.* para generar cargas de trabajo, utilizamos un clúster de tres nodos separado que puede producir y consumir desde este clúster Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Almacenamiento.* utilizamos una instancia NetApp Cloud Volumes ONTAP de un solo nodo con dos volúmenes AWS-EBS de 500 GB conectados a la instancia. Estos volúmenes se expusieron al clúster Kafka como volumen NFSv4.1 único mediante una LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Se seleccionaron las propiedades predeterminadas de Kafka para todos los servidores. Lo mismo se hizo para el zookeeper enjambre.</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Metodología de las pruebas</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Se crearon dos clústeres Kafka similares con la siguiente diferencia:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Cluster 1.* el servidor NFS v4.1 back-end con ONTAP versión 9.12.1 listo para producción estaba alojado en una instancia de CVO de NetApp. RHEL 8.7/RHEL 9.1 se han instalado en los intermediarios.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Cluster 2.* el servidor NFS backend era un servidor Linux NFSv3 genérico creado manualmente.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">Se creó un tema de demostración en los dos clusters de Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Clúster 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Esta captura de pantalla muestra el tema de demostración creado en el clúster 1.</block>
  <block id="c99c5591acf7724aed404fdd225a51d6" category="paragraph"><block ref="c99c5591acf7724aed404fdd225a51d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Clúster 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Esta captura de pantalla muestra el tema de demostración creado en el clúster 2.</block>
  <block id="1fd29f3ac81f16a73dae3761643fac74" category="paragraph"><block ref="1fd29f3ac81f16a73dae3761643fac74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">Los datos se han cargado en estos temas recién creados para ambos clústeres. Esto se hizo con el kit de herramientas de prueba de rendimiento-productor que se incluye en el paquete Kafka predeterminado:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Se realizó una comprobación de estado para broker-1 para cada uno de los clústeres mediante telnet:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">En la siguiente captura de pantalla se muestra una comprobación del estado correcta de los agentes en ambos clusters:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Esta captura de pantalla muestra la información para una comprobación de estado correcta en ambos corredores.</block>
  <block id="0017223ce5bee33d9165b88b478ac306" category="paragraph"><block ref="0017223ce5bee33d9165b88b478ac306" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Para activar la condición de fallo que provoca que los clústeres de Kafka utilicen volúmenes de almacenamiento NFSv3 se bloquee, hemos iniciado el proceso de reasignación de partición en ambos clústeres. La reasignación de particiones se ha realizado utilizando<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block>. El proceso detallado es el siguiente:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Para reasignar las particiones de un tema de un clúster Kafka, generamos la configuración JSON de reasignación propuesta (esto se realizó para ambos clústeres).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">La reasignación JSON generada se guardó en<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block>.</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">El proceso real de reasignación de particiones se ha activado mediante el siguiente comando:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Después de unos minutos cuando se completó la reasignación, otra comprobación del estado de los agentes mostró que el clúster con volúmenes de almacenamiento NFSv3 se había ejecutado en un problema tonto de cambio y se había bloqueado, mientras que el clúster 1 con los volúmenes de almacenamiento NFSv4.1 de ONTAP de NetApp con la corrección continuó las operaciones sin ninguna interrupción.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Esta captura de pantalla muestra el resultado de un agente bloqueado.</block>
  <block id="b32b7199140b7e4479d72c3f0c8c506b" category="paragraph"><block ref="b32b7199140b7e4479d72c3f0c8c506b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 está vivo.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 está muerto.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Tras comprobar los directorios de registro de Kafka, estaba claro que el clúster 1 con los volúmenes de almacenamiento NFSv4.1 de ONTAP de NetApp con la solución tenía una asignación de particiones limpia, mientras que el clúster 2 con almacenamiento NFSv3 genérico no se debía a problemas tontos de cambio de nombre, lo que provocó el bloqueo. En la siguiente imagen, se muestra el reequilibrio de particiones del clúster 2, lo que dio lugar a un problema de cambio de nombre tonto en el almacenamiento NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Esta captura de pantalla muestra la salida del registro para el bloqueo del clúster 2.</block>
  <block id="14b7c5d09f2ae8862c1f59ee1823a5e3" category="paragraph"><block ref="14b7c5d09f2ae8862c1f59ee1823a5e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">La siguiente imagen muestra un reequilibrado de particiones limpio del clúster 1 mediante NFSv4.1 de NetApp.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Esta captura de pantalla muestra la salida del registro para una asignación de partición limpia correcta para el clúster 1 mientras que</block>
  <block id="bdab654bf4d623f517718ee0c01ce4f2" category="paragraph"><block ref="bdab654bf4d623f517718ee0c01ce4f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ecf40a5f4c022357e753dea69b66285" category="inline-link-macro">Siguiente: ¿Por qué NFS de NetApp para cargas de trabajo de Kafka?</block>
  <block id="1a2139ac1273f5dc6ebea0a90a0b8caa" category="paragraph"><block ref="1a2139ac1273f5dc6ebea0a90a0b8caa" category="inline-link-macro-rx"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Ahora que hay una solución para el tonto problema de cambio de nombre del almacenamiento NFS con Kafka, se pueden crear puestas en marcha sólidas que aprovechan el almacenamiento ONTAP de NetApp para su carga de trabajo Kafka. Esto no solo reduce significativamente la sobrecarga operativa, sino que también aporta las siguientes ventajas a los clústeres de Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">¿Por qué NFS de NetApp para las cargas de trabajo de Kafka?</block>
  <block id="dfcc8e1c7335951df2dcc87acef063d3" category="inline-link-macro">Anterior: Validación funcional - arreglo Silly rename.</block>
  <block id="daa2168d5bad682cea233a9548c0172f" category="paragraph"><block ref="daa2168d5bad682cea233a9548c0172f" category="inline-link-macro-rx"></block></block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Ahora que hay una solución para el tonto problema de cambio de nombre del almacenamiento NFS con Kafka, se pueden crear puestas en marcha sólidas que aprovechan el almacenamiento ONTAP de NetApp para su carga de trabajo Kafka. Esto no solo reduce significativamente los gastos operativos, sino que también aporta las siguientes ventajas a los clústeres de Kafka:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">* Reducción del uso de la CPU en los intermediarios de Kafka.* utilizando el almacenamiento desagregado de ONTAP de NetApp separa las operaciones de I/o de disco del intermediario y, por tanto, reduce el espacio físico utilizado de la CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Tiempo de recuperación de broker más rápido.* desde que el almacenamiento desagregado de ONTAP de NetApp se comparte en los nodos de broker de Kafka, una nueva instancia informática puede sustituir a un intermediario defectuoso en cualquier momento, en comparación con las puestas en marcha convencionales de Kafka sin tener que volver a crear los datos.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">* Eficiencia del almacenamiento.* como la capa de almacenamiento de la aplicación se aprovisiona ahora a través de ONTAP de NetApp, los clientes pueden aprovechar las ventajas de la eficiencia del almacenamiento que incluye ONTAP, como la compresión de datos inline, la deduplicación y la compactación.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Estas ventajas se probaron y validaron en casos de prueba que comentamos detalladamente en esta sección.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Reducción del uso de CPU en Kafka Broker</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Descubrimos que el aprovechamiento de la CPU general es inferior al de su homólogo de DAS, cuando ejecutamos cargas de trabajo similares en dos clústeres de Spermiate Kafka que eran idénticas en sus especificaciones técnicas, pero que diferían en sus tecnologías de almacenamiento. El uso general de la CPU no sólo es inferior cuando el clúster Kafka utiliza almacenamiento ONTAP, sino que, además, el aumento del uso de la CPU ha mostrado un gradiente más suave que en un clúster Kafka basado en DAS.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configuración de la arquitectura</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">La siguiente tabla muestra la configuración del entorno utilizada para demostrar la reducción del uso de CPU.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 herramienta de Benchmarking: OpenMessaging</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 zookeepers – t2.pequeño</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 servidores de broker: i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xgrande</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x productor/consumidor -- c5n.2xgrande</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 o posterior</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Instancia de un solo nodo: M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Herramienta de evaluación comparativa</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">Mensajería abierta</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">La herramienta de evaluación comparativa utilizada en este caso de prueba es la<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> marco. OpenMessaging es independiente del lenguaje y está neutral en todos los proveedores; proporciona directrices del sector para finanzas, comercio electrónico, Internet de las cosas y Big Data; además, ayuda a desarrollar aplicaciones de mensajería y transmisión de datos en sistemas y plataformas heterogéneos. La figura siguiente muestra la interacción de los clientes de OpenMessaging con un clúster Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Esta imagen muestra la interacción de los clientes de OpenMessaging con un clúster Kafka.</block>
  <block id="370c47f03f13e0b2954d14225811e64c" category="paragraph"><block ref="370c47f03f13e0b2954d14225811e64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Compute.* utilizamos un clúster Kafka de tres nodos con un conjunto de zoomkeeper de tres nodos que se ejecuta en servidores dedicados. Cada agente tenía dos puntos de montaje de NFSv4.1 en un único volumen de la instancia de CVO de NetApp a través de un LIF dedicado.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Supervisión.* utilizamos dos nodos para una combinación Prometheus-Grafana. Para generar cargas de trabajo, tenemos un clúster de tres nodos separado que puede producir y consumir a partir de este clúster Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Almacenamiento.* utilizamos una instancia Cloud Volumes ONTAP de NetApp de un solo nodo con seis volúmenes AWS-EBS de 250 GB montados en la instancia. Estos volúmenes se expusieron entonces al clúster Kafka como seis volúmenes de NFSv4.1 mediante LIF dedicadas.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configuración.* los dos elementos configurables en este caso de prueba fueron los agentes Kafka y las cargas de trabajo de OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Broker config.* las siguientes especificaciones fueron seleccionadas para los corredores Kafka. Utilizamos el factor de replicación 3 para todas las mediciones, tal y como se destaca a continuación.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Esta imagen muestra las especificaciones seleccionadas para los corredores Kafka.</block>
  <block id="d0255d634f4013c1da82b391ac0fa7f5" category="paragraph"><block ref="d0255d634f4013c1da82b391ac0fa7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*Configuración de carga de trabajo de OpenMessaging Benchmark (OMB).* se proporcionaron las siguientes especificaciones. Hemos especificado una tasa de producción objetivo, que se destaca a continuación.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Esta imagen muestra las especificaciones seleccionadas para la configuración de carga de trabajo del punto de referencia de OpenMessaging.</block>
  <block id="39e4197e665f900596d0136c11eaa851" category="paragraph"><block ref="39e4197e665f900596d0136c11eaa851" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Se crearon dos grupos similares, cada uno con su propio conjunto de enjambres de racimo de benchmarking.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Cluster 1.* clúster Kafka basado en NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Cluster 2.* clúster Kafka basado en DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Con un comando OpenMessaging, se activaron cargas de trabajo similares en cada clúster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">La configuración de la tasa de producción se aumentó en cuatro iteraciones, y se registró un aprovechamiento de la CPU en Grafana. La tasa de producción se ha establecido en los siguientes niveles:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observación</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Se obtienen dos principales ventajas de usar el almacenamiento NFS de NetApp con Kafka:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*Puede reducir el uso de la CPU en casi un tercio.* el uso general de la CPU en cargas de trabajo similares fue menor para NFS en comparación con los SSD DAS; los ahorros varían de un 5% para tasas de producción más bajas a un 32% para tasas de producción más altas.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">* Una reducción de tres veces en la deriva de la utilización de la CPU a tasas de producción más altas.* como se esperaba, hubo una deriva ascendente para el aumento de la utilización de la CPU a medida que se aumentaron las tasas de producción. Sin embargo, el uso de la CPU en los agentes Kafka que utilizan DAS ha aumentado del 31% con la tasa de producción inferior al 70% con la tasa de producción más alta, lo que representa un aumento del 39%. Sin embargo, con un back-end de almacenamiento NFS, el uso de CPU ha aumentado del 26 % al 38 %, lo que representa un aumento del 12 %.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Este gráfico muestra el comportamiento de un clúster basado en DAS.</block>
  <block id="1e669d4d02de91a94a05137bdd1dc491" category="paragraph"><block ref="1e669d4d02de91a94a05137bdd1dc491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Este gráfico muestra el comportamiento de un clúster basado en NFS.</block>
  <block id="68437c53e33bd5423258ea6fd20a35f5" category="paragraph"><block ref="68437c53e33bd5423258ea6fd20a35f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Asimismo, en 100,000 mensajes, el almacenamiento DAS muestra más uso de CPU que un clúster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Este gráfico muestra el comportamiento de un clúster basado en DAS en 100,000 mensajes.</block>
  <block id="7c994cd9d5150762faf629fff71db6c6" category="paragraph"><block ref="7c994cd9d5150762faf629fff71db6c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Este gráfico muestra el comportamiento de un clúster basado en NFS en 100,000 mensajes.</block>
  <block id="0dd7c57e19e01e516dc697178954bfd5" category="paragraph"><block ref="0dd7c57e19e01e516dc697178954bfd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Recuperación de agentes más rápida</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Descubrimos que los agentes de Kafka se recuperan con mayor rapidez cuando se utiliza el almacenamiento NFS compartido de NetApp. Cuando un agente se bloquea en un clúster de Kafka, este agente se puede reemplazar por un agente en buen estado con un mismo ID de agente. Tras realizar este caso de prueba, descubrimos que, en el caso de un clúster Kafka basado en DAS, el clúster recompila los datos en un nuevo agente de buena salud añadido, lo cual requiere mucho tiempo. En el caso de un clúster Kafka basado en NFS de NetApp, el agente de sustitución sigue leyendo datos del directorio de registros anterior y recupera mucho más rápido.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">En la siguiente tabla se muestra la configuración del entorno de un clúster de Kafka con NAS.</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x productor/consumidor -- c5n.2xgrande</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 nodo Kafka de backup: I3en.2xgrande</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 o posterior</block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">En la figura siguiente se muestra la arquitectura de un clúster Kafka basado en NAS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">En esta figura, se muestra la arquitectura de un clúster Kafka basado en NAS.</block>
  <block id="f11ab4a9f30f1c13023294b83c1968fb" category="paragraph"><block ref="f11ab4a9f30f1c13023294b83c1968fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Compute.* un clúster Kafka de tres nodos con un conjunto de zomantenimiento de tres nodos que se ejecuta en servidores dedicados. Cada agente tiene dos puntos de montaje NFS en un único volumen en la instancia de NetApp CVO a través de un LIF dedicado.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Supervisión.* dos nodos para una combinación Prometheus-Grafana. Para generar cargas de trabajo, utilizamos un clúster de tres nodos independiente que puede producir y consumir con este clúster de Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Almacenamiento.* una instancia de NetApp Cloud Volumes ONTAP de un solo nodo con seis volúmenes AWS-EBS de 250 GB montados en la instancia. A continuación, estos volúmenes se exponen al clúster de Kafka en seis volúmenes NFS mediante LIF dedicadas.</block>
  <block id="1f4b2c66cbc586fa9658b18333582240" category="list-text">*Configuración de Broker.* el único elemento configurable en este caso de prueba son agentes Kafka. Se seleccionaron las siguientes especificaciones para los corredores Kafka. La<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> Se establece en un valor alto porque determina la rapidez con la que se sale un nodo concreto de la lista ISR. Cuando cambia entre nodos defectuosos y sanos, no desea que ese ID de broker se excluya de la lista ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Esta imagen muestra las especificaciones elegidas para los corredores Kafka.</block>
  <block id="4bc3bbed275832f042bf33735b245eee" category="paragraph"><block ref="4bc3bbed275832f042bf33735b245eee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Se crearon dos clústeres similares:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Un clúster fluido basado en EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Un clúster fluido basado en NFS de NetApp.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">Se creó un nodo Kafka en espera con una configuración idéntica a los nodos del clúster Kafka original.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">En cada uno de los clústeres se creó un tema de ejemplo y se rellenaron aproximadamente 110 GB de datos en cada uno de los agentes de valores.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Clúster basado en EC2.* se asigna Un directorio de datos de Kafka broker<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (En la siguiente figura, Broker-1 de cluster1 [terminal izquierdo]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">*Clúster basado en NFS de NetApp.* un directorio de datos de Kafka Broker está montado en punto NFS<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (En la siguiente figura, Broker-1 de cluster2 [terminal derecho]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Esta imagen muestra dos pantallas de terminal.</block>
  <block id="390d46f539d5037b90b3b548ca4abc79" category="paragraph"><block ref="390d46f539d5037b90b3b548ca4abc79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">En cada uno de los clústeres, Broker-1 se terminó para activar un proceso de recuperación de broker fallido.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Una vez que el broker fue terminado, la dirección IP del broker fue asignada como IP secundaria al broker en espera. Esto fue necesario porque a un corredor de un clúster de Kafka se le identifica lo siguiente:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Dirección IP.* asignado reasignando el IP de broker fallido al intermediario en espera.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*ID de broker.* se configuró en el broker en espera<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>.</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Tras la asignación de IP, el servicio Kafka se inició en el agente de reserva.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Tras un tiempo, los registros del servidor se han extraído para comprobar el tiempo que se tarda en crear datos en el nodo de reemplazo del clúster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">La recuperación de los intermediarios de Kafka fue casi nueve veces más rápida. Se constató que el tiempo que se tardaba en recuperar un nodo de agente fallido era significativamente más rápido cuando se usa el almacenamiento compartido NFS de NetApp en comparación con el uso de SSD DAS en un clúster Kafka. En 1 TB de datos de temas, el tiempo de recuperación de un clúster basado en DAS era de 48 minutos, en comparación con menos de 5 minutos para un clúster Kafka basado en NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Observamos que el clúster basado en EC2 tardó 10 minutos en reconstruir los 110 GB de datos en el nuevo nodo de agente, mientras que el clúster basado en NFS completó la recuperación en 3 minutos. También observamos en los registros in que los offsets de los consumidores para las particiones para EC2 eran 0, mientras que, en el clúster NFS, los offsets de los consumidores se recogían del intermediario anterior.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Clúster basado en DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">El nodo de backup se inició a las 08:55:53,730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Esta imagen muestra la salida del registro para un clúster basado en DAS.</block>
  <block id="04b616f87a48976d96105dd8da106220" category="paragraph"><block ref="04b616f87a48976d96105dd8da106220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">El proceso de recompilación de datos finalizó a las 09:05:24,860. El procesamiento de 110 GB de datos requería aproximadamente 10 minutos.</block>
  <block id="56e5a0f063355e55045e219c7ff3cae3" category="paragraph"><block ref="56e5a0f063355e55045e219c7ff3cae3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Clúster basado en NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">El nodo de backup se inició a las 09:39:17,213. A continuación se resalta la entrada del registro inicial.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Esta imagen muestra la salida del registro para un clúster basado en NFS.</block>
  <block id="97d0b1f6f9620cf3ad52778c81887d14" category="paragraph"><block ref="97d0b1f6f9620cf3ad52778c81887d14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">El proceso de reconstrucción de los datos terminó a las 09:42:29,115. El procesamiento de 110 GB de datos requería aproximadamente 3 minutos.</block>
  <block id="f21adb2cdf95034f20ec22d797a2b2be" category="paragraph"><block ref="f21adb2cdf95034f20ec22d797a2b2be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">La prueba fue repetida para los agentes que tenían alrededor de 1 TB de datos, lo que supuso aproximadamente 48 minutos para el sistema DAS y 3 minutos para NFS. Los resultados se muestran en el siguiente gráfico.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Este gráfico muestra el tiempo necesario para la recuperación de broker en función de la cantidad de datos cargados en el intermediario para un clúster basado en DAS o un clúster basado en NFS.</block>
  <block id="a853fdd02599082a126937405a2c304c" category="paragraph"><block ref="a853fdd02599082a126937405a2c304c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Como la capa de almacenamiento del clúster Kafka se aprovisionaba a través de ONTAP de NetApp, obtuvimos todas las funcionalidades de eficiencia del almacenamiento de ONTAP. Esto se probó generando una cantidad significativa de datos en un clúster de Kafka con almacenamiento NFS aprovisionado en Cloud Volumes ONTAP. Pudimos ver que hubo una reducción significativa del espacio gracias a las funcionalidades de ONTAP.</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x productor/consumidor -- c5n.2xgrande *</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Instancia de un solo nodo: M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Compute.* utilizamos un clúster Kafka de tres nodos con un conjunto de zoomkeeper de tres nodos que se ejecuta en servidores dedicados. Cada agente tenía dos puntos de montaje NFS en un único volumen en la instancia de NetApp CVO a través de un LIF dedicado.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Supervisión.* utilizamos dos nodos para una combinación Prometheus-Grafana. Para generar cargas de trabajo, utilizamos un clúster de tres nodos independiente que podía producir y consumir este clúster Kafka.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Almacenamiento.* utilizamos una instancia Cloud Volumes ONTAP de NetApp de un solo nodo con seis volúmenes AWS-EBS de 250 GB montados en la instancia. Estos volúmenes se expusieron a continuación al clúster de Kafka en seis volúmenes NFS mediante LIF dedicadas.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configuración.* los elementos configurables en este caso de prueba fueron los agentes Kafka.</block>
  <block id="86e1dede1fc5701676bec82003409aff" category="paragraph">La compresión se apagó al final del productor, lo que permitió a los productores generar un alto rendimiento. En lugar de eso, la capa informática gestionó la eficiencia del almacenamiento.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">Se aprovisionó un clúster de Kafka con las especificaciones mencionadas anteriormente.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">En el clúster, se produjeron unos 350 GB de datos con la herramienta de puntos de referencia OpenMessaging.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Una vez completada la carga de trabajo, las estadísticas de eficiencia del almacenamiento se recogieron con ONTAP System Manager y CLI.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Para los datos generados con la herramienta OMB, observamos un ahorro de espacio de ~33 % con una relación de eficiencia de almacenamiento de 1.70:1. Tal y como se aprecia en las siguientes figuras, el espacio lógico utilizado por los datos producidos era de 420,3 GB y el espacio físico utilizado para almacenar los datos era de 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Esta imagen muestra el ahorro de espacio en VMDISK.</block>
  <block id="e9cfd3a2897ae25384f04fb11643ac21" category="paragraph"><block ref="e9cfd3a2897ae25384f04fb11643ac21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Captura de pantalla</block>
  <block id="1509f2dafd7ef601c7bf6b69e651ebaf" category="paragraph"><block ref="1509f2dafd7ef601c7bf6b69e651ebaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="419c9cc44cd35123f9e118ff58d18c8d" category="paragraph"><block ref="419c9cc44cd35123f9e118ff58d18c8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336817b144fc8ca86c3b1bf261ff0dc" category="inline-link-macro">Siguiente: Información general y validación del rendimiento en AWS.</block>
  <block id="2843eeeffb833436dcf46445acebde91" category="paragraph"><block ref="2843eeeffb833436dcf46445acebde91" category="inline-link-macro-rx"></block></block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Se realizó una prueba de rendimiento de un clúster Kafka con capa de almacenamiento montada en NFS de NetApp en el cloud de AWS. Los ejemplos de pruebas comparativas se describen en las siguientes secciones.</block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Información general y validación del rendimiento en AWS</block>
  <block id="514db64c2189adefee1fd55171e6c154" category="inline-link-macro">Anterior: ¿Por qué NFS de NetApp para cargas de trabajo de Kafka?</block>
  <block id="5ff5bf199d6f8c7420eaf142a44e1b84" category="paragraph"><block ref="5ff5bf199d6f8c7420eaf142a44e1b84" category="inline-link-macro-rx"></block></block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka en el cloud de AWS con Cloud Volumes ONTAP de NetApp (pareja de alta disponibilidad y nodo único)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Se realizó una prueba de rendimiento de un clúster de Kafka con Cloud Volumes ONTAP de NetApp (pareja de alta disponibilidad) en el cloud de AWS. Esta evaluación comparativa se describe en las siguientes secciones.</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Instancia de par DE ALTA DISPONIBILIDAD – m5dn.12xLarge x 2 node Single Node Instance - m5dn.12xLarge x 1 node</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configuración de ONTAP para volúmenes del clúster de NetApp</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Para el par de alta disponibilidad de Cloud Volumes ONTAP, hemos creado dos agregados con tres volúmenes en cada agregado de cada controladora de almacenamiento. Para el nodo único de Cloud Volumes ONTAP, creamos seis volúmenes en un agregado.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Esta imagen muestra las propiedades de aggr3 y aggr22.</block>
  <block id="3fb62725866c106a90b2f81d00b4bfd8" category="paragraph"><block ref="3fb62725866c106a90b2f81d00b4bfd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Esta imagen muestra las propiedades de aggr2.</block>
  <block id="2ec040888274c50ed4f2140a40ff8b70" category="paragraph"><block ref="2ec040888274c50ed4f2140a40ff8b70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Para mejorar el rendimiento de red, hemos habilitado redes de alta velocidad para el par de alta disponibilidad y el nodo único.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Esta imagen muestra cómo activar redes de alta velocidad.</block>
  <block id="ebfcaff376ca9e4653f751fb35b6ff05" category="paragraph"><block ref="ebfcaff376ca9e4653f751fb35b6ff05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Hemos observado que el ONTAP NVRAM tenía más IOPS, por lo que hemos cambiado el IOPS a 2350 para el volumen raíz de Cloud Volumes ONTAP. El disco del volumen raíz en Cloud Volumes ONTAP tenía un tamaño de 47 GB. El siguiente comando ONTAP es para el par de alta disponibilidad, y el mismo paso es aplicable para el único nodo.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Estas imágenes muestran la forma de modificar las propiedades del volumen.</block>
  <block id="a278e7398c9bee17762c3a92d2e6f247" category="paragraph"><block ref="a278e7398c9bee17762c3a92d2e6f247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Compute.* utilizamos un clúster Kafka de tres nodos con un conjunto de zoomkeeper de tres nodos que se ejecuta en servidores dedicados. Cada agente tenía dos puntos de montaje NFS en un único volumen de la instancia de Cloud Volumes ONTAP a través de un LIF dedicado.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Almacenamiento.* utilizamos una instancia Cloud Volumes ONTAP de par de alta disponibilidad con un volumen GP3 de 6 TB AWS-EBS montado en la instancia. El volumen se exportó después al agente de Kafka con un montaje NFS.</block>
  <block id="e4d534a810d0b173e29dc8ae17ae8e30" category="paragraph"><block ref="e4d534a810d0b173e29dc8ae17ae8e30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configuraciones de pruebas de rendimiento de OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Para obtener un mejor rendimiento NFS, se necesitan más conexiones de red entre el servidor NFS y el cliente NFS, que se pueden crear utilizando nconnect. Monte los volúmenes NFS en los nodos de broker con la opción nconnect ejecutando el siguiente comando:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Compruebe las conexiones de red en Cloud Volumes ONTAP. El siguiente comando ONTAP se usa desde el nodo único de Cloud Volumes ONTAP. El mismo paso es aplicable al par de alta disponibilidad de Cloud Volumes ONTAP.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Utilizamos el siguiente Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> En todos los agentes de Kafka para el par de alta disponibilidad de Cloud Volumes ONTAP. La<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la propiedad es diferente para cada agente, y las propiedades restantes son comunes para los corredores. Para corredura1, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> el valor es el siguiente:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Para corredura2, la<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> el valor de la propiedad es el siguiente:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Para corredura3, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> el valor de la propiedad es el siguiente:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Para el nodo único de Cloud Volumes ONTAP, el Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> Es lo mismo que para el par de alta disponibilidad de Cloud Volumes ONTAP, a excepción de la<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> propiedad.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Para corredura1, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> el valor es el siguiente:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Para corredura2, la<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> el valor es el siguiente:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">La carga de trabajo en el OMB se configura con las siguientes propiedades:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block>.</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">La<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> puede variar para cada caso de uso. En nuestra prueba de rendimiento, utilizamos 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Utilizamos dos controladores distintos, Sync o Throughput, de OMB, para generar la carga de trabajo en el clúster Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">El archivo yaml utilizado para las propiedades del controlador Sync es el siguiente<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block>:</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">El archivo yaml utilizado para las propiedades del controlador de rendimiento es el siguiente<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block>:</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Se aprovisionó un clúster de Kafka según las especificaciones descritas anteriormente con Terraform y Ansible. Terraform se utiliza para crear la infraestructura con instancias de AWS para el clúster de Kafka y Ansible crea el clúster de Kafka.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Se activó una carga de trabajo de OMB con la configuración de carga de trabajo descrita anteriormente y el controlador de sincronización.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Se activó otra carga de trabajo con el controlador de rendimiento con la misma configuración de carga de trabajo.</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Se utilizaron dos tipos distintos de controladores para generar cargas de trabajo con el fin de llevar a cabo una prueba de rendimiento de una instancia de Kafka que se ejecuta en NFS. La diferencia entre los controladores es la propiedad log flush.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">En un par de alta disponibilidad de Cloud Volumes ONTAP:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Rendimiento total generado de forma coherente por el controlador Sync: ~1236 Mbps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Rendimiento total generado para el controlador de rendimiento: Pico de ~1412 Mbps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Para un único nodo Cloud Volumes ONTAP:</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Rendimiento total generado de forma consistente por el controlador Sync: ~ 1962MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Rendimiento total generado por el controlador de rendimiento: Pico de ~1660 MB</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">El controlador Sync puede generar un rendimiento constante a medida que los registros se vacíen en el disco al instante, mientras que el controlador de rendimiento genera ráfagas de rendimiento a medida que los registros se envían al disco de forma masiva.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Estos números de rendimiento se generan para la configuración de AWS determinada. Para requisitos de rendimiento más altos, los tipos de instancias se pueden escalar verticalmente para mejorar los números de rendimiento. El rendimiento total o la tasa total es la combinación de la tasa de producción y del consumidor.</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Aquí se presentan cuatro gráficos diferentes. Controlador de rendimiento de par CVO-ha. Controlador de sincronización de pares CVO-ha. Controlador de rendimiento de nodo único CVO. Controlador CVO-Single Node Sync.</block>
  <block id="0e33cf4077892dd25c1212a135870c2b" category="paragraph"><block ref="0e33cf4077892dd25c1212a135870c2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Asegúrese de comprobar el rendimiento del almacenamiento al realizar el rendimiento o sincronizar las pruebas de rendimiento del controlador.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Este gráfico muestra el rendimiento en la latencia, IOPS y rendimiento.</block>
  <block id="cd86eb722445699d358d0ded28ff649a" category="paragraph"><block ref="cd86eb722445699d358d0ded28ff649a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43553dc216049ebf89672dd26173e4b2" category="inline-link-macro">Siguiente: Información general y validación del rendimiento con AFF en las instalaciones.</block>
  <block id="310a0beeb0f22515730a4e70d0b545ec" category="paragraph"><block ref="310a0beeb0f22515730a4e70d0b545ec" category="inline-link-macro-rx"></block></block>
  <block id="19e775234c718c1f4e40d8023fe9dbad" category="paragraph"><block ref="19e775234c718c1f4e40d8023fe9dbad" category="inline-link-macro-rx"></block></block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">¿Qué es Apache Kafka?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">¿Qué es el tonto renombrar?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP se lee para aplicaciones de transmisión.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="6a12d786416c40632fb0604b5414460b" category="list-text">Tonto- renombrar tema con Kafka.</block>
  <block id="e31eb904be590e91ff0fbce5199e738b" category="inline-link"><block ref="e31eb904be590e91ff0fbce5199e738b" category="inline-link-rx"></block></block>
  <block id="0c1546e70acde7c8a21a85e45df7d5a1" category="paragraph"><block ref="0c1546e70acde7c8a21a85e45df7d5a1" category="inline-link-rx"></block></block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">¿Qué es NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">¿Qué es la reasignación de particiones Kafka?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">¿Qué es la prueba de rendimiento de OpenMessaging?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">¿Cómo se migra a un agente de Kafka?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">¿Cómo se supervisa a Kafka Broker con Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="01a314c1b9df8a1e936aee8eb0691f89" category="cell">Noviembre de 2022</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Cargas de trabajo de Apache Kafka con almacenamiento NFS de NetApp</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Solución de NetApp para el problema del cambio de nombre tonto en NFS a la carga de trabajo de Kafka</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Información general y validación del rendimiento con AFF en las instalaciones</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Actualizar<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> al volumen de kafka, como sigue:</block>
</blocks>